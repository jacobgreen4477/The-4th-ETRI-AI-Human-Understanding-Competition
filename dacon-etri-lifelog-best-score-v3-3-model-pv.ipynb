{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11544904,"sourceType":"datasetVersion","datasetId":7210916}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> title : 제 4회 ETRI 휴먼이해 인공지능 논문경진대회 <br>\n> author : hjy,byc <br>","metadata":{"id":"cTgURBTcpY0Q"}},{"cell_type":"markdown","source":"In our study, we used smartphones, smartwatches, sleep sensors, and self-recording apps to collect daily life logs and sleep health records of study participants in 2024.The data collection procedures and methods followed a similar approach to those used in previous studies. Here, we pu﻿blicly provide the following 12 data items, which comprise a total of 700 days' worth of lifelog data, strictly for non-commercial and academic research purposes only.\n- mACStatus: Indicates whether the smartphone is currently being charged.\n- mActivity: Value calculated by the Google Activity Recognition API.\n- mAmbience: Ambient sound identification labels and their respective probabilities.\n- mBle: Bluetooth devices around individual subject.\n- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n- mLight: Ambient light measured by the smartphone.\n- mScreenStatus: Indicates whether the smartphone screen is in use.\n- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n- mWifi: Wifi devices around individual subject.\n- wHr: Heart rate readings recorded by the smartwatch.\n- wLight: Ambient light measured by the smartwatch.\n- wPedo: Step data recorded by the smartwatch.","metadata":{"id":"2QhncbejZIfV"}},{"cell_type":"markdown","source":"For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records. Each metric consists of values categorized into either two levels (0, 1) or three levels (0, 1, 2), depending on the specific metric. The detailed classification criteria for each metric's levels will be provided in a separate document.These\nmetrics assign a value of 0 for sleep records that do not meet the recommended guidelines.For instance, the first questionnaire metric (Q1) is assigned a value of 1 on days when an\nindividual’s self-reported sleep quality exceeds their average over the experimental period, and 0 when it\nfalls below that average. Similarly, the second and third metrics (Q2 and Q3) are assigned a value of 0\non days when the participant’s fatigue and stress levels, respectively, exceed their average, and a value of\n1 when these levels are below average.\n\n- Q1: Overall sleep quality as perceived by a subject immediately after waking up.\n- Q2: Physical fatigue of a subject just before sleep.\n- Q3: Stress level experienced by a subject just before sleep.\n- S1: Adherence to sleep guidelines for total sleep time (TST).\n- S2: Adherence to sleep guidelines for sleep efficiency (SE).\n- S3: Adherence to sleep guidelines for sleep onset latency (SOL, or SL).\n\n수면 건강, 피로, 스트레스 예측을 위한 학습 모델을 훈련시키기 위해, 수면 센서 데이터와 자기 보고식 설문 기록을 기반으로 다음의 6가지 지표를 도출했습니다.\n각 지표는 해당 항목에 따라 두 수준(0, 1) 또는 세 수준(0, 1, 2)으로 구분된 값을 가집니다.\n각 지표의 세부 분류 기준은 별도의 문서에서 제공될 예정입니다.\n\n- Q1: 기상 직후 본인이 인지한 전반적인 수면의 질\n - 0: 개인 평균 이하\n - 1: 개인 평균 이상\n- Q2: 취침 직전 본인이 느낀 신체적 피로 수준\n - 0: 높은 피로 수준\n - 1: 낮은 피로 수준\n- Q3: 취침 직전 본인이 느낀 스트레스 수준\n - 0: 높은 스트레스 수준\n - 1: 낮은 스트레스 수준\n- S1: 총 수면 시간(TST) 가이드라인을 준수했는지 3LEVELS\n - 0: 가이드라인 미준수\n - 1: 가이드라인 부분적 준수\n - 2: 가이드라인 완전 준수\n- S2: 수면 효율(SE) 가이드라인을 준수했는지 여부\n- (SE: 잠자리에 누워 있었던 전체 시간 대비, 실제로 잠든 시간의 비율)\n - 0: 가이드라인 미준수\n - 1: 가이드라인 준수\n- S3: 수면 잠들기 지연 시간(SOL 또는 SL) 가이드라인을 준수했는지 여부\n- (SOL: 잠자리에 누운 순간부터 실제로 잠드는 데까지 걸린 시간)\n - 0: 가이드라인 미준수\n - 1: 가이드라인 준수","metadata":{"id":"QkY5S7k0ZLFG"}},{"cell_type":"markdown","source":"### 📦 라이브러리","metadata":{"id":"sDVNXLQtLU6X"}},{"cell_type":"code","source":"! pip install haversine\n! pip install optuna\n! pip install category_encoders\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport warnings\nfrom tqdm.auto import tqdm\nfrom collections import Counter\nfrom scipy.stats import entropy\nfrom haversine import haversine  # 설치 필요: pip install haversine\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"MN6iwVhQpR_a","outputId":"0f4a5220-adf6-4d9d-de5c-3f4cce30ace6","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:29:56.777950Z","iopub.execute_input":"2025-05-20T10:29:56.778632Z","iopub.status.idle":"2025-05-20T10:30:13.536734Z","shell.execute_reply.started":"2025-05-20T10:29:56.778593Z","shell.execute_reply":"2025-05-20T10:30:13.535485Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: haversine in /usr/local/lib/python3.11/dist-packages (2.9.0)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.7.0)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\nRequirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.3)\nRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\nRequirement already satisfied: scikit-learn<1.6.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.2.2)\nRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.2)\nRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->category_encoders) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->category_encoders) (3.6.0)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->category_encoders) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->category_encoders) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->category_encoders) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->category_encoders) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->category_encoders) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport ast\nfrom tqdm import tqdm  # ← 추가\nfrom math import radians, cos, sin, asin, sqrt\nfrom datetime import time\nfrom datetime import timedelta\nfrom functools import reduce\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport glob\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\nimport lightgbm as lgb\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom category_encoders import TargetEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightgbm import LGBMClassifier, log_evaluation, early_stopping\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# seed 고정\nSD = 42\nrandom.seed(SD)\nnp.random.seed(SD)\nos.environ['PYTHONHASHSEED'] = str(SD)","metadata":{"id":"cFvEVmxWsRH4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:13.538430Z","iopub.execute_input":"2025-05-20T10:30:13.538936Z","iopub.status.idle":"2025-05-20T10:30:26.331957Z","shell.execute_reply.started":"2025-05-20T10:30:13.538899Z","shell.execute_reply":"2025-05-20T10:30:26.330827Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# pandas 옵션\npd.set_option('display.max_columns', 999)\npd.set_option('display.max_rows', 999)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%0.4f' % x)","metadata":{"id":"gIbC9LQkv6T4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.332853Z","iopub.execute_input":"2025-05-20T10:30:26.333485Z","iopub.status.idle":"2025-05-20T10:30:26.339138Z","shell.execute_reply.started":"2025-05-20T10:30:26.333458Z","shell.execute_reply":"2025-05-20T10:30:26.337769Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(1)","metadata":{"id":"38uzdH-UYh_3","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.341555Z","iopub.execute_input":"2025-05-20T10:30:26.341877Z","iopub.status.idle":"2025-05-20T10:30:26.369956Z","shell.execute_reply.started":"2025-05-20T10:30:26.341844Z","shell.execute_reply":"2025-05-20T10:30:26.368726Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom io import StringIO\n\nstring = \"\"\"\nsubject_id\tsleep_date\nid01\t2024-07-24\nid01\t2024-07-27\nid01\t2024-08-18\nid01\t2024-08-19\nid01\t2024-08-20\nid01\t2024-08-21\nid01\t2024-08-22\nid01\t2024-08-24\nid01\t2024-08-25\nid01\t2024-08-26\nid01\t2024-08-27\nid01\t2024-08-28\nid01\t2024-08-29\nid01\t2024-08-30\nid02\t2024-08-23\nid02\t2024-08-24\nid02\t2024-09-16\nid02\t2024-09-17\nid02\t2024-09-19\nid02\t2024-09-20\nid02\t2024-09-21\nid02\t2024-09-22\nid02\t2024-09-23\nid02\t2024-09-24\nid02\t2024-09-25\nid02\t2024-09-26\nid02\t2024-09-27\nid02\t2024-09-28\nid03\t2024-08-30\nid03\t2024-09-01\nid03\t2024-09-02\nid03\t2024-09-03\nid03\t2024-09-05\nid03\t2024-09-06\nid03\t2024-09-07\nid04\t2024-09-03\nid04\t2024-09-04\nid04\t2024-09-05\nid04\t2024-09-06\nid04\t2024-09-07\nid04\t2024-09-08\nid04\t2024-09-09\nid04\t2024-10-08\nid04\t2024-10-09\nid04\t2024-10-10\nid04\t2024-10-11\nid04\t2024-10-12\nid04\t2024-10-13\nid04\t2024-10-14\nid05\t2024-10-19\nid05\t2024-10-23\nid05\t2024-10-24\nid05\t2024-10-25\nid05\t2024-10-26\nid05\t2024-10-27\nid05\t2024-10-28\nid06\t2024-07-25\nid06\t2024-07-26\nid06\t2024-07-27\nid06\t2024-07-28\nid06\t2024-07-29\nid06\t2024-07-30\nid06\t2024-07-31\nid07\t2024-07-07\nid07\t2024-07-08\nid07\t2024-07-09\nid07\t2024-07-10\nid07\t2024-07-11\nid07\t2024-07-12\nid07\t2024-07-13\nid07\t2024-07-30\nid07\t2024-08-01\nid07\t2024-08-02\nid07\t2024-08-03\nid07\t2024-08-04\nid07\t2024-08-05\nid07\t2024-08-06\nid08\t2024-08-28\nid08\t2024-08-29\nid08\t2024-08-30\nid08\t2024-08-31\nid08\t2024-09-01\nid08\t2024-09-02\nid08\t2024-09-04\nid09\t2024-08-02\nid09\t2024-08-22\nid09\t2024-08-23\nid09\t2024-08-24\nid09\t2024-08-25\nid09\t2024-08-27\nid09\t2024-08-28\nid09\t2024-08-29\nid09\t2024-08-30\nid09\t2024-08-31\nid09\t2024-09-01\nid09\t2024-09-02\nid09\t2024-09-03\nid09\t2024-09-04\nid10\t2024-08-28\nid10\t2024-08-30\nid10\t2024-08-31\nid10\t2024-09-01\nid10\t2024-09-02\nid10\t2024-09-03\nid10\t2024-09-06\n\"\"\"\n\n# DataFrame 생성\nvalid_ids = pd.read_csv(StringIO(string), sep='\\t')\nvalid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']","metadata":{"id":"S_ZQfubWYiCk","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.371424Z","iopub.execute_input":"2025-05-20T10:30:26.371781Z","iopub.status.idle":"2025-05-20T10:30:26.407149Z","shell.execute_reply.started":"2025-05-20T10:30:26.371748Z","shell.execute_reply":"2025-05-20T10:30:26.405919Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"id":"8ikO0GN_KxyQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"WEHsA6naKx0G","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 📦 데이터 읽기","metadata":{"id":"BodxdJFiv_DJ"}},{"cell_type":"code","source":"path = '/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_data_items/'\n\n# 1\nmACStatus = pd.read_parquet(path+'ch2025_mACStatus.parquet')\nmActivity = pd.read_parquet(path+'ch2025_mActivity.parquet')\nmAmbience = pd.read_parquet(path+'ch2025_mAmbience.parquet')\nmBle = pd.read_parquet(path+'ch2025_mBle.parquet')\nmGps = pd.read_parquet(path+'ch2025_mGps.parquet')\nmLight = pd.read_parquet(path+'ch2025_mLight.parquet')\nmScreenStatus = pd.read_parquet(path+'ch2025_mScreenStatus.parquet')\nmUsageStats = pd.read_parquet(path+'ch2025_mUsageStats.parquet')\nmWifi = pd.read_parquet(path+'ch2025_mWifi.parquet')\nwHr = pd.read_parquet(path+'ch2025_wHr.parquet')\nwLight = pd.read_parquet(path+'ch2025_wLight.parquet')\nwPedo = pd.read_parquet(path+'ch2025_wPedo.parquet')\n\n# 2\ntrain = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\ntest = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_submission_sample.csv')","metadata":{"id":"jw0cx3wwpSE2","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.408259Z","iopub.execute_input":"2025-05-20T10:30:26.408633Z","iopub.status.idle":"2025-05-20T10:30:46.316665Z","shell.execute_reply.started":"2025-05-20T10:30:26.408597Z","shell.execute_reply":"2025-05-20T10:30:46.315692Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"id":"Tk45v0V5xiay","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"prr7ohi9xigF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"C4xrmW1wxik-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ykbdRSk-fv-V","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mACStatus 핸드폰 충전상태\n- Indicates whether the smartphone is currently being charged.\n- m_charging : 0/1 상태\n- 핸드폰이 오랫 동안 충전했다는 의미?\n - 한 자리에 장시간 머물러 있었다.\n - 핸드폰을 장시간 사용하지 않았다.  ","metadata":{"id":"3W53JPEe7Oq9"}},{"cell_type":"code","source":"mACStatus['lifelog_date'] = mACStatus['timestamp'].astype(str).str[:10]\nmACStatus.head(1)","metadata":{"id":"KbbCp8nmfwCH","outputId":"8a42beb4-9054-4f70-e5ed-b7f47eb7c1a0","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:46.317669Z","iopub.execute_input":"2025-05-20T10:30:46.317988Z","iopub.status.idle":"2025-05-20T10:30:47.958495Z","shell.execute_reply.started":"2025-05-20T10:30:46.317956Z","shell.execute_reply":"2025-05-20T10:30:47.957275Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_charging lifelog_date\n0       id01 2024-06-26 12:03:00           0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_charging</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def process_mACStatus(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df = df.sort_values(['subject_id', 'timestamp'])\n\n    results = []\n\n    for (subj, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        status = group['m_charging'].values  # 0/1 상태\n        times = group['timestamp'].values\n\n        ratio_charging = status.mean()\n        sum_charging = status.sum()\n\n        # 상태 전이 횟수\n        transitions = (status[1:] != status[:-1]).sum()\n\n        # 연속된 1 상태 길이들\n        lengths = []\n        current_len = 0\n        for val in status:\n            if val == 1:\n                current_len += 1\n            elif current_len > 0:\n                lengths.append(current_len)\n                current_len = 0\n        if current_len > 0:\n            lengths.append(current_len)\n\n        avg_charging_duration = np.mean(lengths) if lengths else 0\n        max_charging_duration = np.max(lengths) if lengths else 0\n\n        results.append({\n            'subject_id': subj,\n            'lifelog_date': lifelog_date,\n            'charging_ratio': ratio_charging,\n            'charging_sum': sum_charging,\n            'charging_transitions': transitions,\n            'avg_charging_duration': avg_charging_duration,\n            'max_charging_duration': max_charging_duration,\n        })\n\n    return pd.DataFrame(results)\n\nmACStatus2 = process_mACStatus(mACStatus)\n\n# check\nprint(f'# mACStatus2 shape: {mACStatus2.shape}')\nmACStatus2.head(1)","metadata":{"id":"PxT8eg447Ztu","outputId":"0c20b19b-c525-4220-82ec-5937ac440a4c","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:47.959382Z","iopub.execute_input":"2025-05-20T10:30:47.959649Z","iopub.status.idle":"2025-05-20T10:30:48.679114Z","shell.execute_reply.started":"2025-05-20T10:30:47.959627Z","shell.execute_reply":"2025-05-20T10:30:48.678228Z"}},"outputs":[{"name":"stdout","text":"# mACStatus2 shape: (700, 7)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  charging_ratio  charging_sum  charging_transitions  \\\n0       id01   2024-06-26          0.2159           147                    22   \n\n   avg_charging_duration  max_charging_duration  \n0                13.3636                     41  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>charging_ratio</th>\n      <th>charging_sum</th>\n      <th>charging_transitions</th>\n      <th>avg_charging_duration</th>\n      <th>max_charging_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>0.2159</td>\n      <td>147</td>\n      <td>22</td>\n      <td>13.3636</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"id":"dIe2M-fE7Zwm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"LlMDuFeK7ZzZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"8uvGhvN07Z4l","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"D09tdsYf7Z7R","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mActivity 추정행동\n- Value calculated by the Google Activity Recognition API.\n - 0 : IN_VEHICLE\n - 1 : ON_BICYCLE\n - 2 : ON_FOOT\n - 3 : STILL (not moving)\n - 4 : UNKNOWN\n - 5 : TILTING (This often occurs when a device is picked up from a desk or a user who is sitting stands up.)\n - 7 : WALKING\n - 8 : RUNNING\n- 근무시간   : 오전 7시부터 오후 6시까지\n- 근무외시간 : 오후6시부터 12시까지","metadata":{"id":"dHrp0dO_--pm"}},{"cell_type":"code","source":"mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]\nmActivity.head()","metadata":{"id":"8Qy8JcbJfwEA","outputId":"85352916-ac64-4697-9d79-e6f351f6800d","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:48.680204Z","iopub.execute_input":"2025-05-20T10:30:48.680682Z","iopub.status.idle":"2025-05-20T10:30:50.300945Z","shell.execute_reply.started":"2025-05-20T10:30:48.680655Z","shell.execute_reply":"2025-05-20T10:30:50.299946Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_activity lifelog_date\n0       id01 2024-06-26 12:03:00           4   2024-06-26\n1       id01 2024-06-26 12:04:00           0   2024-06-26\n2       id01 2024-06-26 12:05:00           0   2024-06-26\n3       id01 2024-06-26 12:06:00           0   2024-06-26\n4       id01 2024-06-26 12:07:00           0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_activity</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>4</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>2024-06-26 12:04:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id01</td>\n      <td>2024-06-26 12:05:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id01</td>\n      <td>2024-06-26 12:06:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id01</td>\n      <td>2024-06-26 12:07:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def process_mActivity(df):\n    \"\"\"\n    # 포함\n    - 0 : IN_VEHICLE\n    - 1 : ON_BICYCLE\n    - 2 : ON_FOOT\n    - 5 : TILTING (This often occurs when a device is picked up from a desk or a user who is sitting stands up.)\n    - 7 : WALKING\n    - 8 : RUNNING\n\n    # 제외\n    - 3 : STILL (not moving)\n    - 4 : UNKNOWN\n    \"\"\"\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['hour'] = df['timestamp'].dt.hour\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        row = {'subject_id': subj, 'lifelog_date': date}\n\n        # 전체 시간에서 1,2,7,8\n        a1 = group[group['m_activity'].isin([1,2,7,8])]\n        row['all_WALKING_n_ETC_minutes'] = len(a1)\n\n        # 전체 시간에서 0 (IN_VEHICLE)\n        a2 = group[group['m_activity'].isin([0])]\n        row['all_VEHICLE_minutes'] = len(a2)\n\n        # 전체 시간에서 유효한 활동\n        all_valid = group[group['m_activity'].isin([0, 1, 2, 5, 7, 8])]\n        row['all_ACTIVITY_minutes'] = len(all_valid)\n\n        # sleeptime 0~5시 에서 유효한 활동\n        dawn_valid = all_valid[(all_valid['hour'] >= 0) & (all_valid['hour'] <5)]\n        row['dawn_ACTIVITY_minutes'] = len(dawn_valid)\n\n        results.append(row)\n\n    return pd.DataFrame(results)","metadata":{"id":"Y5AVuzGc7rLx","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:50.304048Z","iopub.execute_input":"2025-05-20T10:30:50.304383Z","iopub.status.idle":"2025-05-20T10:30:50.312311Z","shell.execute_reply.started":"2025-05-20T10:30:50.304358Z","shell.execute_reply":"2025-05-20T10:30:50.311282Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"mActivity2 = process_mActivity(mActivity)\n\n# check\nprint(f'# mActivity2 shape: {mActivity2.shape}')\nmActivity2.head(1)","metadata":{"id":"7l4K9h3etIhs","outputId":"7fcf4c65-e487-441e-aa80-98040de557c5","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:50.313481Z","iopub.execute_input":"2025-05-20T10:30:50.313945Z","iopub.status.idle":"2025-05-20T10:30:52.036272Z","shell.execute_reply.started":"2025-05-20T10:30:50.313912Z","shell.execute_reply":"2025-05-20T10:30:52.035405Z"}},"outputs":[{"name":"stdout","text":"# mActivity2 shape: (700, 6)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  all_WALKING_n_ETC_minutes  all_VEHICLE_minutes  \\\n0       id01   2024-06-26                         32                   89   \n\n   all_ACTIVITY_minutes  dawn_ACTIVITY_minutes  \n0                   121                      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>all_WALKING_n_ETC_minutes</th>\n      <th>all_VEHICLE_minutes</th>\n      <th>all_ACTIVITY_minutes</th>\n      <th>dawn_ACTIVITY_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>32</td>\n      <td>89</td>\n      <td>121</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"id":"bIowSdSDxq1M","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"n-G_pz1G7rTd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"VB6M-WRHhmQG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"wy-jlVrchmSy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mAmbience 추정주변소리\n- Ambient sound identification labels and their respective probabilities.\n- 무슨 소리가 난게 중요할까?\n- 새벽에 무슨 소리던지 소리가 난게 중요한 걸까?\n- 여러 가지 소리 중에 노이즈도 포함되어 있을까?","metadata":{"id":"bEu5F-6-hmgI"}},{"cell_type":"code","source":"def extract_labels_and_probs(row):\n    items = row['m_ambience']\n    labels = [item[0] for item in items]\n    probs = [item[1] for item in items]\n    return pd.Series({'labels': labels, 'prob': probs})\n\nmAmbience[['labels', 'prob']]  = mAmbience.apply(extract_labels_and_probs, axis=1)\nmAmbience['lifelog_date'] = mAmbience['timestamp'].astype(str).str[:10]\nmAmbience = mAmbience.drop(columns=['m_ambience'])\nmAmbience.head(1)","metadata":{"id":"snxx7CH6gtif","outputId":"164ec02b-f6d8-4b75-dd4d-892f20dafd91","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:52.037213Z","iopub.execute_input":"2025-05-20T10:30:52.037625Z","iopub.status.idle":"2025-05-20T10:32:36.075138Z","shell.execute_reply.started":"2025-05-20T10:30:52.037600Z","shell.execute_reply":"2025-05-20T10:32:36.074217Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 13:00:10   \n\n                                                                                                                                                       labels  \\\n0  [Music, Vehicle, Motor vehicle (road), Outside, urban or manmade, Outside, rural or natural, Car, Speech, Inside, large room or hall, Truck, Sound effect]   \n\n                                                                                                                            prob  \\\n0  [0.30902618, 0.081680894, 0.04035286, 0.037144363, 0.032663062, 0.03199804, 0.029806137, 0.01684492, 0.016206821, 0.01591479]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>labels</th>\n      <th>prob</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 13:00:10</td>\n      <td>[Music, Vehicle, Motor vehicle (road), Outside, urban or manmade, Outside, rural or natural, Car, Speech, Inside, large room or hall, Truck, Sound effect]</td>\n      <td>[0.30902618, 0.081680894, 0.04035286, 0.037144363, 0.032663062, 0.03199804, 0.029806137, 0.01684492, 0.016206821, 0.01591479]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def process_mAmbience(df):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['hour'] = df['timestamp'].dt.hour\n\n    # 시간대 분류\n    df['time_period'] = df['hour'].apply(lambda h: 'sleeptime' if 0 <= h < 5 else 'activehour')\n\n    # explode labels\n    exploded = df.explode('labels')\n\n    # unique label count\n    unique_labels = (\n        exploded.groupby(['subject_id', 'lifelog_date', 'time_period'])['labels']\n        .nunique()\n        .reset_index(name='unique_label_count')\n    )\n\n    # snor 포함 라벨 count\n    snor_labels = (\n        exploded[exploded['labels'].astype(str).str.contains('snor', case=False, na=False)]\n        .groupby(['subject_id', 'lifelog_date', 'time_period'])['labels']\n        .count()\n        .reset_index(name='snor_count')\n    )\n\n    # 병합\n    result = pd.merge(unique_labels, snor_labels, on=['subject_id', 'lifelog_date', 'time_period'], how='outer').fillna(0)\n    result['snor_count'] = result['snor_count'].astype(int)\n    result = result.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    result.columns = [f\"{tp}_{metric}\" for metric, tp in result.columns]\n    result = result.reset_index()\n\n    return result","metadata":{"id":"vTLHu7k24dfJ","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:36.076172Z","iopub.execute_input":"2025-05-20T10:32:36.076528Z","iopub.status.idle":"2025-05-20T10:32:36.086050Z","shell.execute_reply.started":"2025-05-20T10:32:36.076498Z","shell.execute_reply":"2025-05-20T10:32:36.085059Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"mAmbience2 = process_mAmbience(mAmbience)\n\n# check\nprint(f'# mAmbience2 shape: {mAmbience2.shape}')\nmAmbience2.head(1)","metadata":{"id":"4tNjfKEv6eZl","outputId":"34d6ec43-fbaa-41f3-b839-4e8cb708d365","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:36.087445Z","iopub.execute_input":"2025-05-20T10:32:36.087733Z","iopub.status.idle":"2025-05-20T10:32:42.900988Z","shell.execute_reply.started":"2025-05-20T10:32:36.087710Z","shell.execute_reply":"2025-05-20T10:32:42.899822Z"}},"outputs":[{"name":"stdout","text":"# mAmbience2 shape: (700, 6)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  activehour_unique_label_count  \\\n0       id01   2024-06-26                       265.0000   \n\n   sleeptime_unique_label_count  activehour_snor_count  sleeptime_snor_count  \n0                           NaN                 4.0000                   NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>activehour_unique_label_count</th>\n      <th>sleeptime_unique_label_count</th>\n      <th>activehour_snor_count</th>\n      <th>sleeptime_snor_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>265.0000</td>\n      <td>NaN</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"id":"QCxHeB836ekw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"5QnUfNL-ceIA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"TfbNZ1WsceMN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Yh2wt8LycePt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mBle 블루투스\n- Bluetooth devices around individual subject.\n - 7936 : Wearable, Headset, AV Device\n - 1796 : Peripheral (입력장치) 계열\n - 0 : 정보 없음 또는 알 수 없음(Unknown)\n - 1084 : Audio/Video (스피커, 헤드셋, 이어폰, TV 등)\n - 524 : Phone (휴대폰, 스마트폰)\n - 1060 : Headphones\n - 284 : commputer (PC, 노트북, PDA)","metadata":{"id":"tyS90xE7WAJV"}},{"cell_type":"code","source":"def extract_mble_info(row):\n    m_data = row['m_ble']\n    address = [item['address'] for item in m_data]\n    device_class = [item['device_class'] for item in m_data]\n    rssi = [item['rssi'] for item in m_data]\n    return pd.Series({'address': address, 'device_class': device_class, 'rssi': rssi})\n\nmBle[['address','device_class','rssi']] = mBle.apply(extract_mble_info, axis=1)\nmBle['lifelog_date'] = mBle['timestamp'].astype(str).str[:10]\nmBle.head(1)","metadata":{"id":"u9J8u61OV9-V","outputId":"8b4f09bf-5128-41b2-8abe-cd7c8bf0f36f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:42.902253Z","iopub.execute_input":"2025-05-20T10:32:42.902631Z","iopub.status.idle":"2025-05-20T10:32:47.058302Z","shell.execute_reply.started":"2025-05-20T10:32:42.902600Z","shell.execute_reply":"2025-05-20T10:32:47.057421Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:13:00   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 m_ble  \\\n0  [{'address': '00:15:7C:11:80:8D', 'device_class': '0', 'rssi': -82}, {'address': '01:B1:D2:20:9E:3A', 'device_class': '0', 'rssi': -61}, {'address': '04:33:1F:D9:C1:50', 'device_class': '0', 'rssi': -86}, {'address': '06:5C:2D:BC:39:BE', 'device_class': '0', 'rssi': -75}, {'address': '09:42:21:0D:AD:DF', 'device_class': '0', 'rssi': -70}, {'address': '0B:66:0D:D5:9C:4A', 'device_class': '0', 'rssi': -89}, {'address': '10:B5:88:E7:85:69', 'device_class': '0', 'rssi': -89}, {'address': '13:F0:CA:3B:DB:EF', 'device_class': '0', 'rssi': -77}, {'address': '1A:23:C0:8F:43:4D', 'device_class': '0', 'rssi': -66}, {'address': '24:11:53:BB:62:89', 'device_class': '1796', 'rssi': -37}, {'address': '24:2D:F0:EE:1E:D0', 'device_class': '0', 'rssi': -85}, {'address': '26:0C:48:28:15:77', 'device_class': '0', 'rssi': -63}, {'address': '27:C1:C0:8B:82:C9', 'device_class': '0', 'rssi': -88}, {'address': '28:9C:11:73:39:05', 'device_class': '0', 'rssi': -30}, {'address': '34:40:DE:35:F8:65', 'device_class': '0', 'rssi': -93}, {'address': '35:0A:59:BF:75:F5', 'device_class': '0', 'rssi': -72}, {'address': '41:A6:C4:20:E3:2C', 'device_class': '7936', 'rssi': -83}, {'address': '42:6B:51:95:1B:D4', 'device_class': '0', 'rssi': -77}, {'address': '44:B2:0B:78:04:0F', 'device_class': '0', 'rssi': -69}, {'address': '45:37:48:E2:7F:CC', 'device_class': '0', 'rssi': -87}, {'address': '4E:1B:C2:DF:C5:87', 'device_class': '0', 'rssi': -76}, {'address': '4E:9F:1B:A9:56:5D', 'device_class': '0', 'rssi': -66}, {'address': '50:63:B0:82:07:00', 'device_class': '0', 'rssi': -86}, {'address': '53:13:6C:4F:04:D2', 'device_class': '0', 'rssi': -69}, {'address': '54:15:89:95:27:44', 'device_class': '7936', 'rssi': -71}, {'address': '56:0E:2E:B0:D4:11', 'device_class': '0', 'rssi': -61}, {'address': '5A:7A:2E:42:03:B1', 'device_class': '0', 'rssi': -82}, {'address': '5A:9D:3E:AB:38:C6', 'device_class': '0', 'rssi': -83}, {'address': '5E:A6:8E:B8:74:74', 'device_class': '0', 'rssi': -84}, {'address': '5F:BC:08:0F:C1:6A', 'device_class': '0', 'rssi': -87}, {'address': '62:E1:9D:41:F4:AE', 'device_class': '0', 'rssi': -73}, {'address': '67:23:FE:88:69:A8', 'device_class': '0', 'rssi': -88}, {'address': '68:EC:C5:0C:D1:C1', 'device_class': '0', 'rssi': -78}, {'address': '6B:28:DA:C0:1B:29', 'device_class': '0', 'rssi': -75}, {'address': '6F:0B:91:00:33:19', 'device_class': '0', 'rssi': -80}, {'address': '70:7A:4B:82:44:90', 'device_class': '0', 'rssi': -88}, {'address': '7B:62:D4:5B:59:D3', 'device_class': '0', 'rssi': -74}, {'address': '7B:BE:A4:9D:FD:11', 'device_class': '0', 'rssi': -72}, {'address': '7F:FD:C4:00:77:7D', 'device_class': '0', 'rssi': -52}, {'address': 'C4:F0:92:C8:F1:8D', 'device_class': '7936', 'rssi': -87}, {'address': 'C7:3F:2C:7B:86:66', 'device_class': '7936', 'rssi': -89}]   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       address  \\\n0  [00:15:7C:11:80:8D, 01:B1:D2:20:9E:3A, 04:33:1F:D9:C1:50, 06:5C:2D:BC:39:BE, 09:42:21:0D:AD:DF, 0B:66:0D:D5:9C:4A, 10:B5:88:E7:85:69, 13:F0:CA:3B:DB:EF, 1A:23:C0:8F:43:4D, 24:11:53:BB:62:89, 24:2D:F0:EE:1E:D0, 26:0C:48:28:15:77, 27:C1:C0:8B:82:C9, 28:9C:11:73:39:05, 34:40:DE:35:F8:65, 35:0A:59:BF:75:F5, 41:A6:C4:20:E3:2C, 42:6B:51:95:1B:D4, 44:B2:0B:78:04:0F, 45:37:48:E2:7F:CC, 4E:1B:C2:DF:C5:87, 4E:9F:1B:A9:56:5D, 50:63:B0:82:07:00, 53:13:6C:4F:04:D2, 54:15:89:95:27:44, 56:0E:2E:B0:D4:11, 5A:7A:2E:42:03:B1, 5A:9D:3E:AB:38:C6, 5E:A6:8E:B8:74:74, 5F:BC:08:0F:C1:6A, 62:E1:9D:41:F4:AE, 67:23:FE:88:69:A8, 68:EC:C5:0C:D1:C1, 6B:28:DA:C0:1B:29, 6F:0B:91:00:33:19, 70:7A:4B:82:44:90, 7B:62:D4:5B:59:D3, 7B:BE:A4:9D:FD:11, 7F:FD:C4:00:77:7D, C4:F0:92:C8:F1:8D, C7:3F:2C:7B:86:66]   \n\n                                                                                                                                 device_class  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1796, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7936, 7936]   \n\n                                                                                                                                                                                                            rssi  \\\n0  [-82, -61, -86, -75, -70, -89, -89, -77, -66, -37, -85, -63, -88, -30, -93, -72, -83, -77, -69, -87, -76, -66, -86, -69, -71, -61, -82, -83, -84, -87, -73, -88, -78, -75, -80, -88, -74, -72, -52, -87, -89]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_ble</th>\n      <th>address</th>\n      <th>device_class</th>\n      <th>rssi</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:13:00</td>\n      <td>[{'address': '00:15:7C:11:80:8D', 'device_class': '0', 'rssi': -82}, {'address': '01:B1:D2:20:9E:3A', 'device_class': '0', 'rssi': -61}, {'address': '04:33:1F:D9:C1:50', 'device_class': '0', 'rssi': -86}, {'address': '06:5C:2D:BC:39:BE', 'device_class': '0', 'rssi': -75}, {'address': '09:42:21:0D:AD:DF', 'device_class': '0', 'rssi': -70}, {'address': '0B:66:0D:D5:9C:4A', 'device_class': '0', 'rssi': -89}, {'address': '10:B5:88:E7:85:69', 'device_class': '0', 'rssi': -89}, {'address': '13:F0:CA:3B:DB:EF', 'device_class': '0', 'rssi': -77}, {'address': '1A:23:C0:8F:43:4D', 'device_class': '0', 'rssi': -66}, {'address': '24:11:53:BB:62:89', 'device_class': '1796', 'rssi': -37}, {'address': '24:2D:F0:EE:1E:D0', 'device_class': '0', 'rssi': -85}, {'address': '26:0C:48:28:15:77', 'device_class': '0', 'rssi': -63}, {'address': '27:C1:C0:8B:82:C9', 'device_class': '0', 'rssi': -88}, {'address': '28:9C:11:73:39:05', 'device_class': '0', 'rssi': -30}, {'address': '34:40:DE:35:F8:65', 'device_class': '0', 'rssi': -93}, {'address': '35:0A:59:BF:75:F5', 'device_class': '0', 'rssi': -72}, {'address': '41:A6:C4:20:E3:2C', 'device_class': '7936', 'rssi': -83}, {'address': '42:6B:51:95:1B:D4', 'device_class': '0', 'rssi': -77}, {'address': '44:B2:0B:78:04:0F', 'device_class': '0', 'rssi': -69}, {'address': '45:37:48:E2:7F:CC', 'device_class': '0', 'rssi': -87}, {'address': '4E:1B:C2:DF:C5:87', 'device_class': '0', 'rssi': -76}, {'address': '4E:9F:1B:A9:56:5D', 'device_class': '0', 'rssi': -66}, {'address': '50:63:B0:82:07:00', 'device_class': '0', 'rssi': -86}, {'address': '53:13:6C:4F:04:D2', 'device_class': '0', 'rssi': -69}, {'address': '54:15:89:95:27:44', 'device_class': '7936', 'rssi': -71}, {'address': '56:0E:2E:B0:D4:11', 'device_class': '0', 'rssi': -61}, {'address': '5A:7A:2E:42:03:B1', 'device_class': '0', 'rssi': -82}, {'address': '5A:9D:3E:AB:38:C6', 'device_class': '0', 'rssi': -83}, {'address': '5E:A6:8E:B8:74:74', 'device_class': '0', 'rssi': -84}, {'address': '5F:BC:08:0F:C1:6A', 'device_class': '0', 'rssi': -87}, {'address': '62:E1:9D:41:F4:AE', 'device_class': '0', 'rssi': -73}, {'address': '67:23:FE:88:69:A8', 'device_class': '0', 'rssi': -88}, {'address': '68:EC:C5:0C:D1:C1', 'device_class': '0', 'rssi': -78}, {'address': '6B:28:DA:C0:1B:29', 'device_class': '0', 'rssi': -75}, {'address': '6F:0B:91:00:33:19', 'device_class': '0', 'rssi': -80}, {'address': '70:7A:4B:82:44:90', 'device_class': '0', 'rssi': -88}, {'address': '7B:62:D4:5B:59:D3', 'device_class': '0', 'rssi': -74}, {'address': '7B:BE:A4:9D:FD:11', 'device_class': '0', 'rssi': -72}, {'address': '7F:FD:C4:00:77:7D', 'device_class': '0', 'rssi': -52}, {'address': 'C4:F0:92:C8:F1:8D', 'device_class': '7936', 'rssi': -87}, {'address': 'C7:3F:2C:7B:86:66', 'device_class': '7936', 'rssi': -89}]</td>\n      <td>[00:15:7C:11:80:8D, 01:B1:D2:20:9E:3A, 04:33:1F:D9:C1:50, 06:5C:2D:BC:39:BE, 09:42:21:0D:AD:DF, 0B:66:0D:D5:9C:4A, 10:B5:88:E7:85:69, 13:F0:CA:3B:DB:EF, 1A:23:C0:8F:43:4D, 24:11:53:BB:62:89, 24:2D:F0:EE:1E:D0, 26:0C:48:28:15:77, 27:C1:C0:8B:82:C9, 28:9C:11:73:39:05, 34:40:DE:35:F8:65, 35:0A:59:BF:75:F5, 41:A6:C4:20:E3:2C, 42:6B:51:95:1B:D4, 44:B2:0B:78:04:0F, 45:37:48:E2:7F:CC, 4E:1B:C2:DF:C5:87, 4E:9F:1B:A9:56:5D, 50:63:B0:82:07:00, 53:13:6C:4F:04:D2, 54:15:89:95:27:44, 56:0E:2E:B0:D4:11, 5A:7A:2E:42:03:B1, 5A:9D:3E:AB:38:C6, 5E:A6:8E:B8:74:74, 5F:BC:08:0F:C1:6A, 62:E1:9D:41:F4:AE, 67:23:FE:88:69:A8, 68:EC:C5:0C:D1:C1, 6B:28:DA:C0:1B:29, 6F:0B:91:00:33:19, 70:7A:4B:82:44:90, 7B:62:D4:5B:59:D3, 7B:BE:A4:9D:FD:11, 7F:FD:C4:00:77:7D, C4:F0:92:C8:F1:8D, C7:3F:2C:7B:86:66]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1796, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7936, 7936]</td>\n      <td>[-82, -61, -86, -75, -70, -89, -89, -77, -66, -37, -85, -63, -88, -30, -93, -72, -83, -77, -69, -87, -76, -66, -86, -69, -71, -61, -82, -83, -84, -87, -73, -88, -78, -75, -80, -88, -74, -72, -52, -87, -89]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def process_mBle(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['hour'] = df['timestamp'].dt.hour\n\n    # 시간대 분류\n    def map_time_period(row):\n        if 0 <= row['hour'] < 7:\n            return 'sleeptime'\n        elif 7 <= row['hour'] < 18:\n            return 'worktime'\n        else:\n            return 'afterwork'\n\n    df['time_period'] = df.apply(map_time_period, axis=1)\n\n    features = []\n\n    for idx, row in df.iterrows():\n        entry = ast.literal_eval(row['m_ble']) if isinstance(row['m_ble'], str) else row['m_ble']\n\n        rssi_list = []\n        class_0_cnt = 0\n        class_other_cnt = 0\n\n        for device in entry:\n            try:\n                rssi = int(device['rssi'])\n                rssi_list.append(rssi)\n\n                device_class = str(device['device_class'])\n                if device_class == '0':\n                    class_0_cnt += 1\n                else:\n                    class_other_cnt += 1\n            except:\n                continue  # malformed record\n\n        feature = {\n            'subject_id': row['subject_id'],\n            'lifelog_date': row['lifelog_date'],\n            'time_period': row['time_period'],\n            'ble_class_unknwn_cnt': class_0_cnt,\n            'ble_class_others_cnt': class_other_cnt,\n            'ble_count': len(rssi_list),\n            'ble_rssi_mean': np.mean(rssi_list) if rssi_list else np.nan,\n            'ble_rssi_min': np.min(rssi_list) if rssi_list else np.nan,\n            'ble_rssi_max': np.max(rssi_list) if rssi_list else np.nan,\n        }\n        features.append(feature)\n\n    return pd.DataFrame(features)\n\ndef summarize_mBle_daily(df):\n\n    # row 단위 BLE feature 추출\n    df = process_mBle(df)\n\n    # 하루 + 시간대별로 groupby\n    grouped = df.groupby(['subject_id', 'lifelog_date', 'time_period']).agg({\n        'ble_class_unknwn_cnt': 'sum',\n        'ble_class_others_cnt': 'sum',\n        'ble_rssi_mean': 'mean',\n        'ble_rssi_min': 'min',\n        'ble_rssi_max': 'max',\n    }).reset_index()\n\n    # 총합 구해서 비율 계산\n    total_cnt = grouped['ble_class_unknwn_cnt'] + grouped['ble_class_others_cnt']\n    grouped['ble_class_unknwn_ratio'] = grouped['ble_class_unknwn_cnt'] / total_cnt.replace(0, np.nan)\n    grouped['ble_class_others_ratio'] = grouped['ble_class_others_cnt'] / total_cnt.replace(0, np.nan)\n\n    # 필요 없는 cnt 컬럼 제거\n    grouped.drop(columns=[\n        'ble_class_unknwn_cnt',\n        'ble_class_others_cnt'\n    ], inplace=True)\n\n    # pivot해서 time_period별로 펼치기\n    final = grouped.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    final.columns = ['_'.join(col).strip() for col in final.columns.values]\n    final = final.reset_index()\n\n    return final","metadata":{"id":"j8IaISJNceZq","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:47.059387Z","iopub.execute_input":"2025-05-20T10:32:47.059645Z","iopub.status.idle":"2025-05-20T10:32:47.072720Z","shell.execute_reply.started":"2025-05-20T10:32:47.059625Z","shell.execute_reply":"2025-05-20T10:32:47.071752Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"mBle2 = summarize_mBle_daily(mBle)\n\n# check\nprint(f'\\n # mBle2 shape: {mBle2.shape}')\nmBle2.head(1)","metadata":{"id":"SACo8zOKcedD","outputId":"68d72eb9-d2d8-4268-b8cd-78e362cc620e","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:47.073848Z","iopub.execute_input":"2025-05-20T10:32:47.074105Z","iopub.status.idle":"2025-05-20T10:32:49.814717Z","shell.execute_reply.started":"2025-05-20T10:32:47.074083Z","shell.execute_reply":"2025-05-20T10:32:49.813230Z"}},"outputs":[{"name":"stdout","text":"\n # mBle2 shape: (651, 17)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  ble_rssi_mean_afterwork  ble_rssi_mean_sleeptime  \\\n0       id01   2024-06-26                 -76.2155                      NaN   \n\n   ble_rssi_mean_worktime  ble_rssi_min_afterwork  ble_rssi_min_sleeptime  \\\n0                -75.0522                -92.0000                     NaN   \n\n   ble_rssi_min_worktime  ble_rssi_max_afterwork  ble_rssi_max_sleeptime  \\\n0               -94.0000                -43.0000                     NaN   \n\n   ble_rssi_max_worktime  ble_class_unknwn_ratio_afterwork  \\\n0               -27.0000                            0.9237   \n\n   ble_class_unknwn_ratio_sleeptime  ble_class_unknwn_ratio_worktime  \\\n0                               NaN                           0.9421   \n\n   ble_class_others_ratio_afterwork  ble_class_others_ratio_sleeptime  \\\n0                            0.0763                               NaN   \n\n   ble_class_others_ratio_worktime  \n0                           0.0579  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>ble_rssi_mean_afterwork</th>\n      <th>ble_rssi_mean_sleeptime</th>\n      <th>ble_rssi_mean_worktime</th>\n      <th>ble_rssi_min_afterwork</th>\n      <th>ble_rssi_min_sleeptime</th>\n      <th>ble_rssi_min_worktime</th>\n      <th>ble_rssi_max_afterwork</th>\n      <th>ble_rssi_max_sleeptime</th>\n      <th>ble_rssi_max_worktime</th>\n      <th>ble_class_unknwn_ratio_afterwork</th>\n      <th>ble_class_unknwn_ratio_sleeptime</th>\n      <th>ble_class_unknwn_ratio_worktime</th>\n      <th>ble_class_others_ratio_afterwork</th>\n      <th>ble_class_others_ratio_sleeptime</th>\n      <th>ble_class_others_ratio_worktime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>-76.2155</td>\n      <td>NaN</td>\n      <td>-75.0522</td>\n      <td>-92.0000</td>\n      <td>NaN</td>\n      <td>-94.0000</td>\n      <td>-43.0000</td>\n      <td>NaN</td>\n      <td>-27.0000</td>\n      <td>0.9237</td>\n      <td>NaN</td>\n      <td>0.9421</td>\n      <td>0.0763</td>\n      <td>NaN</td>\n      <td>0.0579</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"id":"ZzTh37secegK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"If8EEAGfcejV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tiCtsengLveO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"p5vsYKHoH8lz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mGps, GPS 기반 핸드폰 위치\n- Multiple GPS coordinates measured within a single minute using the smartphone.\n- speed가 1보다 큰경우 정지 상태가 아니고 움직이고 있다고 판단\n - 0.5-2 : 걸어서 이동하는 경우  \n - 2-5 : 조깅\n - 5 이상 : 차를 타고 이동하는 경우\n\n- speed가 0.5-2사이를 하루에 몇분동안 지속했는지?\n- speed가 2-5사이를 하루에 몇분동안 지속했는지? (유산소 운동 시간)\n- speed가 5이상을 하루에 몇분동안 지속했는지?  ","metadata":{"id":"MOiajFjeRFi-"}},{"cell_type":"code","source":"def extract_gps_info(row):\n    m_data = row['m_gps']\n    altitude = [item['altitude'] for item in m_data]\n    latitude = [item['latitude'] for item in m_data]\n    longitude = [item['longitude'] for item in m_data]\n    speed = [item['speed'] for item in m_data]\n    return pd.Series({'altitude': altitude, 'latitude': latitude, 'longitude': longitude, 'speed': speed})\n\nmGps[['altitude','latitude','longitude','speed']] = mGps.apply(extract_gps_info, axis=1)\nmGps['lifelog_date'] = mGps['timestamp'].astype(str).str[:10]\nmGps = mGps.drop(columns=['m_gps'])\nmGps.head(1)","metadata":{"id":"hV_VT5fZH8rj","outputId":"32415846-4d39-435e-9e76-dc0460cdb4d4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:49.816083Z","iopub.execute_input":"2025-05-20T10:32:49.816362Z","iopub.status.idle":"2025-05-20T10:35:55.101821Z","shell.execute_reply.started":"2025-05-20T10:32:49.816319Z","shell.execute_reply":"2025-05-20T10:35:55.100647Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:03:00   \n\n                                                                        altitude  \\\n0  [110.6, 110.8, 110.8, 110.7, 110.7, 110.8, 110.8, 110.8, 110.8, 110.8, 110.8]   \n\n                                                                                                                latitude  \\\n0  [0.2077385, 0.2077759, 0.2077728, 0.20779, 0.2077914, 0.2077972, 0.2078002, 0.2077985, 0.207801, 0.207802, 0.2078011]   \n\n                                                                                                                 longitude  \\\n0  [0.170027, 0.1699851, 0.1699834, 0.1699686, 0.1699708, 0.1699657, 0.1699627, 0.1699631, 0.1699642, 0.1699639, 0.169963]   \n\n                                                                                  speed  \\\n0  [0.0, 0.721, 0.0505, 0.6587, 0.0568, 0.1768, 0.0907, 0.0337, 0.0411, 0.0296, 0.0194]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>altitude</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>speed</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>[110.6, 110.8, 110.8, 110.7, 110.7, 110.8, 110.8, 110.8, 110.8, 110.8, 110.8]</td>\n      <td>[0.2077385, 0.2077759, 0.2077728, 0.20779, 0.2077914, 0.2077972, 0.2078002, 0.2077985, 0.207801, 0.207802, 0.2078011]</td>\n      <td>[0.170027, 0.1699851, 0.1699834, 0.1699686, 0.1699708, 0.1699657, 0.1699627, 0.1699631, 0.1699642, 0.1699639, 0.169963]</td>\n      <td>[0.0, 0.721, 0.0505, 0.6587, 0.0568, 0.1768, 0.0907, 0.0337, 0.0411, 0.0296, 0.0194]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# 거리 계산 함수\ndef haversine(coord1, coord2, unit='m'):\n    lat1, lon1 = coord1\n    lat2, lon2 = coord2\n    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    r = 6371000  # 지구 반지름(m)\n    return c * r if unit == 'm' else c * r / 1000\n\ndef process_mGps(df):\n    df = df.copy()\n\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['week'] = df['timestamp'].dt.isocalendar().week\n\n    expanded_rows = []\n\n    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing GPS data\"):\n        speeds = ast.literal_eval(row['speed']) if isinstance(row['speed'], str) else row['speed']\n        lats = ast.literal_eval(row['latitude']) if isinstance(row['latitude'], str) else row['latitude']\n        lons = ast.literal_eval(row['longitude']) if isinstance(row['longitude'], str) else row['longitude']\n        alts = ast.literal_eval(row['altitude']) if isinstance(row['altitude'], str) else row['altitude']\n        n = len(speeds)\n        if n > 0:\n            expanded_rows.append(pd.DataFrame({\n                'subject_id': [row['subject_id']] * n,\n                'lifelog_date': [row['lifelog_date']] * n,\n                'timestamp': pd.date_range(start=row['timestamp'], periods=n, freq='1S'),\n                'speed': speeds,\n                'latitude': lats,\n                'longitude': lons,\n                'altitude': alts\n            }))\n\n    expanded_df = pd.concat(expanded_rows, ignore_index=True)\n\n    # 벡터화\n    speeds = expanded_df['speed'].values\n\n    walk_mask = (0.5 <= speeds) & (speeds < 2)\n    jog_mask = (2 <= speeds) & (speeds < 5)\n    vehicle_mask = (speeds >= 5)\n    le5_mask = (speeds <= 5)\n\n    expanded_df['walk'] = walk_mask.astype(int)\n    expanded_df['jog'] = jog_mask.astype(int)\n    expanded_df['vehicle'] = vehicle_mask.astype(int)\n    expanded_df['le5_speed'] = expanded_df['speed'].where(le5_mask)\n\n    # 아침/저녁 구간 조건\n    expanded_df['hour'] = expanded_df['timestamp'].dt.hour\n    morning_condition = (expanded_df['hour'] >= 6) & (expanded_df['hour'] < 9) & (expanded_df['speed'] >= 1)\n    evening_condition = (expanded_df['hour'] >= 21) & (expanded_df['hour'] <= 23) & (expanded_df['speed'] <= 1)\n\n    # 이동 특성 계산\n    movement_features = []\n    for (subject_id, lifelog_date), group in expanded_df.groupby(['subject_id', 'lifelog_date']):\n        all_speeds = group['speed'].values\n        all_alts = group['altitude'].values\n        all_lats = group['latitude'].values\n        all_lons = group['longitude'].values\n\n        active_mins = group.shape[0] / 60  # 1초 단위 → 분\n        movement_ratio = (all_speeds > 1.0).mean() if len(all_speeds) > 0 else 0\n        alt_change = all_alts[-1] - all_alts[0] if len(all_alts) > 0 else 0\n        lat_change = all_lats[-1] - all_lats[0] if len(all_lats) > 0 else 0\n        lon_change = all_lons[-1] - all_lons[0] if len(all_lons) > 0 else 0\n\n        total_dist = 0.0\n        if len(all_lats) > 1:\n            for i in range(len(all_lats)-1):\n                coord1 = (all_lats[i], all_lons[i])\n                coord2 = (all_lats[i+1], all_lons[i+1])\n                total_dist += haversine(coord1, coord2, unit='m')\n\n        movement_features.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date,\n            'active_minutes': active_mins,\n            'movement_ratio': movement_ratio,\n            'alt_change': alt_change,\n            'lat_change': lat_change,\n            'lon_change': lon_change,\n            'total_distance_m': total_dist\n        })\n\n    movement_df = pd.DataFrame(movement_features)\n\n    # Groupby + Aggregation\n    agg_funcs = {\n        'walk_minutes': ('walk', lambda x: x.sum() / 60),\n        'jog_minutes': ('jog', lambda x: x.sum() / 60),\n        'vehicle_minutes': ('vehicle', lambda x: x.sum() / 60),\n        'speed_le5_max': ('le5_speed', 'max'),\n        'speed_le5_mean': ('le5_speed', 'mean'),\n        'speed_le5_std': ('le5_speed', 'std')\n    }\n\n    grouped = expanded_df.groupby(['subject_id', 'lifelog_date']).agg(**agg_funcs).reset_index()\n    grouped['exercise_flag'] = np.where(grouped['jog_minutes'] >= 5,1,0)\n\n    # 아침 wakeup time\n    morning_first_movement = (\n        expanded_df[morning_condition]\n        .groupby(['subject_id', 'lifelog_date'])['timestamp']\n        .min()\n        .reset_index()\n        .rename(columns={'timestamp': 'morning_wakeup_time'})\n    )\n\n\n    # 최종 merge\n    final = pd.merge(grouped, movement_df, on=['subject_id', 'lifelog_date'], how='left')\n    final = pd.merge(final, morning_first_movement, on=['subject_id', 'lifelog_date'], how='left')\n\n    # 아침 wakeup_time 처리\n    valid_wakeup = final['morning_wakeup_time'].dropna()\n    if not valid_wakeup.empty:\n        total_seconds = valid_wakeup.dt.hour * 3600 + valid_wakeup.dt.minute * 60 + valid_wakeup.dt.second\n        mean_seconds = total_seconds.mean()\n        mean_hour = int(mean_seconds // 3600)\n        mean_minute = int((mean_seconds % 3600) // 60)\n        mean_second = int(mean_seconds % 60)\n        mean_wakeup_time = time(mean_hour, mean_minute, mean_second)\n    else:\n        mean_wakeup_time = time(7, 0, 0)\n\n    final['morning_wakeup_time'] = final['morning_wakeup_time'].fillna(\n        pd.Timestamp.combine(pd.to_datetime('today').date(), mean_wakeup_time)\n    )\n    final['morning_wakeup_time'] = final['morning_wakeup_time'].dt.hour * 100 + final['morning_wakeup_time'].dt.minute\n\n    mean_wakeup_hhmm = mean_wakeup_time.hour * 100 + mean_wakeup_time.minute\n\n    # wake_up_early_minutes\n    def compute_minutes_diff(actual_hhmm, mean_hhmm):\n        actual_hour = actual_hhmm // 100\n        actual_minute = actual_hhmm % 100\n        mean_hour = mean_hhmm // 100\n        mean_minute = mean_hhmm % 100\n        actual_sec = actual_hour * 3600 + actual_minute * 60\n        mean_sec = mean_hour * 3600 + mean_minute * 60\n        return (mean_sec - actual_sec) / 60\n\n    final['wake_up_early_minutes'] = final['morning_wakeup_time'].apply(lambda x: compute_minutes_diff(x, mean_wakeup_hhmm))\n\n    return final","metadata":{"id":"6OwJ7xTDHt3n","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:35:55.102992Z","iopub.execute_input":"2025-05-20T10:35:55.103339Z","iopub.status.idle":"2025-05-20T10:35:55.139791Z","shell.execute_reply.started":"2025-05-20T10:35:55.103290Z","shell.execute_reply":"2025-05-20T10:35:55.138771Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"%%time\n\nmGps2 = process_mGps(mGps)\n\n# check\nprint(f'\\n # mGps2 shape: {mGps2.shape}')\nmGps2.head(1)","metadata":{"id":"vGgV2PjuwpjQ","outputId":"8996b5b2-141c-48d2-89d1-6d536924e23f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:35:55.140860Z","iopub.execute_input":"2025-05-20T10:35:55.141157Z","iopub.status.idle":"2025-05-20T10:49:20.358986Z","shell.execute_reply.started":"2025-05-20T10:35:55.141135Z","shell.execute_reply":"2025-05-20T10:49:20.357402Z"}},"outputs":[{"name":"stderr","text":"Processing GPS data: 100%|██████████| 800611/800611 [12:01<00:00, 1110.40it/s] \n","output_type":"stream"},{"name":"stdout","text":"\n # mGps2 shape: (660, 17)\nCPU times: user 13min 14s, sys: 37.4 s, total: 13min 51s\nWall time: 13min 25s\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  walk_minutes  jog_minutes  vehicle_minutes  \\\n0       id01   2024-06-26       11.1667       1.3000           3.8667   \n\n   speed_le5_max  speed_le5_mean  speed_le5_std  exercise_flag  \\\n0         4.9907          0.2503         0.5089              0   \n\n   active_minutes  movement_ratio  alt_change  lat_change  lon_change  \\\n0        100.2833          0.1034     -6.7000      0.0229     -0.0757   \n\n   total_distance_m  morning_wakeup_time  wake_up_early_minutes  \n0        29113.5760                  655                 0.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>walk_minutes</th>\n      <th>jog_minutes</th>\n      <th>vehicle_minutes</th>\n      <th>speed_le5_max</th>\n      <th>speed_le5_mean</th>\n      <th>speed_le5_std</th>\n      <th>exercise_flag</th>\n      <th>active_minutes</th>\n      <th>movement_ratio</th>\n      <th>alt_change</th>\n      <th>lat_change</th>\n      <th>lon_change</th>\n      <th>total_distance_m</th>\n      <th>morning_wakeup_time</th>\n      <th>wake_up_early_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>11.1667</td>\n      <td>1.3000</td>\n      <td>3.8667</td>\n      <td>4.9907</td>\n      <td>0.2503</td>\n      <td>0.5089</td>\n      <td>0</td>\n      <td>100.2833</td>\n      <td>0.1034</td>\n      <td>-6.7000</td>\n      <td>0.0229</td>\n      <td>-0.0757</td>\n      <td>29113.5760</td>\n      <td>655</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"id":"riN0msO6wodn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"rTvpgUsLwvNU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"7oHiJLPfaoSw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"X0k3YkQqaodZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mLight 주변 밝기\n- Ambient light measured by the smartphone.\n - 어두운 밤\t0.1 ~ 1 lux\t캄캄한 방, 달빛 없는 밤\n - 가로등 켜진 거리\t10 ~ 20 lux\t흐릿한 외부 조명\n - 실내 조명\t100 ~ 500 lux\t사무실, 일반 거실\n - 밝은 실외\t10,000 ~ 25,000 lux\t맑은 날 햇빛\n - 직사광선 아래\t30,000 ~ 100,000 lux\t여름 한낮, 매우 강한 햇빛\n\n- 밝기에 따라서 언제 불을 끄고 잠든 시간 추정\n- 직사광선 잠에 좋은 영향을 주는지? (논문)\n- 결측치 처리 x","metadata":{"id":"fSRRKaDlaorj"}},{"cell_type":"code","source":"mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\nmLight.head(1)","metadata":{"id":"-0PzJaYUWfVZ","outputId":"8d9e1170-2b9f-4b00-81f6-4bdeba1803a5","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.361365Z","iopub.execute_input":"2025-05-20T10:49:20.361740Z","iopub.status.idle":"2025-05-20T10:49:20.531500Z","shell.execute_reply.started":"2025-05-20T10:49:20.361712Z","shell.execute_reply":"2025-05-20T10:49:20.530618Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_light lifelog_date\n0       id01 2024-06-26 12:03:00 534.0000   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_light</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>534.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def process_mLight(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['hour'] = df['timestamp'].dt.hour\n    df['is_night'] = df['hour'].apply(lambda h: h >= 22 or h < 6)\n\n    # 하루 요약 통계\n    daily_light = df.groupby(['subject_id', 'lifelog_date']).agg(\n        light_mean=('m_light', 'mean'),\n        light_std=('m_light', 'std'),\n        light_max=('m_light', 'max'),\n        light_min=('m_light', 'min'),\n        light_night_mean=('m_light', lambda x: x[df.loc[x.index, 'is_night']].mean()),\n        light_day_mean=('m_light', lambda x: x[~df.loc[x.index, 'is_night']].mean()),\n        light_night_ratio=('is_night', 'mean')\n    ).reset_index()\n\n    results = []\n\n    for subject_id, group in tqdm(df.groupby('subject_id'), desc=\"Processing light-based sleep detection\"):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        recorded_dates = set()\n        sleeping = False\n        zero_count = 0\n        first_zero_time = None\n\n        for i in range(len(group)):\n            light = group.loc[i, 'm_light']\n            hour = group.loc[i, 'hour']\n\n            if light == 0:\n                zero_count += 1\n                if zero_count == 1:\n                    first_zero_time = group.loc[i, 'timestamp']\n                if zero_count >= 6 and not sleeping:\n                    sleep_hour = first_zero_time.hour\n                    if (sleep_hour >= 21 or sleep_hour <= 2):\n                        sleeping = True\n            else:\n                if sleeping:\n                    candidate_wakeup = group.loc[i, 'timestamp']\n                    wake_hour = candidate_wakeup.hour\n\n                    if 5 <= wake_hour <= 9 and first_zero_time is not None:\n                        wake_time = candidate_wakeup\n                        sleep_time = first_zero_time\n                        duration_min = (wake_time - sleep_time).total_seconds() / 60\n\n                        if 0 < duration_min <= 840:\n                            sleep_duration = duration_min\n                        else:\n                            sleep_duration = np.nan\n\n                        lifelog_date = wake_time.date() + pd.Timedelta(days=-1)\n\n                        if lifelog_date not in recorded_dates:\n                            results.append({\n                                'subject_id': subject_id,\n                                'lifelog_date': lifelog_date,\n                                'sleep_duration_min_mLight': sleep_duration,\n                                'sleep_time_min_mLight': sleep_time.hour * 60 + sleep_time.minute,\n                                'wake_time_min_mLight': wake_time.hour * 60 + wake_time.minute,\n                                'hour_slept_mLight': sleep_time.hour + sleep_time.minute / 60,\n                                'hour_woke_up_mLight': wake_time.hour + wake_time.minute / 60\n                            })\n                            recorded_dates.add(lifelog_date)\n\n                        sleeping = False\n                        zero_count = 0\n                        first_zero_time = None\n\n            if light > 0:\n                zero_count = 0\n                first_zero_time = None\n\n    sleep_df = pd.DataFrame(results)\n\n    # 정렬 + 보간\n    sleep_df = sleep_df.sort_values(['subject_id', 'lifelog_date'])\n    sleep_df['sleep_duration_interp_mLight'] = sleep_df.groupby('subject_id')['sleep_duration_min_mLight'].transform(lambda x: x.interpolate())\n\n    # 시간 단위 파생 컬럼\n    sleep_df['sleep_duration_hour_mLight'] = sleep_df['sleep_duration_min_mLight'] / 60\n    sleep_df['sleep_duration_interp_hour_mLight'] = sleep_df['sleep_duration_interp_mLight'] / 60\n\n    # 병합\n    final = pd.merge(daily_light, sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    return final","metadata":{"id":"fIGfYpnFufpT","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.533036Z","iopub.execute_input":"2025-05-20T10:49:20.533377Z","iopub.status.idle":"2025-05-20T10:49:20.552589Z","shell.execute_reply.started":"2025-05-20T10:49:20.533320Z","shell.execute_reply":"2025-05-20T10:49:20.551285Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"mLight2 = process_mLight(mLight)\n\n# check\nprint(f'\\n # mLight2 shape: {mLight2.shape}')\nmLight2.head(1)","metadata":{"id":"vDmnunATbHJ5","outputId":"e502e963-a7d9-4d54-efaf-89e3466cd101","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.553992Z","iopub.execute_input":"2025-05-20T10:49:20.554254Z","iopub.status.idle":"2025-05-20T10:49:22.867173Z","shell.execute_reply.started":"2025-05-20T10:49:20.554234Z","shell.execute_reply":"2025-05-20T10:49:22.866267Z"}},"outputs":[{"name":"stderr","text":"Processing light-based sleep detection: 100%|██████████| 10/10 [00:01<00:00,  6.36it/s]","output_type":"stream"},{"name":"stdout","text":"\n # mLight2 shape: (700, 17)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  light_mean  light_std  light_max  light_min  \\\n0       id01   2024-06-26    364.5068   395.6594  1886.0000     0.0000   \n\n   light_night_mean  light_day_mean  light_night_ratio  \\\n0          184.9231        403.4167             0.1781   \n\n   sleep_duration_min_mLight  sleep_time_min_mLight  wake_time_min_mLight  \\\n0                   340.0000              1409.0000              309.0000   \n\n   hour_slept_mLight  hour_woke_up_mLight  sleep_duration_interp_mLight  \\\n0            23.4833               5.1500                      340.0000   \n\n   sleep_duration_hour_mLight  sleep_duration_interp_hour_mLight  \n0                      5.6667                             5.6667  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>light_mean</th>\n      <th>light_std</th>\n      <th>light_max</th>\n      <th>light_min</th>\n      <th>light_night_mean</th>\n      <th>light_day_mean</th>\n      <th>light_night_ratio</th>\n      <th>sleep_duration_min_mLight</th>\n      <th>sleep_time_min_mLight</th>\n      <th>wake_time_min_mLight</th>\n      <th>hour_slept_mLight</th>\n      <th>hour_woke_up_mLight</th>\n      <th>sleep_duration_interp_mLight</th>\n      <th>sleep_duration_hour_mLight</th>\n      <th>sleep_duration_interp_hour_mLight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>364.5068</td>\n      <td>395.6594</td>\n      <td>1886.0000</td>\n      <td>0.0000</td>\n      <td>184.9231</td>\n      <td>403.4167</td>\n      <td>0.1781</td>\n      <td>340.0000</td>\n      <td>1409.0000</td>\n      <td>309.0000</td>\n      <td>23.4833</td>\n      <td>5.1500</td>\n      <td>340.0000</td>\n      <td>5.6667</td>\n      <td>5.6667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"id":"x6Cb1b3RXHEY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"npFr7zVBXHHt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"M5ZTeeq0XHLk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"5UEjOZN2XHPK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"QSosIjMtXHTs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"bgoIsV5bgXSA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ZHIH4SYXbHUK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"fUlU9AKma3Tg","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔥 mScreenStatus 화면 사용여부\n\n- Indicates whether the smartphone screen is in use.\n - 기상시간, 취침시간, 수면시간\n - 휴대폰 이용횟수, 이용시간\n - 00 - 05 사이에 휴대폰 이용한 건수\n - 결측치 처리 x","metadata":{"id":"BHYijr_sa3sz"}},{"cell_type":"code","source":"mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\nmScreenStatus.head(1)","metadata":{"id":"AGEyFT4ha4bU","outputId":"9226d206-14cc-4b13-e039-0149300de9e7","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:22.868061Z","iopub.execute_input":"2025-05-20T10:49:22.868301Z","iopub.status.idle":"2025-05-20T10:49:24.390177Z","shell.execute_reply.started":"2025-05-20T10:49:22.868279Z","shell.execute_reply":"2025-05-20T10:49:24.389030Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_screen_use lifelog_date\n0       id01 2024-06-26 12:03:00             0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_screen_use</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def preprocess_mScreenStatus(df):\n    from datetime import datetime, time as dtime, timedelta\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n\n    # base key 확보\n    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n\n    # 밤 9시부터 다음날 오전 11시 필터링\n    df['hour'] = df['timestamp'].dt.hour\n    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n\n    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n\n    results = []\n\n    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        # 1. 중간 각성(앞뒤 0, 본인 1) 제거\n        prev = group['m_screen_use'].shift(1)\n        next_ = group['m_screen_use'].shift(-1)\n        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n        group.loc[mask, 'm_screen_use'] = 0\n\n        # 2. 블록 단위로 짧은 각성 블록 제거\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        block_info = group.groupby('block').agg(\n            is_sleep=('is_sleep', 'first'),\n            size=('is_sleep', 'size')\n        )\n\n        for i in range(1, len(block_info) - 1):\n            if (\n                block_info.iloc[i]['is_sleep'] == False and\n                block_info.iloc[i]['size'] <= 2 and\n                block_info.iloc[i - 1]['is_sleep'] and\n                block_info.iloc[i + 1]['is_sleep']\n            ):\n                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n\n        # 다시 블록 재계산 후 수면 추정\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n            sleep_start=('timestamp', 'first'),\n            sleep_end=('timestamp', 'last'),\n            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n        )\n\n        sleep_time = wake_time = duration_min = None\n        if not sleep_blocks.empty:\n            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n            sleep_time = longest_sleep['sleep_start'].time()\n            wake_time = longest_sleep['sleep_end'].time()\n            duration_min = (\n                datetime.combine(datetime.today(), wake_time) - datetime.combine(datetime.today(), sleep_time)\n            ).total_seconds() / 60\n            if duration_min < 0:\n                duration_min += 1440\n\n            if not (4 <= wake_time.hour < 11):\n                wake_time = None\n            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n                sleep_time = None\n            if duration_min < 100:\n                sleep_time = None\n                wake_time = None\n                duration_min = None\n\n        results.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date.date(),\n            'sleep_time': sleep_time,\n            'wake_time': wake_time,\n            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n        })\n\n\n    sleep_df = pd.DataFrame(results)\n    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    # 시간 → 실수형 숫자 (예: 23:30 → 23.5)\n    def time_to_float(t):\n        if pd.isna(t):\n            return None\n        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n\n    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n\n    return result_df","metadata":{"id":"6cWpAYZxy32U","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.390974Z","iopub.execute_input":"2025-05-20T10:49:24.391382Z","iopub.status.idle":"2025-05-20T10:49:24.420784Z","shell.execute_reply.started":"2025-05-20T10:49:24.391362Z","shell.execute_reply":"2025-05-20T10:49:24.419314Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def preprocess_mScreenStatus(df):\n    from datetime import datetime, timedelta\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n\n    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n\n    # 밤 9시 ~ 다음날 오전 11시 필터링\n    df['hour'] = df['timestamp'].dt.hour\n    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n\n    results = []\n\n    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        # 중간 각성 제거\n        prev = group['m_screen_use'].shift(1)\n        next_ = group['m_screen_use'].shift(-1)\n        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n        group.loc[mask, 'm_screen_use'] = 0\n\n        # 짧은 각성 블록 제거\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        block_info = group.groupby('block').agg(\n            is_sleep=('is_sleep', 'first'),\n            size=('is_sleep', 'size')\n        )\n\n        for i in range(1, len(block_info) - 1):\n            if (\n                block_info.iloc[i]['is_sleep'] == False and\n                block_info.iloc[i]['size'] <= 2 and\n                block_info.iloc[i - 1]['is_sleep'] and\n                block_info.iloc[i + 1]['is_sleep']\n            ):\n                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n\n        # 블록 재계산\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n\n        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n            sleep_start=('timestamp', 'first'),\n            sleep_end=('timestamp', 'last'),\n            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n        )\n\n        sleep_time = wake_time = duration_min = None\n        if not sleep_blocks.empty:\n            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n            sleep_time = longest_sleep['sleep_start'].time()\n            wake_time = longest_sleep['sleep_end'].time()\n            duration_min = longest_sleep['duration_min']  # ✅ 정확하게 자정 넘는 경우도 반영됨\n\n            # 유효 시간 범위 조건\n            if not (4 <= wake_time.hour < 11):\n                wake_time = None\n            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n                sleep_time = None\n            if duration_min < 100:\n                sleep_time = None\n                wake_time = None\n                duration_min = None\n\n        results.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date.date(),\n            'sleep_time': sleep_time,\n            'wake_time': wake_time,\n            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n        })\n\n    sleep_df = pd.DataFrame(results)\n    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    # 시간 → 실수형 숫자 변환\n    def time_to_float(t):\n        if pd.isna(t):\n            return None\n        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n\n    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n\n    # 자정 넘어가는 경우 고려한 sleep_duration_min 재계산\n    def compute_duration(row):\n        sleep = row['sleep_time']\n        wake = row['wake_time']\n        if pd.isna(sleep) or pd.isna(wake):\n            return None\n        duration = (wake - sleep + 24) % 24\n        return round(duration * 60, 1)  # 시간 단위 → 분 단위\n\n    result_df['sleep_duration_min'] = result_df.apply(compute_duration, axis=1)\n\n    return result_df","metadata":{"id":"q5EqRmCxgYoq","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.422148Z","iopub.execute_input":"2025-05-20T10:49:24.422657Z","iopub.status.idle":"2025-05-20T10:49:24.450125Z","shell.execute_reply.started":"2025-05-20T10:49:24.422629Z","shell.execute_reply":"2025-05-20T10:49:24.448891Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def calculate_circular_mean_sleep_time(sleep_times):\n    sleep_times = pd.Series(sleep_times).dropna()\n    if len(sleep_times) == 0:\n        return np.nan  # 혹은 return 0.0 등 기본값 설정 가능\n\n    def hour_to_radian(hour):\n        return (hour % 24) / 24 * 2 * np.pi\n\n    radians = np.array([hour_to_radian(t) for t in sleep_times])\n    mean_radian = np.arctan2(np.mean(np.sin(radians)), np.mean(np.cos(radians)))\n    mean_hour = (mean_radian / (2 * np.pi)) * 24 % 24\n\n    return mean_hour","metadata":{"id":"iMAqJissamth","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.451158Z","iopub.execute_input":"2025-05-20T10:49:24.451598Z","iopub.status.idle":"2025-05-20T10:49:24.473143Z","shell.execute_reply.started":"2025-05-20T10:49:24.451578Z","shell.execute_reply":"2025-05-20T10:49:24.472069Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def circular_mean_sleep_time(times):\n\n    # 결측치 제거\n    valid_times = [t for t in times if pd.notna(t)]\n\n    # 유효 데이터 개수 확인\n    if len(valid_times) == 0:\n        return None  # 결측치만 있는 경우\n\n    # 시간 → 라디안 변환\n    radians = [(t % 24) / 24 * 2 * np.pi for t in valid_times]\n\n    # 사인/코사인 평균 계산\n    sin_sum = np.mean(np.sin(radians))\n    cos_sum = np.mean(np.cos(radians))\n\n    # 평균 각도 계산\n    if sin_sum == 0 and cos_sum == 0:\n        return np.nan  # 불가능한 경우\n\n    mean_radian = np.arctan2(sin_sum, cos_sum)\n\n    # 평균 시간으로 변환\n    mean_hour = (mean_radian / (2 * np.pi)) * 24\n    if mean_hour < 0:\n        mean_hour += 24\n\n    return f'{int(mean_hour):02d}:{int((mean_hour % 1) * 60):02d}'","metadata":{"id":"iA554Qkxb6LU","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.479289Z","iopub.execute_input":"2025-05-20T10:49:24.480247Z","iopub.status.idle":"2025-05-20T10:49:24.494195Z","shell.execute_reply.started":"2025-05-20T10:49:24.480216Z","shell.execute_reply":"2025-05-20T10:49:24.492850Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def add_ratios(df):\n    df = df.copy()\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n    df['weekday'] = df['lifelog_date'].dt.weekday  # 0=월 ~ 6=일\n    df['week_type'] = df['weekday'].apply(lambda x: 'weekend' if x >= 5 else 'weekday')\n    df['month'] = df['lifelog_date'].dt.month\n\n    # 일반 평균 계산\n    avg_duration = (\n        df.groupby(['subject_id', 'month', 'week_type'])['sleep_duration_min']\n        .mean()\n        .reset_index(name='avg_sleep_duration')\n    )\n\n    # sleep_time, wake_time은 원형 평균 적용\n    sleep_time_avg = (\n        df.groupby(['subject_id', 'month', 'week_type'])['sleep_time']\n        .apply(calculate_circular_mean_sleep_time)\n        .reset_index(name='avg_sleep_time')\n    )\n\n    wake_time_avg = (\n        df.groupby(['subject_id', 'month', 'week_type'])['wake_time']\n        .apply(calculate_circular_mean_sleep_time)\n        .reset_index(name='avg_wake_time')\n    )\n\n    # 평균값 합치기\n    avg_df = sleep_time_avg.merge(wake_time_avg, on=['subject_id', 'month', 'week_type'])\n    avg_df = avg_df.merge(avg_duration, on=['subject_id', 'month', 'week_type'])\n\n    # 원본에 매칭\n    df = df.merge(avg_df, on=['subject_id', 'month', 'week_type'], how='left')\n\n    # 비율 변수 계산 (음수면 더 일찍 취침/기상/수면시간 짧음)\n    df['sleep_time_diff'] = df['avg_sleep_time'] - df['sleep_time']\n    df['wake_time_diff'] = df['avg_wake_time'] - df['wake_time']\n    df['sleep_duration_diff'] = df['avg_sleep_duration'] - df['sleep_duration_min']\n    df['sleep_time_ratio'] = df['sleep_time'] / df['avg_sleep_time']\n    df['wake_time_ratio'] = df['wake_time'] / df['avg_wake_time']\n    df['sleep_duration_ratio'] = df['sleep_duration_min'] / df['avg_sleep_duration']\n\n    # lag feature\n    df = df.sort_values(['subject_id', 'lifelog_date'])\n    df['sleep_time_lag1'] = df.groupby('subject_id')['sleep_time'].shift(1)\n    df['wake_time_lag1'] = df.groupby('subject_id')['wake_time'].shift(1)\n    df['sleep_duration_lag1'] = df.groupby('subject_id')['sleep_duration_min'].shift(1)\n    df['week_type_lag1'] = df.groupby('subject_id')['week_type'].shift(1)\n\n    # 변화량\n    df['sleep_time_diff_lag1'] = df.groupby('subject_id')['sleep_time'].diff()\n    df['wake_time_diff_lag1'] = df.groupby('subject_id')['wake_time'].diff()\n    df['sleep_duration_diff_lag1'] = df.groupby('subject_id')['sleep_duration_min'].diff()\n\n    # 이동 평균 (3일)\n    df['rolling_sleep_time_3d'] = (\n        df.groupby('subject_id')['sleep_time']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n    df['rolling_wake_time_3d'] = (\n        df.groupby('subject_id')['wake_time']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n    df['rolling_sleep_duration_3d'] = (\n        df.groupby('subject_id')['sleep_duration_min']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n\n    # 존재하는 컬럼만 채우기\n    existing_columns = df.columns.tolist()\n    columns_to_fill_filtered = [col for col in [\n        'sleep_time', 'wake_time', 'sleep_duration_min',\n        'sleep_time_ratio', 'wake_time_ratio', 'sleep_duration_ratio',\n        'sleep_time_diff', 'wake_time_diff', 'sleep_duration_diff',\n        'sleep_time_lag1', 'wake_time_lag1', 'sleep_duration_lag1',\n        'sleep_time_diff_lag1', 'wake_time_diff_lag1', 'sleep_duration_diff_lag1',\n        'rolling_sleep_time_3d', 'rolling_wake_time_3d', 'rolling_sleep_duration_3d'\n    ] if col in existing_columns]\n\n    df[columns_to_fill_filtered] = df.groupby('subject_id')[columns_to_fill_filtered].ffill()\n\n    result = df[[\n        'subject_id', 'lifelog_date', 'week_type',\n        'sleep_time', 'wake_time', 'sleep_duration_min',\n        'avg_sleep_time', 'avg_wake_time', 'avg_sleep_duration',\n        'sleep_time_ratio', 'wake_time_ratio', 'sleep_duration_ratio',\n        'sleep_time_diff', 'wake_time_diff', 'sleep_duration_diff',\n        'sleep_time_lag1','wake_time_lag1', 'sleep_duration_lag1','week_type_lag1',\n        'sleep_time_diff_lag1','wake_time_diff_lag1','sleep_duration_diff_lag1',\n        'rolling_sleep_time_3d','rolling_wake_time_3d','rolling_sleep_duration_3d'\n    ]]\n\n    return result","metadata":{"id":"HpmsLYaPoD0d","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.495196Z","iopub.execute_input":"2025-05-20T10:49:24.495605Z","iopub.status.idle":"2025-05-20T10:49:24.518506Z","shell.execute_reply.started":"2025-05-20T10:49:24.495583Z","shell.execute_reply":"2025-05-20T10:49:24.516894Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"mScreenStatus2 = preprocess_mScreenStatus(mScreenStatus)\nmScreenStatus2 = add_ratios(mScreenStatus2)\n\n# check\nprint(f'\\n # mScreenStatus2 shape: {mScreenStatus2.shape}')\nmScreenStatus2.head(1)","metadata":{"id":"-F1Nm26-Qxo4","outputId":"fd66f62c-0fdb-44b9-860c-fcd3ab06f7d4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.519570Z","iopub.execute_input":"2025-05-20T10:49:24.520246Z","iopub.status.idle":"2025-05-20T10:49:38.530444Z","shell.execute_reply.started":"2025-05-20T10:49:24.520022Z","shell.execute_reply":"2025-05-20T10:49:38.529560Z"}},"outputs":[{"name":"stdout","text":"\n # mScreenStatus2 shape: (700, 25)\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date week_type  sleep_time  wake_time  \\\n0       id01   2024-06-26   weekday     23.4500     5.2500   \n\n   sleep_duration_min  avg_sleep_time  avg_wake_time  avg_sleep_duration  \\\n0            348.0000         23.1944         5.4887            377.6667   \n\n   sleep_time_ratio  wake_time_ratio  sleep_duration_ratio  sleep_time_diff  \\\n0            1.0110           0.9565                0.9214          -0.2556   \n\n   wake_time_diff  sleep_duration_diff  sleep_time_lag1  wake_time_lag1  \\\n0          0.2387              29.6667              NaN             NaN   \n\n   sleep_duration_lag1 week_type_lag1  sleep_time_diff_lag1  \\\n0                  NaN            NaN                   NaN   \n\n   wake_time_diff_lag1  sleep_duration_diff_lag1  rolling_sleep_time_3d  \\\n0                  NaN                       NaN                23.4500   \n\n   rolling_wake_time_3d  rolling_sleep_duration_3d  \n0                5.2500                   348.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>week_type</th>\n      <th>sleep_time</th>\n      <th>wake_time</th>\n      <th>sleep_duration_min</th>\n      <th>avg_sleep_time</th>\n      <th>avg_wake_time</th>\n      <th>avg_sleep_duration</th>\n      <th>sleep_time_ratio</th>\n      <th>wake_time_ratio</th>\n      <th>sleep_duration_ratio</th>\n      <th>sleep_time_diff</th>\n      <th>wake_time_diff</th>\n      <th>sleep_duration_diff</th>\n      <th>sleep_time_lag1</th>\n      <th>wake_time_lag1</th>\n      <th>sleep_duration_lag1</th>\n      <th>week_type_lag1</th>\n      <th>sleep_time_diff_lag1</th>\n      <th>wake_time_diff_lag1</th>\n      <th>sleep_duration_diff_lag1</th>\n      <th>rolling_sleep_time_3d</th>\n      <th>rolling_wake_time_3d</th>\n      <th>rolling_sleep_duration_3d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>weekday</td>\n      <td>23.4500</td>\n      <td>5.2500</td>\n      <td>348.0000</td>\n      <td>23.1944</td>\n      <td>5.4887</td>\n      <td>377.6667</td>\n      <td>1.0110</td>\n      <td>0.9565</td>\n      <td>0.9214</td>\n      <td>-0.2556</td>\n      <td>0.2387</td>\n      <td>29.6667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.4500</td>\n      <td>5.2500</td>\n      <td>348.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"mScreenStatus2평균수면시간 = mScreenStatus2.groupby(['subject_id','week_type']).apply(lambda x: pd.Series({\n     '평균 취침시간':circular_mean_sleep_time(x['sleep_time'])\n    ,'평균 기상시간':circular_mean_sleep_time(x['wake_time'])\n    ,'평균 수면시간':x['sleep_duration_min'].mean()\n})).reset_index()\n\n# 저장\nfname = f'mScreenStatus2평균수면시간.xlsx'\nprint(fname)\nmScreenStatus2평균수면시간.to_excel(fname, index=False)\n\n# # check\nmScreenStatus2평균수면시간","metadata":{"id":"MUE2qxE7Qx0I","outputId":"bae6d256-1a7a-4199-e8ef-aff935a65777","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:38.531951Z","iopub.execute_input":"2025-05-20T10:49:38.532432Z","iopub.status.idle":"2025-05-20T10:49:39.202195Z","shell.execute_reply.started":"2025-05-20T10:49:38.532404Z","shell.execute_reply":"2025-05-20T10:49:39.201039Z"}},"outputs":[{"name":"stdout","text":"mScreenStatus2평균수면시간.xlsx\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   subject_id week_type 평균 취침시간 평균 기상시간  평균 수면시간\n0        id01   weekday   22:42   05:55 429.2292\n1        id01   weekend   22:21   06:09 467.4500\n2        id02   weekday   22:54   07:13 496.0000\n3        id02   weekend   23:13   07:27 494.9583\n4        id03   weekday   00:21   09:03 457.4359\n5        id03   weekend   00:18   08:54 450.8667\n6        id04   weekday   00:03   06:50 396.6721\n7        id04   weekend   00:09   06:59 401.1739\n8        id05   weekday   22:52   07:25 500.1064\n9        id05   weekend   22:39   07:42 518.2778\n10       id06   weekday   23:56   08:30 505.7115\n11       id06   weekend   00:33   08:54 490.3500\n12       id07   weekday   00:08   07:16 424.9273\n13       id07   weekend   00:18   07:56 433.2500\n14       id08   weekday   01:35   08:22 360.4906\n15       id08   weekend   01:47   08:54 380.7619\n16       id09   weekday   00:08   07:47 358.4783\n17       id09   weekend   00:19   08:53 383.5294\n18       id10   weekday   01:45   08:25 369.9714\n19       id10   weekend   01:58   09:33 407.4444","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>week_type</th>\n      <th>평균 취침시간</th>\n      <th>평균 기상시간</th>\n      <th>평균 수면시간</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>weekday</td>\n      <td>22:42</td>\n      <td>05:55</td>\n      <td>429.2292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>weekend</td>\n      <td>22:21</td>\n      <td>06:09</td>\n      <td>467.4500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id02</td>\n      <td>weekday</td>\n      <td>22:54</td>\n      <td>07:13</td>\n      <td>496.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id02</td>\n      <td>weekend</td>\n      <td>23:13</td>\n      <td>07:27</td>\n      <td>494.9583</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id03</td>\n      <td>weekday</td>\n      <td>00:21</td>\n      <td>09:03</td>\n      <td>457.4359</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>id03</td>\n      <td>weekend</td>\n      <td>00:18</td>\n      <td>08:54</td>\n      <td>450.8667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>id04</td>\n      <td>weekday</td>\n      <td>00:03</td>\n      <td>06:50</td>\n      <td>396.6721</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>id04</td>\n      <td>weekend</td>\n      <td>00:09</td>\n      <td>06:59</td>\n      <td>401.1739</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>id05</td>\n      <td>weekday</td>\n      <td>22:52</td>\n      <td>07:25</td>\n      <td>500.1064</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>id05</td>\n      <td>weekend</td>\n      <td>22:39</td>\n      <td>07:42</td>\n      <td>518.2778</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>id06</td>\n      <td>weekday</td>\n      <td>23:56</td>\n      <td>08:30</td>\n      <td>505.7115</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>id06</td>\n      <td>weekend</td>\n      <td>00:33</td>\n      <td>08:54</td>\n      <td>490.3500</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>id07</td>\n      <td>weekday</td>\n      <td>00:08</td>\n      <td>07:16</td>\n      <td>424.9273</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>id07</td>\n      <td>weekend</td>\n      <td>00:18</td>\n      <td>07:56</td>\n      <td>433.2500</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>id08</td>\n      <td>weekday</td>\n      <td>01:35</td>\n      <td>08:22</td>\n      <td>360.4906</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>id08</td>\n      <td>weekend</td>\n      <td>01:47</td>\n      <td>08:54</td>\n      <td>380.7619</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>id09</td>\n      <td>weekday</td>\n      <td>00:08</td>\n      <td>07:47</td>\n      <td>358.4783</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>id09</td>\n      <td>weekend</td>\n      <td>00:19</td>\n      <td>08:53</td>\n      <td>383.5294</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>id10</td>\n      <td>weekday</td>\n      <td>01:45</td>\n      <td>08:25</td>\n      <td>369.9714</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>id10</td>\n      <td>weekend</td>\n      <td>01:58</td>\n      <td>09:33</td>\n      <td>407.4444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"id":"-dvQ-tBxQx6n","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"NXxXWnhTj-XV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"t5m7Jll1a_Bh","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"AUxk1jIqa4jT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mUsageStats 앱사용통계\n- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n\n - 몇시까지 핸드폰 보다가 잠잤는지\n - 통화, 전화 얼마나 했는지\n - YouTube 얼마나 봤는지\n - 메시지, 카카오톡 얼마나 했는지\n - NAVER 얼마나 했는지\n - 평소보다 얼마나 많은 앱을 이용했는지\n - 제외? -> 시스템 UI,One UI 홈","metadata":{"id":"orMu9LKiW58-"}},{"cell_type":"code","source":"def extract_mUsageStats_info(row):\n    m_data = row['m_usage_stats']\n    app_name = [item['app_name'] for item in m_data]\n    total_time = [item['total_time'] for item in m_data]\n    return pd.Series({'app_name': app_name, 'total_time': total_time})\n\nmUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\nmUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\nmUsageStats.head(1)","metadata":{"id":"Zr1oENhJWfh0","outputId":"8867560c-8fb8-4963-df23-03f1676de7ec","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:39.203296Z","iopub.execute_input":"2025-05-20T10:49:39.204058Z","iopub.status.idle":"2025-05-20T10:49:47.415841Z","shell.execute_reply.started":"2025-05-20T10:49:39.204033Z","shell.execute_reply":"2025-05-20T10:49:47.415060Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 13:00:00   \n\n                                                                                                                       m_usage_stats  \\\n0  [{'app_name': ' 캐시워크', 'total_time': 69}, {'app_name': 'NAVER', 'total_time': 549}, {'app_name': ' ✝️성경일독Q', 'total_time': 7337}]   \n\n                   app_name       total_time lifelog_date  \n0  [ 캐시워크, NAVER,  ✝️성경일독Q]  [69, 549, 7337]   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_usage_stats</th>\n      <th>app_name</th>\n      <th>total_time</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 13:00:00</td>\n      <td>[{'app_name': ' 캐시워크', 'total_time': 69}, {'app_name': 'NAVER', 'total_time': 549}, {'app_name': ' ✝️성경일독Q', 'total_time': 7337}]</td>\n      <td>[ 캐시워크, NAVER,  ✝️성경일독Q]</td>\n      <td>[69, 549, 7337]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# def process_mUsageStats(df):\n#     df = df.copy()\n#     df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n#     df['timestamp'] = pd.to_datetime(df['timestamp'])\n#     df['요일'] = df['lifelog_date'].dt.day_name()\n\n#     # 리스트 평탄화\n#     exploded_df = df.explode(['app_name', 'total_time'])\n#     exploded_df['total_time'] = exploded_df['total_time'].astype(float)\n#     exploded_df['total_time'] = exploded_df['total_time'] * 0.001 / 60  # 밀리초 → 초 → 분 변환\n\n#     # app_name 특수문자 제거\n#     exploded_df['app_name'] = exploded_df['app_name'].astype(str).apply(\n#         lambda x: re.sub(r'[^가-힣a-zA-Z0-9]', '', x)\n#     )\n\n#     # 시스템 앱 제거\n#     filtered_df = exploded_df[~exploded_df['app_name'].isin(['시스템UI'])]  # '시스템UI'만 제거 (OneUI홈은 포함)\n\n#     # 주요 파생변수 생성\n#     def calculate_daily_metrics(group):\n#         last_use = group['timestamp'].max()\n\n#         app_times = {\n#             '통화_time': group[group['app_name'] == '통화']['total_time'].sum(),\n#             '전화_time': group[group['app_name'] == '전화']['total_time'].sum(),\n#             'YouTube_time': group[group['app_name'] == 'YouTube']['total_time'].sum(),\n#             '메신저_time': group[group['app_name'].isin(['메시지', '카카오톡'])]['total_time'].sum(),\n#             'NAVER_time': group[group['app_name'] == 'NAVER']['total_time'].sum(),\n#             '캐시워크_time': group[group['app_name'] == '캐시워크']['total_time'].sum(),\n#             '성경일독Q_time': group[group['app_name'] == '성경일독Q']['total_time'].sum(),\n#             'OneUI홈_time': group[group['app_name'] == 'OneUI홈']['total_time'].sum(),\n#         }\n\n#         return pd.Series({\n#             **app_times,\n#             'unique_app_count': group['app_name'].nunique(),\n#             'total_screen_time': group['total_time'].sum()\n#         })\n\n#     # daily metrics 생성\n#     daily_stats = filtered_df.groupby(['subject_id', 'lifelog_date']).apply(calculate_daily_metrics).reset_index()\n\n#     # subject_id별 평균 총화면시간 구하기\n#     avg_screen_time = daily_stats.groupby('subject_id')['total_screen_time'].mean().to_dict()\n\n#     # 평균대비 화면사용량(%) 생성\n#     def compute_screen_usage(row):\n#         avg_time = avg_screen_time.get(row['subject_id'], np.nan)\n#         if pd.isna(avg_time) or avg_time == 0:\n#             return np.nan\n#         return round((row['total_screen_time'] / avg_time - 1) * 100, 1)\n\n#     daily_stats['screen_time_vs_avg_pct'] = daily_stats.apply(compute_screen_usage, axis=1)\n\n#     return daily_stats","metadata":{"id":"GUZVZ8LXXhrK","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.416935Z","iopub.execute_input":"2025-05-20T10:49:47.417239Z","iopub.status.idle":"2025-05-20T10:49:47.422704Z","shell.execute_reply.started":"2025-05-20T10:49:47.417207Z","shell.execute_reply":"2025-05-20T10:49:47.421760Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def process_mUsageStats(df):\n    df = df.copy()\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['요일'] = df['lifelog_date'].dt.day_name()\n    df['hour'] = df['timestamp'].dt.hour\n\n    # 시간대 분류\n    def map_time_period(row):\n        if 20 <= row['hour'] <= 23:\n            return 'beforebed'\n        else:\n            return 'activehour'\n\n    df['time_period'] = df.apply(map_time_period, axis=1)\n\n    # 리스트 평탄화\n    exploded_df = df.explode(['app_name', 'total_time'])\n    exploded_df['total_time'] = exploded_df['total_time'].astype(float)\n    exploded_df['total_time'] = exploded_df['total_time'] * 0.001 / 60  # 밀리초 → 초 → 분 변환\n\n    # app_name 특수문자 제거\n    exploded_df['app_name'] = exploded_df['app_name'].astype(str).apply(\n        lambda x: re.sub(r'[^가-힣a-zA-Z0-9]', '', x)\n    )\n\n    # 시스템 앱 제거\n    filtered_df = exploded_df[~exploded_df['app_name'].isin(['시스템UI'])]\n\n    # 주요 파생변수 생성\n    def calculate_daily_metrics(group):\n        app_times = {\n            '통화_time': group[group['app_name'] == '통화']['total_time'].sum(),\n            '전화_time': group[group['app_name'] == '전화']['total_time'].sum(),\n            'YouTube_time': group[group['app_name'] == 'YouTube']['total_time'].sum(),\n            '메신저_time': group[group['app_name'].isin(['메시지', '카카오톡'])]['total_time'].sum(),\n            'NAVER_time': group[group['app_name'] == 'NAVER']['total_time'].sum(),\n            '캐시워크_time': group[group['app_name'] == '캐시워크']['total_time'].sum(),\n            '성경일독Q_time': group[group['app_name'] == '성경일독Q']['total_time'].sum(),\n            'OneUI홈_time': group[group['app_name'] == 'OneUI홈']['total_time'].sum(),\n        }\n\n        return pd.Series({\n            **app_times,\n            'unique_app_count': group['app_name'].nunique(),\n            'total_screen_time': group['total_time'].sum()\n        })\n\n    # 일자/시간대별 요약\n    daily_stats = filtered_df.groupby(['subject_id', 'lifelog_date', 'time_period']).apply(calculate_daily_metrics).reset_index()\n\n    # subject_id별 평균 총화면시간\n    avg_screen_time = daily_stats.groupby('subject_id')['total_screen_time'].mean().to_dict()\n\n    # 평균 대비 비율\n    def compute_screen_usage(row):\n        avg_time = avg_screen_time.get(row['subject_id'], np.nan)\n        if pd.isna(avg_time) or avg_time == 0:\n            return np.nan\n        return round((row['total_screen_time'] / avg_time - 1) * 100, 1)\n\n    daily_stats['screen_time_vs_avg_pct'] = daily_stats.apply(compute_screen_usage, axis=1)\n\n    # 피벗\n    daily_stats = daily_stats.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    daily_stats.columns = [f\"{tp}_{metric}\" for metric, tp in daily_stats.columns]\n    daily_stats = daily_stats.reset_index()\n\n    return daily_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.423613Z","iopub.execute_input":"2025-05-20T10:49:47.423867Z","iopub.status.idle":"2025-05-20T10:49:47.448205Z","shell.execute_reply.started":"2025-05-20T10:49:47.423846Z","shell.execute_reply":"2025-05-20T10:49:47.447124Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"mUsageStats2 = process_mUsageStats(mUsageStats)\n\n# check\nprint(f'\\n # mUsageStats2 shape: {mUsageStats2.shape}')\nmUsageStats2.head(1)","metadata":{"id":"l8CRKpC4iDKa","outputId":"953412a6-b6ad-4440-b940-7e7dbb1e819c","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.449279Z","iopub.execute_input":"2025-05-20T10:49:47.449602Z","iopub.status.idle":"2025-05-20T10:49:53.896818Z","shell.execute_reply.started":"2025-05-20T10:49:47.449576Z","shell.execute_reply":"2025-05-20T10:49:53.895710Z"}},"outputs":[{"name":"stdout","text":"\n # mUsageStats2 shape: (689, 24)\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  activehour_통화_time  beforebed_통화_time  \\\n0       id01   2024-06-26              9.0010             0.2079   \n\n   activehour_전화_time  beforebed_전화_time  activehour_YouTube_time  \\\n0             11.3007             0.7731                   0.1061   \n\n   beforebed_YouTube_time  activehour_메신저_time  beforebed_메신저_time  \\\n0                  0.0000              43.6359             14.5713   \n\n   activehour_NAVER_time  beforebed_NAVER_time  activehour_캐시워크_time  \\\n0                 8.4852                0.1351               18.6694   \n\n   beforebed_캐시워크_time  activehour_성경일독Q_time  beforebed_성경일독Q_time  \\\n0               5.4722                88.3836               27.6892   \n\n   activehour_OneUI홈_time  beforebed_OneUI홈_time  activehour_unique_app_count  \\\n0                 61.1160                27.9861                      25.0000   \n\n   beforebed_unique_app_count  activehour_total_screen_time  \\\n0                     20.0000                      266.7672   \n\n   beforebed_total_screen_time  activehour_screen_time_vs_avg_pct  \\\n0                     156.8681                           -29.0000   \n\n   beforebed_screen_time_vs_avg_pct  \n0                          -58.3000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>activehour_통화_time</th>\n      <th>beforebed_통화_time</th>\n      <th>activehour_전화_time</th>\n      <th>beforebed_전화_time</th>\n      <th>activehour_YouTube_time</th>\n      <th>beforebed_YouTube_time</th>\n      <th>activehour_메신저_time</th>\n      <th>beforebed_메신저_time</th>\n      <th>activehour_NAVER_time</th>\n      <th>beforebed_NAVER_time</th>\n      <th>activehour_캐시워크_time</th>\n      <th>beforebed_캐시워크_time</th>\n      <th>activehour_성경일독Q_time</th>\n      <th>beforebed_성경일독Q_time</th>\n      <th>activehour_OneUI홈_time</th>\n      <th>beforebed_OneUI홈_time</th>\n      <th>activehour_unique_app_count</th>\n      <th>beforebed_unique_app_count</th>\n      <th>activehour_total_screen_time</th>\n      <th>beforebed_total_screen_time</th>\n      <th>activehour_screen_time_vs_avg_pct</th>\n      <th>beforebed_screen_time_vs_avg_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>9.0010</td>\n      <td>0.2079</td>\n      <td>11.3007</td>\n      <td>0.7731</td>\n      <td>0.1061</td>\n      <td>0.0000</td>\n      <td>43.6359</td>\n      <td>14.5713</td>\n      <td>8.4852</td>\n      <td>0.1351</td>\n      <td>18.6694</td>\n      <td>5.4722</td>\n      <td>88.3836</td>\n      <td>27.6892</td>\n      <td>61.1160</td>\n      <td>27.9861</td>\n      <td>25.0000</td>\n      <td>20.0000</td>\n      <td>266.7672</td>\n      <td>156.8681</td>\n      <td>-29.0000</td>\n      <td>-58.3000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"id":"4pXwcGHxiDPQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2ecpVUVhRo4e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"R1PcAUtkH81I","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"iZHkETiDH84G","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ mWifi 주변wifi 정보\n- Wifi devices around individual subject.\n - -30 ~ -50 dBm\t매우 강한 신호 (최적)\n - -51 ~ -60 dBm\t강한 신호 (문제 없음)\n - -61 ~ -70 dBm\t괜찮은 신호 (약간 느릴 수 있음)\n - -71 ~ -80 dBm\t약한 신호 (끊김 주의)\n - -81 dBm 이하\t매우 약한 신호 (거의 끊김)","metadata":{"id":"sFVRGf8cbJMo"}},{"cell_type":"code","source":"def extract_wifi_info(row):\n    wifi_data = row['m_wifi']\n    bssids = [item['bssid'] for item in wifi_data]\n    rssis = [item['rssi'] for item in wifi_data]\n    return pd.Series({'bssid': bssids, 'rssi': rssis})\n\nmWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\nmWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\nmWifi.head(1)","metadata":{"id":"WCIgP5FaH86F","outputId":"056d5d70-0c30-4ea8-f3cb-a40624d77d0e","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:53.897979Z","iopub.execute_input":"2025-05-20T10:49:53.898371Z","iopub.status.idle":"2025-05-20T10:50:11.701108Z","shell.execute_reply.started":"2025-05-20T10:49:53.898316Z","shell.execute_reply":"2025-05-20T10:50:11.699983Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:03:00   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            m_wifi  \\\n0  [{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8c', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8d', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8e', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8f', 'rssi': -78}, {'bssid': 'a0:0f:37:96:56:ef', 'rssi': -58}, {'bssid': '88:36:6c:86:75:84', 'rssi': -72}, {'bssid': 'a0:0f:37:96:56:ee', 'rssi': -58}, {'bssid': 'a0:0f:37:96:56:ed', 'rssi': -58}, {'bssid': '86:25:19:b5:b2:a5', 'rssi': -61}, {'bssid': 'a0:0f:37:96:56:ec', 'rssi': -58}, {'bssid': '1e:39:29:8e:fb:e9', 'rssi': -71}, {'bssid': '52:c2:e8:c7:9b:e4', 'rssi': -82}, {'bssid': 'a0:0f:37:96:56:eb', 'rssi': -58}, {'bssid': '12:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '58:86:94:4a:08:b8', 'rssi': -82}, {'bssid': '90:9f:33:28:d0:2e', 'rssi': -78}, {'bssid': '00:26:66:bc:4e:18', 'rssi': -85}, {'bssid': 'f6:0a:f4:43:4b:ba', 'rssi': -45}, {'bssid': '10:e3:c7:09:20:35', 'rssi': -63}, {'bssid': '10:e3:c7:09:20:34', 'rssi': -89}, {'bssid': '1c:39:29:48:04:92', 'rssi': -82}, {'bssid': '12:e3:c7:07:9d:df', 'rssi': -83}, {'bssid': '86:25:19:c3:44:07', 'rssi': -84}, {'bssid': 'a0:0f:37:9a:37:2f', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2e', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2d', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:ec', 'rssi': -72}, {'bssid': 'a0:0f:37:9a:37:2c', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2b', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:eb', 'rssi': -59}, {'bssid': 'c0:25:2f:d8:c1:a6', 'rssi': -82}, {'bssid': '16:7f:67:bb:fa:f8', 'rssi': -79}, {'bssid': '3c:f3:92:ff:00:01', 'rssi': -82}, {'bssid': '06:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '06:09:b4:74:05:eb', 'rssi': -59}, {'bssid': '12:e3:c7:0a:74:d1', 'rssi': -78}, {'bssid': '88:36:6c:a9:6f:8e', 'rssi': -63}, {'bssid': '02:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '00:09:b4:74:05:eb', 'rssi': -60}, {'bssid': '00:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '00:1d:93:93:cf:fe', 'rssi': -19}, {'bssid': '8e:e2:ac:a5:9d:15', 'rssi': -72}]   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               bssid  \\\n0  [a0:0f:37:9a:5d:8b, a0:0f:37:9a:5d:8c, a0:0f:37:9a:5d:8d, a0:0f:37:9a:5d:8e, a0:0f:37:9a:5d:8f, a0:0f:37:96:56:ef, 88:36:6c:86:75:84, a0:0f:37:96:56:ee, a0:0f:37:96:56:ed, 86:25:19:b5:b2:a5, a0:0f:37:96:56:ec, 1e:39:29:8e:fb:e9, 52:c2:e8:c7:9b:e4, a0:0f:37:96:56:eb, 12:e3:c7:09:20:34, 58:86:94:4a:08:b8, 90:9f:33:28:d0:2e, 00:26:66:bc:4e:18, f6:0a:f4:43:4b:ba, 10:e3:c7:09:20:35, 10:e3:c7:09:20:34, 1c:39:29:48:04:92, 12:e3:c7:07:9d:df, 86:25:19:c3:44:07, a0:0f:37:9a:37:2f, a0:0f:37:9a:37:2e, a0:0f:37:9a:37:2d, 0a:09:b4:74:05:ec, a0:0f:37:9a:37:2c, a0:0f:37:9a:37:2b, 0a:09:b4:74:05:eb, c0:25:2f:d8:c1:a6, 16:7f:67:bb:fa:f8, 3c:f3:92:ff:00:01, 06:09:b4:74:05:ec, 06:09:b4:74:05:eb, 12:e3:c7:0a:74:d1, 88:36:6c:a9:6f:8e, 02:e3:c7:09:20:34, 00:09:b4:74:05:eb, 00:09:b4:74:05:ec, 00:1d:93:93:cf:fe, 8e:e2:ac:a5:9d:15]   \n\n                                                                                                                                                                                                                      rssi  \\\n0  [-78, -78, -78, -78, -78, -58, -72, -58, -58, -61, -58, -71, -82, -58, -88, -82, -78, -85, -45, -63, -89, -82, -83, -84, -76, -76, -76, -72, -76, -76, -59, -82, -79, -82, -72, -59, -78, -63, -88, -60, -72, -19, -72]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_wifi</th>\n      <th>bssid</th>\n      <th>rssi</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>[{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8c', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8d', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8e', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8f', 'rssi': -78}, {'bssid': 'a0:0f:37:96:56:ef', 'rssi': -58}, {'bssid': '88:36:6c:86:75:84', 'rssi': -72}, {'bssid': 'a0:0f:37:96:56:ee', 'rssi': -58}, {'bssid': 'a0:0f:37:96:56:ed', 'rssi': -58}, {'bssid': '86:25:19:b5:b2:a5', 'rssi': -61}, {'bssid': 'a0:0f:37:96:56:ec', 'rssi': -58}, {'bssid': '1e:39:29:8e:fb:e9', 'rssi': -71}, {'bssid': '52:c2:e8:c7:9b:e4', 'rssi': -82}, {'bssid': 'a0:0f:37:96:56:eb', 'rssi': -58}, {'bssid': '12:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '58:86:94:4a:08:b8', 'rssi': -82}, {'bssid': '90:9f:33:28:d0:2e', 'rssi': -78}, {'bssid': '00:26:66:bc:4e:18', 'rssi': -85}, {'bssid': 'f6:0a:f4:43:4b:ba', 'rssi': -45}, {'bssid': '10:e3:c7:09:20:35', 'rssi': -63}, {'bssid': '10:e3:c7:09:20:34', 'rssi': -89}, {'bssid': '1c:39:29:48:04:92', 'rssi': -82}, {'bssid': '12:e3:c7:07:9d:df', 'rssi': -83}, {'bssid': '86:25:19:c3:44:07', 'rssi': -84}, {'bssid': 'a0:0f:37:9a:37:2f', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2e', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2d', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:ec', 'rssi': -72}, {'bssid': 'a0:0f:37:9a:37:2c', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2b', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:eb', 'rssi': -59}, {'bssid': 'c0:25:2f:d8:c1:a6', 'rssi': -82}, {'bssid': '16:7f:67:bb:fa:f8', 'rssi': -79}, {'bssid': '3c:f3:92:ff:00:01', 'rssi': -82}, {'bssid': '06:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '06:09:b4:74:05:eb', 'rssi': -59}, {'bssid': '12:e3:c7:0a:74:d1', 'rssi': -78}, {'bssid': '88:36:6c:a9:6f:8e', 'rssi': -63}, {'bssid': '02:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '00:09:b4:74:05:eb', 'rssi': -60}, {'bssid': '00:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '00:1d:93:93:cf:fe', 'rssi': -19}, {'bssid': '8e:e2:ac:a5:9d:15', 'rssi': -72}]</td>\n      <td>[a0:0f:37:9a:5d:8b, a0:0f:37:9a:5d:8c, a0:0f:37:9a:5d:8d, a0:0f:37:9a:5d:8e, a0:0f:37:9a:5d:8f, a0:0f:37:96:56:ef, 88:36:6c:86:75:84, a0:0f:37:96:56:ee, a0:0f:37:96:56:ed, 86:25:19:b5:b2:a5, a0:0f:37:96:56:ec, 1e:39:29:8e:fb:e9, 52:c2:e8:c7:9b:e4, a0:0f:37:96:56:eb, 12:e3:c7:09:20:34, 58:86:94:4a:08:b8, 90:9f:33:28:d0:2e, 00:26:66:bc:4e:18, f6:0a:f4:43:4b:ba, 10:e3:c7:09:20:35, 10:e3:c7:09:20:34, 1c:39:29:48:04:92, 12:e3:c7:07:9d:df, 86:25:19:c3:44:07, a0:0f:37:9a:37:2f, a0:0f:37:9a:37:2e, a0:0f:37:9a:37:2d, 0a:09:b4:74:05:ec, a0:0f:37:9a:37:2c, a0:0f:37:9a:37:2b, 0a:09:b4:74:05:eb, c0:25:2f:d8:c1:a6, 16:7f:67:bb:fa:f8, 3c:f3:92:ff:00:01, 06:09:b4:74:05:ec, 06:09:b4:74:05:eb, 12:e3:c7:0a:74:d1, 88:36:6c:a9:6f:8e, 02:e3:c7:09:20:34, 00:09:b4:74:05:eb, 00:09:b4:74:05:ec, 00:1d:93:93:cf:fe, 8e:e2:ac:a5:9d:15]</td>\n      <td>[-78, -78, -78, -78, -78, -58, -72, -58, -58, -61, -58, -71, -82, -58, -88, -82, -78, -85, -45, -63, -89, -82, -83, -84, -76, -76, -76, -72, -76, -76, -59, -82, -79, -82, -72, -59, -78, -63, -88, -60, -72, -19, -72]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"def process_mWifi(df,threshold):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    def filter_strong_rssi(df,threshold):\n        filtered_df = df.copy()\n        def filter_row(row):\n            bssids = row['bssid']\n            rssis = row['rssi']\n            # RSSI > threshold 조건 만족하는 항목만 추출\n            filtered = [(b, r) for b, r in zip(bssids, rssis) if r > threshold]\n            if filtered:\n                new_bssids, new_rssis = zip(*filtered)\n                return pd.Series({'bssid': list(new_bssids), 'rssi': list(new_rssis)})\n            else:\n                return pd.Series({'bssid': [], 'rssi': []})\n        filtered_df[['bssid', 'rssi']] = filtered_df.apply(filter_row, axis=1)\n        return filtered_df\n\n    # === wifi 약신호 제거 ===\n    df = filter_strong_rssi(df, threshold=threshold) ####\n\n    features = []\n    grouped = df.groupby(['subject_id', 'lifelog_date'])\n\n    for (subject_id, date), group in grouped:\n        scan_count = len(group)\n        bssid_flat = sum(group['bssid'], [])  # flatten\n        rssi_flat = sum(group['rssi'], [])    # flatten\n\n        unique_bssid_count = len(set(bssid_flat))\n        avg_rssi = sum(rssi_flat) / len(rssi_flat) if rssi_flat else None\n        max_rssi = max(rssi_flat) if rssi_flat else None\n        min_rssi = min(rssi_flat) if rssi_flat else None\n        strong_rssi_ratio = sum(1 for r in rssi_flat if r > -60) / len(rssi_flat) if rssi_flat else 0\n        empty_scan_count = sum(1 for b in group['bssid'] if len(b) == 0)\n\n        # 가장 많이 탐지된 BSSID\n        bssid_counter = Counter(bssid_flat)\n        top_bssid, top_bssid_count = bssid_counter.most_common(1)[0] if bssid_counter else (None, 0)\n\n        first_time = group['timestamp'].min()\n        last_time = group['timestamp'].max()\n        hour_span = (last_time - first_time).total_seconds() / 60  # 분 단위\n\n        features.append({\n            'subject_id': subject_id,\n            'lifelog_date': date,\n            'scan_count': scan_count,\n            'unique_bssid_count': unique_bssid_count,\n            'avg_rssi': avg_rssi,\n            'max_rssi': max_rssi,\n            # 'min_rssi': min_rssi,\n            # 'strong_signal_ratio': strong_rssi_ratio,\n            'empty_scan_count': empty_scan_count,\n            'top_bssid': top_bssid,\n            'top_bssid_count': top_bssid_count,\n            'hour_span_minutes': hour_span\n        })\n\n    return pd.DataFrame(features)","metadata":{"id":"CeDXOGXDcYmo","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:11.702106Z","iopub.execute_input":"2025-05-20T10:50:11.702439Z","iopub.status.idle":"2025-05-20T10:50:11.715319Z","shell.execute_reply.started":"2025-05-20T10:50:11.702404Z","shell.execute_reply":"2025-05-20T10:50:11.714486Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"mWifi2 = process_mWifi(mWifi,threshold=-60)\n\n# check\nprint(f'\\n # mWifi2 shape: {mWifi2.shape}')\nmWifi2.head(1)","metadata":{"id":"pJujoyH8H9Cw","outputId":"64a5ca5c-e818-49f1-8a13-36294e2c5d4f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:11.716249Z","iopub.execute_input":"2025-05-20T10:50:11.716563Z","iopub.status.idle":"2025-05-20T10:50:29.826232Z","shell.execute_reply.started":"2025-05-20T10:50:11.716541Z","shell.execute_reply":"2025-05-20T10:50:29.825020Z"}},"outputs":[{"name":"stdout","text":"\n # mWifi2 shape: (685, 10)\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  scan_count  unique_bssid_count  avg_rssi  max_rssi  \\\n0       id01   2024-06-26          69                  48  -49.6109  -19.0000   \n\n   empty_scan_count          top_bssid  top_bssid_count  hour_span_minutes  \n0                11  86:25:19:9f:9b:be               19           716.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>scan_count</th>\n      <th>unique_bssid_count</th>\n      <th>avg_rssi</th>\n      <th>max_rssi</th>\n      <th>empty_scan_count</th>\n      <th>top_bssid</th>\n      <th>top_bssid_count</th>\n      <th>hour_span_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>69</td>\n      <td>48</td>\n      <td>-49.6109</td>\n      <td>-19.0000</td>\n      <td>11</td>\n      <td>86:25:19:9f:9b:be</td>\n      <td>19</td>\n      <td>716.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"id":"dsAzWwCFYL2q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"FDYMQG6EYMVT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"AWKrkwFSiA3H","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"z0TwqdaHiA6a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ wHr 심박동수\n- Heart rate readings recorded by the smartwatch.\n","metadata":{"id":"GQkZX8zrb53H"}},{"cell_type":"code","source":"wHr['lifelog_date'] = wHr['timestamp'].astype(str).str[:10]\nwHr.head(1)","metadata":{"id":"rQTSKYiTiA-D","outputId":"78206979-2f8d-4cd3-bec6-641f574b9088","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:29.827542Z","iopub.execute_input":"2025-05-20T10:50:29.827817Z","iopub.status.idle":"2025-05-20T10:50:30.452227Z","shell.execute_reply.started":"2025-05-20T10:50:29.827794Z","shell.execute_reply":"2025-05-20T10:50:30.451256Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:23:00   \n\n                                                                                                                                                                                            heart_rate  \\\n0  [134, 134, 135, 133, 134, 135, 134, 135, 134, 133, 133, 133, 132, 132, 131, 131, 131, 132, 132, 134, 134, 134, 132, 130, 128, 126, 126, 126, 127, 129, 130, 129, 130, 130, 127, 127, 126, 125, 123]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>heart_rate</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:23:00</td>\n      <td>[134, 134, 135, 133, 134, 135, 134, 135, 134, 133, 133, 133, 132, 132, 131, 131, 131, 132, 132, 134, 134, 134, 132, 130, 128, 126, 126, 126, 127, 129, 130, 129, 130, 130, 127, 127, 126, 125, 123]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def get_time_block(hour):\n    if 0 <= hour < 6:\n        return 'early_morning'\n    elif 6 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 18:\n        return 'afternoon'\n    else:\n        return 'evening'\n\ndef process_wHr_by_timeblock(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        block_stats = {'subject_id': subj, 'lifelog_date': date}\n\n        for block, block_group in group.groupby('block'):\n            hr_all = []\n            for row in block_group['heart_rate']:\n                parsed = ast.literal_eval(row) if isinstance(row, str) else row\n                hr_all.extend([int(h) for h in parsed if h is not None])\n\n            if not hr_all:\n                continue\n\n            above_100 = [hr for hr in hr_all if hr > 100]\n            block_stats[f'hr_{block}_mean'] = np.mean(hr_all)\n            block_stats[f'hr_{block}_std'] = np.std(hr_all)\n            block_stats[f'hr_{block}_max'] = np.max(hr_all)\n            block_stats[f'hr_{block}_min'] = np.min(hr_all)\n            block_stats[f'hr_{block}_above_100_ratio'] = len(above_100) / len(hr_all)\n\n        results.append(block_stats)\n\n    return pd.DataFrame(results)","metadata":{"id":"QdEddMsBiBAw","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:30.453269Z","iopub.execute_input":"2025-05-20T10:50:30.453598Z","iopub.status.idle":"2025-05-20T10:50:30.464087Z","shell.execute_reply.started":"2025-05-20T10:50:30.453572Z","shell.execute_reply":"2025-05-20T10:50:30.462677Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"wHr2 = process_wHr_by_timeblock(wHr)\n\n# check\nprint(f'\\n # wHr2 shape: {wHr2.shape}')\nwHr2.head(1)","metadata":{"id":"aLFRbbc3cEFJ","outputId":"2dc46be7-6873-4a0c-e803-29c1b0a43154","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:30.465115Z","iopub.execute_input":"2025-05-20T10:50:30.465456Z","iopub.status.idle":"2025-05-20T10:50:41.488063Z","shell.execute_reply.started":"2025-05-20T10:50:30.465431Z","shell.execute_reply":"2025-05-20T10:50:41.486899Z"}},"outputs":[{"name":"stdout","text":"\n # wHr2 shape: (636, 22)\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  hr_afternoon_mean  hr_afternoon_std  \\\n0       id01   2024-06-26            80.5333           12.6366   \n\n   hr_afternoon_max  hr_afternoon_min  hr_afternoon_above_100_ratio  \\\n0          142.0000           59.0000                        0.0773   \n\n   hr_evening_mean  hr_evening_std  hr_evening_max  hr_evening_min  \\\n0          82.4768         10.2932        124.0000         59.0000   \n\n   hr_evening_above_100_ratio  hr_early_morning_mean  hr_early_morning_std  \\\n0                      0.0555                    NaN                   NaN   \n\n   hr_early_morning_max  hr_early_morning_min  \\\n0                   NaN                   NaN   \n\n   hr_early_morning_above_100_ratio  hr_morning_mean  hr_morning_std  \\\n0                               NaN              NaN             NaN   \n\n   hr_morning_max  hr_morning_min  hr_morning_above_100_ratio  \n0             NaN             NaN                         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>hr_afternoon_mean</th>\n      <th>hr_afternoon_std</th>\n      <th>hr_afternoon_max</th>\n      <th>hr_afternoon_min</th>\n      <th>hr_afternoon_above_100_ratio</th>\n      <th>hr_evening_mean</th>\n      <th>hr_evening_std</th>\n      <th>hr_evening_max</th>\n      <th>hr_evening_min</th>\n      <th>hr_evening_above_100_ratio</th>\n      <th>hr_early_morning_mean</th>\n      <th>hr_early_morning_std</th>\n      <th>hr_early_morning_max</th>\n      <th>hr_early_morning_min</th>\n      <th>hr_early_morning_above_100_ratio</th>\n      <th>hr_morning_mean</th>\n      <th>hr_morning_std</th>\n      <th>hr_morning_max</th>\n      <th>hr_morning_min</th>\n      <th>hr_morning_above_100_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>80.5333</td>\n      <td>12.6366</td>\n      <td>142.0000</td>\n      <td>59.0000</td>\n      <td>0.0773</td>\n      <td>82.4768</td>\n      <td>10.2932</td>\n      <td>124.0000</td>\n      <td>59.0000</td>\n      <td>0.0555</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"id":"zARTShxhetw6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ZT7srO3MeuXD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"gRO-TD8_cEIH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ wLight 앰비언트 라이트\n- Ambient light measured by the smartwatch.  \n  - 어두운 밤 0.1 ~ 1 lux 캄캄한 방, 달빛 없는 밤\n  - 가로등 켜진 거리 10 ~ 20 lux 흐릿한 외부 조명\n  - 실내 조명 100 ~ 500 lux 사무실, 일반 거실\n  - 밝은 실외 10,000 ~ 25,000 lux 맑은 날 햇빛\n  - 직사광선 아래 30,000 ~ 100,000 lux 여름 한낮, 매우 강한 햇빛","metadata":{"id":"DYFlbAd_bYca"}},{"cell_type":"code","source":"wLight['lifelog_date'] = wLight['timestamp'].astype(str).str[:10]\nwLight.head(1)","metadata":{"id":"wfAGaJQ0iBHP","outputId":"3dfce3f8-dc19-49e4-afbd-b33682a71e79","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:41.489226Z","iopub.execute_input":"2025-05-20T10:50:41.489600Z","iopub.status.idle":"2025-05-20T10:50:42.540939Z","shell.execute_reply.started":"2025-05-20T10:50:41.489573Z","shell.execute_reply":"2025-05-20T10:50:42.539939Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  w_light lifelog_date\n0       id01 2024-06-26 12:17:00 633.0000   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>w_light</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:17:00</td>\n      <td>633.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"def get_time_block(hour):\n    if 0 <= hour < 6:\n        return 'early_morning'\n    elif 6 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 18:\n        return 'afternoon'\n    else:\n        return 'evening'\n\ndef process_wLight_by_timeblock(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        block_stats = {'subject_id': subj, 'lifelog_date': date}\n\n        for block, block_group in group.groupby('block'):\n            lux = block_group['w_light'].dropna().values\n            if len(lux) == 0:\n                continue\n\n            block_stats[f'wlight_{block}_mean'] = np.mean(lux)\n            block_stats[f'wlight_{block}_std'] = np.std(lux)\n            block_stats[f'wlight_{block}_max'] = np.max(lux)\n            block_stats[f'wlight_{block}_min'] = np.min(lux)\n\n        results.append(block_stats)\n\n    return pd.DataFrame(results)","metadata":{"id":"jIJgKkmjiBOG","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:42.541753Z","iopub.execute_input":"2025-05-20T10:50:42.541986Z","iopub.status.idle":"2025-05-20T10:50:42.549836Z","shell.execute_reply.started":"2025-05-20T10:50:42.541968Z","shell.execute_reply":"2025-05-20T10:50:42.548892Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"wLight2 = process_wLight_by_timeblock(wLight)\n\n# check\nprint(f'\\n # wLight2 shape: {wLight2.shape}')\nwLight2.head(1)","metadata":{"id":"iUhMoFPaiBQw","outputId":"358f2a4f-927a-46da-c83b-6de840556e35","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:42.550790Z","iopub.execute_input":"2025-05-20T10:50:42.551165Z","iopub.status.idle":"2025-05-20T10:50:44.277190Z","shell.execute_reply.started":"2025-05-20T10:50:42.551138Z","shell.execute_reply":"2025-05-20T10:50:44.276030Z"}},"outputs":[{"name":"stdout","text":"\n # wLight2 shape: (664, 18)\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  wlight_afternoon_mean  wlight_afternoon_std  \\\n0       id01   2024-06-26               394.5251             1458.7346   \n\n   wlight_afternoon_max  wlight_afternoon_min  wlight_evening_mean  \\\n0            20874.0000                0.0000              89.0202   \n\n   wlight_evening_std  wlight_evening_max  wlight_evening_min  \\\n0            101.6844            264.0000              0.0000   \n\n   wlight_early_morning_mean  wlight_early_morning_std  \\\n0                        NaN                       NaN   \n\n   wlight_early_morning_max  wlight_early_morning_min  wlight_morning_mean  \\\n0                       NaN                       NaN                  NaN   \n\n   wlight_morning_std  wlight_morning_max  wlight_morning_min  \n0                 NaN                 NaN                 NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>wlight_afternoon_mean</th>\n      <th>wlight_afternoon_std</th>\n      <th>wlight_afternoon_max</th>\n      <th>wlight_afternoon_min</th>\n      <th>wlight_evening_mean</th>\n      <th>wlight_evening_std</th>\n      <th>wlight_evening_max</th>\n      <th>wlight_evening_min</th>\n      <th>wlight_early_morning_mean</th>\n      <th>wlight_early_morning_std</th>\n      <th>wlight_early_morning_max</th>\n      <th>wlight_early_morning_min</th>\n      <th>wlight_morning_mean</th>\n      <th>wlight_morning_std</th>\n      <th>wlight_morning_max</th>\n      <th>wlight_morning_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>394.5251</td>\n      <td>1458.7346</td>\n      <td>20874.0000</td>\n      <td>0.0000</td>\n      <td>89.0202</td>\n      <td>101.6844</td>\n      <td>264.0000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"id":"aAiZk_kWfR8m","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"OcU6IavGfSAw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"kp0et2XoiBZ7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"eX2gVvMzcF7h","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ✔️ wPedo 걸음수\n- Step data recorded by the smartwatch.","metadata":{"id":"tQvyhHhBbmzN"}},{"cell_type":"code","source":"wPedo['lifelog_date'] = wPedo['timestamp'].astype(str).str[:10]\nwPedo.head(1)","metadata":{"id":"3poFH3LmiBc2","outputId":"1ab190bb-5ba8-47f1-85e0-86341913eaf1","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:44.278358Z","iopub.execute_input":"2025-05-20T10:50:44.278605Z","iopub.status.idle":"2025-05-20T10:50:45.499225Z","shell.execute_reply.started":"2025-05-20T10:50:44.278586Z","shell.execute_reply":"2025-05-20T10:50:45.498354Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  step  step_frequency  running_step  \\\n0       id01 2024-06-26 12:09:00    10          0.1667             0   \n\n   walking_step  distance  speed  burned_calories lifelog_date  \n0             0    8.3300 0.1388           0.0000   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>step</th>\n      <th>step_frequency</th>\n      <th>running_step</th>\n      <th>walking_step</th>\n      <th>distance</th>\n      <th>speed</th>\n      <th>burned_calories</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:09:00</td>\n      <td>10</td>\n      <td>0.1667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.3300</td>\n      <td>0.1388</td>\n      <td>0.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"def process_wPedo(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n\n    summary = df.groupby(['subject_id', 'lifelog_date']).agg({\n        'step': 'sum',\n        'step_frequency': 'mean',\n        'distance': 'sum',\n        'speed': ['mean', 'max'],\n        'burned_calories': 'sum'\n    }).reset_index()\n\n    # 컬럼 이름 정리\n    summary.columns = ['subject_id', 'lifelog_date',\n                       'step_sum', 'step_frequency_mean',\n                       'distance_sum', 'speed_mean', 'speed_max',\n                       'burned_calories_sum']\n\n    return summary","metadata":{"id":"48ljm6voiBfd","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.500316Z","iopub.execute_input":"2025-05-20T10:50:45.500691Z","iopub.status.idle":"2025-05-20T10:50:45.507091Z","shell.execute_reply.started":"2025-05-20T10:50:45.500659Z","shell.execute_reply":"2025-05-20T10:50:45.506120Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"wPedo2 = process_wPedo(wPedo)\n\n# check\nprint(f'\\n # wPedo2 shape: {wPedo2.shape}')\nwPedo2.head(1)","metadata":{"id":"Z3kBqrgNhfXN","outputId":"d2b18581-ae64-4f5a-dff8-de5d1ce3d34b","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.508021Z","iopub.execute_input":"2025-05-20T10:50:45.508307Z","iopub.status.idle":"2025-05-20T10:50:45.961254Z","shell.execute_reply.started":"2025-05-20T10:50:45.508284Z","shell.execute_reply":"2025-05-20T10:50:45.960395Z"}},"outputs":[{"name":"stdout","text":"\n # wPedo2 shape: (653, 8)\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  step_sum  step_frequency_mean  distance_sum  \\\n0       id01   2024-06-26      3578               0.0927     2782.1901   \n\n   speed_mean  speed_max  burned_calories_sum  \n0      0.0721     1.5882             189.3191  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>step_sum</th>\n      <th>step_frequency_mean</th>\n      <th>distance_sum</th>\n      <th>speed_mean</th>\n      <th>speed_max</th>\n      <th>burned_calories_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>3578</td>\n      <td>0.0927</td>\n      <td>2782.1901</td>\n      <td>0.0721</td>\n      <td>1.5882</td>\n      <td>189.3191</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"id":"msyUxfoLgpq1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YLPmg7oWhFMa","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Db44ae3XDtKE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"4L_sSEhnDtN5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔥 운동 추정 파생변수\n\n- mActivity 추정행동\n- mGps, 핸드폰 위치\n- wHr 심박동수\n- wPedo 걸음수","metadata":{"id":"io-bh_LODuyv"}},{"cell_type":"code","source":"def average_list_columns(df, list_columns, pk_cols=['subject_id', 'lifelog_date']):\n\n    for col in list_columns:\n\n        def safe_mean(x):\n            if isinstance(x, list):\n                return np.mean(x) if len(x) > 0 else np.nan\n            elif isinstance(x, (int, float, np.integer, np.floating, type(None))):\n                return x\n            elif isinstance(x, (np.ndarray, pd.Series)):\n                return np.mean(x)\n            elif pd.api.types.is_scalar(x) and pd.isna(x):\n                return np.nan\n            else:\n                return np.nan\n\n        df[col] = df[col].apply(safe_mean)\n\n    return df\n\ndef compute_estimated_exercise(mActivity, mGps, wHr, wPedo, minutes):\n\n    # 리스트 평균 처리\n    mGps = mGps.copy()\n    wHr = wHr.copy()\n    mGps = average_list_columns(mGps, ['speed'])\n    Hr = average_list_columns(wHr, ['heart_rate'])\n\n    for df in [mActivity, mGps, wHr, wPedo]:\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    # 5분 지속 조건 판단 함수\n    def sustained_condition(df, cond_col,minutes):\n        df = df[df[cond_col]].sort_values('timestamp')\n        times = df['timestamp']\n        start = prev = None\n        for t in times:\n            if start is None:\n                start = prev = t\n            elif t <= prev + timedelta(minutes=1):\n                prev = t\n            else:\n                if prev - start >= timedelta(minutes=minutes):\n                    return True\n                start = prev = t\n        return (prev - start) >= timedelta(minutes=minutes) if start else False\n\n    # mActivity: m_activity == 7 지속\n    mActivity['m_cond'] = mActivity['m_activity'] == 7\n    act_flag = mActivity.groupby(['subject_id', 'lifelog_date']) \\\n                        .apply(lambda df: sustained_condition(df, 'm_cond',40)) \\\n                        .reset_index(name='act_exe_flag')\n\n    # mGps: speed ∈ [2.5, 5.5] 지속\n    mGps['gps_cond'] = mGps['speed'].between(2.5, 5.5)\n    gps_flag = mGps.groupby(['subject_id', 'lifelog_date']) \\\n                   .apply(lambda df: sustained_condition(df, 'gps_cond',minutes)) \\\n                   .reset_index(name='gps_exe_flag')\n\n    # wHr: hr ≥ 133 상태가 5분 이상 유지\n    wHr['whr_cond'] = wHr['heart_rate'] >= 133\n    hr_flag = wHr.groupby(['subject_id', 'lifelog_date']) \\\n                   .apply(lambda df: sustained_condition(df, 'whr_cond',minutes)) \\\n                   .reset_index(name='hr_exe_flag')\n\n    # wPedo: step ≥ 10000 또는 running_step ≥ 1이 5분 이상\n    pedo_daily = wPedo.groupby(['subject_id', 'lifelog_date'])['step'].sum().reset_index(name='total_steps')\n    pedo_daily['step_flag'] = pedo_daily['total_steps'] >= 10000\n\n    wPedo['r_cond'] = wPedo['running_step'] >= 1\n    run_flag = wPedo.groupby(['subject_id', 'lifelog_date']) \\\n                    .apply(lambda df: sustained_condition(df, 'r_cond', minutes)) \\\n                    .reset_index(name='run_flag')\n\n    pedo_flag = pedo_daily.merge(run_flag, on=['subject_id', 'lifelog_date'], how='outer')\n    pedo_flag['step_flag'] = pedo_flag['step_flag'].fillna(False)\n    pedo_flag['run_flag'] = pedo_flag['run_flag'].fillna(False)\n    pedo_flag['pedo_exe_flag'] = pedo_flag[['step_flag', 'run_flag']].any(axis=1)\n\n    # 병합 및 최종 판단\n    result = act_flag.merge(gps_flag, on=['subject_id', 'lifelog_date'], how='outer') \\\n                     .merge(hr_flag, on=['subject_id', 'lifelog_date'], how='outer') \\\n                     .merge(pedo_flag[['subject_id', 'lifelog_date', 'pedo_exe_flag']], on=['subject_id', 'lifelog_date'], how='outer')\n\n    # NaN 처리 및 1/0 변환\n    for col in ['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']:\n        result[col] = result[col].fillna(False)\n\n    result['pred_exe_flag'] = result[['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']].any(axis=1)\n\n    # 👉 1/0 변환\n    for col in ['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag', 'pred_exe_flag']:\n        result[col] = result[col].astype(int)\n\n    display(result[['pred_exe_flag', 'act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']].sum())\n\n    return result[['subject_id', 'lifelog_date', 'pred_exe_flag', 'act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']]","metadata":{"id":"b8Nz9fSTDtWu","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.962299Z","iopub.execute_input":"2025-05-20T10:50:45.962612Z","iopub.status.idle":"2025-05-20T10:50:45.979685Z","shell.execute_reply.started":"2025-05-20T10:50:45.962588Z","shell.execute_reply":"2025-05-20T10:50:45.978809Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# 추정운동여부\nexeFlag = compute_estimated_exercise(mActivity, mGps, wHr, wPedo,10)\n\n# check\nprint(f'\\n # exeFlag shape: {exeFlag.shape}')\nexeFlag.head(1)","metadata":{"id":"mE0523emDta_","outputId":"79b19748-03c8-47d2-a66f-6ff141b5a938","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.980567Z","iopub.execute_input":"2025-05-20T10:50:45.981010Z","iopub.status.idle":"2025-05-20T10:51:00.002892Z","shell.execute_reply.started":"2025-05-20T10:50:45.980972Z","shell.execute_reply":"2025-05-20T10:51:00.002020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pred_exe_flag    66\nact_exe_flag     31\ngps_exe_flag      5\nhr_exe_flag      18\npedo_exe_flag    19\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"\n # exeFlag shape: (700, 7)\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  pred_exe_flag  act_exe_flag  gps_exe_flag  \\\n0       id01   2024-06-26              0             0             0   \n\n   hr_exe_flag  pedo_exe_flag  \n0            0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>pred_exe_flag</th>\n      <th>act_exe_flag</th>\n      <th>gps_exe_flag</th>\n      <th>hr_exe_flag</th>\n      <th>pedo_exe_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"id":"Di5WcfQSDtfQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YnVbACW6DtkE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"dofyaM3mDtpH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Zbaes4GnDtuy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 🔥 Sleeptime 일어난 건수\n\n- Sleeptime에 (mLight 주변 밝기), (wLight 앰비언트 라이트) 변화 건수","metadata":{"id":"ahIQqHGXGSez"}},{"cell_type":"code","source":"def compute_night_awake_features(df, prefix):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    # 00시~06시 필터\n    df['hour'] = df['timestamp'].dt.hour\n    df_night = df[(df['hour'] >= 0) & (df['hour'] < 6)].copy()\n\n    # 깨어있는 분 계산\n    df_night['awake_minute'] = (df_night[prefix] > 0).astype(int)\n\n    # 깨어난 횟수 계산 (0 → 양수 전환)\n    def count_awake_blocks(x):\n        return ((x > 0) & (x.shift(fill_value=0) == 0)).sum()\n\n    # 그룹별 집계\n    result = df_night.groupby(['subject_id', 'lifelog_date']).agg(\n        awake_minutes=('awake_minute', 'sum'),\n        awake_blocks=(prefix, count_awake_blocks)\n    ).reset_index()\n\n    # 컬럼명 변경\n    result = result.rename(columns={\n        'awake_minutes': f'{prefix}_awake_minutes',\n        'awake_blocks': f'{prefix}_awake_blocks'\n    })\n\n    # train에 결과 합치기 위해서 -1 day 하기\n    result['lifelog_date'] = pd.to_datetime(result['lifelog_date'])\n    result['lifelog_date'] = result['lifelog_date'] + pd.Timedelta(days=-1)\n\n    result['lifelog_date'] = result['lifelog_date'].astype(str)\n\n    return result","metadata":{"id":"AFvyBXsEGPXi","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.004181Z","iopub.execute_input":"2025-05-20T10:51:00.004778Z","iopub.status.idle":"2025-05-20T10:51:00.012444Z","shell.execute_reply.started":"2025-05-20T10:51:00.004753Z","shell.execute_reply":"2025-05-20T10:51:00.011408Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"a1 = compute_night_awake_features(mLight,'m_light')\na2 = compute_night_awake_features(wLight,'w_light')\nsleepWakeCnt = train[['subject_id','lifelog_date']].copy()\n\nsleepWakeCnt = sleepWakeCnt.merge(a1, on=['subject_id','lifelog_date'], how='left')\nsleepWakeCnt = sleepWakeCnt.merge(a2, on=['subject_id','lifelog_date'], how='left')\n\nsleepWakeCnt['awake_minutes'] = sleepWakeCnt[['m_light_awake_minutes','w_light_awake_minutes']].max(axis=1)\nsleepWakeCnt['awake_blocks'] = sleepWakeCnt[['m_light_awake_blocks','w_light_awake_blocks']].max(axis=1)\n\n# check\nsleepWakeCnt.head()","metadata":{"id":"-CpwIQM4GPbo","outputId":"2b1b110a-68d1-4a0d-9a93-73dd8c773bdc","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.013464Z","iopub.execute_input":"2025-05-20T10:51:00.014263Z","iopub.status.idle":"2025-05-20T10:51:00.593742Z","shell.execute_reply.started":"2025-05-20T10:51:00.014237Z","shell.execute_reply":"2025-05-20T10:51:00.592968Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  m_light_awake_minutes  m_light_awake_blocks  \\\n0       id01   2024-06-26                 4.0000                1.0000   \n1       id01   2024-06-27                 4.0000                1.0000   \n2       id01   2024-06-28                 4.0000                1.0000   \n3       id01   2024-06-29                 1.0000                1.0000   \n4       id01   2024-06-30                 2.0000                1.0000   \n\n   w_light_awake_minutes  w_light_awake_blocks  awake_minutes  awake_blocks  \n0                17.0000                3.0000        17.0000        3.0000  \n1                14.0000                3.0000        14.0000        3.0000  \n2                 0.0000                0.0000         4.0000        1.0000  \n3                 0.0000                0.0000         1.0000        1.0000  \n4                 0.0000                0.0000         2.0000        1.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>m_light_awake_minutes</th>\n      <th>m_light_awake_blocks</th>\n      <th>w_light_awake_minutes</th>\n      <th>w_light_awake_blocks</th>\n      <th>awake_minutes</th>\n      <th>awake_blocks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>17.0000</td>\n      <td>3.0000</td>\n      <td>17.0000</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>2024-06-27</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>14.0000</td>\n      <td>3.0000</td>\n      <td>14.0000</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id01</td>\n      <td>2024-06-28</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id01</td>\n      <td>2024-06-29</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id01</td>\n      <td>2024-06-30</td>\n      <td>2.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.0000</td>\n      <td>1.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"id":"v2Br3gMtGPfP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Wkad6IThGPi5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"SSPT0v_uGPnj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"p2hYN0XqGPsD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Ka4Vyd0DGPwO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"XgEdUjOEDt0j","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"LMlyCuPPDt5i","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zE-06HN6gtqy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"b0ICeW88gttt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 📦 merge 데이터\n- train, test 기간 서로 겹침","metadata":{"id":"YhcVIyeuguwP"}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\ntest = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_submission_sample.csv')\n\n# 일자변수 타입 변환\nmACStatus2['lifelog_date'] = mACStatus2['lifelog_date'].astype(str)\nmActivity2['lifelog_date'] = mActivity2['lifelog_date'].astype(str)\nmAmbience2['lifelog_date'] = mAmbience2['lifelog_date'].astype(str)\nmBle2['lifelog_date'] = mBle2['lifelog_date'].astype(str)\nmGps2['lifelog_date'] = mGps2['lifelog_date'].astype(str)\nmLight2['lifelog_date'] = mLight2['lifelog_date'].astype(str)\nmScreenStatus2['lifelog_date'] = mScreenStatus2['lifelog_date'].astype(str)\nmUsageStats2['lifelog_date'] = mUsageStats2['lifelog_date'].astype(str)\nmWifi2['lifelog_date'] = mWifi2['lifelog_date'].astype(str)\nwHr2['lifelog_date'] = wHr2['lifelog_date'].astype(str)\nwLight2['lifelog_date'] = wLight2['lifelog_date'].astype(str)\nwPedo2['lifelog_date'] = wPedo2['lifelog_date'].astype(str)\n\n# ---- new ----\n\nexeFlag['lifelog_date'] = exeFlag['lifelog_date'].astype(str)\nsleepWakeCnt['lifelog_date'] = sleepWakeCnt['lifelog_date'].astype(str)","metadata":{"id":"ylxgRVjO0cPS","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.594558Z","iopub.execute_input":"2025-05-20T10:51:00.595005Z","iopub.status.idle":"2025-05-20T10:51:00.626409Z","shell.execute_reply.started":"2025-05-20T10:51:00.594976Z","shell.execute_reply":"2025-05-20T10:51:00.625654Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"df_list = [\n    mACStatus2,       # 1\n    mActivity2,       # 2\n    mAmbience2,       # 3\n    mBle2,            # 4\n    mGps2,            # 5\n    mLight2,          # 6\n    mScreenStatus2,   # 7\n    mUsageStats2,     # 8\n    mWifi2,           # 9\n    wHr2,             # 10\n    wLight2,          # 11\n    wPedo2,           # 12\n    # ---- new ----\n    sleepWakeCnt,\n    exeFlag\n]\n\ndata = reduce(lambda left, right: pd.merge(left, right, on=['subject_id', 'lifelog_date'], how='outer'), df_list)\ndata['lifelog_date'] = data['lifelog_date'].astype(str)\n\n# 중복체크\nprint(data.shape)\nprint(data[['subject_id','lifelog_date']].drop_duplicates().shape)\n\n# merge\ntrain2 = train.merge(data, on=['subject_id','lifelog_date'], how='left')\ntest2 = test.merge(data, on=['subject_id','lifelog_date'], how='left')\n\n# 저장\nprint('# train  shape:',train.shape)\nprint('# train2 shape:',test2.shape)\nprint('# test   shape:',test.shape)\nprint('# test2  shape:',test2.shape)","metadata":{"id":"wyqyR1HyKtYM","outputId":"34fe6de5-75ad-4d39-9526-22bba0447e80","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.627379Z","iopub.execute_input":"2025-05-20T10:51:00.627647Z","iopub.status.idle":"2025-05-20T10:51:00.692714Z","shell.execute_reply.started":"2025-05-20T10:51:00.627626Z","shell.execute_reply":"2025-05-20T10:51:00.691720Z"}},"outputs":[{"name":"stdout","text":"(700, 166)\n(700, 2)\n# train  shape: (450, 9)\n# train2 shape: (250, 173)\n# test   shape: (250, 9)\n# test2  shape: (250, 173)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"# 저장\ntrain2.to_parquet(f\"train_0512.parquet\")\ntest2.to_parquet(f\"test_0512.parquet\")","metadata":{"id":"FJHeu7wQpSdL","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.693779Z","iopub.execute_input":"2025-05-20T10:51:00.694455Z","iopub.status.idle":"2025-05-20T10:51:00.761839Z","shell.execute_reply.started":"2025-05-20T10:51:00.694422Z","shell.execute_reply":"2025-05-20T10:51:00.760770Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"","metadata":{"id":"JApa_DpNpSf8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"KCkzm9hupSoY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"JBZKGmxSRBQW","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 📌 모델 학습","metadata":{"id":"QO4m6vmGjlkC"}},{"cell_type":"code","source":"# train2 = pd.read_parquet(f\"/content/drive/MyDrive/data/train_v07141.parquet\")\n# test2 = pd.read_parquet(f\"/content/drive/MyDrive/data/test_v07141.parquet\")","metadata":{"id":"l4qv4t3ULZsR","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.763715Z","iopub.execute_input":"2025-05-20T10:51:00.763984Z","iopub.status.idle":"2025-05-20T10:51:00.767646Z","shell.execute_reply.started":"2025-05-20T10:51:00.763963Z","shell.execute_reply":"2025-05-20T10:51:00.766912Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# train = pd.read_parquet(f\"{path}/train2.parquet\")\n# test = pd.read_parquet(f\"{path}/test2.parquet\")\ntrain = train2.copy()\ntest = test2.copy()\n\n# drop_features = ['afterwork_max_label','sleeptime_max_label','worktime_max_label']\ndrop_features = ['top_bssid'] # ,'week_type','week_type_lag1'\ndrop_features = [i for i in drop_features if i in train.columns.tolist()]\nprint('# drop_features:',drop_features)\ntrain = train.drop(columns=drop_features)\ntest = test.drop(columns=drop_features)","metadata":{"id":"FqlfmXYOyXOE","outputId":"08199b45-dd1b-4690-fe08-8907cde8f14a","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.768505Z","iopub.execute_input":"2025-05-20T10:51:00.768797Z","iopub.status.idle":"2025-05-20T10:51:00.791730Z","shell.execute_reply.started":"2025-05-20T10:51:00.768776Z","shell.execute_reply":"2025-05-20T10:51:00.790850Z"}},"outputs":[{"name":"stdout","text":"# drop_features: ['top_bssid']\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"train[['week_type','week_type_lag1']].dtypes","metadata":{"id":"T_q9fmnlCQeo","outputId":"b63c4101-775d-446b-f13d-b8914e00677f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.792648Z","iopub.execute_input":"2025-05-20T10:51:00.793047Z","iopub.status.idle":"2025-05-20T10:51:00.811252Z","shell.execute_reply.started":"2025-05-20T10:51:00.793013Z","shell.execute_reply":"2025-05-20T10:51:00.810427Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"week_type         object\nweek_type_lag1    object\ndtype: object"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"# sleep duration\n\n# train['sleep_duration_min_max'] = train[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].max(axis=1)\n# train['sleep_duration_min_min'] = train[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].min(axis=1)\n\n# train['sleep_duration_hour_max'] = train[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].max(axis=1)\n# train['sleep_duration_hour_min'] = train[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].min(axis=1)\n\n# train['sleep_duration_min_interp_max'] = train[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].max(axis=1)\n# train['sleep_duration_min_interp_min'] = train[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].min(axis=1)\n\n# train['sleep_time_min_max'] = train[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].max(axis=1)\n# train['sleep_time_min_min'] = train[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].min(axis=1)\n\n# test['sleep_duration_min_max'] = test[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].max(axis=1)\n# test['sleep_duration_min_min'] = test[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].min(axis=1)\n\n# test['sleep_duration_hour_max'] = test[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].max(axis=1)\n# test['sleep_duration_hour_min'] = test[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].min(axis=1)\n\n# test['sleep_duration_min_interp_max'] = test[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].max(axis=1)\n# test['sleep_duration_min_interp_min'] = test[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].min(axis=1)\n\n# test['sleep_time_min_max'] = test[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].max(axis=1)\n# test['sleep_time_min_min'] = test[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].min(axis=1)\n\n# 요일 컬럼 추가 (예: 월요일, 화요일, ...)\ntrain['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\ntest['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n\n# 요일\nweekday_map = {\n    0: '월요일', 1: '화요일', 2: '수요일', 3: '목요일',\n    4: '금요일', 5: '토요일', 6: '일요일'\n}\ntrain['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\ntest['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n\n# 월\ntrain['month'] = train['lifelog_date'].dt.month\ntest['month'] = test['lifelog_date'].dt.month\n\n# weekend\ntrain['weekend'] = np.where(train['weekday'].isin(['토요일','일요일']),1,0)\ntest['weekend'] = np.where(test['weekday'].isin(['토요일','일요일']),1,0)\n\n# 공휴일\n공휴일 = [\n     '2024-08-15'\n    ,'2024-09-16'\n    ,'2024-09-17'\n    ,'2024-09-18'\n    ,'2024-10-03'\n    ,'2024-10-09'\n]\ntrain['공휴일'] = np.where(train['lifelog_date'].isin(공휴일),1,0)\ntest['공휴일'] = np.where(test['lifelog_date'].isin(공휴일),1,0)\n\n# 주말 + 공휴일 묶어주기\n# train['weekend'] = np.where( ((train['weekend']==0) & (train['공휴일']==1)), 1, train['weekend'])\n# test['weekend'] = np.where( ((test['weekend']==0) & (test['공휴일']==1)), 1, test['weekend'])","metadata":{"id":"lI616WgshZtT","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.812146Z","iopub.execute_input":"2025-05-20T10:51:00.812420Z","iopub.status.idle":"2025-05-20T10:51:00.844281Z","shell.execute_reply.started":"2025-05-20T10:51:00.812400Z","shell.execute_reply":"2025-05-20T10:51:00.843273Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# 숫자형 컬럼만 선택해서 결측값 -1로 채우기\ntrain[train.select_dtypes(include='number').columns] = train.select_dtypes(include='number').fillna(-1)\ntest[test.select_dtypes(include='number').columns] = test.select_dtypes(include='number').fillna(-1)","metadata":{"id":"UZoZJcI-1b9r","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.845476Z","iopub.execute_input":"2025-05-20T10:51:00.845769Z","iopub.status.idle":"2025-05-20T10:51:00.902606Z","shell.execute_reply.started":"2025-05-20T10:51:00.845747Z","shell.execute_reply":"2025-05-20T10:51:00.901551Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:55:54.028231Z","iopub.execute_input":"2025-05-20T10:55:54.029236Z","iopub.status.idle":"2025-05-20T10:55:54.392249Z","shell.execute_reply.started":"2025-05-20T10:55:54.029190Z","shell.execute_reply":"2025-05-20T10:55:54.391131Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# def get_oof_predictions(X, y, params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n\n#     oof_preds = np.zeros(len(X))  # ✅ 1차원으로 변경\n#     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n#     for train_idx, valid_idx in skf.split(X, y):\n#         X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n#         y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n#         if is_multiclass:\n#             model = LGBMClassifier(**params, objective='multiclass', num_class=num_class)\n#         else:\n#             model = LGBMClassifier(**params)\n\n#         if early_stop:\n#             model.fit(\n#                 X_train, y_train,\n#                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#                 callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n#             )\n#         else:\n#             model.fit(X_train, y_train)\n\n#         preds = model.predict(X_valid)  # ✅ returns 1D array\n#         oof_preds[valid_idx] = preds  # ✅ 1D -> 1D 저장\n\n#     return oof_preds","metadata":{"id":"VuirfLhGp4o0","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:55:54.393913Z","iopub.execute_input":"2025-05-20T10:55:54.394996Z","iopub.status.idle":"2025-05-20T10:55:54.400182Z","shell.execute_reply.started":"2025-05-20T10:55:54.394965Z","shell.execute_reply":"2025-05-20T10:55:54.399105Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"lgb_A = 0.3\nxgb_B = 0.3\ncat_C = 0.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.107804Z","iopub.execute_input":"2025-05-20T11:55:41.108204Z","iopub.status.idle":"2025-05-20T11:55:41.115126Z","shell.execute_reply.started":"2025-05-20T11:55:41.108179Z","shell.execute_reply":"2025-05-20T11:55:41.113216Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n    oof_preds_lgb = np.zeros(len(X))\n    oof_preds_xgb = np.zeros(len(X))\n    oof_preds_cat = np.zeros(len(X))\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    for train_idx, valid_idx in skf.split(X, y):\n        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n        # LightGBM\n        if is_multiclass:\n            lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=num_class)\n        else:\n            lgb_model = LGBMClassifier(**lgb_params)\n\n        # XGBoost\n        if is_multiclass:\n            xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=num_class)\n        else:\n            xgb_model = XGBClassifier(**xgb_params)\n\n        # CatBoost\n        if is_multiclass:\n            cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=num_class)\n        else:\n            cat_model = CatBoostClassifier(**common_params_cat)\n\n        if early_stop:\n            lgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n            )\n            xgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n            cat_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            lgb_model.fit(X_train, y_train)\n            xgb_model.fit(X_train, y_train)\n            cat_model.fit(X_train, y_train)\n\n        # Get predictions\n        lgb_preds = lgb_model.predict(X_valid)\n        xgb_preds = xgb_model.predict(X_valid)\n        cat_preds = cat_model.predict(X_valid).ravel()  # ✅ 2차원 → 1차원\n        \n        # Store predictions\n        oof_preds_lgb[valid_idx] = lgb_preds\n        oof_preds_xgb[valid_idx] = xgb_preds\n        oof_preds_cat[valid_idx] = cat_preds\n\n    # Ensemble predictions (7:3 ratio)\n    oof_preds = lgb_A * oof_preds_lgb + xgb_B * oof_preds_xgb + cat_C * oof_preds_cat\n    \n    if not is_multiclass:\n        oof_preds = (oof_preds > 0.5).astype(int)\n    else:\n        oof_preds = np.round(oof_preds).astype(int)\n\n    return oof_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.116677Z","iopub.execute_input":"2025-05-20T11:55:41.117061Z","iopub.status.idle":"2025-05-20T11:55:41.139194Z","shell.execute_reply.started":"2025-05-20T11:55:41.117034Z","shell.execute_reply":"2025-05-20T11:55:41.138196Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n\n#     train_df = train.copy()\n#     test_df = test.copy()\n\n#     submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n#     submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n\n#     # 타겟\n#     targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n#     targets_binary_name = ['기상직후수면질','취침전신체적피로','취침전스트레스','수면효율','수면잠들기시간']\n#     target_multiclass = 'S1'\n#     all_targets = targets_binary + [target_multiclass]\n\n#     # 노이즈 수준 설정\n#     def add_noise(series, noise_level, seed=3):\n#         rng = np.random.default_rng(seed)\n#         return series * (1 + noise_level * rng.standard_normal(len(series)))\n\n#     noise_level = 0.015  # 필요에 따라 조정\n\n#     # 타겟인코딩\n#     # m = 0: 스무딩 없이 범주별 평균만 사용합니다. 관측 수가 많은 범주에는 적합하지만, 적은 경우 과적합 위험이 있습니다.\n#     # m = 1~10: 일반적인 기본값으로, 대부분의 상황에서 안정적인 성능을 보입니다.\n#     # m = 50~300: 관측 수가 매우 적은 범주가 많거나 데이터가 희소한 경우에 유용합니다.\n#     for tgt in all_targets:\n\n#       encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n\n#       #### 타겟인코딩1\n\n#       subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n#       train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n#       test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n#       global_mean = train_df[tgt].mean()\n#       test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n\n#       # 노이즈 추가\n#       train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n#       test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n\n#       #### 타겟인코딩2\n\n#       # 새로운 범주형 열 생성\n#       train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n#       test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n\n#       # 인코더\n#       encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n#       encoder.fit(train_df[['TMP']], train_df[tgt])\n\n#       # 인코딩 결과를 새로운 열에 저장\n#       train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n#       test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n\n#       # 노이즈 추가\n#       train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n#       test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n\n#       # 불필요한 변수 제거\n#       train_df = train_df.drop(columns=['TMP'])\n#       test_df = test_df.drop(columns=['TMP'])\n\n\n#     # 인코딩\n#     PK = ['sleep_date', 'lifelog_date', 'subject_id']\n#     encoder = LabelEncoder()\n#     categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n#     for col in categorical_features:\n#         print(col)\n#         train_df[col] = encoder.fit_transform(train_df[col])\n#         test_df[col] = encoder.fit_transform(test_df[col])\n\n\n#     # X\n#     X = train_df.drop(columns=PK + all_targets)\n#     test_X = test_df.drop(columns=PK + all_targets)\n#     print(f'# X shape: {X.shape}')\n#     print(f'# test_X shape: {test_X.shape}')\n\n#     print('\\n STEP1: 실험 결과 확인')\n#     print(\"=============== Validation Results ==============\")\n#     total_avg_f1s = []\n#     best_iteration_temp = {k: [] for k in all_targets}\n\n#     val_f1 = []\n#     for col in targets_binary:\n\n#         # binary\n#         y = train_df[col]\n\n#         valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n#         train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n\n#         X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#         X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#         y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#         y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#         # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n\n#         best_param = best_param_dict[col].copy()\n#         best_param['random_state'] = random_state\n#         model = LGBMClassifier(**best_param)\n\n#         if early_stop:\n#             model.fit(\n#                 X_train, y_train,\n#                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#                 callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n#             )\n#             best_iteration_temp[col].append(model.best_iteration_)\n#         else:\n#             model.fit(X_train, y_train)\n#             best_iteration_temp[col].append(1000)\n\n#         pred_valid = model.predict(X_valid)\n#         f1 = f1_score(y_valid, pred_valid, average='macro') ### 수정\n#         val_f1.append(f1)\n\n#     # multi\n#     y = train_df[target_multiclass]\n\n#     X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#     X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#     y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#     y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#     # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n\n#     best_param = best_param_dict['S1'].copy()\n#     best_param['random_state'] = random_state\n#     model = LGBMClassifier(**best_param, objective='multiclass', num_class=3)\n\n#     if early_stop:\n#         model.fit(\n#             X_train, y_train,\n#             eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#             callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n#         )\n#         best_iteration_temp[target_multiclass].append(model.best_iteration_)\n#     else:\n#         model.fit(X_train, y_train)\n#         best_iteration_temp[target_multiclass].append(1000)\n\n#     pred_valid = model.predict(X_valid)\n#     f1 = f1_score(y_valid, pred_valid, average='macro')\n#     val_f1.append(f1)\n\n\n#     avg_f1 = np.mean(val_f1)\n#     total_avg_f1s.append(avg_f1)\n#     detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n#     print(f\" 평균 F1: {avg_f1:.4f} / [상세] {detail}\")\n\n#     best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n\n#     if early_stop==True:\n#       print(\"\\n[best_iteration_dict]\")\n#       for k, v in best_iteration_dict.items():\n#           print(f\"{k}: {v}\")\n\n\n#     print(f\"# 전체 평균 F1: {np.mean(total_avg_f1s):.4f}\")\n#     print(\"================================================\")\n\n#     # modoling with 100% train & no valid\n#     print('\\n STEP2: 전체 데이터로 모델 재학습')\n#     print(\"====== modoling with 100% train & no valid =====\")\n\n#     # binary\n#     binary_preds = {}\n#     binary_preds_proba = {}  # 확률 저장용\n#     for col in targets_binary:\n#         binary_params = best_param_dict[col].copy()\n#         binary_params['random_state'] = random_state\n#         y = train_df[col]\n\n#         if early_stop:\n#           binary_params['n_estimators']=best_iteration_dict[col]\n#           model = LGBMClassifier(**binary_params)\n#           model.fit(X, y)\n#         else:\n#           model = LGBMClassifier(**binary_params)\n#           model.fit(X, y)\n\n#         binary_preds[col] = model.predict(test_X)\n#         binary_preds_proba[col] = model.predict_proba(test_X)\n#         fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n#         top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n#         feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n#         print(f\"[{col}] {feat_str}\")\n\n#     # multiclass\n#     y = train_df['S1']\n#     binary_params = best_param_dict['S1'].copy()\n#     binary_params['random_state'] = random_state\n\n#     if early_stop:\n#       binary_params['n_estimators']=best_iteration_dict['S1']\n#       model = LGBMClassifier(**binary_params)\n#       model.fit(X, y)\n#     else:\n#       model = LGBMClassifier(**binary_params)\n#       model.fit(X, y)\n\n#     multiclass_pred = model.predict(test_X)\n#     multiclass_pred_proba = model.predict_proba(test_X)  # 2D: (N, 3)\n#     fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n#     top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n#     feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n#     print(f\"[S1] {feat_str}\")\n\n#     # 예측 저장\n#     submission_final['S1'] = multiclass_pred\n#     for col in targets_binary:\n#       submission_final[col] = binary_preds[col]\n#     submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n#     fname = f\"submission_{np.mean(total_avg_f1s)}.csv\"\n#     submission_final.to_csv(fname, index=False)\n#     print(f\"# {fname} 저장 완료\")\n#     print(f\"# submission shape:{submission_final.shape}\")\n#     print(\"================================================\")\n\n#     # 확률 결과 추가\n#     submission_proba = submission_final.copy()\n#     for col in targets_binary:\n#         for i in range(2):\n#             submission_proba[f'{col}_class{i}_proba'] = binary_preds_proba[col][:, i]\n#     for i in range(3):\n#         submission_proba[f'S1_class{i}_proba'] = multiclass_pred_proba[:, i]\n    \n#     # 저장\n#     fname_proba = f\"submission_with_proba_{np.mean(total_avg_f1s):.4f}.csv\"\n#     submission_proba.to_csv(fname_proba, index=False)\n#     print(f\"# {fname_proba} 저장 완료 (확률 포함)\")\n\n#     # 모델별 예측결과 비율 비교\n#     a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n#     a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n#     a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n#     a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n#     a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n#     a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n#     result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n#     result.columns = ['학습sum','학습len','학습mean','테스트sum','테스트len','테스트mean']\n#     print('\\n STEP3: 예측결과 비교표')\n#     display(result)\n\n#     # === STEP4: OOF 예측 생성 (train set에 대해) ===\n\n#     # n_splits = 10\n#     mask = train['month'] != 6\n#     print(f'# k-fold: {n_splits}')\n#     print(f'# train: {len(y[mask])}')\n\n#     oof_f1 = []\n#     print('\\n STEP4: OOF 예측 생성')\n#     oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n#     for col in targets_binary:\n#         params = best_param_dict[col].copy()\n#         params['random_state'] = random_state\n#         y = train_df[col]\n#         oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n#         oof_result[col] = oof_preds\n#         f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n#         oof_f1.append(f1)\n#         print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n\n#     # multiclass\n#     col = 'S1'\n#     params = best_param_dict[col].copy()\n#     params['random_state'] = random_state\n#     y = train_df[col]\n#     oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n#     oof_result[col] = oof_preds\n#     f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n#     oof_f1.append(f1)\n#     print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n#     print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n\n#     # oof_result 저장\n#     fname = f\"oof_result_{np.mean(total_avg_f1s)}.csv\"\n#     oof_result.to_csv(fname, index=False)\n#     print(f\"# {fname} 저장 완료\")\n\n#     return submission_final, oof_result","metadata":{"id":"llyNammy2Q4n","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.297042Z","iopub.execute_input":"2025-05-20T11:55:41.297385Z","iopub.status.idle":"2025-05-20T11:55:41.309931Z","shell.execute_reply.started":"2025-05-20T11:55:41.297357Z","shell.execute_reply":"2025-05-20T11:55:41.308518Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n\n    train_df = train.copy()\n    test_df = test.copy()\n\n    submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n    submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n\n    # 타겟\n    targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n    targets_binary_name = ['기상직후수면질','취침전신체적피로','취침전스트레스','수면효율','수면잠들기시간']\n    target_multiclass = 'S1'\n    all_targets = targets_binary + [target_multiclass]\n\n    # 노이즈 수준 설정\n    def add_noise(series, noise_level, seed=3):\n        rng = np.random.default_rng(seed)\n        return series * (1 + noise_level * rng.standard_normal(len(series)))\n\n    noise_level = 0.015  # 필요에 따라 조정\n\n    # 타겟인코딩\n    # m = 0: 스무딩 없이 범주별 평균만 사용합니다. 관측 수가 많은 범주에는 적합하지만, 적은 경우 과적합 위험이 있습니다.\n    # m = 1~10: 일반적인 기본값으로, 대부분의 상황에서 안정적인 성능을 보입니다.\n    # m = 50~300: 관측 수가 매우 적은 범주가 많거나 데이터가 희소한 경우에 유용합니다.\n    for tgt in all_targets:\n\n      encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n\n      #### 타겟인코딩1\n\n      subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n      train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n      test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n      global_mean = train_df[tgt].mean()\n      test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n\n      # 노이즈 추가\n      train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n      test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n\n      #### 타겟인코딩2\n\n      # 새로운 범주형 열 생성\n      train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n      test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n\n      # 인코더\n      encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n      encoder.fit(train_df[['TMP']], train_df[tgt])\n\n      # 인코딩 결과를 새로운 열에 저장\n      train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n      test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n\n      # 노이즈 추가\n      train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n      test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n\n      # 불필요한 변수 제거\n      train_df = train_df.drop(columns=['TMP'])\n      test_df = test_df.drop(columns=['TMP'])\n\n\n    # 인코딩\n    PK = ['sleep_date', 'lifelog_date', 'subject_id']\n    encoder = LabelEncoder()\n    categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n    for col in categorical_features:\n        print(col)\n        train_df[col] = encoder.fit_transform(train_df[col])\n        test_df[col] = encoder.fit_transform(test_df[col])\n\n\n    # X\n    X = train_df.drop(columns=PK + all_targets)\n    test_X = test_df.drop(columns=PK + all_targets)\n    print(f'# X shape: {X.shape}')\n    print(f'# test_X shape: {test_X.shape}')\n\n    print('\\n STEP1: 실험 결과 확인')\n    print(\"=============== Validation Results ==============\")\n    total_avg_f1s = []\n    best_iteration_temp = {k: [] for k in all_targets}\n\n    val_f1 = []\n    for col in targets_binary:\n        # binary\n        y = train_df[col]\n\n        valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n        train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n\n        X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n        X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n        y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n        y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n\n        # Get parameters for both models\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n            'n_estimators': 1000,\n            'learning_rate': 0.01,\n            'max_depth': 6,\n            'min_child_weight': 1,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'random_state': random_state\n        }\n\n        # Train LightGBM\n        lgb_model = LGBMClassifier(**lgb_params)\n        if early_stop:\n            lgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n            )\n            best_iteration_temp[col].append(lgb_model.best_iteration_)\n        else:\n            lgb_model.fit(X_train, y_train)\n            best_iteration_temp[col].append(1000)\n\n        # Train XGBoost\n        xgb_model = XGBClassifier(**xgb_params)\n        if early_stop:\n            xgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            xgb_model.fit(X_train, y_train)\n\n        # Train Catboost\n        cat_model = CatBoostClassifier(**common_params_cat, loss_function='Logloss')\n        if early_stop:\n            cat_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            cat_model.fit(X_train, y_train)\n\n        # Get predictions and ensemble\n        lgb_pred_valid = lgb_model.predict_proba(X_valid)[:, 1]\n        xgb_pred_valid = xgb_model.predict_proba(X_valid)[:, 1]\n        cat_pred_valid = cat_model.predict_proba(X_valid)[:, 1]\n        pred_valid = (lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid  > 0.5).astype(int)\n        \n        f1 = f1_score(y_valid, pred_valid, average='macro')\n        val_f1.append(f1)\n\n    # multiclass\n    y = train_df[target_multiclass]\n\n    X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n    X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n    y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n    y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n\n    # Get parameters for both models\n    lgb_params = common_params['S1'].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n        'n_estimators': 1000,\n        'learning_rate': 0.01,\n        'max_depth': 6,\n        'min_child_weight': 1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': random_state\n    }\n\n    # Train LightGBM\n    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n    if early_stop:\n        lgb_model.fit(\n            X_train, y_train,\n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n        )\n        best_iteration_temp[target_multiclass].append(lgb_model.best_iteration_)\n    else:\n        lgb_model.fit(X_train, y_train)\n        best_iteration_temp[target_multiclass].append(1000)\n\n    # Train XGBoost\n    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n    if early_stop:\n        xgb_model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            early_stopping_rounds=100,\n            verbose=False\n        )\n    else:\n        xgb_model.fit(X_train, y_train)\n\n    # Train Catboost\n    cat_model = CatBoostClassifier(**common_params_cat2, loss_function='MultiClass', classes_count=3)\n    if early_stop:\n        cat_model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            early_stopping_rounds=100,\n            verbose=False\n        )\n    else:\n        cat_model.fit(X_train, y_train)\n\n    # Get predictions and ensemble\n    lgb_pred_valid = lgb_model.predict_proba(X_valid)\n    xgb_pred_valid = xgb_model.predict_proba(X_valid)\n    cat_pred_valid = cat_model.predict_proba(X_valid)\n    pred_valid = np.argmax(lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid, axis=1)\n    \n    f1 = f1_score(y_valid, pred_valid, average='macro')\n    val_f1.append(f1)\n\n    avg_f1 = np.mean(val_f1)\n    total_avg_f1s.append(avg_f1)\n    detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n    print(f\" 평균 F1: {avg_f1:.4f} / [상세] {detail}\")\n\n    best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n\n    if early_stop==True:\n      print(\"\\n[best_iteration_dict]\")\n      for k, v in best_iteration_dict.items():\n          print(f\"{k}: {v}\")\n\n\n    print(f\"# 전체 평균 F1: {np.mean(total_avg_f1s):.4f}\")\n    print(\"================================================\")\n\n    # modoling with 100% train & no valid\n    print('\\n STEP2: 전체 데이터로 모델 재학습')\n    print(\"====== modoling with 100% train & no valid =====\")\n\n    # binary\n    binary_preds = {}\n    binary_preds_proba = {}\n    for col in targets_binary:\n        # Get parameters for both models\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n            'n_estimators': 1000,\n            'learning_rate': 0.01,\n            'max_depth': 6,\n            'min_child_weight': 1,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'random_state': random_state\n        }\n\n        y = train_df[col]\n\n        if early_stop:\n            lgb_params['n_estimators'] = best_iteration_dict[col]\n            xgb_params['n_estimators'] = best_iteration_dict[col]\n\n        # Train LightGBM\n        lgb_model = LGBMClassifier(**lgb_params)\n        lgb_model.fit(X, y)\n\n        # Train XGBoost\n        xgb_model = XGBClassifier(**xgb_params)\n        xgb_model.fit(X, y)\n\n        # Train CatBoost\n        cat_model = CatBoostClassifier(**common_params_cat)\n        cat_model.fit(X, y)\n\n        # Get predictions and ensemble\n        lgb_pred = lgb_model.predict_proba(test_X)[:, 1]\n        xgb_pred = xgb_model.predict_proba(test_X)[:, 1]\n        cat_pred = cat_model.predict_proba(test_X)[:, 1]\n        binary_preds[col] = (lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred > 0.5).astype(int)\n        binary_preds_proba[col] = lgb_A * lgb_model.predict_proba(test_X) + xgb_B * xgb_model.predict_proba(test_X) + cat_C * cat_model.predict_proba(test_X)\n\n        # Feature importance (using LightGBM's importance)\n        fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n        top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n        feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n        print(f\"[{col}] {feat_str}\")\n\n    # multiclass\n    y = train_df['S1']\n    \n    # Get parameters for both models\n    lgb_params = common_params['S1'].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n        'n_estimators': 1000,\n        'learning_rate': 0.01,\n        'max_depth': 6,\n        'min_child_weight': 1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': random_state\n    }\n\n    if early_stop:\n        lgb_params['n_estimators'] = best_iteration_dict['S1']\n        xgb_params['n_estimators'] = best_iteration_dict['S1']\n\n    # Train LightGBM\n    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n    lgb_model.fit(X, y)\n\n    # Train XGBoost\n    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n    xgb_model.fit(X, y)\n\n    # Train CatBoost\n    cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=3)\n    cat_model.fit(X, y)\n\n    # Get predictions and ensemble\n    lgb_pred = lgb_model.predict_proba(test_X)\n    xgb_pred = xgb_model.predict_proba(test_X)\n    cat_pred = cat_model.predict_proba(test_X)\n    multiclass_pred = np.argmax(lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred, axis=1)\n    multiclass_pred_proba = lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred\n\n    # Feature importance\n    fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n    top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n    feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n    print(f\"[S1] {feat_str}\")\n\n    # 예측 저장\n    submission_final['S1'] = multiclass_pred\n    for col in targets_binary:\n      submission_final[col] = binary_preds[col]\n    submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n    fname = f\"submission_{np.mean(total_avg_f1s)}.csv\"\n    submission_final.to_csv(fname, index=False)\n    print(f\"# {fname} 저장 완료\")\n    print(f\"# submission shape:{submission_final.shape}\")\n    print(\"================================================\")\n\n    # 확률 결과 추가\n    submission_proba = submission_final.copy()\n    for col in targets_binary:\n        for i in range(2):\n            submission_proba[f'{col}_class{i}_proba'] = binary_preds_proba[col][:, i]\n    for i in range(3):\n        submission_proba[f'S1_class{i}_proba'] = multiclass_pred_proba[:, i]\n    \n    # 저장\n    fname_proba = f\"submission_with_proba_{np.mean(total_avg_f1s):.4f}.csv\"\n    submission_proba.to_csv(fname_proba, index=False)\n    print(f\"# {fname_proba} 저장 완료 (확률 포함)\")\n\n    # 모델별 예측결과 비율 비교\n    a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n    a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n    a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n    a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n    a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n    a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n    result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n    result.columns = ['학습sum','학습len','학습mean','테스트sum','테스트len','테스트mean']\n    print('\\n STEP3: 예측결과 비교표')\n    display(result)\n\n    # === STEP4: OOF 예측 생성 (train set에 대해) ===\n\n    # n_splits = 10\n    mask = train['month'] != 6\n    print(f'# k-fold: {n_splits}')\n    print(f'# train: {len(y[mask])}')\n\n    oof_f1 = []\n    print('\\n STEP4: OOF 예측 생성')\n    oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n    for col in targets_binary:\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n          'n_estimators': 1000,\n          \"learning_rate\": 0.01,\n          'reg_lambda': 1,\n          'max_depth': 6,\n          'n_jobs': -1,\n          'subsample': 0.8,\n          'colsample_bylevel': 0.8,\n          'min_child_weight': 1,\n          'max_bin': 200,\n          'tree_method': 'hist',\n          'random_state': random_state,\n        }\n        \n        y = train_df[col]\n        oof_preds = get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n        oof_result[col] = oof_preds\n        f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n        oof_f1.append(f1)\n        print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n\n    # multiclass\n    col = 'S1'\n    lgb_params = common_params[col].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n      'n_estimators': 1000,\n      \"learning_rate\": 0.01,\n      'reg_lambda': 1,\n      'max_depth': 6,\n      'n_jobs': -1,\n      'subsample': 0.8,\n      'colsample_bylevel': 0.8,\n      'min_child_weight': 1,\n      'max_bin': 200,\n      'tree_method': 'hist',\n      'random_state': random_state,\n    }\n    \n    \n    y = train_df[col]\n    oof_preds = get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n    oof_result[col] = oof_preds\n    f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n    oof_f1.append(f1)\n    print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n    print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n\n    # oof_result 저장\n    fname = f\"oof_result_{np.mean(total_avg_f1s)}.csv\"\n    oof_result.to_csv(fname, index=False)\n    print(f\"# {fname} 저장 완료\")\n\n    return submission_final, oof_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.328489Z","iopub.execute_input":"2025-05-20T11:55:41.329504Z","iopub.status.idle":"2025-05-20T11:55:41.382818Z","shell.execute_reply.started":"2025-05-20T11:55:41.329431Z","shell.execute_reply":"2025-05-20T11:55:41.381724Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"\"\"\"\nweek_type\nweek_type_lag1\nweekday\n# X shape: (450, 168)\n# test_X shape: (250, 168)\n\n STEP1: 실험 결과 확인\n=============== Validation Results ==============\n 평균 F1: 0.6322 / [상세] Q1(기상직후수면질):0.7278 Q2(취침전신체적피로):0.7122 Q3(취침전스트레스):0.6830 S2(수면효율):0.5726 S3(수면잠들기시간):0.6686 S1(S1):0.4293\n# 전체 평균 F1: 0.6322\n================================================\n\n STEP2: 전체 데이터로 모델 재학습\n====== modoling with 100% train & no valid =====\n[Q1] Q1_te2(557), light_night_mean(469), wake_time_ratio(405), wake_time_diff_lag1(340), 통화_time(326), Q1_te(325), sleep_duration_diff(242), activehour_unique_label_count(200), ble_class_others_ratio_worktime(175), wake_time(155)\n[Q2] Q2_te2(2791), total_screen_time(351), wake_up_early_minutes(331), speed_le5_max(307), rolling_wake_time_3d(288), rolling_sleep_time_3d(233), sleep_time_diff(224), Q2_te(198), wlight_evening_mean(182), hr_evening_std(176)\n[Q3] Q3_te2(2199), light_max(366), sleep_duration_diff_lag1(274), sleep_duration_min(227), sleep_duration_ratio(211), screen_time_vs_avg_pct(187), lat_change(181), all_VEHICLE_minutes(179), sleep_time(177), 통화_time(167)\n[S2] S2_te(3725), S2_te2(2773), wake_time_diff_lag1(340), light_max(292), light_night_mean(245), S1_te2(189), ble_class_unknwn_ratio_sleeptime(179), 통화_time(175), sleep_duration_lag1(171), sleep_duration_min(170)\n[S3] S3_te(639), light_night_mean(443), S3_te2(336), ble_rssi_mean_afterwork(256), hr_evening_min(242), activehour_unique_label_count(242), ble_class_unknwn_ratio_sleeptime(235), wlight_evening_mean(231), sleep_time_diff_lag1(230), vehicle_minutes(180)\n[S1] S1_te2(3990), S1_te(661), sleep_duration_ratio(646), wake_time_ratio(554), sleep_duration_diff(452), sleep_duration_min(429), vehicle_minutes(427), rolling_wake_time_3d(410), speed_le5_max(408), hour_span_minutes(379)\n# /content/drive/MyDrive/data/submission_0.6322252622334963.csv 저장 완료\n# submission shape:(250, 9)\n================================================\n\n STEP3: 예측결과 비교표\n학습sum\t학습len\t학습mean\t테스트sum\t테스트len\t테스트mean\nQ1\t223\t450\t0.4956\t131\t250\t0.5240\nQ2\t253\t450\t0.5622\t150\t250\t0.6000\nQ3\t270\t450\t0.6000\t173\t250\t0.6920\nS1\t390\t450\t0.8667\t202\t250\t0.8080\nS2\t293\t450\t0.6511\t170\t250\t0.6800\nS3\t298\t450\t0.6622\t171\t250\t0.6840\n\n\n# k-fold: 5\n# train: 392\n\n STEP4: OOF 예측 생성\n[OOF - Q1] F1 score: 0.6976\n[OOF - Q2] F1 score: 0.7041\n[OOF - Q3] F1 score: 0.6605\n[OOF - S2] F1 score: 0.6610\n[OOF - S3] F1 score: 0.7106\n[OOF - S1] F1 score: 0.5233\n[OOF] F1 score: 0.6595\n# /content/drive/MyDrive/data/oof_result_0.6322252622334963.csv 저장 완료\n\"\"\"\n\n# 공통 하이퍼파라미터\ncommon_params = {\n  'n_estimators': 5000,\n  \"learning_rate\": 0.01,\n  # \"shrinkage_rate\": 0.12,\n  # 'min_data_in_leaf':2,\n  # 'bagging_fraction':0.9,\n  # 'feature_fraction':0.6,\n  'lambda_l1': 5,\n  'lambda_l2': 1,\n  # 'max_depth': 4,\n  'n_jobs': -1,\n  'verbosity': -1\n}\n\n# 모델별 세부 하이퍼파라미터\nbest_param_dict = {'Q1': {'learning_rate': 0.1473150575266255,\n  'shrinkage_rate': 0.08585454450680065,\n  'min_data_in_leaf': 13,\n  'bagging_fraction': 0.5900885111562433,\n  'feature_fraction': 0.7398526832500182,\n  'lambda_l1': 0.7309384079752819,\n  'lambda_l2': 0.010419978985191203,\n  'max_depth': 2},\n 'Q2': {'learning_rate': 0.1433742819325529,\n  'shrinkage_rate': 0.4777741359643458,\n  'min_data_in_leaf': 11,\n  'bagging_fraction': 0.8942012129234453,\n  'feature_fraction': 0.3442323511952453,\n  'lambda_l1': 0.11108296857244106,\n  'lambda_l2': 0.5000682520529595,\n  'max_depth': 11},\n 'Q3': {'learning_rate': 0.005440413154494791,\n  'shrinkage_rate': 0.4869550654391126,\n  'min_data_in_leaf': 5,\n  'bagging_fraction': 0.992720410336095,\n  'feature_fraction': 0.10854085794750301,\n  'lambda_l1': 8.765258863766789,\n  'lambda_l2': 0.010911793484805324,\n  'max_depth': -1},\n 'S1': {'learning_rate': 0.19808502263166988,\n  'shrinkage_rate': 0.3292477285579064,\n  'min_data_in_leaf': 9,\n  'bagging_fraction': 0.5929013243246726,\n  'feature_fraction': 0.8481981135327139,\n  'lambda_l1': 0.010377995886618164,\n  'lambda_l2': 0.6226891522266145,\n  'max_depth': 10},\n 'S2': {'learning_rate': 0.27099064035077214,\n  'shrinkage_rate': 0.028901883938906636,\n  'min_data_in_leaf': 9,\n  'bagging_fraction': 0.8134249396247819,\n  'feature_fraction': 0.2321570003912355,\n  'lambda_l1': 8.780092357464005,\n  'lambda_l2': 9.605716023562762,\n  'max_depth': 7},\n 'S3': {'learning_rate': 0.14542046442644,\n  'shrinkage_rate': 0.3047247759570036,\n  'min_data_in_leaf': 10,\n  'bagging_fraction': 0.8493532899163512,\n  'feature_fraction': 0.7940889257506005,\n  'lambda_l1': 9.299803284110112,\n  'lambda_l2': 0.12938944891518922,\n  'max_depth': 6}\n}\n\n# 공통 하이퍼파라미터 대체 (이상한 모델의 경우)\nbest_param_dict['Q3'] = common_params\nbest_param_dict['S1'] = common_params\nbest_param_dict['S2'] = common_params\nbest_param_dict['S3'] = common_params\nbest_param_dict['Q1'] = common_params\nbest_param_dict['Q2'] = common_params\n\n# 전체 평균 F1: 0.6069\n# [OOF] F1 score: 0.6491\n# [OOF - Q1] F1 score: 0.6913\n# [OOF - Q2] F1 score: 0.7078\n# [OOF - Q3] F1 score: 0.6432\n# [OOF - S2] F1 score: 0.6542\n# [OOF - S3] F1 score: 0.7088\n# [OOF - S1] F1 score: 0.4895\n\n# 전체 평균 F1: 0.6109\n# [OOF] F1 score: 0.6575\n\n# 전체 평균 F1: 0.6172\n# [OOF] F1 score: 0.6463\n\n# [수정 전]\n# 전체 평균 F1: 0.6308\n# [OOF] F1 score: 0.6526\n\n# [수정 후]\n# 전체 평균 F1: 0.6322\n# [OOF] F1 score: 0.6595\n\n\ncommon_params_cat = {\n    'iterations': 1000,           # n_estimators에 해당\n    'learning_rate': 0.01,\n    'l2_leaf_reg': 1,             # reg_lambda에 해당\n    'depth': 6,                   # max_depth에 해당\n    'thread_count': -1,           # n_jobs에 해당\n    # 'subsample': 0.8,\n    'rsm': 0.8,                   # colsample_bylevel에 해당\n    'min_data_in_leaf': 1,        # min_child_weight에 유사\n    'border_count': 200,          # max_bin에 해당\n    'task_type': 'CPU',           # 'hist'에 대응\n    'random_state' : 41,\n    'verbose' : False\n}\n\ncommon_params_cat2 = {\n    'iterations': 1000,           # n_estimators에 해당\n    'learning_rate': 0.01,\n    'class_weights': [1.048, 0.670, 1.807],  # [0, 1, 2] 순서\n    'l2_leaf_reg': 1,             # reg_lambda에 해당\n    'depth': 6,                   # max_depth에 해당\n    'thread_count': -1,           # n_jobs에 해당\n    # 'subsample': 0.8,\n    'rsm': 0.8,                   # colsample_bylevel에 해당\n    'min_data_in_leaf': 1,        # min_child_weight에 유사\n    'border_count': 200,          # max_bin에 해당\n    'task_type': 'CPU',           # 'hist'에 대응\n    'random_state' : 41,\n    'verbose' : False\n}\n\nsubmission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)","metadata":{"id":"M7sjChm1-ZaF","outputId":"2b847b8e-2d61-4c99-d254-ff950b2719c8","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.478197Z","iopub.execute_input":"2025-05-20T11:55:41.479278Z","iopub.status.idle":"2025-05-20T12:15:05.549458Z","shell.execute_reply.started":"2025-05-20T11:55:41.479244Z","shell.execute_reply":"2025-05-20T12:15:05.548487Z"}},"outputs":[{"name":"stdout","text":"week_type\nweek_type_lag1\nweekday\n# X shape: (450, 179)\n# test_X shape: (250, 179)\n\n STEP1: 실험 결과 확인\n=============== Validation Results ==============\n 평균 F1: 0.6451 / [상세] Q1(기상직후수면질):0.7229 Q2(취침전신체적피로):0.7588 Q3(취침전스트레스):0.6520 S2(수면효율):0.5881 S3(수면잠들기시간):0.6822 S1(S1):0.4665\n# 전체 평균 F1: 0.6451\n================================================\n\n STEP2: 전체 데이터로 모델 재학습\n====== modoling with 100% train & no valid =====\n[Q1] Q1_te2(590), wake_time_ratio(412), light_night_mean(352), Q1_te(288), wake_time_diff_lag1(244), sleep_duration_ratio(218), beforebed_전화_time(215), sleep_duration_diff(203), beforebed_통화_time(200), hr_evening_std(193)\n[Q2] Q2_te2(1992), rolling_wake_time_3d(295), wake_up_early_minutes(262), wlight_evening_mean(262), avg_rssi(226), Q2_te(221), sleep_time_diff(200), activehour_total_screen_time(180), speed_le5_max(167), rolling_sleep_time_3d(165)\n[Q3] Q3_te2(3370), light_max(384), sleep_duration_diff_lag1(255), sleep_duration_min(235), activehour_통화_time(227), lat_change(163), Q3_te(160), sleep_time(151), hr_evening_max(149), wake_time_diff_lag1(144)\n[S2] S2_te2(1968), S2_te(1638), beforebed_total_screen_time(389), wake_time_diff_lag1(294), light_max(255), sleep_duration_min(205), sleep_duration_ratio(200), S1_te2(196), avg_rssi(189), light_night_mean(185)\n[S3] S3_te(2008), light_night_mean(444), S3_te2(369), ble_rssi_mean_afterwork(246), ble_class_unknwn_ratio_sleeptime(231), sleep_time_diff_lag1(231), activehour_unique_label_count(229), hr_evening_min(221), wlight_early_morning_max(200), vehicle_minutes(187)\n[S1] S1_te2(3985), S1_te(939), beforebed_screen_time_vs_avg_pct(866), sleep_duration_min(722), wake_time_ratio(709), sleep_duration_ratio(578), beforebed_total_screen_time(488), hour_span_minutes(450), sleep_duration_diff(408), rolling_wake_time_3d(381)\n# submission_0.6450682487167021.csv 저장 완료\n# submission shape:(250, 9)\n================================================\n# submission_with_proba_0.6451.csv 저장 완료 (확률 포함)\n\n STEP3: 예측결과 비교표\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    학습sum  학습len  학습mean  테스트sum  테스트len  테스트mean\nQ1    223    450  0.4956     130     250   0.5200\nQ2    253    450  0.5622     155     250   0.6200\nQ3    270    450  0.6000     173     250   0.6920\nS1    390    450  0.8667     208     250   0.8320\nS2    293    450  0.6511     170     250   0.6800\nS3    298    450  0.6622     169     250   0.6760","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>학습sum</th>\n      <th>학습len</th>\n      <th>학습mean</th>\n      <th>테스트sum</th>\n      <th>테스트len</th>\n      <th>테스트mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Q1</th>\n      <td>223</td>\n      <td>450</td>\n      <td>0.4956</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0.5200</td>\n    </tr>\n    <tr>\n      <th>Q2</th>\n      <td>253</td>\n      <td>450</td>\n      <td>0.5622</td>\n      <td>155</td>\n      <td>250</td>\n      <td>0.6200</td>\n    </tr>\n    <tr>\n      <th>Q3</th>\n      <td>270</td>\n      <td>450</td>\n      <td>0.6000</td>\n      <td>173</td>\n      <td>250</td>\n      <td>0.6920</td>\n    </tr>\n    <tr>\n      <th>S1</th>\n      <td>390</td>\n      <td>450</td>\n      <td>0.8667</td>\n      <td>208</td>\n      <td>250</td>\n      <td>0.8320</td>\n    </tr>\n    <tr>\n      <th>S2</th>\n      <td>293</td>\n      <td>450</td>\n      <td>0.6511</td>\n      <td>170</td>\n      <td>250</td>\n      <td>0.6800</td>\n    </tr>\n    <tr>\n      <th>S3</th>\n      <td>298</td>\n      <td>450</td>\n      <td>0.6622</td>\n      <td>169</td>\n      <td>250</td>\n      <td>0.6760</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"# k-fold: 5\n# train: 392\n\n STEP4: OOF 예측 생성\n[OOF - Q1] F1 score: 0.7185\n[OOF - Q2] F1 score: 0.6855\n[OOF - Q3] F1 score: 0.6542\n[OOF - S2] F1 score: 0.6712\n[OOF - S3] F1 score: 0.6949\n[OOF - S1] F1 score: 0.5423\n[OOF] F1 score: 0.6611\n# oof_result_0.6450682487167021.csv 저장 완료\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"","metadata":{"id":"JB23rMBGBDD6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"biUlibpQBDHH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"-omUNJKu4FQ2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"kXkq6d_UZvW2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"6OtuWwCdZvjl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Tizi0KM8ZvxZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"oAy96acfohaC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ccOGl_LVohd3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"7_alWM8Rohih","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zYhYMpt9ohm_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"pI8vcwS0ohrk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2KeVlJrCohwO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zhYJGws1oh1b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"0GhN3UK5Zv2H","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"3WcoqLu_2Kpl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"EOL5Sj6aCMXz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"C4wkMmnRwRQV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"OmKky7O2wRSx","trusted":true},"outputs":[],"execution_count":null}]}