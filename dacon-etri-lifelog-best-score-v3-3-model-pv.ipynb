{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"machine_shape":"hm"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11544904,"sourceType":"datasetVersion","datasetId":7210916}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"> title : Ï†ú 4Ìöå ETRI Ìú¥Î®ºÏù¥Ìï¥ Ïù∏Í≥µÏßÄÎä• ÎÖºÎ¨∏Í≤ΩÏßÑÎåÄÌöå <br>\n> author : hjy,byc <br>","metadata":{"id":"cTgURBTcpY0Q"}},{"cell_type":"markdown","source":"In our study, we used smartphones, smartwatches, sleep sensors, and self-recording apps to collect daily life logs and sleep health records of study participants in 2024.The data collection procedures and methods followed a similar approach to those used in previous studies. Here, we puÔªøblicly provide the following 12 data items, which comprise a total of 700 days' worth of lifelog data, strictly for non-commercial and academic research purposes only.\n- mACStatus: Indicates whether the smartphone is currently being charged.\n- mActivity: Value calculated by the Google Activity Recognition API.\n- mAmbience: Ambient sound identification labels and their respective probabilities.\n- mBle: Bluetooth devices around individual subject.\n- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n- mLight: Ambient light measured by the smartphone.\n- mScreenStatus: Indicates whether the smartphone screen is in use.\n- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n- mWifi: Wifi devices around individual subject.\n- wHr: Heart rate readings recorded by the smartwatch.\n- wLight: Ambient light measured by the smartwatch.\n- wPedo: Step data recorded by the smartwatch.","metadata":{"id":"2QhncbejZIfV"}},{"cell_type":"markdown","source":"For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records. Each metric consists of values categorized into either two levels (0, 1) or three levels (0, 1, 2), depending on the specific metric. The detailed classification criteria for each metric's levels will be provided in a separate document.These\nmetrics assign a value of 0 for sleep records that do not meet the recommended guidelines.For instance, the first questionnaire metric (Q1) is assigned a value of 1 on days when an\nindividual‚Äôs self-reported sleep quality exceeds their average over the experimental period, and 0 when it\nfalls below that average. Similarly, the second and third metrics (Q2 and Q3) are assigned a value of 0\non days when the participant‚Äôs fatigue and stress levels, respectively, exceed their average, and a value of\n1 when these levels are below average.\n\n- Q1: Overall sleep quality as perceived by a subject immediately after waking up.\n- Q2: Physical fatigue of a subject just before sleep.\n- Q3: Stress level experienced by a subject just before sleep.\n- S1: Adherence to sleep guidelines for total sleep time (TST).\n- S2: Adherence to sleep guidelines for sleep efficiency (SE).\n- S3: Adherence to sleep guidelines for sleep onset latency (SOL, or SL).\n\nÏàòÎ©¥ Í±¥Í∞ï, ÌîºÎ°ú, Ïä§Ìä∏Î†àÏä§ ÏòàÏ∏°ÏùÑ ÏúÑÌïú ÌïôÏäµ Î™®Îç∏ÏùÑ ÌõàÎ†®ÏãúÌÇ§Í∏∞ ÏúÑÌï¥, ÏàòÎ©¥ ÏÑºÏÑú Îç∞Ïù¥ÌÑ∞ÏôÄ ÏûêÍ∏∞ Î≥¥Í≥†Ïãù ÏÑ§Î¨∏ Í∏∞Î°ùÏùÑ Í∏∞Î∞òÏúºÎ°ú Îã§ÏùåÏùò 6Í∞ÄÏßÄ ÏßÄÌëúÎ•º ÎèÑÏ∂úÌñàÏäµÎãàÎã§.\nÍ∞Å ÏßÄÌëúÎäî Ìï¥Îãπ Ìï≠Î™©Ïóê Îî∞Îùº Îëê ÏàòÏ§Ä(0, 1) ÎòêÎäî ÏÑ∏ ÏàòÏ§Ä(0, 1, 2)ÏúºÎ°ú Íµ¨Î∂ÑÎêú Í∞íÏùÑ Í∞ÄÏßëÎãàÎã§.\nÍ∞Å ÏßÄÌëúÏùò ÏÑ∏Î∂Ä Î∂ÑÎ•ò Í∏∞Ï§ÄÏùÄ Î≥ÑÎèÑÏùò Î¨∏ÏÑúÏóêÏÑú Ï†úÍ≥µÎê† ÏòàÏ†ïÏûÖÎãàÎã§.\n\n- Q1: Í∏∞ÏÉÅ ÏßÅÌõÑ Î≥∏Ïù∏Ïù¥ Ïù∏ÏßÄÌïú Ï†ÑÎ∞òÏ†ÅÏù∏ ÏàòÎ©¥Ïùò Ïßà\n - 0: Í∞úÏù∏ ÌèâÍ∑† Ïù¥Ìïò\n - 1: Í∞úÏù∏ ÌèâÍ∑† Ïù¥ÏÉÅ\n- Q2: Ï∑®Ïπ® ÏßÅÏ†Ñ Î≥∏Ïù∏Ïù¥ ÎäêÎÇÄ Ïã†Ï≤¥Ï†Å ÌîºÎ°ú ÏàòÏ§Ä\n - 0: ÎÜíÏùÄ ÌîºÎ°ú ÏàòÏ§Ä\n - 1: ÎÇÆÏùÄ ÌîºÎ°ú ÏàòÏ§Ä\n- Q3: Ï∑®Ïπ® ÏßÅÏ†Ñ Î≥∏Ïù∏Ïù¥ ÎäêÎÇÄ Ïä§Ìä∏Î†àÏä§ ÏàòÏ§Ä\n - 0: ÎÜíÏùÄ Ïä§Ìä∏Î†àÏä§ ÏàòÏ§Ä\n - 1: ÎÇÆÏùÄ Ïä§Ìä∏Î†àÏä§ ÏàòÏ§Ä\n- S1: Ï¥ù ÏàòÎ©¥ ÏãúÍ∞Ñ(TST) Í∞ÄÏù¥ÎìúÎùºÏù∏ÏùÑ Ï§ÄÏàòÌñàÎäîÏßÄ 3LEVELS\n - 0: Í∞ÄÏù¥ÎìúÎùºÏù∏ ÎØ∏Ï§ÄÏàò\n - 1: Í∞ÄÏù¥ÎìúÎùºÏù∏ Î∂ÄÎ∂ÑÏ†Å Ï§ÄÏàò\n - 2: Í∞ÄÏù¥ÎìúÎùºÏù∏ ÏôÑÏ†Ñ Ï§ÄÏàò\n- S2: ÏàòÎ©¥ Ìö®Ïú®(SE) Í∞ÄÏù¥ÎìúÎùºÏù∏ÏùÑ Ï§ÄÏàòÌñàÎäîÏßÄ Ïó¨Î∂Ä\n- (SE: Ïû†ÏûêÎ¶¨Ïóê ÎàÑÏõå ÏûàÏóàÎçò Ï†ÑÏ≤¥ ÏãúÍ∞Ñ ÎåÄÎπÑ, Ïã§Ï†úÎ°ú Ïû†Îì† ÏãúÍ∞ÑÏùò ÎπÑÏú®)\n - 0: Í∞ÄÏù¥ÎìúÎùºÏù∏ ÎØ∏Ï§ÄÏàò\n - 1: Í∞ÄÏù¥ÎìúÎùºÏù∏ Ï§ÄÏàò\n- S3: ÏàòÎ©¥ Ïû†Îì§Í∏∞ ÏßÄÏó∞ ÏãúÍ∞Ñ(SOL ÎòêÎäî SL) Í∞ÄÏù¥ÎìúÎùºÏù∏ÏùÑ Ï§ÄÏàòÌñàÎäîÏßÄ Ïó¨Î∂Ä\n- (SOL: Ïû†ÏûêÎ¶¨Ïóê ÎàÑÏö¥ ÏàúÍ∞ÑÎ∂ÄÌÑ∞ Ïã§Ï†úÎ°ú Ïû†ÎìúÎäî Îç∞ÍπåÏßÄ Í±∏Î¶∞ ÏãúÍ∞Ñ)\n - 0: Í∞ÄÏù¥ÎìúÎùºÏù∏ ÎØ∏Ï§ÄÏàò\n - 1: Í∞ÄÏù¥ÎìúÎùºÏù∏ Ï§ÄÏàò","metadata":{"id":"QkY5S7k0ZLFG"}},{"cell_type":"markdown","source":"### üì¶ ÎùºÏù¥Î∏åÎü¨Î¶¨","metadata":{"id":"sDVNXLQtLU6X"}},{"cell_type":"code","source":"! pip install haversine\n! pip install optuna\n! pip install category_encoders\nimport pandas as pd\nimport numpy as np\nimport os\nimport sys\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\nimport warnings\nfrom tqdm.auto import tqdm\nfrom collections import Counter\nfrom scipy.stats import entropy\nfrom haversine import haversine  # ÏÑ§Ïπò ÌïÑÏöî: pip install haversine\n\nwarnings.filterwarnings('ignore')","metadata":{"id":"MN6iwVhQpR_a","outputId":"0f4a5220-adf6-4d9d-de5c-3f4cce30ace6","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:29:56.777950Z","iopub.execute_input":"2025-05-20T10:29:56.778632Z","iopub.status.idle":"2025-05-20T10:30:13.536734Z","shell.execute_reply.started":"2025-05-20T10:29:56.778593Z","shell.execute_reply":"2025-05-20T10:30:13.535485Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: haversine in /usr/local/lib/python3.11/dist-packages (2.9.0)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->optuna) (2.4.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->optuna) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->optuna) (2024.2.0)\nRequirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.7.0)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\nRequirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.3)\nRequirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\nRequirement already satisfied: scikit-learn<1.6.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.2.2)\nRequirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.2)\nRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->category_encoders) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->category_encoders) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.6.0,>=1.0.0->category_encoders) (3.6.0)\nRequirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (25.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->category_encoders) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->category_encoders) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->category_encoders) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->category_encoders) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->category_encoders) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport ast\nfrom tqdm import tqdm  # ‚Üê Ï∂îÍ∞Ä\nfrom math import radians, cos, sin, asin, sqrt\nfrom datetime import time\nfrom datetime import timedelta\nfrom functools import reduce\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import f1_score\nimport glob\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score, roc_curve, f1_score\nfrom sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\nimport lightgbm as lgb\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom category_encoders import TargetEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom lightgbm import LGBMClassifier, log_evaluation, early_stopping\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# seed Í≥†Ï†ï\nSD = 42\nrandom.seed(SD)\nnp.random.seed(SD)\nos.environ['PYTHONHASHSEED'] = str(SD)","metadata":{"id":"cFvEVmxWsRH4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:13.538430Z","iopub.execute_input":"2025-05-20T10:30:13.538936Z","iopub.status.idle":"2025-05-20T10:30:26.331957Z","shell.execute_reply.started":"2025-05-20T10:30:13.538899Z","shell.execute_reply":"2025-05-20T10:30:26.330827Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# pandas ÏòµÏÖò\npd.set_option('display.max_columns', 999)\npd.set_option('display.max_rows', 999)\npd.set_option('display.max_colwidth', None)\npd.set_option('display.float_format', lambda x: '%0.4f' % x)","metadata":{"id":"gIbC9LQkv6T4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.332853Z","iopub.execute_input":"2025-05-20T10:30:26.333485Z","iopub.status.idle":"2025-05-20T10:30:26.339138Z","shell.execute_reply.started":"2025-05-20T10:30:26.333458Z","shell.execute_reply":"2025-05-20T10:30:26.337769Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(1)","metadata":{"id":"38uzdH-UYh_3","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.341555Z","iopub.execute_input":"2025-05-20T10:30:26.341877Z","iopub.status.idle":"2025-05-20T10:30:26.369956Z","shell.execute_reply.started":"2025-05-20T10:30:26.341844Z","shell.execute_reply":"2025-05-20T10:30:26.368726Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nfrom io import StringIO\n\nstring = \"\"\"\nsubject_id\tsleep_date\nid01\t2024-07-24\nid01\t2024-07-27\nid01\t2024-08-18\nid01\t2024-08-19\nid01\t2024-08-20\nid01\t2024-08-21\nid01\t2024-08-22\nid01\t2024-08-24\nid01\t2024-08-25\nid01\t2024-08-26\nid01\t2024-08-27\nid01\t2024-08-28\nid01\t2024-08-29\nid01\t2024-08-30\nid02\t2024-08-23\nid02\t2024-08-24\nid02\t2024-09-16\nid02\t2024-09-17\nid02\t2024-09-19\nid02\t2024-09-20\nid02\t2024-09-21\nid02\t2024-09-22\nid02\t2024-09-23\nid02\t2024-09-24\nid02\t2024-09-25\nid02\t2024-09-26\nid02\t2024-09-27\nid02\t2024-09-28\nid03\t2024-08-30\nid03\t2024-09-01\nid03\t2024-09-02\nid03\t2024-09-03\nid03\t2024-09-05\nid03\t2024-09-06\nid03\t2024-09-07\nid04\t2024-09-03\nid04\t2024-09-04\nid04\t2024-09-05\nid04\t2024-09-06\nid04\t2024-09-07\nid04\t2024-09-08\nid04\t2024-09-09\nid04\t2024-10-08\nid04\t2024-10-09\nid04\t2024-10-10\nid04\t2024-10-11\nid04\t2024-10-12\nid04\t2024-10-13\nid04\t2024-10-14\nid05\t2024-10-19\nid05\t2024-10-23\nid05\t2024-10-24\nid05\t2024-10-25\nid05\t2024-10-26\nid05\t2024-10-27\nid05\t2024-10-28\nid06\t2024-07-25\nid06\t2024-07-26\nid06\t2024-07-27\nid06\t2024-07-28\nid06\t2024-07-29\nid06\t2024-07-30\nid06\t2024-07-31\nid07\t2024-07-07\nid07\t2024-07-08\nid07\t2024-07-09\nid07\t2024-07-10\nid07\t2024-07-11\nid07\t2024-07-12\nid07\t2024-07-13\nid07\t2024-07-30\nid07\t2024-08-01\nid07\t2024-08-02\nid07\t2024-08-03\nid07\t2024-08-04\nid07\t2024-08-05\nid07\t2024-08-06\nid08\t2024-08-28\nid08\t2024-08-29\nid08\t2024-08-30\nid08\t2024-08-31\nid08\t2024-09-01\nid08\t2024-09-02\nid08\t2024-09-04\nid09\t2024-08-02\nid09\t2024-08-22\nid09\t2024-08-23\nid09\t2024-08-24\nid09\t2024-08-25\nid09\t2024-08-27\nid09\t2024-08-28\nid09\t2024-08-29\nid09\t2024-08-30\nid09\t2024-08-31\nid09\t2024-09-01\nid09\t2024-09-02\nid09\t2024-09-03\nid09\t2024-09-04\nid10\t2024-08-28\nid10\t2024-08-30\nid10\t2024-08-31\nid10\t2024-09-01\nid10\t2024-09-02\nid10\t2024-09-03\nid10\t2024-09-06\n\"\"\"\n\n# DataFrame ÏÉùÏÑ±\nvalid_ids = pd.read_csv(StringIO(string), sep='\\t')\nvalid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']","metadata":{"id":"S_ZQfubWYiCk","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.371424Z","iopub.execute_input":"2025-05-20T10:30:26.371781Z","iopub.status.idle":"2025-05-20T10:30:26.407149Z","shell.execute_reply.started":"2025-05-20T10:30:26.371748Z","shell.execute_reply":"2025-05-20T10:30:26.405919Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"id":"8ikO0GN_KxyQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"WEHsA6naKx0G","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üì¶ Îç∞Ïù¥ÌÑ∞ ÏùΩÍ∏∞","metadata":{"id":"BodxdJFiv_DJ"}},{"cell_type":"code","source":"path = '/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_data_items/'\n\n# 1\nmACStatus = pd.read_parquet(path+'ch2025_mACStatus.parquet')\nmActivity = pd.read_parquet(path+'ch2025_mActivity.parquet')\nmAmbience = pd.read_parquet(path+'ch2025_mAmbience.parquet')\nmBle = pd.read_parquet(path+'ch2025_mBle.parquet')\nmGps = pd.read_parquet(path+'ch2025_mGps.parquet')\nmLight = pd.read_parquet(path+'ch2025_mLight.parquet')\nmScreenStatus = pd.read_parquet(path+'ch2025_mScreenStatus.parquet')\nmUsageStats = pd.read_parquet(path+'ch2025_mUsageStats.parquet')\nmWifi = pd.read_parquet(path+'ch2025_mWifi.parquet')\nwHr = pd.read_parquet(path+'ch2025_wHr.parquet')\nwLight = pd.read_parquet(path+'ch2025_wLight.parquet')\nwPedo = pd.read_parquet(path+'ch2025_wPedo.parquet')\n\n# 2\ntrain = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\ntest = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_submission_sample.csv')","metadata":{"id":"jw0cx3wwpSE2","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:26.408259Z","iopub.execute_input":"2025-05-20T10:30:26.408633Z","iopub.status.idle":"2025-05-20T10:30:46.316665Z","shell.execute_reply.started":"2025-05-20T10:30:26.408597Z","shell.execute_reply":"2025-05-20T10:30:46.315692Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"id":"Tk45v0V5xiay","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"prr7ohi9xigF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"C4xrmW1wxik-","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ykbdRSk-fv-V","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mACStatus Ìï∏ÎìúÌè∞ Ï∂©Ï†ÑÏÉÅÌÉú\n- Indicates whether the smartphone is currently being charged.\n- m_charging : 0/1 ÏÉÅÌÉú\n- Ìï∏ÎìúÌè∞Ïù¥ Ïò§Îû´ ÎèôÏïà Ï∂©Ï†ÑÌñàÎã§Îäî ÏùòÎØ∏?\n - Ìïú ÏûêÎ¶¨Ïóê Ïû•ÏãúÍ∞Ñ Î®∏Î¨ºÎü¨ ÏûàÏóàÎã§.\n - Ìï∏ÎìúÌè∞ÏùÑ Ïû•ÏãúÍ∞Ñ ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏïòÎã§.  ","metadata":{"id":"3W53JPEe7Oq9"}},{"cell_type":"code","source":"mACStatus['lifelog_date'] = mACStatus['timestamp'].astype(str).str[:10]\nmACStatus.head(1)","metadata":{"id":"KbbCp8nmfwCH","outputId":"8a42beb4-9054-4f70-e5ed-b7f47eb7c1a0","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:46.317669Z","iopub.execute_input":"2025-05-20T10:30:46.317988Z","iopub.status.idle":"2025-05-20T10:30:47.958495Z","shell.execute_reply.started":"2025-05-20T10:30:46.317956Z","shell.execute_reply":"2025-05-20T10:30:47.957275Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_charging lifelog_date\n0       id01 2024-06-26 12:03:00           0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_charging</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"def process_mACStatus(df):\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df = df.sort_values(['subject_id', 'timestamp'])\n\n    results = []\n\n    for (subj, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        status = group['m_charging'].values  # 0/1 ÏÉÅÌÉú\n        times = group['timestamp'].values\n\n        ratio_charging = status.mean()\n        sum_charging = status.sum()\n\n        # ÏÉÅÌÉú Ï†ÑÏù¥ ÌöüÏàò\n        transitions = (status[1:] != status[:-1]).sum()\n\n        # Ïó∞ÏÜçÎêú 1 ÏÉÅÌÉú Í∏∏Ïù¥Îì§\n        lengths = []\n        current_len = 0\n        for val in status:\n            if val == 1:\n                current_len += 1\n            elif current_len > 0:\n                lengths.append(current_len)\n                current_len = 0\n        if current_len > 0:\n            lengths.append(current_len)\n\n        avg_charging_duration = np.mean(lengths) if lengths else 0\n        max_charging_duration = np.max(lengths) if lengths else 0\n\n        results.append({\n            'subject_id': subj,\n            'lifelog_date': lifelog_date,\n            'charging_ratio': ratio_charging,\n            'charging_sum': sum_charging,\n            'charging_transitions': transitions,\n            'avg_charging_duration': avg_charging_duration,\n            'max_charging_duration': max_charging_duration,\n        })\n\n    return pd.DataFrame(results)\n\nmACStatus2 = process_mACStatus(mACStatus)\n\n# check\nprint(f'# mACStatus2 shape: {mACStatus2.shape}')\nmACStatus2.head(1)","metadata":{"id":"PxT8eg447Ztu","outputId":"0c20b19b-c525-4220-82ec-5937ac440a4c","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:47.959382Z","iopub.execute_input":"2025-05-20T10:30:47.959649Z","iopub.status.idle":"2025-05-20T10:30:48.679114Z","shell.execute_reply.started":"2025-05-20T10:30:47.959627Z","shell.execute_reply":"2025-05-20T10:30:48.678228Z"}},"outputs":[{"name":"stdout","text":"# mACStatus2 shape: (700, 7)\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  charging_ratio  charging_sum  charging_transitions  \\\n0       id01   2024-06-26          0.2159           147                    22   \n\n   avg_charging_duration  max_charging_duration  \n0                13.3636                     41  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>charging_ratio</th>\n      <th>charging_sum</th>\n      <th>charging_transitions</th>\n      <th>avg_charging_duration</th>\n      <th>max_charging_duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>0.2159</td>\n      <td>147</td>\n      <td>22</td>\n      <td>13.3636</td>\n      <td>41</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"id":"dIe2M-fE7Zwm","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"LlMDuFeK7ZzZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"8uvGhvN07Z4l","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"D09tdsYf7Z7R","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mActivity Ï∂îÏ†ïÌñâÎèô\n- Value calculated by the Google Activity Recognition API.\n - 0 : IN_VEHICLE\n - 1 : ON_BICYCLE\n - 2 : ON_FOOT\n - 3 : STILL (not moving)\n - 4 : UNKNOWN\n - 5 : TILTING (This often occurs when a device is picked up from a desk or a user who is sitting stands up.)\n - 7 : WALKING\n - 8 : RUNNING\n- Í∑ºÎ¨¥ÏãúÍ∞Ñ   : Ïò§Ï†Ñ 7ÏãúÎ∂ÄÌÑ∞ Ïò§ÌõÑ 6ÏãúÍπåÏßÄ\n- Í∑ºÎ¨¥Ïô∏ÏãúÍ∞Ñ : Ïò§ÌõÑ6ÏãúÎ∂ÄÌÑ∞ 12ÏãúÍπåÏßÄ","metadata":{"id":"dHrp0dO_--pm"}},{"cell_type":"code","source":"mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]\nmActivity.head()","metadata":{"id":"8Qy8JcbJfwEA","outputId":"85352916-ac64-4697-9d79-e6f351f6800d","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:48.680204Z","iopub.execute_input":"2025-05-20T10:30:48.680682Z","iopub.status.idle":"2025-05-20T10:30:50.300945Z","shell.execute_reply.started":"2025-05-20T10:30:48.680655Z","shell.execute_reply":"2025-05-20T10:30:50.299946Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_activity lifelog_date\n0       id01 2024-06-26 12:03:00           4   2024-06-26\n1       id01 2024-06-26 12:04:00           0   2024-06-26\n2       id01 2024-06-26 12:05:00           0   2024-06-26\n3       id01 2024-06-26 12:06:00           0   2024-06-26\n4       id01 2024-06-26 12:07:00           0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_activity</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>4</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>2024-06-26 12:04:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id01</td>\n      <td>2024-06-26 12:05:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id01</td>\n      <td>2024-06-26 12:06:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id01</td>\n      <td>2024-06-26 12:07:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def process_mActivity(df):\n    \"\"\"\n    # Ìè¨Ìï®\n    - 0 : IN_VEHICLE\n    - 1 : ON_BICYCLE\n    - 2 : ON_FOOT\n    - 5 : TILTING (This often occurs when a device is picked up from a desk or a user who is sitting stands up.)\n    - 7 : WALKING\n    - 8 : RUNNING\n\n    # Ï†úÏô∏\n    - 3 : STILL (not moving)\n    - 4 : UNKNOWN\n    \"\"\"\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['hour'] = df['timestamp'].dt.hour\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        row = {'subject_id': subj, 'lifelog_date': date}\n\n        # Ï†ÑÏ≤¥ ÏãúÍ∞ÑÏóêÏÑú 1,2,7,8\n        a1 = group[group['m_activity'].isin([1,2,7,8])]\n        row['all_WALKING_n_ETC_minutes'] = len(a1)\n\n        # Ï†ÑÏ≤¥ ÏãúÍ∞ÑÏóêÏÑú 0 (IN_VEHICLE)\n        a2 = group[group['m_activity'].isin([0])]\n        row['all_VEHICLE_minutes'] = len(a2)\n\n        # Ï†ÑÏ≤¥ ÏãúÍ∞ÑÏóêÏÑú Ïú†Ìö®Ìïú ÌôúÎèô\n        all_valid = group[group['m_activity'].isin([0, 1, 2, 5, 7, 8])]\n        row['all_ACTIVITY_minutes'] = len(all_valid)\n\n        # sleeptime 0~5Ïãú ÏóêÏÑú Ïú†Ìö®Ìïú ÌôúÎèô\n        dawn_valid = all_valid[(all_valid['hour'] >= 0) & (all_valid['hour'] <5)]\n        row['dawn_ACTIVITY_minutes'] = len(dawn_valid)\n\n        results.append(row)\n\n    return pd.DataFrame(results)","metadata":{"id":"Y5AVuzGc7rLx","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:50.304048Z","iopub.execute_input":"2025-05-20T10:30:50.304383Z","iopub.status.idle":"2025-05-20T10:30:50.312311Z","shell.execute_reply.started":"2025-05-20T10:30:50.304358Z","shell.execute_reply":"2025-05-20T10:30:50.311282Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"mActivity2 = process_mActivity(mActivity)\n\n# check\nprint(f'# mActivity2 shape: {mActivity2.shape}')\nmActivity2.head(1)","metadata":{"id":"7l4K9h3etIhs","outputId":"7fcf4c65-e487-441e-aa80-98040de557c5","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:50.313481Z","iopub.execute_input":"2025-05-20T10:30:50.313945Z","iopub.status.idle":"2025-05-20T10:30:52.036272Z","shell.execute_reply.started":"2025-05-20T10:30:50.313912Z","shell.execute_reply":"2025-05-20T10:30:52.035405Z"}},"outputs":[{"name":"stdout","text":"# mActivity2 shape: (700, 6)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  all_WALKING_n_ETC_minutes  all_VEHICLE_minutes  \\\n0       id01   2024-06-26                         32                   89   \n\n   all_ACTIVITY_minutes  dawn_ACTIVITY_minutes  \n0                   121                      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>all_WALKING_n_ETC_minutes</th>\n      <th>all_VEHICLE_minutes</th>\n      <th>all_ACTIVITY_minutes</th>\n      <th>dawn_ACTIVITY_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>32</td>\n      <td>89</td>\n      <td>121</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"id":"bIowSdSDxq1M","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"n-G_pz1G7rTd","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"VB6M-WRHhmQG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"wy-jlVrchmSy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mAmbience Ï∂îÏ†ïÏ£ºÎ≥ÄÏÜåÎ¶¨\n- Ambient sound identification labels and their respective probabilities.\n- Î¨¥Ïä® ÏÜåÎ¶¨Í∞Ä ÎÇúÍ≤å Ï§ëÏöîÌï†Íπå?\n- ÏÉàÎ≤ΩÏóê Î¨¥Ïä® ÏÜåÎ¶¨ÎçòÏßÄ ÏÜåÎ¶¨Í∞Ä ÎÇúÍ≤å Ï§ëÏöîÌïú Í±∏Íπå?\n- Ïó¨Îü¨ Í∞ÄÏßÄ ÏÜåÎ¶¨ Ï§ëÏóê ÎÖ∏Ïù¥Ï¶àÎèÑ Ìè¨Ìï®ÎêòÏñ¥ ÏûàÏùÑÍπå?","metadata":{"id":"bEu5F-6-hmgI"}},{"cell_type":"code","source":"def extract_labels_and_probs(row):\n    items = row['m_ambience']\n    labels = [item[0] for item in items]\n    probs = [item[1] for item in items]\n    return pd.Series({'labels': labels, 'prob': probs})\n\nmAmbience[['labels', 'prob']]  = mAmbience.apply(extract_labels_and_probs, axis=1)\nmAmbience['lifelog_date'] = mAmbience['timestamp'].astype(str).str[:10]\nmAmbience = mAmbience.drop(columns=['m_ambience'])\nmAmbience.head(1)","metadata":{"id":"snxx7CH6gtif","outputId":"164ec02b-f6d8-4b75-dd4d-892f20dafd91","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:30:52.037213Z","iopub.execute_input":"2025-05-20T10:30:52.037625Z","iopub.status.idle":"2025-05-20T10:32:36.075138Z","shell.execute_reply.started":"2025-05-20T10:30:52.037600Z","shell.execute_reply":"2025-05-20T10:32:36.074217Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 13:00:10   \n\n                                                                                                                                                       labels  \\\n0  [Music, Vehicle, Motor vehicle (road), Outside, urban or manmade, Outside, rural or natural, Car, Speech, Inside, large room or hall, Truck, Sound effect]   \n\n                                                                                                                            prob  \\\n0  [0.30902618, 0.081680894, 0.04035286, 0.037144363, 0.032663062, 0.03199804, 0.029806137, 0.01684492, 0.016206821, 0.01591479]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>labels</th>\n      <th>prob</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 13:00:10</td>\n      <td>[Music, Vehicle, Motor vehicle (road), Outside, urban or manmade, Outside, rural or natural, Car, Speech, Inside, large room or hall, Truck, Sound effect]</td>\n      <td>[0.30902618, 0.081680894, 0.04035286, 0.037144363, 0.032663062, 0.03199804, 0.029806137, 0.01684492, 0.016206821, 0.01591479]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def process_mAmbience(df):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['hour'] = df['timestamp'].dt.hour\n\n    # ÏãúÍ∞ÑÎåÄ Î∂ÑÎ•ò\n    df['time_period'] = df['hour'].apply(lambda h: 'sleeptime' if 0 <= h < 5 else 'activehour')\n\n    # explode labels\n    exploded = df.explode('labels')\n\n    # unique label count\n    unique_labels = (\n        exploded.groupby(['subject_id', 'lifelog_date', 'time_period'])['labels']\n        .nunique()\n        .reset_index(name='unique_label_count')\n    )\n\n    # snor Ìè¨Ìï® ÎùºÎ≤® count\n    snor_labels = (\n        exploded[exploded['labels'].astype(str).str.contains('snor', case=False, na=False)]\n        .groupby(['subject_id', 'lifelog_date', 'time_period'])['labels']\n        .count()\n        .reset_index(name='snor_count')\n    )\n\n    # Î≥ëÌï©\n    result = pd.merge(unique_labels, snor_labels, on=['subject_id', 'lifelog_date', 'time_period'], how='outer').fillna(0)\n    result['snor_count'] = result['snor_count'].astype(int)\n    result = result.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    result.columns = [f\"{tp}_{metric}\" for metric, tp in result.columns]\n    result = result.reset_index()\n\n    return result","metadata":{"id":"vTLHu7k24dfJ","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:36.076172Z","iopub.execute_input":"2025-05-20T10:32:36.076528Z","iopub.status.idle":"2025-05-20T10:32:36.086050Z","shell.execute_reply.started":"2025-05-20T10:32:36.076498Z","shell.execute_reply":"2025-05-20T10:32:36.085059Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"mAmbience2 = process_mAmbience(mAmbience)\n\n# check\nprint(f'# mAmbience2 shape: {mAmbience2.shape}')\nmAmbience2.head(1)","metadata":{"id":"4tNjfKEv6eZl","outputId":"34d6ec43-fbaa-41f3-b839-4e8cb708d365","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:36.087445Z","iopub.execute_input":"2025-05-20T10:32:36.087733Z","iopub.status.idle":"2025-05-20T10:32:42.900988Z","shell.execute_reply.started":"2025-05-20T10:32:36.087710Z","shell.execute_reply":"2025-05-20T10:32:42.899822Z"}},"outputs":[{"name":"stdout","text":"# mAmbience2 shape: (700, 6)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  activehour_unique_label_count  \\\n0       id01   2024-06-26                       265.0000   \n\n   sleeptime_unique_label_count  activehour_snor_count  sleeptime_snor_count  \n0                           NaN                 4.0000                   NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>activehour_unique_label_count</th>\n      <th>sleeptime_unique_label_count</th>\n      <th>activehour_snor_count</th>\n      <th>sleeptime_snor_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>265.0000</td>\n      <td>NaN</td>\n      <td>4.0000</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"id":"QCxHeB836ekw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"5QnUfNL-ceIA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"TfbNZ1WsceMN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Yh2wt8LycePt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mBle Î∏îÎ£®Ìà¨Ïä§\n- Bluetooth devices around individual subject.\n - 7936 : Wearable, Headset, AV Device\n - 1796 : Peripheral (ÏûÖÎ†•Ïû•Ïπò) Í≥ÑÏó¥\n - 0 : Ï†ïÎ≥¥ ÏóÜÏùå ÎòêÎäî Ïïå Ïàò ÏóÜÏùå(Unknown)\n - 1084 : Audio/Video (Ïä§ÌîºÏª§, Ìó§ÎìúÏÖã, Ïù¥Ïñ¥Ìè∞, TV Îì±)\n - 524 : Phone (Ìú¥ÎåÄÌè∞, Ïä§ÎßàÌä∏Ìè∞)\n - 1060 : Headphones\n - 284 : commputer (PC, ÎÖ∏Ìä∏Î∂Å, PDA)","metadata":{"id":"tyS90xE7WAJV"}},{"cell_type":"code","source":"def extract_mble_info(row):\n    m_data = row['m_ble']\n    address = [item['address'] for item in m_data]\n    device_class = [item['device_class'] for item in m_data]\n    rssi = [item['rssi'] for item in m_data]\n    return pd.Series({'address': address, 'device_class': device_class, 'rssi': rssi})\n\nmBle[['address','device_class','rssi']] = mBle.apply(extract_mble_info, axis=1)\nmBle['lifelog_date'] = mBle['timestamp'].astype(str).str[:10]\nmBle.head(1)","metadata":{"id":"u9J8u61OV9-V","outputId":"8b4f09bf-5128-41b2-8abe-cd7c8bf0f36f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:42.902253Z","iopub.execute_input":"2025-05-20T10:32:42.902631Z","iopub.status.idle":"2025-05-20T10:32:47.058302Z","shell.execute_reply.started":"2025-05-20T10:32:42.902600Z","shell.execute_reply":"2025-05-20T10:32:47.057421Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:13:00   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 m_ble  \\\n0  [{'address': '00:15:7C:11:80:8D', 'device_class': '0', 'rssi': -82}, {'address': '01:B1:D2:20:9E:3A', 'device_class': '0', 'rssi': -61}, {'address': '04:33:1F:D9:C1:50', 'device_class': '0', 'rssi': -86}, {'address': '06:5C:2D:BC:39:BE', 'device_class': '0', 'rssi': -75}, {'address': '09:42:21:0D:AD:DF', 'device_class': '0', 'rssi': -70}, {'address': '0B:66:0D:D5:9C:4A', 'device_class': '0', 'rssi': -89}, {'address': '10:B5:88:E7:85:69', 'device_class': '0', 'rssi': -89}, {'address': '13:F0:CA:3B:DB:EF', 'device_class': '0', 'rssi': -77}, {'address': '1A:23:C0:8F:43:4D', 'device_class': '0', 'rssi': -66}, {'address': '24:11:53:BB:62:89', 'device_class': '1796', 'rssi': -37}, {'address': '24:2D:F0:EE:1E:D0', 'device_class': '0', 'rssi': -85}, {'address': '26:0C:48:28:15:77', 'device_class': '0', 'rssi': -63}, {'address': '27:C1:C0:8B:82:C9', 'device_class': '0', 'rssi': -88}, {'address': '28:9C:11:73:39:05', 'device_class': '0', 'rssi': -30}, {'address': '34:40:DE:35:F8:65', 'device_class': '0', 'rssi': -93}, {'address': '35:0A:59:BF:75:F5', 'device_class': '0', 'rssi': -72}, {'address': '41:A6:C4:20:E3:2C', 'device_class': '7936', 'rssi': -83}, {'address': '42:6B:51:95:1B:D4', 'device_class': '0', 'rssi': -77}, {'address': '44:B2:0B:78:04:0F', 'device_class': '0', 'rssi': -69}, {'address': '45:37:48:E2:7F:CC', 'device_class': '0', 'rssi': -87}, {'address': '4E:1B:C2:DF:C5:87', 'device_class': '0', 'rssi': -76}, {'address': '4E:9F:1B:A9:56:5D', 'device_class': '0', 'rssi': -66}, {'address': '50:63:B0:82:07:00', 'device_class': '0', 'rssi': -86}, {'address': '53:13:6C:4F:04:D2', 'device_class': '0', 'rssi': -69}, {'address': '54:15:89:95:27:44', 'device_class': '7936', 'rssi': -71}, {'address': '56:0E:2E:B0:D4:11', 'device_class': '0', 'rssi': -61}, {'address': '5A:7A:2E:42:03:B1', 'device_class': '0', 'rssi': -82}, {'address': '5A:9D:3E:AB:38:C6', 'device_class': '0', 'rssi': -83}, {'address': '5E:A6:8E:B8:74:74', 'device_class': '0', 'rssi': -84}, {'address': '5F:BC:08:0F:C1:6A', 'device_class': '0', 'rssi': -87}, {'address': '62:E1:9D:41:F4:AE', 'device_class': '0', 'rssi': -73}, {'address': '67:23:FE:88:69:A8', 'device_class': '0', 'rssi': -88}, {'address': '68:EC:C5:0C:D1:C1', 'device_class': '0', 'rssi': -78}, {'address': '6B:28:DA:C0:1B:29', 'device_class': '0', 'rssi': -75}, {'address': '6F:0B:91:00:33:19', 'device_class': '0', 'rssi': -80}, {'address': '70:7A:4B:82:44:90', 'device_class': '0', 'rssi': -88}, {'address': '7B:62:D4:5B:59:D3', 'device_class': '0', 'rssi': -74}, {'address': '7B:BE:A4:9D:FD:11', 'device_class': '0', 'rssi': -72}, {'address': '7F:FD:C4:00:77:7D', 'device_class': '0', 'rssi': -52}, {'address': 'C4:F0:92:C8:F1:8D', 'device_class': '7936', 'rssi': -87}, {'address': 'C7:3F:2C:7B:86:66', 'device_class': '7936', 'rssi': -89}]   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       address  \\\n0  [00:15:7C:11:80:8D, 01:B1:D2:20:9E:3A, 04:33:1F:D9:C1:50, 06:5C:2D:BC:39:BE, 09:42:21:0D:AD:DF, 0B:66:0D:D5:9C:4A, 10:B5:88:E7:85:69, 13:F0:CA:3B:DB:EF, 1A:23:C0:8F:43:4D, 24:11:53:BB:62:89, 24:2D:F0:EE:1E:D0, 26:0C:48:28:15:77, 27:C1:C0:8B:82:C9, 28:9C:11:73:39:05, 34:40:DE:35:F8:65, 35:0A:59:BF:75:F5, 41:A6:C4:20:E3:2C, 42:6B:51:95:1B:D4, 44:B2:0B:78:04:0F, 45:37:48:E2:7F:CC, 4E:1B:C2:DF:C5:87, 4E:9F:1B:A9:56:5D, 50:63:B0:82:07:00, 53:13:6C:4F:04:D2, 54:15:89:95:27:44, 56:0E:2E:B0:D4:11, 5A:7A:2E:42:03:B1, 5A:9D:3E:AB:38:C6, 5E:A6:8E:B8:74:74, 5F:BC:08:0F:C1:6A, 62:E1:9D:41:F4:AE, 67:23:FE:88:69:A8, 68:EC:C5:0C:D1:C1, 6B:28:DA:C0:1B:29, 6F:0B:91:00:33:19, 70:7A:4B:82:44:90, 7B:62:D4:5B:59:D3, 7B:BE:A4:9D:FD:11, 7F:FD:C4:00:77:7D, C4:F0:92:C8:F1:8D, C7:3F:2C:7B:86:66]   \n\n                                                                                                                                 device_class  \\\n0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1796, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7936, 7936]   \n\n                                                                                                                                                                                                            rssi  \\\n0  [-82, -61, -86, -75, -70, -89, -89, -77, -66, -37, -85, -63, -88, -30, -93, -72, -83, -77, -69, -87, -76, -66, -86, -69, -71, -61, -82, -83, -84, -87, -73, -88, -78, -75, -80, -88, -74, -72, -52, -87, -89]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_ble</th>\n      <th>address</th>\n      <th>device_class</th>\n      <th>rssi</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:13:00</td>\n      <td>[{'address': '00:15:7C:11:80:8D', 'device_class': '0', 'rssi': -82}, {'address': '01:B1:D2:20:9E:3A', 'device_class': '0', 'rssi': -61}, {'address': '04:33:1F:D9:C1:50', 'device_class': '0', 'rssi': -86}, {'address': '06:5C:2D:BC:39:BE', 'device_class': '0', 'rssi': -75}, {'address': '09:42:21:0D:AD:DF', 'device_class': '0', 'rssi': -70}, {'address': '0B:66:0D:D5:9C:4A', 'device_class': '0', 'rssi': -89}, {'address': '10:B5:88:E7:85:69', 'device_class': '0', 'rssi': -89}, {'address': '13:F0:CA:3B:DB:EF', 'device_class': '0', 'rssi': -77}, {'address': '1A:23:C0:8F:43:4D', 'device_class': '0', 'rssi': -66}, {'address': '24:11:53:BB:62:89', 'device_class': '1796', 'rssi': -37}, {'address': '24:2D:F0:EE:1E:D0', 'device_class': '0', 'rssi': -85}, {'address': '26:0C:48:28:15:77', 'device_class': '0', 'rssi': -63}, {'address': '27:C1:C0:8B:82:C9', 'device_class': '0', 'rssi': -88}, {'address': '28:9C:11:73:39:05', 'device_class': '0', 'rssi': -30}, {'address': '34:40:DE:35:F8:65', 'device_class': '0', 'rssi': -93}, {'address': '35:0A:59:BF:75:F5', 'device_class': '0', 'rssi': -72}, {'address': '41:A6:C4:20:E3:2C', 'device_class': '7936', 'rssi': -83}, {'address': '42:6B:51:95:1B:D4', 'device_class': '0', 'rssi': -77}, {'address': '44:B2:0B:78:04:0F', 'device_class': '0', 'rssi': -69}, {'address': '45:37:48:E2:7F:CC', 'device_class': '0', 'rssi': -87}, {'address': '4E:1B:C2:DF:C5:87', 'device_class': '0', 'rssi': -76}, {'address': '4E:9F:1B:A9:56:5D', 'device_class': '0', 'rssi': -66}, {'address': '50:63:B0:82:07:00', 'device_class': '0', 'rssi': -86}, {'address': '53:13:6C:4F:04:D2', 'device_class': '0', 'rssi': -69}, {'address': '54:15:89:95:27:44', 'device_class': '7936', 'rssi': -71}, {'address': '56:0E:2E:B0:D4:11', 'device_class': '0', 'rssi': -61}, {'address': '5A:7A:2E:42:03:B1', 'device_class': '0', 'rssi': -82}, {'address': '5A:9D:3E:AB:38:C6', 'device_class': '0', 'rssi': -83}, {'address': '5E:A6:8E:B8:74:74', 'device_class': '0', 'rssi': -84}, {'address': '5F:BC:08:0F:C1:6A', 'device_class': '0', 'rssi': -87}, {'address': '62:E1:9D:41:F4:AE', 'device_class': '0', 'rssi': -73}, {'address': '67:23:FE:88:69:A8', 'device_class': '0', 'rssi': -88}, {'address': '68:EC:C5:0C:D1:C1', 'device_class': '0', 'rssi': -78}, {'address': '6B:28:DA:C0:1B:29', 'device_class': '0', 'rssi': -75}, {'address': '6F:0B:91:00:33:19', 'device_class': '0', 'rssi': -80}, {'address': '70:7A:4B:82:44:90', 'device_class': '0', 'rssi': -88}, {'address': '7B:62:D4:5B:59:D3', 'device_class': '0', 'rssi': -74}, {'address': '7B:BE:A4:9D:FD:11', 'device_class': '0', 'rssi': -72}, {'address': '7F:FD:C4:00:77:7D', 'device_class': '0', 'rssi': -52}, {'address': 'C4:F0:92:C8:F1:8D', 'device_class': '7936', 'rssi': -87}, {'address': 'C7:3F:2C:7B:86:66', 'device_class': '7936', 'rssi': -89}]</td>\n      <td>[00:15:7C:11:80:8D, 01:B1:D2:20:9E:3A, 04:33:1F:D9:C1:50, 06:5C:2D:BC:39:BE, 09:42:21:0D:AD:DF, 0B:66:0D:D5:9C:4A, 10:B5:88:E7:85:69, 13:F0:CA:3B:DB:EF, 1A:23:C0:8F:43:4D, 24:11:53:BB:62:89, 24:2D:F0:EE:1E:D0, 26:0C:48:28:15:77, 27:C1:C0:8B:82:C9, 28:9C:11:73:39:05, 34:40:DE:35:F8:65, 35:0A:59:BF:75:F5, 41:A6:C4:20:E3:2C, 42:6B:51:95:1B:D4, 44:B2:0B:78:04:0F, 45:37:48:E2:7F:CC, 4E:1B:C2:DF:C5:87, 4E:9F:1B:A9:56:5D, 50:63:B0:82:07:00, 53:13:6C:4F:04:D2, 54:15:89:95:27:44, 56:0E:2E:B0:D4:11, 5A:7A:2E:42:03:B1, 5A:9D:3E:AB:38:C6, 5E:A6:8E:B8:74:74, 5F:BC:08:0F:C1:6A, 62:E1:9D:41:F4:AE, 67:23:FE:88:69:A8, 68:EC:C5:0C:D1:C1, 6B:28:DA:C0:1B:29, 6F:0B:91:00:33:19, 70:7A:4B:82:44:90, 7B:62:D4:5B:59:D3, 7B:BE:A4:9D:FD:11, 7F:FD:C4:00:77:7D, C4:F0:92:C8:F1:8D, C7:3F:2C:7B:86:66]</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1796, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 7936, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7936, 7936]</td>\n      <td>[-82, -61, -86, -75, -70, -89, -89, -77, -66, -37, -85, -63, -88, -30, -93, -72, -83, -77, -69, -87, -76, -66, -86, -69, -71, -61, -82, -83, -84, -87, -73, -88, -78, -75, -80, -88, -74, -72, -52, -87, -89]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"def process_mBle(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['hour'] = df['timestamp'].dt.hour\n\n    # ÏãúÍ∞ÑÎåÄ Î∂ÑÎ•ò\n    def map_time_period(row):\n        if 0 <= row['hour'] < 7:\n            return 'sleeptime'\n        elif 7 <= row['hour'] < 18:\n            return 'worktime'\n        else:\n            return 'afterwork'\n\n    df['time_period'] = df.apply(map_time_period, axis=1)\n\n    features = []\n\n    for idx, row in df.iterrows():\n        entry = ast.literal_eval(row['m_ble']) if isinstance(row['m_ble'], str) else row['m_ble']\n\n        rssi_list = []\n        class_0_cnt = 0\n        class_other_cnt = 0\n\n        for device in entry:\n            try:\n                rssi = int(device['rssi'])\n                rssi_list.append(rssi)\n\n                device_class = str(device['device_class'])\n                if device_class == '0':\n                    class_0_cnt += 1\n                else:\n                    class_other_cnt += 1\n            except:\n                continue  # malformed record\n\n        feature = {\n            'subject_id': row['subject_id'],\n            'lifelog_date': row['lifelog_date'],\n            'time_period': row['time_period'],\n            'ble_class_unknwn_cnt': class_0_cnt,\n            'ble_class_others_cnt': class_other_cnt,\n            'ble_count': len(rssi_list),\n            'ble_rssi_mean': np.mean(rssi_list) if rssi_list else np.nan,\n            'ble_rssi_min': np.min(rssi_list) if rssi_list else np.nan,\n            'ble_rssi_max': np.max(rssi_list) if rssi_list else np.nan,\n        }\n        features.append(feature)\n\n    return pd.DataFrame(features)\n\ndef summarize_mBle_daily(df):\n\n    # row Îã®ÏúÑ BLE feature Ï∂îÏ∂ú\n    df = process_mBle(df)\n\n    # ÌïòÎ£® + ÏãúÍ∞ÑÎåÄÎ≥ÑÎ°ú groupby\n    grouped = df.groupby(['subject_id', 'lifelog_date', 'time_period']).agg({\n        'ble_class_unknwn_cnt': 'sum',\n        'ble_class_others_cnt': 'sum',\n        'ble_rssi_mean': 'mean',\n        'ble_rssi_min': 'min',\n        'ble_rssi_max': 'max',\n    }).reset_index()\n\n    # Ï¥ùÌï© Íµ¨Ìï¥ÏÑú ÎπÑÏú® Í≥ÑÏÇ∞\n    total_cnt = grouped['ble_class_unknwn_cnt'] + grouped['ble_class_others_cnt']\n    grouped['ble_class_unknwn_ratio'] = grouped['ble_class_unknwn_cnt'] / total_cnt.replace(0, np.nan)\n    grouped['ble_class_others_ratio'] = grouped['ble_class_others_cnt'] / total_cnt.replace(0, np.nan)\n\n    # ÌïÑÏöî ÏóÜÎäî cnt Ïª¨Îüº Ï†úÍ±∞\n    grouped.drop(columns=[\n        'ble_class_unknwn_cnt',\n        'ble_class_others_cnt'\n    ], inplace=True)\n\n    # pivotÌï¥ÏÑú time_periodÎ≥ÑÎ°ú ÌéºÏπòÍ∏∞\n    final = grouped.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    final.columns = ['_'.join(col).strip() for col in final.columns.values]\n    final = final.reset_index()\n\n    return final","metadata":{"id":"j8IaISJNceZq","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:47.059387Z","iopub.execute_input":"2025-05-20T10:32:47.059645Z","iopub.status.idle":"2025-05-20T10:32:47.072720Z","shell.execute_reply.started":"2025-05-20T10:32:47.059625Z","shell.execute_reply":"2025-05-20T10:32:47.071752Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"mBle2 = summarize_mBle_daily(mBle)\n\n# check\nprint(f'\\n # mBle2 shape: {mBle2.shape}')\nmBle2.head(1)","metadata":{"id":"SACo8zOKcedD","outputId":"68d72eb9-d2d8-4268-b8cd-78e362cc620e","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:47.073848Z","iopub.execute_input":"2025-05-20T10:32:47.074105Z","iopub.status.idle":"2025-05-20T10:32:49.814717Z","shell.execute_reply.started":"2025-05-20T10:32:47.074083Z","shell.execute_reply":"2025-05-20T10:32:49.813230Z"}},"outputs":[{"name":"stdout","text":"\n # mBle2 shape: (651, 17)\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  ble_rssi_mean_afterwork  ble_rssi_mean_sleeptime  \\\n0       id01   2024-06-26                 -76.2155                      NaN   \n\n   ble_rssi_mean_worktime  ble_rssi_min_afterwork  ble_rssi_min_sleeptime  \\\n0                -75.0522                -92.0000                     NaN   \n\n   ble_rssi_min_worktime  ble_rssi_max_afterwork  ble_rssi_max_sleeptime  \\\n0               -94.0000                -43.0000                     NaN   \n\n   ble_rssi_max_worktime  ble_class_unknwn_ratio_afterwork  \\\n0               -27.0000                            0.9237   \n\n   ble_class_unknwn_ratio_sleeptime  ble_class_unknwn_ratio_worktime  \\\n0                               NaN                           0.9421   \n\n   ble_class_others_ratio_afterwork  ble_class_others_ratio_sleeptime  \\\n0                            0.0763                               NaN   \n\n   ble_class_others_ratio_worktime  \n0                           0.0579  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>ble_rssi_mean_afterwork</th>\n      <th>ble_rssi_mean_sleeptime</th>\n      <th>ble_rssi_mean_worktime</th>\n      <th>ble_rssi_min_afterwork</th>\n      <th>ble_rssi_min_sleeptime</th>\n      <th>ble_rssi_min_worktime</th>\n      <th>ble_rssi_max_afterwork</th>\n      <th>ble_rssi_max_sleeptime</th>\n      <th>ble_rssi_max_worktime</th>\n      <th>ble_class_unknwn_ratio_afterwork</th>\n      <th>ble_class_unknwn_ratio_sleeptime</th>\n      <th>ble_class_unknwn_ratio_worktime</th>\n      <th>ble_class_others_ratio_afterwork</th>\n      <th>ble_class_others_ratio_sleeptime</th>\n      <th>ble_class_others_ratio_worktime</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>-76.2155</td>\n      <td>NaN</td>\n      <td>-75.0522</td>\n      <td>-92.0000</td>\n      <td>NaN</td>\n      <td>-94.0000</td>\n      <td>-43.0000</td>\n      <td>NaN</td>\n      <td>-27.0000</td>\n      <td>0.9237</td>\n      <td>NaN</td>\n      <td>0.9421</td>\n      <td>0.0763</td>\n      <td>NaN</td>\n      <td>0.0579</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"id":"ZzTh37secegK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"If8EEAGfcejV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tiCtsengLveO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"p5vsYKHoH8lz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mGps, GPS Í∏∞Î∞ò Ìï∏ÎìúÌè∞ ÏúÑÏπò\n- Multiple GPS coordinates measured within a single minute using the smartphone.\n- speedÍ∞Ä 1Î≥¥Îã§ ÌÅ∞Í≤ΩÏö∞ Ï†ïÏßÄ ÏÉÅÌÉúÍ∞Ä ÏïÑÎãàÍ≥† ÏõÄÏßÅÏù¥Í≥† ÏûàÎã§Í≥† ÌåêÎã®\n - 0.5-2 : Í±∏Ïñ¥ÏÑú Ïù¥ÎèôÌïòÎäî Í≤ΩÏö∞  \n - 2-5 : Ï°∞ÍπÖ\n - 5 Ïù¥ÏÉÅ : Ï∞®Î•º ÌÉÄÍ≥† Ïù¥ÎèôÌïòÎäî Í≤ΩÏö∞\n\n- speedÍ∞Ä 0.5-2ÏÇ¨Ïù¥Î•º ÌïòÎ£®Ïóê Î™áÎ∂ÑÎèôÏïà ÏßÄÏÜçÌñàÎäîÏßÄ?\n- speedÍ∞Ä 2-5ÏÇ¨Ïù¥Î•º ÌïòÎ£®Ïóê Î™áÎ∂ÑÎèôÏïà ÏßÄÏÜçÌñàÎäîÏßÄ? (Ïú†ÏÇ∞ÏÜå Ïö¥Îèô ÏãúÍ∞Ñ)\n- speedÍ∞Ä 5Ïù¥ÏÉÅÏùÑ ÌïòÎ£®Ïóê Î™áÎ∂ÑÎèôÏïà ÏßÄÏÜçÌñàÎäîÏßÄ?  ","metadata":{"id":"MOiajFjeRFi-"}},{"cell_type":"code","source":"def extract_gps_info(row):\n    m_data = row['m_gps']\n    altitude = [item['altitude'] for item in m_data]\n    latitude = [item['latitude'] for item in m_data]\n    longitude = [item['longitude'] for item in m_data]\n    speed = [item['speed'] for item in m_data]\n    return pd.Series({'altitude': altitude, 'latitude': latitude, 'longitude': longitude, 'speed': speed})\n\nmGps[['altitude','latitude','longitude','speed']] = mGps.apply(extract_gps_info, axis=1)\nmGps['lifelog_date'] = mGps['timestamp'].astype(str).str[:10]\nmGps = mGps.drop(columns=['m_gps'])\nmGps.head(1)","metadata":{"id":"hV_VT5fZH8rj","outputId":"32415846-4d39-435e-9e76-dc0460cdb4d4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:32:49.816083Z","iopub.execute_input":"2025-05-20T10:32:49.816362Z","iopub.status.idle":"2025-05-20T10:35:55.101821Z","shell.execute_reply.started":"2025-05-20T10:32:49.816319Z","shell.execute_reply":"2025-05-20T10:35:55.100647Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:03:00   \n\n                                                                        altitude  \\\n0  [110.6, 110.8, 110.8, 110.7, 110.7, 110.8, 110.8, 110.8, 110.8, 110.8, 110.8]   \n\n                                                                                                                latitude  \\\n0  [0.2077385, 0.2077759, 0.2077728, 0.20779, 0.2077914, 0.2077972, 0.2078002, 0.2077985, 0.207801, 0.207802, 0.2078011]   \n\n                                                                                                                 longitude  \\\n0  [0.170027, 0.1699851, 0.1699834, 0.1699686, 0.1699708, 0.1699657, 0.1699627, 0.1699631, 0.1699642, 0.1699639, 0.169963]   \n\n                                                                                  speed  \\\n0  [0.0, 0.721, 0.0505, 0.6587, 0.0568, 0.1768, 0.0907, 0.0337, 0.0411, 0.0296, 0.0194]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>altitude</th>\n      <th>latitude</th>\n      <th>longitude</th>\n      <th>speed</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>[110.6, 110.8, 110.8, 110.7, 110.7, 110.8, 110.8, 110.8, 110.8, 110.8, 110.8]</td>\n      <td>[0.2077385, 0.2077759, 0.2077728, 0.20779, 0.2077914, 0.2077972, 0.2078002, 0.2077985, 0.207801, 0.207802, 0.2078011]</td>\n      <td>[0.170027, 0.1699851, 0.1699834, 0.1699686, 0.1699708, 0.1699657, 0.1699627, 0.1699631, 0.1699642, 0.1699639, 0.169963]</td>\n      <td>[0.0, 0.721, 0.0505, 0.6587, 0.0568, 0.1768, 0.0907, 0.0337, 0.0411, 0.0296, 0.0194]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# Í±∞Î¶¨ Í≥ÑÏÇ∞ Ìï®Ïàò\ndef haversine(coord1, coord2, unit='m'):\n    lat1, lon1 = coord1\n    lat2, lon2 = coord2\n    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n    dlat = lat2 - lat1\n    dlon = lon2 - lon1\n    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n    c = 2 * asin(sqrt(a))\n    r = 6371000  # ÏßÄÍµ¨ Î∞òÏßÄÎ¶Ñ(m)\n    return c * r if unit == 'm' else c * r / 1000\n\ndef process_mGps(df):\n    df = df.copy()\n\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['week'] = df['timestamp'].dt.isocalendar().week\n\n    expanded_rows = []\n\n    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing GPS data\"):\n        speeds = ast.literal_eval(row['speed']) if isinstance(row['speed'], str) else row['speed']\n        lats = ast.literal_eval(row['latitude']) if isinstance(row['latitude'], str) else row['latitude']\n        lons = ast.literal_eval(row['longitude']) if isinstance(row['longitude'], str) else row['longitude']\n        alts = ast.literal_eval(row['altitude']) if isinstance(row['altitude'], str) else row['altitude']\n        n = len(speeds)\n        if n > 0:\n            expanded_rows.append(pd.DataFrame({\n                'subject_id': [row['subject_id']] * n,\n                'lifelog_date': [row['lifelog_date']] * n,\n                'timestamp': pd.date_range(start=row['timestamp'], periods=n, freq='1S'),\n                'speed': speeds,\n                'latitude': lats,\n                'longitude': lons,\n                'altitude': alts\n            }))\n\n    expanded_df = pd.concat(expanded_rows, ignore_index=True)\n\n    # Î≤°ÌÑ∞Ìôî\n    speeds = expanded_df['speed'].values\n\n    walk_mask = (0.5 <= speeds) & (speeds < 2)\n    jog_mask = (2 <= speeds) & (speeds < 5)\n    vehicle_mask = (speeds >= 5)\n    le5_mask = (speeds <= 5)\n\n    expanded_df['walk'] = walk_mask.astype(int)\n    expanded_df['jog'] = jog_mask.astype(int)\n    expanded_df['vehicle'] = vehicle_mask.astype(int)\n    expanded_df['le5_speed'] = expanded_df['speed'].where(le5_mask)\n\n    # ÏïÑÏπ®/Ï†ÄÎÖÅ Íµ¨Í∞Ñ Ï°∞Í±¥\n    expanded_df['hour'] = expanded_df['timestamp'].dt.hour\n    morning_condition = (expanded_df['hour'] >= 6) & (expanded_df['hour'] < 9) & (expanded_df['speed'] >= 1)\n    evening_condition = (expanded_df['hour'] >= 21) & (expanded_df['hour'] <= 23) & (expanded_df['speed'] <= 1)\n\n    # Ïù¥Îèô ÌäπÏÑ± Í≥ÑÏÇ∞\n    movement_features = []\n    for (subject_id, lifelog_date), group in expanded_df.groupby(['subject_id', 'lifelog_date']):\n        all_speeds = group['speed'].values\n        all_alts = group['altitude'].values\n        all_lats = group['latitude'].values\n        all_lons = group['longitude'].values\n\n        active_mins = group.shape[0] / 60  # 1Ï¥à Îã®ÏúÑ ‚Üí Î∂Ñ\n        movement_ratio = (all_speeds > 1.0).mean() if len(all_speeds) > 0 else 0\n        alt_change = all_alts[-1] - all_alts[0] if len(all_alts) > 0 else 0\n        lat_change = all_lats[-1] - all_lats[0] if len(all_lats) > 0 else 0\n        lon_change = all_lons[-1] - all_lons[0] if len(all_lons) > 0 else 0\n\n        total_dist = 0.0\n        if len(all_lats) > 1:\n            for i in range(len(all_lats)-1):\n                coord1 = (all_lats[i], all_lons[i])\n                coord2 = (all_lats[i+1], all_lons[i+1])\n                total_dist += haversine(coord1, coord2, unit='m')\n\n        movement_features.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date,\n            'active_minutes': active_mins,\n            'movement_ratio': movement_ratio,\n            'alt_change': alt_change,\n            'lat_change': lat_change,\n            'lon_change': lon_change,\n            'total_distance_m': total_dist\n        })\n\n    movement_df = pd.DataFrame(movement_features)\n\n    # Groupby + Aggregation\n    agg_funcs = {\n        'walk_minutes': ('walk', lambda x: x.sum() / 60),\n        'jog_minutes': ('jog', lambda x: x.sum() / 60),\n        'vehicle_minutes': ('vehicle', lambda x: x.sum() / 60),\n        'speed_le5_max': ('le5_speed', 'max'),\n        'speed_le5_mean': ('le5_speed', 'mean'),\n        'speed_le5_std': ('le5_speed', 'std')\n    }\n\n    grouped = expanded_df.groupby(['subject_id', 'lifelog_date']).agg(**agg_funcs).reset_index()\n    grouped['exercise_flag'] = np.where(grouped['jog_minutes'] >= 5,1,0)\n\n    # ÏïÑÏπ® wakeup time\n    morning_first_movement = (\n        expanded_df[morning_condition]\n        .groupby(['subject_id', 'lifelog_date'])['timestamp']\n        .min()\n        .reset_index()\n        .rename(columns={'timestamp': 'morning_wakeup_time'})\n    )\n\n\n    # ÏµúÏ¢Ö merge\n    final = pd.merge(grouped, movement_df, on=['subject_id', 'lifelog_date'], how='left')\n    final = pd.merge(final, morning_first_movement, on=['subject_id', 'lifelog_date'], how='left')\n\n    # ÏïÑÏπ® wakeup_time Ï≤òÎ¶¨\n    valid_wakeup = final['morning_wakeup_time'].dropna()\n    if not valid_wakeup.empty:\n        total_seconds = valid_wakeup.dt.hour * 3600 + valid_wakeup.dt.minute * 60 + valid_wakeup.dt.second\n        mean_seconds = total_seconds.mean()\n        mean_hour = int(mean_seconds // 3600)\n        mean_minute = int((mean_seconds % 3600) // 60)\n        mean_second = int(mean_seconds % 60)\n        mean_wakeup_time = time(mean_hour, mean_minute, mean_second)\n    else:\n        mean_wakeup_time = time(7, 0, 0)\n\n    final['morning_wakeup_time'] = final['morning_wakeup_time'].fillna(\n        pd.Timestamp.combine(pd.to_datetime('today').date(), mean_wakeup_time)\n    )\n    final['morning_wakeup_time'] = final['morning_wakeup_time'].dt.hour * 100 + final['morning_wakeup_time'].dt.minute\n\n    mean_wakeup_hhmm = mean_wakeup_time.hour * 100 + mean_wakeup_time.minute\n\n    # wake_up_early_minutes\n    def compute_minutes_diff(actual_hhmm, mean_hhmm):\n        actual_hour = actual_hhmm // 100\n        actual_minute = actual_hhmm % 100\n        mean_hour = mean_hhmm // 100\n        mean_minute = mean_hhmm % 100\n        actual_sec = actual_hour * 3600 + actual_minute * 60\n        mean_sec = mean_hour * 3600 + mean_minute * 60\n        return (mean_sec - actual_sec) / 60\n\n    final['wake_up_early_minutes'] = final['morning_wakeup_time'].apply(lambda x: compute_minutes_diff(x, mean_wakeup_hhmm))\n\n    return final","metadata":{"id":"6OwJ7xTDHt3n","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:35:55.102992Z","iopub.execute_input":"2025-05-20T10:35:55.103339Z","iopub.status.idle":"2025-05-20T10:35:55.139791Z","shell.execute_reply.started":"2025-05-20T10:35:55.103290Z","shell.execute_reply":"2025-05-20T10:35:55.138771Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"%%time\n\nmGps2 = process_mGps(mGps)\n\n# check\nprint(f'\\n # mGps2 shape: {mGps2.shape}')\nmGps2.head(1)","metadata":{"id":"vGgV2PjuwpjQ","outputId":"8996b5b2-141c-48d2-89d1-6d536924e23f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:35:55.140860Z","iopub.execute_input":"2025-05-20T10:35:55.141157Z","iopub.status.idle":"2025-05-20T10:49:20.358986Z","shell.execute_reply.started":"2025-05-20T10:35:55.141135Z","shell.execute_reply":"2025-05-20T10:49:20.357402Z"}},"outputs":[{"name":"stderr","text":"Processing GPS data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 800611/800611 [12:01<00:00, 1110.40it/s] \n","output_type":"stream"},{"name":"stdout","text":"\n # mGps2 shape: (660, 17)\nCPU times: user 13min 14s, sys: 37.4 s, total: 13min 51s\nWall time: 13min 25s\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  walk_minutes  jog_minutes  vehicle_minutes  \\\n0       id01   2024-06-26       11.1667       1.3000           3.8667   \n\n   speed_le5_max  speed_le5_mean  speed_le5_std  exercise_flag  \\\n0         4.9907          0.2503         0.5089              0   \n\n   active_minutes  movement_ratio  alt_change  lat_change  lon_change  \\\n0        100.2833          0.1034     -6.7000      0.0229     -0.0757   \n\n   total_distance_m  morning_wakeup_time  wake_up_early_minutes  \n0        29113.5760                  655                 0.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>walk_minutes</th>\n      <th>jog_minutes</th>\n      <th>vehicle_minutes</th>\n      <th>speed_le5_max</th>\n      <th>speed_le5_mean</th>\n      <th>speed_le5_std</th>\n      <th>exercise_flag</th>\n      <th>active_minutes</th>\n      <th>movement_ratio</th>\n      <th>alt_change</th>\n      <th>lat_change</th>\n      <th>lon_change</th>\n      <th>total_distance_m</th>\n      <th>morning_wakeup_time</th>\n      <th>wake_up_early_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>11.1667</td>\n      <td>1.3000</td>\n      <td>3.8667</td>\n      <td>4.9907</td>\n      <td>0.2503</td>\n      <td>0.5089</td>\n      <td>0</td>\n      <td>100.2833</td>\n      <td>0.1034</td>\n      <td>-6.7000</td>\n      <td>0.0229</td>\n      <td>-0.0757</td>\n      <td>29113.5760</td>\n      <td>655</td>\n      <td>0.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"id":"riN0msO6wodn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"rTvpgUsLwvNU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"7oHiJLPfaoSw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"X0k3YkQqaodZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mLight Ï£ºÎ≥Ä Î∞ùÍ∏∞\n- Ambient light measured by the smartphone.\n - Ïñ¥ÎëêÏö¥ Î∞§\t0.1 ~ 1 lux\tÏ∫ÑÏ∫ÑÌïú Î∞©, Îã¨Îπõ ÏóÜÎäî Î∞§\n - Í∞ÄÎ°úÎì± ÏºúÏßÑ Í±∞Î¶¨\t10 ~ 20 lux\tÌùêÎ¶øÌïú Ïô∏Î∂Ä Ï°∞Î™Ö\n - Ïã§ÎÇ¥ Ï°∞Î™Ö\t100 ~ 500 lux\tÏÇ¨Î¨¥Ïã§, ÏùºÎ∞ò Í±∞Ïã§\n - Î∞ùÏùÄ Ïã§Ïô∏\t10,000 ~ 25,000 lux\tÎßëÏùÄ ÎÇ† ÌñáÎπõ\n - ÏßÅÏÇ¨Í¥ëÏÑ† ÏïÑÎûò\t30,000 ~ 100,000 lux\tÏó¨Î¶Ñ ÌïúÎÇÆ, Îß§Ïö∞ Í∞ïÌïú ÌñáÎπõ\n\n- Î∞ùÍ∏∞Ïóê Îî∞ÎùºÏÑú Ïñ∏Ï†ú Î∂àÏùÑ ÎÅÑÍ≥† Ïû†Îì† ÏãúÍ∞Ñ Ï∂îÏ†ï\n- ÏßÅÏÇ¨Í¥ëÏÑ† Ïû†Ïóê Ï¢ãÏùÄ ÏòÅÌñ•ÏùÑ Ï£ºÎäîÏßÄ? (ÎÖºÎ¨∏)\n- Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ x","metadata":{"id":"fSRRKaDlaorj"}},{"cell_type":"code","source":"mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\nmLight.head(1)","metadata":{"id":"-0PzJaYUWfVZ","outputId":"8d9e1170-2b9f-4b00-81f6-4bdeba1803a5","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.361365Z","iopub.execute_input":"2025-05-20T10:49:20.361740Z","iopub.status.idle":"2025-05-20T10:49:20.531500Z","shell.execute_reply.started":"2025-05-20T10:49:20.361712Z","shell.execute_reply":"2025-05-20T10:49:20.530618Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_light lifelog_date\n0       id01 2024-06-26 12:03:00 534.0000   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_light</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>534.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def process_mLight(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['hour'] = df['timestamp'].dt.hour\n    df['is_night'] = df['hour'].apply(lambda h: h >= 22 or h < 6)\n\n    # ÌïòÎ£® ÏöîÏïΩ ÌÜµÍ≥Ñ\n    daily_light = df.groupby(['subject_id', 'lifelog_date']).agg(\n        light_mean=('m_light', 'mean'),\n        light_std=('m_light', 'std'),\n        light_max=('m_light', 'max'),\n        light_min=('m_light', 'min'),\n        light_night_mean=('m_light', lambda x: x[df.loc[x.index, 'is_night']].mean()),\n        light_day_mean=('m_light', lambda x: x[~df.loc[x.index, 'is_night']].mean()),\n        light_night_ratio=('is_night', 'mean')\n    ).reset_index()\n\n    results = []\n\n    for subject_id, group in tqdm(df.groupby('subject_id'), desc=\"Processing light-based sleep detection\"):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        recorded_dates = set()\n        sleeping = False\n        zero_count = 0\n        first_zero_time = None\n\n        for i in range(len(group)):\n            light = group.loc[i, 'm_light']\n            hour = group.loc[i, 'hour']\n\n            if light == 0:\n                zero_count += 1\n                if zero_count == 1:\n                    first_zero_time = group.loc[i, 'timestamp']\n                if zero_count >= 6 and not sleeping:\n                    sleep_hour = first_zero_time.hour\n                    if (sleep_hour >= 21 or sleep_hour <= 2):\n                        sleeping = True\n            else:\n                if sleeping:\n                    candidate_wakeup = group.loc[i, 'timestamp']\n                    wake_hour = candidate_wakeup.hour\n\n                    if 5 <= wake_hour <= 9 and first_zero_time is not None:\n                        wake_time = candidate_wakeup\n                        sleep_time = first_zero_time\n                        duration_min = (wake_time - sleep_time).total_seconds() / 60\n\n                        if 0 < duration_min <= 840:\n                            sleep_duration = duration_min\n                        else:\n                            sleep_duration = np.nan\n\n                        lifelog_date = wake_time.date() + pd.Timedelta(days=-1)\n\n                        if lifelog_date not in recorded_dates:\n                            results.append({\n                                'subject_id': subject_id,\n                                'lifelog_date': lifelog_date,\n                                'sleep_duration_min_mLight': sleep_duration,\n                                'sleep_time_min_mLight': sleep_time.hour * 60 + sleep_time.minute,\n                                'wake_time_min_mLight': wake_time.hour * 60 + wake_time.minute,\n                                'hour_slept_mLight': sleep_time.hour + sleep_time.minute / 60,\n                                'hour_woke_up_mLight': wake_time.hour + wake_time.minute / 60\n                            })\n                            recorded_dates.add(lifelog_date)\n\n                        sleeping = False\n                        zero_count = 0\n                        first_zero_time = None\n\n            if light > 0:\n                zero_count = 0\n                first_zero_time = None\n\n    sleep_df = pd.DataFrame(results)\n\n    # Ï†ïÎ†¨ + Î≥¥Í∞Ñ\n    sleep_df = sleep_df.sort_values(['subject_id', 'lifelog_date'])\n    sleep_df['sleep_duration_interp_mLight'] = sleep_df.groupby('subject_id')['sleep_duration_min_mLight'].transform(lambda x: x.interpolate())\n\n    # ÏãúÍ∞Ñ Îã®ÏúÑ ÌååÏÉù Ïª¨Îüº\n    sleep_df['sleep_duration_hour_mLight'] = sleep_df['sleep_duration_min_mLight'] / 60\n    sleep_df['sleep_duration_interp_hour_mLight'] = sleep_df['sleep_duration_interp_mLight'] / 60\n\n    # Î≥ëÌï©\n    final = pd.merge(daily_light, sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    return final","metadata":{"id":"fIGfYpnFufpT","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.533036Z","iopub.execute_input":"2025-05-20T10:49:20.533377Z","iopub.status.idle":"2025-05-20T10:49:20.552589Z","shell.execute_reply.started":"2025-05-20T10:49:20.533320Z","shell.execute_reply":"2025-05-20T10:49:20.551285Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"mLight2 = process_mLight(mLight)\n\n# check\nprint(f'\\n # mLight2 shape: {mLight2.shape}')\nmLight2.head(1)","metadata":{"id":"vDmnunATbHJ5","outputId":"e502e963-a7d9-4d54-efaf-89e3466cd101","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:20.553992Z","iopub.execute_input":"2025-05-20T10:49:20.554254Z","iopub.status.idle":"2025-05-20T10:49:22.867173Z","shell.execute_reply.started":"2025-05-20T10:49:20.554234Z","shell.execute_reply":"2025-05-20T10:49:22.866267Z"}},"outputs":[{"name":"stderr","text":"Processing light-based sleep detection: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:01<00:00,  6.36it/s]","output_type":"stream"},{"name":"stdout","text":"\n # mLight2 shape: (700, 17)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  light_mean  light_std  light_max  light_min  \\\n0       id01   2024-06-26    364.5068   395.6594  1886.0000     0.0000   \n\n   light_night_mean  light_day_mean  light_night_ratio  \\\n0          184.9231        403.4167             0.1781   \n\n   sleep_duration_min_mLight  sleep_time_min_mLight  wake_time_min_mLight  \\\n0                   340.0000              1409.0000              309.0000   \n\n   hour_slept_mLight  hour_woke_up_mLight  sleep_duration_interp_mLight  \\\n0            23.4833               5.1500                      340.0000   \n\n   sleep_duration_hour_mLight  sleep_duration_interp_hour_mLight  \n0                      5.6667                             5.6667  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>light_mean</th>\n      <th>light_std</th>\n      <th>light_max</th>\n      <th>light_min</th>\n      <th>light_night_mean</th>\n      <th>light_day_mean</th>\n      <th>light_night_ratio</th>\n      <th>sleep_duration_min_mLight</th>\n      <th>sleep_time_min_mLight</th>\n      <th>wake_time_min_mLight</th>\n      <th>hour_slept_mLight</th>\n      <th>hour_woke_up_mLight</th>\n      <th>sleep_duration_interp_mLight</th>\n      <th>sleep_duration_hour_mLight</th>\n      <th>sleep_duration_interp_hour_mLight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>364.5068</td>\n      <td>395.6594</td>\n      <td>1886.0000</td>\n      <td>0.0000</td>\n      <td>184.9231</td>\n      <td>403.4167</td>\n      <td>0.1781</td>\n      <td>340.0000</td>\n      <td>1409.0000</td>\n      <td>309.0000</td>\n      <td>23.4833</td>\n      <td>5.1500</td>\n      <td>340.0000</td>\n      <td>5.6667</td>\n      <td>5.6667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"id":"x6Cb1b3RXHEY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"npFr7zVBXHHt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"M5ZTeeq0XHLk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"5UEjOZN2XHPK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"QSosIjMtXHTs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"bgoIsV5bgXSA","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ZHIH4SYXbHUK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"fUlU9AKma3Tg","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üî• mScreenStatus ÌôîÎ©¥ ÏÇ¨Ïö©Ïó¨Î∂Ä\n\n- Indicates whether the smartphone screen is in use.\n - Í∏∞ÏÉÅÏãúÍ∞Ñ, Ï∑®Ïπ®ÏãúÍ∞Ñ, ÏàòÎ©¥ÏãúÍ∞Ñ\n - Ìú¥ÎåÄÌè∞ Ïù¥Ïö©ÌöüÏàò, Ïù¥Ïö©ÏãúÍ∞Ñ\n - 00 - 05 ÏÇ¨Ïù¥Ïóê Ìú¥ÎåÄÌè∞ Ïù¥Ïö©Ìïú Í±¥Ïàò\n - Í≤∞Ï∏°Ïπò Ï≤òÎ¶¨ x","metadata":{"id":"BHYijr_sa3sz"}},{"cell_type":"code","source":"mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\nmScreenStatus.head(1)","metadata":{"id":"AGEyFT4ha4bU","outputId":"9226d206-14cc-4b13-e039-0149300de9e7","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:22.868061Z","iopub.execute_input":"2025-05-20T10:49:22.868301Z","iopub.status.idle":"2025-05-20T10:49:24.390177Z","shell.execute_reply.started":"2025-05-20T10:49:22.868279Z","shell.execute_reply":"2025-05-20T10:49:24.389030Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  m_screen_use lifelog_date\n0       id01 2024-06-26 12:03:00             0   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_screen_use</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>0</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"def preprocess_mScreenStatus(df):\n    from datetime import datetime, time as dtime, timedelta\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n\n    # base key ÌôïÎ≥¥\n    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n\n    # Î∞§ 9ÏãúÎ∂ÄÌÑ∞ Îã§ÏùåÎÇ† Ïò§Ï†Ñ 11Ïãú ÌïÑÌÑ∞ÎßÅ\n    df['hour'] = df['timestamp'].dt.hour\n    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n\n    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n\n    results = []\n\n    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        # 1. Ï§ëÍ∞Ñ Í∞ÅÏÑ±(ÏïûÎí§ 0, Î≥∏Ïù∏ 1) Ï†úÍ±∞\n        prev = group['m_screen_use'].shift(1)\n        next_ = group['m_screen_use'].shift(-1)\n        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n        group.loc[mask, 'm_screen_use'] = 0\n\n        # 2. Î∏îÎ°ù Îã®ÏúÑÎ°ú ÏßßÏùÄ Í∞ÅÏÑ± Î∏îÎ°ù Ï†úÍ±∞\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        block_info = group.groupby('block').agg(\n            is_sleep=('is_sleep', 'first'),\n            size=('is_sleep', 'size')\n        )\n\n        for i in range(1, len(block_info) - 1):\n            if (\n                block_info.iloc[i]['is_sleep'] == False and\n                block_info.iloc[i]['size'] <= 2 and\n                block_info.iloc[i - 1]['is_sleep'] and\n                block_info.iloc[i + 1]['is_sleep']\n            ):\n                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n\n        # Îã§Ïãú Î∏îÎ°ù Ïû¨Í≥ÑÏÇ∞ ÌõÑ ÏàòÎ©¥ Ï∂îÏ†ï\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n            sleep_start=('timestamp', 'first'),\n            sleep_end=('timestamp', 'last'),\n            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n        )\n\n        sleep_time = wake_time = duration_min = None\n        if not sleep_blocks.empty:\n            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n            sleep_time = longest_sleep['sleep_start'].time()\n            wake_time = longest_sleep['sleep_end'].time()\n            duration_min = (\n                datetime.combine(datetime.today(), wake_time) - datetime.combine(datetime.today(), sleep_time)\n            ).total_seconds() / 60\n            if duration_min < 0:\n                duration_min += 1440\n\n            if not (4 <= wake_time.hour < 11):\n                wake_time = None\n            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n                sleep_time = None\n            if duration_min < 100:\n                sleep_time = None\n                wake_time = None\n                duration_min = None\n\n        results.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date.date(),\n            'sleep_time': sleep_time,\n            'wake_time': wake_time,\n            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n        })\n\n\n    sleep_df = pd.DataFrame(results)\n    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    # ÏãúÍ∞Ñ ‚Üí Ïã§ÏàòÌòï Ïà´Ïûê (Ïòà: 23:30 ‚Üí 23.5)\n    def time_to_float(t):\n        if pd.isna(t):\n            return None\n        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n\n    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n\n    return result_df","metadata":{"id":"6cWpAYZxy32U","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.390974Z","iopub.execute_input":"2025-05-20T10:49:24.391382Z","iopub.status.idle":"2025-05-20T10:49:24.420784Z","shell.execute_reply.started":"2025-05-20T10:49:24.391362Z","shell.execute_reply":"2025-05-20T10:49:24.419314Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def preprocess_mScreenStatus(df):\n    from datetime import datetime, timedelta\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n\n    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n\n    # Î∞§ 9Ïãú ~ Îã§ÏùåÎÇ† Ïò§Ï†Ñ 11Ïãú ÌïÑÌÑ∞ÎßÅ\n    df['hour'] = df['timestamp'].dt.hour\n    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n\n    results = []\n\n    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n        group = group.sort_values('timestamp').reset_index(drop=True)\n\n        # Ï§ëÍ∞Ñ Í∞ÅÏÑ± Ï†úÍ±∞\n        prev = group['m_screen_use'].shift(1)\n        next_ = group['m_screen_use'].shift(-1)\n        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n        group.loc[mask, 'm_screen_use'] = 0\n\n        # ÏßßÏùÄ Í∞ÅÏÑ± Î∏îÎ°ù Ï†úÍ±∞\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n        block_info = group.groupby('block').agg(\n            is_sleep=('is_sleep', 'first'),\n            size=('is_sleep', 'size')\n        )\n\n        for i in range(1, len(block_info) - 1):\n            if (\n                block_info.iloc[i]['is_sleep'] == False and\n                block_info.iloc[i]['size'] <= 2 and\n                block_info.iloc[i - 1]['is_sleep'] and\n                block_info.iloc[i + 1]['is_sleep']\n            ):\n                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n\n        # Î∏îÎ°ù Ïû¨Í≥ÑÏÇ∞\n        group['is_sleep'] = group['m_screen_use'] == 0\n        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n\n        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n            sleep_start=('timestamp', 'first'),\n            sleep_end=('timestamp', 'last'),\n            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n        )\n\n        sleep_time = wake_time = duration_min = None\n        if not sleep_blocks.empty:\n            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n            sleep_time = longest_sleep['sleep_start'].time()\n            wake_time = longest_sleep['sleep_end'].time()\n            duration_min = longest_sleep['duration_min']  # ‚úÖ Ï†ïÌôïÌïòÍ≤å ÏûêÏ†ï ÎÑòÎäî Í≤ΩÏö∞ÎèÑ Î∞òÏòÅÎê®\n\n            # Ïú†Ìö® ÏãúÍ∞Ñ Î≤îÏúÑ Ï°∞Í±¥\n            if not (4 <= wake_time.hour < 11):\n                wake_time = None\n            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n                sleep_time = None\n            if duration_min < 100:\n                sleep_time = None\n                wake_time = None\n                duration_min = None\n\n        results.append({\n            'subject_id': subject_id,\n            'lifelog_date': lifelog_date.date(),\n            'sleep_time': sleep_time,\n            'wake_time': wake_time,\n            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n        })\n\n    sleep_df = pd.DataFrame(results)\n    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n\n    # ÏãúÍ∞Ñ ‚Üí Ïã§ÏàòÌòï Ïà´Ïûê Î≥ÄÌôò\n    def time_to_float(t):\n        if pd.isna(t):\n            return None\n        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n\n    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n\n    # ÏûêÏ†ï ÎÑòÏñ¥Í∞ÄÎäî Í≤ΩÏö∞ Í≥†Î†§Ìïú sleep_duration_min Ïû¨Í≥ÑÏÇ∞\n    def compute_duration(row):\n        sleep = row['sleep_time']\n        wake = row['wake_time']\n        if pd.isna(sleep) or pd.isna(wake):\n            return None\n        duration = (wake - sleep + 24) % 24\n        return round(duration * 60, 1)  # ÏãúÍ∞Ñ Îã®ÏúÑ ‚Üí Î∂Ñ Îã®ÏúÑ\n\n    result_df['sleep_duration_min'] = result_df.apply(compute_duration, axis=1)\n\n    return result_df","metadata":{"id":"q5EqRmCxgYoq","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.422148Z","iopub.execute_input":"2025-05-20T10:49:24.422657Z","iopub.status.idle":"2025-05-20T10:49:24.450125Z","shell.execute_reply.started":"2025-05-20T10:49:24.422629Z","shell.execute_reply":"2025-05-20T10:49:24.448891Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def calculate_circular_mean_sleep_time(sleep_times):\n    sleep_times = pd.Series(sleep_times).dropna()\n    if len(sleep_times) == 0:\n        return np.nan  # ÌòπÏùÄ return 0.0 Îì± Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï Í∞ÄÎä•\n\n    def hour_to_radian(hour):\n        return (hour % 24) / 24 * 2 * np.pi\n\n    radians = np.array([hour_to_radian(t) for t in sleep_times])\n    mean_radian = np.arctan2(np.mean(np.sin(radians)), np.mean(np.cos(radians)))\n    mean_hour = (mean_radian / (2 * np.pi)) * 24 % 24\n\n    return mean_hour","metadata":{"id":"iMAqJissamth","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.451158Z","iopub.execute_input":"2025-05-20T10:49:24.451598Z","iopub.status.idle":"2025-05-20T10:49:24.473143Z","shell.execute_reply.started":"2025-05-20T10:49:24.451578Z","shell.execute_reply":"2025-05-20T10:49:24.472069Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def circular_mean_sleep_time(times):\n\n    # Í≤∞Ï∏°Ïπò Ï†úÍ±∞\n    valid_times = [t for t in times if pd.notna(t)]\n\n    # Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ Í∞úÏàò ÌôïÏù∏\n    if len(valid_times) == 0:\n        return None  # Í≤∞Ï∏°ÏπòÎßå ÏûàÎäî Í≤ΩÏö∞\n\n    # ÏãúÍ∞Ñ ‚Üí ÎùºÎîîÏïà Î≥ÄÌôò\n    radians = [(t % 24) / 24 * 2 * np.pi for t in valid_times]\n\n    # ÏÇ¨Ïù∏/ÏΩîÏÇ¨Ïù∏ ÌèâÍ∑† Í≥ÑÏÇ∞\n    sin_sum = np.mean(np.sin(radians))\n    cos_sum = np.mean(np.cos(radians))\n\n    # ÌèâÍ∑† Í∞ÅÎèÑ Í≥ÑÏÇ∞\n    if sin_sum == 0 and cos_sum == 0:\n        return np.nan  # Î∂àÍ∞ÄÎä•Ìïú Í≤ΩÏö∞\n\n    mean_radian = np.arctan2(sin_sum, cos_sum)\n\n    # ÌèâÍ∑† ÏãúÍ∞ÑÏúºÎ°ú Î≥ÄÌôò\n    mean_hour = (mean_radian / (2 * np.pi)) * 24\n    if mean_hour < 0:\n        mean_hour += 24\n\n    return f'{int(mean_hour):02d}:{int((mean_hour % 1) * 60):02d}'","metadata":{"id":"iA554Qkxb6LU","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.479289Z","iopub.execute_input":"2025-05-20T10:49:24.480247Z","iopub.status.idle":"2025-05-20T10:49:24.494195Z","shell.execute_reply.started":"2025-05-20T10:49:24.480216Z","shell.execute_reply":"2025-05-20T10:49:24.492850Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def add_ratios(df):\n    df = df.copy()\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n    df['weekday'] = df['lifelog_date'].dt.weekday  # 0=Ïõî ~ 6=Ïùº\n    df['week_type'] = df['weekday'].apply(lambda x: 'weekend' if x >= 5 else 'weekday')\n    df['month'] = df['lifelog_date'].dt.month\n\n    # ÏùºÎ∞ò ÌèâÍ∑† Í≥ÑÏÇ∞\n    avg_duration = (\n        df.groupby(['subject_id', 'month', 'week_type'])['sleep_duration_min']\n        .mean()\n        .reset_index(name='avg_sleep_duration')\n    )\n\n    # sleep_time, wake_timeÏùÄ ÏõêÌòï ÌèâÍ∑† Ï†ÅÏö©\n    sleep_time_avg = (\n        df.groupby(['subject_id', 'month', 'week_type'])['sleep_time']\n        .apply(calculate_circular_mean_sleep_time)\n        .reset_index(name='avg_sleep_time')\n    )\n\n    wake_time_avg = (\n        df.groupby(['subject_id', 'month', 'week_type'])['wake_time']\n        .apply(calculate_circular_mean_sleep_time)\n        .reset_index(name='avg_wake_time')\n    )\n\n    # ÌèâÍ∑†Í∞í Ìï©ÏπòÍ∏∞\n    avg_df = sleep_time_avg.merge(wake_time_avg, on=['subject_id', 'month', 'week_type'])\n    avg_df = avg_df.merge(avg_duration, on=['subject_id', 'month', 'week_type'])\n\n    # ÏõêÎ≥∏Ïóê Îß§Ïπ≠\n    df = df.merge(avg_df, on=['subject_id', 'month', 'week_type'], how='left')\n\n    # ÎπÑÏú® Î≥ÄÏàò Í≥ÑÏÇ∞ (ÏùåÏàòÎ©¥ Îçî ÏùºÏ∞ç Ï∑®Ïπ®/Í∏∞ÏÉÅ/ÏàòÎ©¥ÏãúÍ∞Ñ ÏßßÏùå)\n    df['sleep_time_diff'] = df['avg_sleep_time'] - df['sleep_time']\n    df['wake_time_diff'] = df['avg_wake_time'] - df['wake_time']\n    df['sleep_duration_diff'] = df['avg_sleep_duration'] - df['sleep_duration_min']\n    df['sleep_time_ratio'] = df['sleep_time'] / df['avg_sleep_time']\n    df['wake_time_ratio'] = df['wake_time'] / df['avg_wake_time']\n    df['sleep_duration_ratio'] = df['sleep_duration_min'] / df['avg_sleep_duration']\n\n    # lag feature\n    df = df.sort_values(['subject_id', 'lifelog_date'])\n    df['sleep_time_lag1'] = df.groupby('subject_id')['sleep_time'].shift(1)\n    df['wake_time_lag1'] = df.groupby('subject_id')['wake_time'].shift(1)\n    df['sleep_duration_lag1'] = df.groupby('subject_id')['sleep_duration_min'].shift(1)\n    df['week_type_lag1'] = df.groupby('subject_id')['week_type'].shift(1)\n\n    # Î≥ÄÌôîÎüâ\n    df['sleep_time_diff_lag1'] = df.groupby('subject_id')['sleep_time'].diff()\n    df['wake_time_diff_lag1'] = df.groupby('subject_id')['wake_time'].diff()\n    df['sleep_duration_diff_lag1'] = df.groupby('subject_id')['sleep_duration_min'].diff()\n\n    # Ïù¥Îèô ÌèâÍ∑† (3Ïùº)\n    df['rolling_sleep_time_3d'] = (\n        df.groupby('subject_id')['sleep_time']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n    df['rolling_wake_time_3d'] = (\n        df.groupby('subject_id')['wake_time']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n    df['rolling_sleep_duration_3d'] = (\n        df.groupby('subject_id')['sleep_duration_min']\n        .rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n    )\n\n    # Ï°¥Ïû¨ÌïòÎäî Ïª¨ÎüºÎßå Ï±ÑÏö∞Í∏∞\n    existing_columns = df.columns.tolist()\n    columns_to_fill_filtered = [col for col in [\n        'sleep_time', 'wake_time', 'sleep_duration_min',\n        'sleep_time_ratio', 'wake_time_ratio', 'sleep_duration_ratio',\n        'sleep_time_diff', 'wake_time_diff', 'sleep_duration_diff',\n        'sleep_time_lag1', 'wake_time_lag1', 'sleep_duration_lag1',\n        'sleep_time_diff_lag1', 'wake_time_diff_lag1', 'sleep_duration_diff_lag1',\n        'rolling_sleep_time_3d', 'rolling_wake_time_3d', 'rolling_sleep_duration_3d'\n    ] if col in existing_columns]\n\n    df[columns_to_fill_filtered] = df.groupby('subject_id')[columns_to_fill_filtered].ffill()\n\n    result = df[[\n        'subject_id', 'lifelog_date', 'week_type',\n        'sleep_time', 'wake_time', 'sleep_duration_min',\n        'avg_sleep_time', 'avg_wake_time', 'avg_sleep_duration',\n        'sleep_time_ratio', 'wake_time_ratio', 'sleep_duration_ratio',\n        'sleep_time_diff', 'wake_time_diff', 'sleep_duration_diff',\n        'sleep_time_lag1','wake_time_lag1', 'sleep_duration_lag1','week_type_lag1',\n        'sleep_time_diff_lag1','wake_time_diff_lag1','sleep_duration_diff_lag1',\n        'rolling_sleep_time_3d','rolling_wake_time_3d','rolling_sleep_duration_3d'\n    ]]\n\n    return result","metadata":{"id":"HpmsLYaPoD0d","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.495196Z","iopub.execute_input":"2025-05-20T10:49:24.495605Z","iopub.status.idle":"2025-05-20T10:49:24.518506Z","shell.execute_reply.started":"2025-05-20T10:49:24.495583Z","shell.execute_reply":"2025-05-20T10:49:24.516894Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"mScreenStatus2 = preprocess_mScreenStatus(mScreenStatus)\nmScreenStatus2 = add_ratios(mScreenStatus2)\n\n# check\nprint(f'\\n # mScreenStatus2 shape: {mScreenStatus2.shape}')\nmScreenStatus2.head(1)","metadata":{"id":"-F1Nm26-Qxo4","outputId":"fd66f62c-0fdb-44b9-860c-fcd3ab06f7d4","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:24.519570Z","iopub.execute_input":"2025-05-20T10:49:24.520246Z","iopub.status.idle":"2025-05-20T10:49:38.530444Z","shell.execute_reply.started":"2025-05-20T10:49:24.520022Z","shell.execute_reply":"2025-05-20T10:49:38.529560Z"}},"outputs":[{"name":"stdout","text":"\n # mScreenStatus2 shape: (700, 25)\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date week_type  sleep_time  wake_time  \\\n0       id01   2024-06-26   weekday     23.4500     5.2500   \n\n   sleep_duration_min  avg_sleep_time  avg_wake_time  avg_sleep_duration  \\\n0            348.0000         23.1944         5.4887            377.6667   \n\n   sleep_time_ratio  wake_time_ratio  sleep_duration_ratio  sleep_time_diff  \\\n0            1.0110           0.9565                0.9214          -0.2556   \n\n   wake_time_diff  sleep_duration_diff  sleep_time_lag1  wake_time_lag1  \\\n0          0.2387              29.6667              NaN             NaN   \n\n   sleep_duration_lag1 week_type_lag1  sleep_time_diff_lag1  \\\n0                  NaN            NaN                   NaN   \n\n   wake_time_diff_lag1  sleep_duration_diff_lag1  rolling_sleep_time_3d  \\\n0                  NaN                       NaN                23.4500   \n\n   rolling_wake_time_3d  rolling_sleep_duration_3d  \n0                5.2500                   348.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>week_type</th>\n      <th>sleep_time</th>\n      <th>wake_time</th>\n      <th>sleep_duration_min</th>\n      <th>avg_sleep_time</th>\n      <th>avg_wake_time</th>\n      <th>avg_sleep_duration</th>\n      <th>sleep_time_ratio</th>\n      <th>wake_time_ratio</th>\n      <th>sleep_duration_ratio</th>\n      <th>sleep_time_diff</th>\n      <th>wake_time_diff</th>\n      <th>sleep_duration_diff</th>\n      <th>sleep_time_lag1</th>\n      <th>wake_time_lag1</th>\n      <th>sleep_duration_lag1</th>\n      <th>week_type_lag1</th>\n      <th>sleep_time_diff_lag1</th>\n      <th>wake_time_diff_lag1</th>\n      <th>sleep_duration_diff_lag1</th>\n      <th>rolling_sleep_time_3d</th>\n      <th>rolling_wake_time_3d</th>\n      <th>rolling_sleep_duration_3d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>weekday</td>\n      <td>23.4500</td>\n      <td>5.2500</td>\n      <td>348.0000</td>\n      <td>23.1944</td>\n      <td>5.4887</td>\n      <td>377.6667</td>\n      <td>1.0110</td>\n      <td>0.9565</td>\n      <td>0.9214</td>\n      <td>-0.2556</td>\n      <td>0.2387</td>\n      <td>29.6667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>23.4500</td>\n      <td>5.2500</td>\n      <td>348.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"mScreenStatus2ÌèâÍ∑†ÏàòÎ©¥ÏãúÍ∞Ñ = mScreenStatus2.groupby(['subject_id','week_type']).apply(lambda x: pd.Series({\n     'ÌèâÍ∑† Ï∑®Ïπ®ÏãúÍ∞Ñ':circular_mean_sleep_time(x['sleep_time'])\n    ,'ÌèâÍ∑† Í∏∞ÏÉÅÏãúÍ∞Ñ':circular_mean_sleep_time(x['wake_time'])\n    ,'ÌèâÍ∑† ÏàòÎ©¥ÏãúÍ∞Ñ':x['sleep_duration_min'].mean()\n})).reset_index()\n\n# Ï†ÄÏû•\nfname = f'mScreenStatus2ÌèâÍ∑†ÏàòÎ©¥ÏãúÍ∞Ñ.xlsx'\nprint(fname)\nmScreenStatus2ÌèâÍ∑†ÏàòÎ©¥ÏãúÍ∞Ñ.to_excel(fname, index=False)\n\n# # check\nmScreenStatus2ÌèâÍ∑†ÏàòÎ©¥ÏãúÍ∞Ñ","metadata":{"id":"MUE2qxE7Qx0I","outputId":"bae6d256-1a7a-4199-e8ef-aff935a65777","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:38.531951Z","iopub.execute_input":"2025-05-20T10:49:38.532432Z","iopub.status.idle":"2025-05-20T10:49:39.202195Z","shell.execute_reply.started":"2025-05-20T10:49:38.532404Z","shell.execute_reply":"2025-05-20T10:49:39.201039Z"}},"outputs":[{"name":"stdout","text":"mScreenStatus2ÌèâÍ∑†ÏàòÎ©¥ÏãúÍ∞Ñ.xlsx\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   subject_id week_type ÌèâÍ∑† Ï∑®Ïπ®ÏãúÍ∞Ñ ÌèâÍ∑† Í∏∞ÏÉÅÏãúÍ∞Ñ  ÌèâÍ∑† ÏàòÎ©¥ÏãúÍ∞Ñ\n0        id01   weekday   22:42   05:55 429.2292\n1        id01   weekend   22:21   06:09 467.4500\n2        id02   weekday   22:54   07:13 496.0000\n3        id02   weekend   23:13   07:27 494.9583\n4        id03   weekday   00:21   09:03 457.4359\n5        id03   weekend   00:18   08:54 450.8667\n6        id04   weekday   00:03   06:50 396.6721\n7        id04   weekend   00:09   06:59 401.1739\n8        id05   weekday   22:52   07:25 500.1064\n9        id05   weekend   22:39   07:42 518.2778\n10       id06   weekday   23:56   08:30 505.7115\n11       id06   weekend   00:33   08:54 490.3500\n12       id07   weekday   00:08   07:16 424.9273\n13       id07   weekend   00:18   07:56 433.2500\n14       id08   weekday   01:35   08:22 360.4906\n15       id08   weekend   01:47   08:54 380.7619\n16       id09   weekday   00:08   07:47 358.4783\n17       id09   weekend   00:19   08:53 383.5294\n18       id10   weekday   01:45   08:25 369.9714\n19       id10   weekend   01:58   09:33 407.4444","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>week_type</th>\n      <th>ÌèâÍ∑† Ï∑®Ïπ®ÏãúÍ∞Ñ</th>\n      <th>ÌèâÍ∑† Í∏∞ÏÉÅÏãúÍ∞Ñ</th>\n      <th>ÌèâÍ∑† ÏàòÎ©¥ÏãúÍ∞Ñ</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>weekday</td>\n      <td>22:42</td>\n      <td>05:55</td>\n      <td>429.2292</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>weekend</td>\n      <td>22:21</td>\n      <td>06:09</td>\n      <td>467.4500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id02</td>\n      <td>weekday</td>\n      <td>22:54</td>\n      <td>07:13</td>\n      <td>496.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id02</td>\n      <td>weekend</td>\n      <td>23:13</td>\n      <td>07:27</td>\n      <td>494.9583</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id03</td>\n      <td>weekday</td>\n      <td>00:21</td>\n      <td>09:03</td>\n      <td>457.4359</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>id03</td>\n      <td>weekend</td>\n      <td>00:18</td>\n      <td>08:54</td>\n      <td>450.8667</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>id04</td>\n      <td>weekday</td>\n      <td>00:03</td>\n      <td>06:50</td>\n      <td>396.6721</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>id04</td>\n      <td>weekend</td>\n      <td>00:09</td>\n      <td>06:59</td>\n      <td>401.1739</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>id05</td>\n      <td>weekday</td>\n      <td>22:52</td>\n      <td>07:25</td>\n      <td>500.1064</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>id05</td>\n      <td>weekend</td>\n      <td>22:39</td>\n      <td>07:42</td>\n      <td>518.2778</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>id06</td>\n      <td>weekday</td>\n      <td>23:56</td>\n      <td>08:30</td>\n      <td>505.7115</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>id06</td>\n      <td>weekend</td>\n      <td>00:33</td>\n      <td>08:54</td>\n      <td>490.3500</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>id07</td>\n      <td>weekday</td>\n      <td>00:08</td>\n      <td>07:16</td>\n      <td>424.9273</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>id07</td>\n      <td>weekend</td>\n      <td>00:18</td>\n      <td>07:56</td>\n      <td>433.2500</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>id08</td>\n      <td>weekday</td>\n      <td>01:35</td>\n      <td>08:22</td>\n      <td>360.4906</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>id08</td>\n      <td>weekend</td>\n      <td>01:47</td>\n      <td>08:54</td>\n      <td>380.7619</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>id09</td>\n      <td>weekday</td>\n      <td>00:08</td>\n      <td>07:47</td>\n      <td>358.4783</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>id09</td>\n      <td>weekend</td>\n      <td>00:19</td>\n      <td>08:53</td>\n      <td>383.5294</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>id10</td>\n      <td>weekday</td>\n      <td>01:45</td>\n      <td>08:25</td>\n      <td>369.9714</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>id10</td>\n      <td>weekend</td>\n      <td>01:58</td>\n      <td>09:33</td>\n      <td>407.4444</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"","metadata":{"id":"-dvQ-tBxQx6n","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"NXxXWnhTj-XV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"t5m7Jll1a_Bh","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"AUxk1jIqa4jT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mUsageStats Ïï±ÏÇ¨Ïö©ÌÜµÍ≥Ñ\n- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n\n - Î™áÏãúÍπåÏßÄ Ìï∏ÎìúÌè∞ Î≥¥Îã§Í∞Ä Ïû†Ïû§ÎäîÏßÄ\n - ÌÜµÌôî, Ï†ÑÌôî ÏñºÎßàÎÇò ÌñàÎäîÏßÄ\n - YouTube ÏñºÎßàÎÇò Î¥§ÎäîÏßÄ\n - Î©îÏãúÏßÄ, Ïπ¥Ïπ¥Ïò§ÌÜ° ÏñºÎßàÎÇò ÌñàÎäîÏßÄ\n - NAVER ÏñºÎßàÎÇò ÌñàÎäîÏßÄ\n - ÌèâÏÜåÎ≥¥Îã§ ÏñºÎßàÎÇò ÎßéÏùÄ Ïï±ÏùÑ Ïù¥Ïö©ÌñàÎäîÏßÄ\n - Ï†úÏô∏? -> ÏãúÏä§ÌÖú UI,One UI Ìôà","metadata":{"id":"orMu9LKiW58-"}},{"cell_type":"code","source":"def extract_mUsageStats_info(row):\n    m_data = row['m_usage_stats']\n    app_name = [item['app_name'] for item in m_data]\n    total_time = [item['total_time'] for item in m_data]\n    return pd.Series({'app_name': app_name, 'total_time': total_time})\n\nmUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\nmUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\nmUsageStats.head(1)","metadata":{"id":"Zr1oENhJWfh0","outputId":"8867560c-8fb8-4963-df23-03f1676de7ec","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:39.203296Z","iopub.execute_input":"2025-05-20T10:49:39.204058Z","iopub.status.idle":"2025-05-20T10:49:47.415841Z","shell.execute_reply.started":"2025-05-20T10:49:39.204033Z","shell.execute_reply":"2025-05-20T10:49:47.415060Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 13:00:00   \n\n                                                                                                                       m_usage_stats  \\\n0  [{'app_name': '¬†Ï∫êÏãúÏõåÌÅ¨', 'total_time': 69}, {'app_name': 'NAVER', 'total_time': 549}, {'app_name': '¬†‚úùÔ∏èÏÑ±Í≤ΩÏùºÎèÖQ', 'total_time': 7337}]   \n\n                   app_name       total_time lifelog_date  \n0  [¬†Ï∫êÏãúÏõåÌÅ¨, NAVER, ¬†‚úùÔ∏èÏÑ±Í≤ΩÏùºÎèÖQ]  [69, 549, 7337]   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_usage_stats</th>\n      <th>app_name</th>\n      <th>total_time</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 13:00:00</td>\n      <td>[{'app_name': '¬†Ï∫êÏãúÏõåÌÅ¨', 'total_time': 69}, {'app_name': 'NAVER', 'total_time': 549}, {'app_name': '¬†‚úùÔ∏èÏÑ±Í≤ΩÏùºÎèÖQ', 'total_time': 7337}]</td>\n      <td>[¬†Ï∫êÏãúÏõåÌÅ¨, NAVER, ¬†‚úùÔ∏èÏÑ±Í≤ΩÏùºÎèÖQ]</td>\n      <td>[69, 549, 7337]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"# def process_mUsageStats(df):\n#     df = df.copy()\n#     df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n#     df['timestamp'] = pd.to_datetime(df['timestamp'])\n#     df['ÏöîÏùº'] = df['lifelog_date'].dt.day_name()\n\n#     # Î¶¨Ïä§Ìä∏ ÌèâÌÉÑÌôî\n#     exploded_df = df.explode(['app_name', 'total_time'])\n#     exploded_df['total_time'] = exploded_df['total_time'].astype(float)\n#     exploded_df['total_time'] = exploded_df['total_time'] * 0.001 / 60  # Î∞ÄÎ¶¨Ï¥à ‚Üí Ï¥à ‚Üí Î∂Ñ Î≥ÄÌôò\n\n#     # app_name ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞\n#     exploded_df['app_name'] = exploded_df['app_name'].astype(str).apply(\n#         lambda x: re.sub(r'[^Í∞Ä-Ìû£a-zA-Z0-9]', '', x)\n#     )\n\n#     # ÏãúÏä§ÌÖú Ïï± Ï†úÍ±∞\n#     filtered_df = exploded_df[~exploded_df['app_name'].isin(['ÏãúÏä§ÌÖúUI'])]  # 'ÏãúÏä§ÌÖúUI'Îßå Ï†úÍ±∞ (OneUIÌôàÏùÄ Ìè¨Ìï®)\n\n#     # Ï£ºÏöî ÌååÏÉùÎ≥ÄÏàò ÏÉùÏÑ±\n#     def calculate_daily_metrics(group):\n#         last_use = group['timestamp'].max()\n\n#         app_times = {\n#             'ÌÜµÌôî_time': group[group['app_name'] == 'ÌÜµÌôî']['total_time'].sum(),\n#             'Ï†ÑÌôî_time': group[group['app_name'] == 'Ï†ÑÌôî']['total_time'].sum(),\n#             'YouTube_time': group[group['app_name'] == 'YouTube']['total_time'].sum(),\n#             'Î©îÏã†Ï†Ä_time': group[group['app_name'].isin(['Î©îÏãúÏßÄ', 'Ïπ¥Ïπ¥Ïò§ÌÜ°'])]['total_time'].sum(),\n#             'NAVER_time': group[group['app_name'] == 'NAVER']['total_time'].sum(),\n#             'Ï∫êÏãúÏõåÌÅ¨_time': group[group['app_name'] == 'Ï∫êÏãúÏõåÌÅ¨']['total_time'].sum(),\n#             'ÏÑ±Í≤ΩÏùºÎèÖQ_time': group[group['app_name'] == 'ÏÑ±Í≤ΩÏùºÎèÖQ']['total_time'].sum(),\n#             'OneUIÌôà_time': group[group['app_name'] == 'OneUIÌôà']['total_time'].sum(),\n#         }\n\n#         return pd.Series({\n#             **app_times,\n#             'unique_app_count': group['app_name'].nunique(),\n#             'total_screen_time': group['total_time'].sum()\n#         })\n\n#     # daily metrics ÏÉùÏÑ±\n#     daily_stats = filtered_df.groupby(['subject_id', 'lifelog_date']).apply(calculate_daily_metrics).reset_index()\n\n#     # subject_idÎ≥Ñ ÌèâÍ∑† Ï¥ùÌôîÎ©¥ÏãúÍ∞Ñ Íµ¨ÌïòÍ∏∞\n#     avg_screen_time = daily_stats.groupby('subject_id')['total_screen_time'].mean().to_dict()\n\n#     # ÌèâÍ∑†ÎåÄÎπÑ ÌôîÎ©¥ÏÇ¨Ïö©Îüâ(%) ÏÉùÏÑ±\n#     def compute_screen_usage(row):\n#         avg_time = avg_screen_time.get(row['subject_id'], np.nan)\n#         if pd.isna(avg_time) or avg_time == 0:\n#             return np.nan\n#         return round((row['total_screen_time'] / avg_time - 1) * 100, 1)\n\n#     daily_stats['screen_time_vs_avg_pct'] = daily_stats.apply(compute_screen_usage, axis=1)\n\n#     return daily_stats","metadata":{"id":"GUZVZ8LXXhrK","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.416935Z","iopub.execute_input":"2025-05-20T10:49:47.417239Z","iopub.status.idle":"2025-05-20T10:49:47.422704Z","shell.execute_reply.started":"2025-05-20T10:49:47.417207Z","shell.execute_reply":"2025-05-20T10:49:47.421760Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"def process_mUsageStats(df):\n    df = df.copy()\n    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['ÏöîÏùº'] = df['lifelog_date'].dt.day_name()\n    df['hour'] = df['timestamp'].dt.hour\n\n    # ÏãúÍ∞ÑÎåÄ Î∂ÑÎ•ò\n    def map_time_period(row):\n        if 20 <= row['hour'] <= 23:\n            return 'beforebed'\n        else:\n            return 'activehour'\n\n    df['time_period'] = df.apply(map_time_period, axis=1)\n\n    # Î¶¨Ïä§Ìä∏ ÌèâÌÉÑÌôî\n    exploded_df = df.explode(['app_name', 'total_time'])\n    exploded_df['total_time'] = exploded_df['total_time'].astype(float)\n    exploded_df['total_time'] = exploded_df['total_time'] * 0.001 / 60  # Î∞ÄÎ¶¨Ï¥à ‚Üí Ï¥à ‚Üí Î∂Ñ Î≥ÄÌôò\n\n    # app_name ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞\n    exploded_df['app_name'] = exploded_df['app_name'].astype(str).apply(\n        lambda x: re.sub(r'[^Í∞Ä-Ìû£a-zA-Z0-9]', '', x)\n    )\n\n    # ÏãúÏä§ÌÖú Ïï± Ï†úÍ±∞\n    filtered_df = exploded_df[~exploded_df['app_name'].isin(['ÏãúÏä§ÌÖúUI'])]\n\n    # Ï£ºÏöî ÌååÏÉùÎ≥ÄÏàò ÏÉùÏÑ±\n    def calculate_daily_metrics(group):\n        app_times = {\n            'ÌÜµÌôî_time': group[group['app_name'] == 'ÌÜµÌôî']['total_time'].sum(),\n            'Ï†ÑÌôî_time': group[group['app_name'] == 'Ï†ÑÌôî']['total_time'].sum(),\n            'YouTube_time': group[group['app_name'] == 'YouTube']['total_time'].sum(),\n            'Î©îÏã†Ï†Ä_time': group[group['app_name'].isin(['Î©îÏãúÏßÄ', 'Ïπ¥Ïπ¥Ïò§ÌÜ°'])]['total_time'].sum(),\n            'NAVER_time': group[group['app_name'] == 'NAVER']['total_time'].sum(),\n            'Ï∫êÏãúÏõåÌÅ¨_time': group[group['app_name'] == 'Ï∫êÏãúÏõåÌÅ¨']['total_time'].sum(),\n            'ÏÑ±Í≤ΩÏùºÎèÖQ_time': group[group['app_name'] == 'ÏÑ±Í≤ΩÏùºÎèÖQ']['total_time'].sum(),\n            'OneUIÌôà_time': group[group['app_name'] == 'OneUIÌôà']['total_time'].sum(),\n        }\n\n        return pd.Series({\n            **app_times,\n            'unique_app_count': group['app_name'].nunique(),\n            'total_screen_time': group['total_time'].sum()\n        })\n\n    # ÏùºÏûê/ÏãúÍ∞ÑÎåÄÎ≥Ñ ÏöîÏïΩ\n    daily_stats = filtered_df.groupby(['subject_id', 'lifelog_date', 'time_period']).apply(calculate_daily_metrics).reset_index()\n\n    # subject_idÎ≥Ñ ÌèâÍ∑† Ï¥ùÌôîÎ©¥ÏãúÍ∞Ñ\n    avg_screen_time = daily_stats.groupby('subject_id')['total_screen_time'].mean().to_dict()\n\n    # ÌèâÍ∑† ÎåÄÎπÑ ÎπÑÏú®\n    def compute_screen_usage(row):\n        avg_time = avg_screen_time.get(row['subject_id'], np.nan)\n        if pd.isna(avg_time) or avg_time == 0:\n            return np.nan\n        return round((row['total_screen_time'] / avg_time - 1) * 100, 1)\n\n    daily_stats['screen_time_vs_avg_pct'] = daily_stats.apply(compute_screen_usage, axis=1)\n\n    # ÌîºÎ≤ó\n    daily_stats = daily_stats.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n    daily_stats.columns = [f\"{tp}_{metric}\" for metric, tp in daily_stats.columns]\n    daily_stats = daily_stats.reset_index()\n\n    return daily_stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.423613Z","iopub.execute_input":"2025-05-20T10:49:47.423867Z","iopub.status.idle":"2025-05-20T10:49:47.448205Z","shell.execute_reply.started":"2025-05-20T10:49:47.423846Z","shell.execute_reply":"2025-05-20T10:49:47.447124Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"mUsageStats2 = process_mUsageStats(mUsageStats)\n\n# check\nprint(f'\\n # mUsageStats2 shape: {mUsageStats2.shape}')\nmUsageStats2.head(1)","metadata":{"id":"l8CRKpC4iDKa","outputId":"953412a6-b6ad-4440-b940-7e7dbb1e819c","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:47.449279Z","iopub.execute_input":"2025-05-20T10:49:47.449602Z","iopub.status.idle":"2025-05-20T10:49:53.896818Z","shell.execute_reply.started":"2025-05-20T10:49:47.449576Z","shell.execute_reply":"2025-05-20T10:49:53.895710Z"}},"outputs":[{"name":"stdout","text":"\n # mUsageStats2 shape: (689, 24)\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  activehour_ÌÜµÌôî_time  beforebed_ÌÜµÌôî_time  \\\n0       id01   2024-06-26              9.0010             0.2079   \n\n   activehour_Ï†ÑÌôî_time  beforebed_Ï†ÑÌôî_time  activehour_YouTube_time  \\\n0             11.3007             0.7731                   0.1061   \n\n   beforebed_YouTube_time  activehour_Î©îÏã†Ï†Ä_time  beforebed_Î©îÏã†Ï†Ä_time  \\\n0                  0.0000              43.6359             14.5713   \n\n   activehour_NAVER_time  beforebed_NAVER_time  activehour_Ï∫êÏãúÏõåÌÅ¨_time  \\\n0                 8.4852                0.1351               18.6694   \n\n   beforebed_Ï∫êÏãúÏõåÌÅ¨_time  activehour_ÏÑ±Í≤ΩÏùºÎèÖQ_time  beforebed_ÏÑ±Í≤ΩÏùºÎèÖQ_time  \\\n0               5.4722                88.3836               27.6892   \n\n   activehour_OneUIÌôà_time  beforebed_OneUIÌôà_time  activehour_unique_app_count  \\\n0                 61.1160                27.9861                      25.0000   \n\n   beforebed_unique_app_count  activehour_total_screen_time  \\\n0                     20.0000                      266.7672   \n\n   beforebed_total_screen_time  activehour_screen_time_vs_avg_pct  \\\n0                     156.8681                           -29.0000   \n\n   beforebed_screen_time_vs_avg_pct  \n0                          -58.3000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>activehour_ÌÜµÌôî_time</th>\n      <th>beforebed_ÌÜµÌôî_time</th>\n      <th>activehour_Ï†ÑÌôî_time</th>\n      <th>beforebed_Ï†ÑÌôî_time</th>\n      <th>activehour_YouTube_time</th>\n      <th>beforebed_YouTube_time</th>\n      <th>activehour_Î©îÏã†Ï†Ä_time</th>\n      <th>beforebed_Î©îÏã†Ï†Ä_time</th>\n      <th>activehour_NAVER_time</th>\n      <th>beforebed_NAVER_time</th>\n      <th>activehour_Ï∫êÏãúÏõåÌÅ¨_time</th>\n      <th>beforebed_Ï∫êÏãúÏõåÌÅ¨_time</th>\n      <th>activehour_ÏÑ±Í≤ΩÏùºÎèÖQ_time</th>\n      <th>beforebed_ÏÑ±Í≤ΩÏùºÎèÖQ_time</th>\n      <th>activehour_OneUIÌôà_time</th>\n      <th>beforebed_OneUIÌôà_time</th>\n      <th>activehour_unique_app_count</th>\n      <th>beforebed_unique_app_count</th>\n      <th>activehour_total_screen_time</th>\n      <th>beforebed_total_screen_time</th>\n      <th>activehour_screen_time_vs_avg_pct</th>\n      <th>beforebed_screen_time_vs_avg_pct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>9.0010</td>\n      <td>0.2079</td>\n      <td>11.3007</td>\n      <td>0.7731</td>\n      <td>0.1061</td>\n      <td>0.0000</td>\n      <td>43.6359</td>\n      <td>14.5713</td>\n      <td>8.4852</td>\n      <td>0.1351</td>\n      <td>18.6694</td>\n      <td>5.4722</td>\n      <td>88.3836</td>\n      <td>27.6892</td>\n      <td>61.1160</td>\n      <td>27.9861</td>\n      <td>25.0000</td>\n      <td>20.0000</td>\n      <td>266.7672</td>\n      <td>156.8681</td>\n      <td>-29.0000</td>\n      <td>-58.3000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"","metadata":{"id":"4pXwcGHxiDPQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2ecpVUVhRo4e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"R1PcAUtkH81I","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"iZHkETiDH84G","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è mWifi Ï£ºÎ≥Äwifi Ï†ïÎ≥¥\n- Wifi devices around individual subject.\n - -30 ~ -50 dBm\tÎß§Ïö∞ Í∞ïÌïú Ïã†Ìò∏ (ÏµúÏ†Å)\n - -51 ~ -60 dBm\tÍ∞ïÌïú Ïã†Ìò∏ (Î¨∏Ï†ú ÏóÜÏùå)\n - -61 ~ -70 dBm\tÍ¥úÏ∞ÆÏùÄ Ïã†Ìò∏ (ÏïΩÍ∞Ñ ÎäêÎ¶¥ Ïàò ÏûàÏùå)\n - -71 ~ -80 dBm\tÏïΩÌïú Ïã†Ìò∏ (ÎÅäÍπÄ Ï£ºÏùò)\n - -81 dBm Ïù¥Ìïò\tÎß§Ïö∞ ÏïΩÌïú Ïã†Ìò∏ (Í±∞Ïùò ÎÅäÍπÄ)","metadata":{"id":"sFVRGf8cbJMo"}},{"cell_type":"code","source":"def extract_wifi_info(row):\n    wifi_data = row['m_wifi']\n    bssids = [item['bssid'] for item in wifi_data]\n    rssis = [item['rssi'] for item in wifi_data]\n    return pd.Series({'bssid': bssids, 'rssi': rssis})\n\nmWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\nmWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\nmWifi.head(1)","metadata":{"id":"WCIgP5FaH86F","outputId":"056d5d70-0c30-4ea8-f3cb-a40624d77d0e","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:49:53.897979Z","iopub.execute_input":"2025-05-20T10:49:53.898371Z","iopub.status.idle":"2025-05-20T10:50:11.701108Z","shell.execute_reply.started":"2025-05-20T10:49:53.898316Z","shell.execute_reply":"2025-05-20T10:50:11.699983Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:03:00   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            m_wifi  \\\n0  [{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8c', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8d', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8e', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8f', 'rssi': -78}, {'bssid': 'a0:0f:37:96:56:ef', 'rssi': -58}, {'bssid': '88:36:6c:86:75:84', 'rssi': -72}, {'bssid': 'a0:0f:37:96:56:ee', 'rssi': -58}, {'bssid': 'a0:0f:37:96:56:ed', 'rssi': -58}, {'bssid': '86:25:19:b5:b2:a5', 'rssi': -61}, {'bssid': 'a0:0f:37:96:56:ec', 'rssi': -58}, {'bssid': '1e:39:29:8e:fb:e9', 'rssi': -71}, {'bssid': '52:c2:e8:c7:9b:e4', 'rssi': -82}, {'bssid': 'a0:0f:37:96:56:eb', 'rssi': -58}, {'bssid': '12:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '58:86:94:4a:08:b8', 'rssi': -82}, {'bssid': '90:9f:33:28:d0:2e', 'rssi': -78}, {'bssid': '00:26:66:bc:4e:18', 'rssi': -85}, {'bssid': 'f6:0a:f4:43:4b:ba', 'rssi': -45}, {'bssid': '10:e3:c7:09:20:35', 'rssi': -63}, {'bssid': '10:e3:c7:09:20:34', 'rssi': -89}, {'bssid': '1c:39:29:48:04:92', 'rssi': -82}, {'bssid': '12:e3:c7:07:9d:df', 'rssi': -83}, {'bssid': '86:25:19:c3:44:07', 'rssi': -84}, {'bssid': 'a0:0f:37:9a:37:2f', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2e', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2d', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:ec', 'rssi': -72}, {'bssid': 'a0:0f:37:9a:37:2c', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2b', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:eb', 'rssi': -59}, {'bssid': 'c0:25:2f:d8:c1:a6', 'rssi': -82}, {'bssid': '16:7f:67:bb:fa:f8', 'rssi': -79}, {'bssid': '3c:f3:92:ff:00:01', 'rssi': -82}, {'bssid': '06:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '06:09:b4:74:05:eb', 'rssi': -59}, {'bssid': '12:e3:c7:0a:74:d1', 'rssi': -78}, {'bssid': '88:36:6c:a9:6f:8e', 'rssi': -63}, {'bssid': '02:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '00:09:b4:74:05:eb', 'rssi': -60}, {'bssid': '00:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '00:1d:93:93:cf:fe', 'rssi': -19}, {'bssid': '8e:e2:ac:a5:9d:15', 'rssi': -72}]   \n\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               bssid  \\\n0  [a0:0f:37:9a:5d:8b, a0:0f:37:9a:5d:8c, a0:0f:37:9a:5d:8d, a0:0f:37:9a:5d:8e, a0:0f:37:9a:5d:8f, a0:0f:37:96:56:ef, 88:36:6c:86:75:84, a0:0f:37:96:56:ee, a0:0f:37:96:56:ed, 86:25:19:b5:b2:a5, a0:0f:37:96:56:ec, 1e:39:29:8e:fb:e9, 52:c2:e8:c7:9b:e4, a0:0f:37:96:56:eb, 12:e3:c7:09:20:34, 58:86:94:4a:08:b8, 90:9f:33:28:d0:2e, 00:26:66:bc:4e:18, f6:0a:f4:43:4b:ba, 10:e3:c7:09:20:35, 10:e3:c7:09:20:34, 1c:39:29:48:04:92, 12:e3:c7:07:9d:df, 86:25:19:c3:44:07, a0:0f:37:9a:37:2f, a0:0f:37:9a:37:2e, a0:0f:37:9a:37:2d, 0a:09:b4:74:05:ec, a0:0f:37:9a:37:2c, a0:0f:37:9a:37:2b, 0a:09:b4:74:05:eb, c0:25:2f:d8:c1:a6, 16:7f:67:bb:fa:f8, 3c:f3:92:ff:00:01, 06:09:b4:74:05:ec, 06:09:b4:74:05:eb, 12:e3:c7:0a:74:d1, 88:36:6c:a9:6f:8e, 02:e3:c7:09:20:34, 00:09:b4:74:05:eb, 00:09:b4:74:05:ec, 00:1d:93:93:cf:fe, 8e:e2:ac:a5:9d:15]   \n\n                                                                                                                                                                                                                      rssi  \\\n0  [-78, -78, -78, -78, -78, -58, -72, -58, -58, -61, -58, -71, -82, -58, -88, -82, -78, -85, -45, -63, -89, -82, -83, -84, -76, -76, -76, -72, -76, -76, -59, -82, -79, -82, -72, -59, -78, -63, -88, -60, -72, -19, -72]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>m_wifi</th>\n      <th>bssid</th>\n      <th>rssi</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:03:00</td>\n      <td>[{'bssid': 'a0:0f:37:9a:5d:8b', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8c', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8d', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8e', 'rssi': -78}, {'bssid': 'a0:0f:37:9a:5d:8f', 'rssi': -78}, {'bssid': 'a0:0f:37:96:56:ef', 'rssi': -58}, {'bssid': '88:36:6c:86:75:84', 'rssi': -72}, {'bssid': 'a0:0f:37:96:56:ee', 'rssi': -58}, {'bssid': 'a0:0f:37:96:56:ed', 'rssi': -58}, {'bssid': '86:25:19:b5:b2:a5', 'rssi': -61}, {'bssid': 'a0:0f:37:96:56:ec', 'rssi': -58}, {'bssid': '1e:39:29:8e:fb:e9', 'rssi': -71}, {'bssid': '52:c2:e8:c7:9b:e4', 'rssi': -82}, {'bssid': 'a0:0f:37:96:56:eb', 'rssi': -58}, {'bssid': '12:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '58:86:94:4a:08:b8', 'rssi': -82}, {'bssid': '90:9f:33:28:d0:2e', 'rssi': -78}, {'bssid': '00:26:66:bc:4e:18', 'rssi': -85}, {'bssid': 'f6:0a:f4:43:4b:ba', 'rssi': -45}, {'bssid': '10:e3:c7:09:20:35', 'rssi': -63}, {'bssid': '10:e3:c7:09:20:34', 'rssi': -89}, {'bssid': '1c:39:29:48:04:92', 'rssi': -82}, {'bssid': '12:e3:c7:07:9d:df', 'rssi': -83}, {'bssid': '86:25:19:c3:44:07', 'rssi': -84}, {'bssid': 'a0:0f:37:9a:37:2f', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2e', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2d', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:ec', 'rssi': -72}, {'bssid': 'a0:0f:37:9a:37:2c', 'rssi': -76}, {'bssid': 'a0:0f:37:9a:37:2b', 'rssi': -76}, {'bssid': '0a:09:b4:74:05:eb', 'rssi': -59}, {'bssid': 'c0:25:2f:d8:c1:a6', 'rssi': -82}, {'bssid': '16:7f:67:bb:fa:f8', 'rssi': -79}, {'bssid': '3c:f3:92:ff:00:01', 'rssi': -82}, {'bssid': '06:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '06:09:b4:74:05:eb', 'rssi': -59}, {'bssid': '12:e3:c7:0a:74:d1', 'rssi': -78}, {'bssid': '88:36:6c:a9:6f:8e', 'rssi': -63}, {'bssid': '02:e3:c7:09:20:34', 'rssi': -88}, {'bssid': '00:09:b4:74:05:eb', 'rssi': -60}, {'bssid': '00:09:b4:74:05:ec', 'rssi': -72}, {'bssid': '00:1d:93:93:cf:fe', 'rssi': -19}, {'bssid': '8e:e2:ac:a5:9d:15', 'rssi': -72}]</td>\n      <td>[a0:0f:37:9a:5d:8b, a0:0f:37:9a:5d:8c, a0:0f:37:9a:5d:8d, a0:0f:37:9a:5d:8e, a0:0f:37:9a:5d:8f, a0:0f:37:96:56:ef, 88:36:6c:86:75:84, a0:0f:37:96:56:ee, a0:0f:37:96:56:ed, 86:25:19:b5:b2:a5, a0:0f:37:96:56:ec, 1e:39:29:8e:fb:e9, 52:c2:e8:c7:9b:e4, a0:0f:37:96:56:eb, 12:e3:c7:09:20:34, 58:86:94:4a:08:b8, 90:9f:33:28:d0:2e, 00:26:66:bc:4e:18, f6:0a:f4:43:4b:ba, 10:e3:c7:09:20:35, 10:e3:c7:09:20:34, 1c:39:29:48:04:92, 12:e3:c7:07:9d:df, 86:25:19:c3:44:07, a0:0f:37:9a:37:2f, a0:0f:37:9a:37:2e, a0:0f:37:9a:37:2d, 0a:09:b4:74:05:ec, a0:0f:37:9a:37:2c, a0:0f:37:9a:37:2b, 0a:09:b4:74:05:eb, c0:25:2f:d8:c1:a6, 16:7f:67:bb:fa:f8, 3c:f3:92:ff:00:01, 06:09:b4:74:05:ec, 06:09:b4:74:05:eb, 12:e3:c7:0a:74:d1, 88:36:6c:a9:6f:8e, 02:e3:c7:09:20:34, 00:09:b4:74:05:eb, 00:09:b4:74:05:ec, 00:1d:93:93:cf:fe, 8e:e2:ac:a5:9d:15]</td>\n      <td>[-78, -78, -78, -78, -78, -58, -72, -58, -58, -61, -58, -71, -82, -58, -88, -82, -78, -85, -45, -63, -89, -82, -83, -84, -76, -76, -76, -72, -76, -76, -59, -82, -79, -82, -72, -59, -78, -63, -88, -60, -72, -19, -72]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"def process_mWifi(df,threshold):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    def filter_strong_rssi(df,threshold):\n        filtered_df = df.copy()\n        def filter_row(row):\n            bssids = row['bssid']\n            rssis = row['rssi']\n            # RSSI > threshold Ï°∞Í±¥ ÎßåÏ°±ÌïòÎäî Ìï≠Î™©Îßå Ï∂îÏ∂ú\n            filtered = [(b, r) for b, r in zip(bssids, rssis) if r > threshold]\n            if filtered:\n                new_bssids, new_rssis = zip(*filtered)\n                return pd.Series({'bssid': list(new_bssids), 'rssi': list(new_rssis)})\n            else:\n                return pd.Series({'bssid': [], 'rssi': []})\n        filtered_df[['bssid', 'rssi']] = filtered_df.apply(filter_row, axis=1)\n        return filtered_df\n\n    # === wifi ÏïΩÏã†Ìò∏ Ï†úÍ±∞ ===\n    df = filter_strong_rssi(df, threshold=threshold) ####\n\n    features = []\n    grouped = df.groupby(['subject_id', 'lifelog_date'])\n\n    for (subject_id, date), group in grouped:\n        scan_count = len(group)\n        bssid_flat = sum(group['bssid'], [])  # flatten\n        rssi_flat = sum(group['rssi'], [])    # flatten\n\n        unique_bssid_count = len(set(bssid_flat))\n        avg_rssi = sum(rssi_flat) / len(rssi_flat) if rssi_flat else None\n        max_rssi = max(rssi_flat) if rssi_flat else None\n        min_rssi = min(rssi_flat) if rssi_flat else None\n        strong_rssi_ratio = sum(1 for r in rssi_flat if r > -60) / len(rssi_flat) if rssi_flat else 0\n        empty_scan_count = sum(1 for b in group['bssid'] if len(b) == 0)\n\n        # Í∞ÄÏû• ÎßéÏù¥ ÌÉêÏßÄÎêú BSSID\n        bssid_counter = Counter(bssid_flat)\n        top_bssid, top_bssid_count = bssid_counter.most_common(1)[0] if bssid_counter else (None, 0)\n\n        first_time = group['timestamp'].min()\n        last_time = group['timestamp'].max()\n        hour_span = (last_time - first_time).total_seconds() / 60  # Î∂Ñ Îã®ÏúÑ\n\n        features.append({\n            'subject_id': subject_id,\n            'lifelog_date': date,\n            'scan_count': scan_count,\n            'unique_bssid_count': unique_bssid_count,\n            'avg_rssi': avg_rssi,\n            'max_rssi': max_rssi,\n            # 'min_rssi': min_rssi,\n            # 'strong_signal_ratio': strong_rssi_ratio,\n            'empty_scan_count': empty_scan_count,\n            'top_bssid': top_bssid,\n            'top_bssid_count': top_bssid_count,\n            'hour_span_minutes': hour_span\n        })\n\n    return pd.DataFrame(features)","metadata":{"id":"CeDXOGXDcYmo","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:11.702106Z","iopub.execute_input":"2025-05-20T10:50:11.702439Z","iopub.status.idle":"2025-05-20T10:50:11.715319Z","shell.execute_reply.started":"2025-05-20T10:50:11.702404Z","shell.execute_reply":"2025-05-20T10:50:11.714486Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"mWifi2 = process_mWifi(mWifi,threshold=-60)\n\n# check\nprint(f'\\n # mWifi2 shape: {mWifi2.shape}')\nmWifi2.head(1)","metadata":{"id":"pJujoyH8H9Cw","outputId":"64a5ca5c-e818-49f1-8a13-36294e2c5d4f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:11.716249Z","iopub.execute_input":"2025-05-20T10:50:11.716563Z","iopub.status.idle":"2025-05-20T10:50:29.826232Z","shell.execute_reply.started":"2025-05-20T10:50:11.716541Z","shell.execute_reply":"2025-05-20T10:50:29.825020Z"}},"outputs":[{"name":"stdout","text":"\n # mWifi2 shape: (685, 10)\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  scan_count  unique_bssid_count  avg_rssi  max_rssi  \\\n0       id01   2024-06-26          69                  48  -49.6109  -19.0000   \n\n   empty_scan_count          top_bssid  top_bssid_count  hour_span_minutes  \n0                11  86:25:19:9f:9b:be               19           716.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>scan_count</th>\n      <th>unique_bssid_count</th>\n      <th>avg_rssi</th>\n      <th>max_rssi</th>\n      <th>empty_scan_count</th>\n      <th>top_bssid</th>\n      <th>top_bssid_count</th>\n      <th>hour_span_minutes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>69</td>\n      <td>48</td>\n      <td>-49.6109</td>\n      <td>-19.0000</td>\n      <td>11</td>\n      <td>86:25:19:9f:9b:be</td>\n      <td>19</td>\n      <td>716.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"id":"dsAzWwCFYL2q","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"FDYMQG6EYMVT","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"AWKrkwFSiA3H","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"z0TwqdaHiA6a","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è wHr Ïã¨Î∞ïÎèôÏàò\n- Heart rate readings recorded by the smartwatch.\n","metadata":{"id":"GQkZX8zrb53H"}},{"cell_type":"code","source":"wHr['lifelog_date'] = wHr['timestamp'].astype(str).str[:10]\nwHr.head(1)","metadata":{"id":"rQTSKYiTiA-D","outputId":"78206979-2f8d-4cd3-bec6-641f574b9088","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:29.827542Z","iopub.execute_input":"2025-05-20T10:50:29.827817Z","iopub.status.idle":"2025-05-20T10:50:30.452227Z","shell.execute_reply.started":"2025-05-20T10:50:29.827794Z","shell.execute_reply":"2025-05-20T10:50:30.451256Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  \\\n0       id01 2024-06-26 12:23:00   \n\n                                                                                                                                                                                            heart_rate  \\\n0  [134, 134, 135, 133, 134, 135, 134, 135, 134, 133, 133, 133, 132, 132, 131, 131, 131, 132, 132, 134, 134, 134, 132, 130, 128, 126, 126, 126, 127, 129, 130, 129, 130, 130, 127, 127, 126, 125, 123]   \n\n  lifelog_date  \n0   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>heart_rate</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:23:00</td>\n      <td>[134, 134, 135, 133, 134, 135, 134, 135, 134, 133, 133, 133, 132, 132, 131, 131, 131, 132, 132, 134, 134, 134, 132, 130, 128, 126, 126, 126, 127, 129, 130, 129, 130, 130, 127, 127, 126, 125, 123]</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"def get_time_block(hour):\n    if 0 <= hour < 6:\n        return 'early_morning'\n    elif 6 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 18:\n        return 'afternoon'\n    else:\n        return 'evening'\n\ndef process_wHr_by_timeblock(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        block_stats = {'subject_id': subj, 'lifelog_date': date}\n\n        for block, block_group in group.groupby('block'):\n            hr_all = []\n            for row in block_group['heart_rate']:\n                parsed = ast.literal_eval(row) if isinstance(row, str) else row\n                hr_all.extend([int(h) for h in parsed if h is not None])\n\n            if not hr_all:\n                continue\n\n            above_100 = [hr for hr in hr_all if hr > 100]\n            block_stats[f'hr_{block}_mean'] = np.mean(hr_all)\n            block_stats[f'hr_{block}_std'] = np.std(hr_all)\n            block_stats[f'hr_{block}_max'] = np.max(hr_all)\n            block_stats[f'hr_{block}_min'] = np.min(hr_all)\n            block_stats[f'hr_{block}_above_100_ratio'] = len(above_100) / len(hr_all)\n\n        results.append(block_stats)\n\n    return pd.DataFrame(results)","metadata":{"id":"QdEddMsBiBAw","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:30.453269Z","iopub.execute_input":"2025-05-20T10:50:30.453598Z","iopub.status.idle":"2025-05-20T10:50:30.464087Z","shell.execute_reply.started":"2025-05-20T10:50:30.453572Z","shell.execute_reply":"2025-05-20T10:50:30.462677Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"wHr2 = process_wHr_by_timeblock(wHr)\n\n# check\nprint(f'\\n # wHr2 shape: {wHr2.shape}')\nwHr2.head(1)","metadata":{"id":"aLFRbbc3cEFJ","outputId":"2dc46be7-6873-4a0c-e803-29c1b0a43154","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:30.465115Z","iopub.execute_input":"2025-05-20T10:50:30.465456Z","iopub.status.idle":"2025-05-20T10:50:41.488063Z","shell.execute_reply.started":"2025-05-20T10:50:30.465431Z","shell.execute_reply":"2025-05-20T10:50:41.486899Z"}},"outputs":[{"name":"stdout","text":"\n # wHr2 shape: (636, 22)\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  hr_afternoon_mean  hr_afternoon_std  \\\n0       id01   2024-06-26            80.5333           12.6366   \n\n   hr_afternoon_max  hr_afternoon_min  hr_afternoon_above_100_ratio  \\\n0          142.0000           59.0000                        0.0773   \n\n   hr_evening_mean  hr_evening_std  hr_evening_max  hr_evening_min  \\\n0          82.4768         10.2932        124.0000         59.0000   \n\n   hr_evening_above_100_ratio  hr_early_morning_mean  hr_early_morning_std  \\\n0                      0.0555                    NaN                   NaN   \n\n   hr_early_morning_max  hr_early_morning_min  \\\n0                   NaN                   NaN   \n\n   hr_early_morning_above_100_ratio  hr_morning_mean  hr_morning_std  \\\n0                               NaN              NaN             NaN   \n\n   hr_morning_max  hr_morning_min  hr_morning_above_100_ratio  \n0             NaN             NaN                         NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>hr_afternoon_mean</th>\n      <th>hr_afternoon_std</th>\n      <th>hr_afternoon_max</th>\n      <th>hr_afternoon_min</th>\n      <th>hr_afternoon_above_100_ratio</th>\n      <th>hr_evening_mean</th>\n      <th>hr_evening_std</th>\n      <th>hr_evening_max</th>\n      <th>hr_evening_min</th>\n      <th>hr_evening_above_100_ratio</th>\n      <th>hr_early_morning_mean</th>\n      <th>hr_early_morning_std</th>\n      <th>hr_early_morning_max</th>\n      <th>hr_early_morning_min</th>\n      <th>hr_early_morning_above_100_ratio</th>\n      <th>hr_morning_mean</th>\n      <th>hr_morning_std</th>\n      <th>hr_morning_max</th>\n      <th>hr_morning_min</th>\n      <th>hr_morning_above_100_ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>80.5333</td>\n      <td>12.6366</td>\n      <td>142.0000</td>\n      <td>59.0000</td>\n      <td>0.0773</td>\n      <td>82.4768</td>\n      <td>10.2932</td>\n      <td>124.0000</td>\n      <td>59.0000</td>\n      <td>0.0555</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"","metadata":{"id":"zARTShxhetw6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ZT7srO3MeuXD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"gRO-TD8_cEIH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è wLight Ïï∞ÎπÑÏñ∏Ìä∏ ÎùºÏù¥Ìä∏\n- Ambient light measured by the smartwatch.  \n  - Ïñ¥ÎëêÏö¥ Î∞§ 0.1 ~ 1 lux Ï∫ÑÏ∫ÑÌïú Î∞©, Îã¨Îπõ ÏóÜÎäî Î∞§\n  - Í∞ÄÎ°úÎì± ÏºúÏßÑ Í±∞Î¶¨ 10 ~ 20 lux ÌùêÎ¶øÌïú Ïô∏Î∂Ä Ï°∞Î™Ö\n  - Ïã§ÎÇ¥ Ï°∞Î™Ö 100 ~ 500 lux ÏÇ¨Î¨¥Ïã§, ÏùºÎ∞ò Í±∞Ïã§\n  - Î∞ùÏùÄ Ïã§Ïô∏ 10,000 ~ 25,000 lux ÎßëÏùÄ ÎÇ† ÌñáÎπõ\n  - ÏßÅÏÇ¨Í¥ëÏÑ† ÏïÑÎûò 30,000 ~ 100,000 lux Ïó¨Î¶Ñ ÌïúÎÇÆ, Îß§Ïö∞ Í∞ïÌïú ÌñáÎπõ","metadata":{"id":"DYFlbAd_bYca"}},{"cell_type":"code","source":"wLight['lifelog_date'] = wLight['timestamp'].astype(str).str[:10]\nwLight.head(1)","metadata":{"id":"wfAGaJQ0iBHP","outputId":"3dfce3f8-dc19-49e4-afbd-b33682a71e79","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:41.489226Z","iopub.execute_input":"2025-05-20T10:50:41.489600Z","iopub.status.idle":"2025-05-20T10:50:42.540939Z","shell.execute_reply.started":"2025-05-20T10:50:41.489573Z","shell.execute_reply":"2025-05-20T10:50:42.539939Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  w_light lifelog_date\n0       id01 2024-06-26 12:17:00 633.0000   2024-06-26","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>w_light</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:17:00</td>\n      <td>633.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"def get_time_block(hour):\n    if 0 <= hour < 6:\n        return 'early_morning'\n    elif 6 <= hour < 12:\n        return 'morning'\n    elif 12 <= hour < 18:\n        return 'afternoon'\n    else:\n        return 'evening'\n\ndef process_wLight_by_timeblock(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n    df['block'] = df['timestamp'].dt.hour.map(get_time_block)\n\n    results = []\n\n    for (subj, date), group in df.groupby(['subject_id', 'lifelog_date']):\n        block_stats = {'subject_id': subj, 'lifelog_date': date}\n\n        for block, block_group in group.groupby('block'):\n            lux = block_group['w_light'].dropna().values\n            if len(lux) == 0:\n                continue\n\n            block_stats[f'wlight_{block}_mean'] = np.mean(lux)\n            block_stats[f'wlight_{block}_std'] = np.std(lux)\n            block_stats[f'wlight_{block}_max'] = np.max(lux)\n            block_stats[f'wlight_{block}_min'] = np.min(lux)\n\n        results.append(block_stats)\n\n    return pd.DataFrame(results)","metadata":{"id":"jIJgKkmjiBOG","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:42.541753Z","iopub.execute_input":"2025-05-20T10:50:42.541986Z","iopub.status.idle":"2025-05-20T10:50:42.549836Z","shell.execute_reply.started":"2025-05-20T10:50:42.541968Z","shell.execute_reply":"2025-05-20T10:50:42.548892Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"wLight2 = process_wLight_by_timeblock(wLight)\n\n# check\nprint(f'\\n # wLight2 shape: {wLight2.shape}')\nwLight2.head(1)","metadata":{"id":"iUhMoFPaiBQw","outputId":"358f2a4f-927a-46da-c83b-6de840556e35","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:42.550790Z","iopub.execute_input":"2025-05-20T10:50:42.551165Z","iopub.status.idle":"2025-05-20T10:50:44.277190Z","shell.execute_reply.started":"2025-05-20T10:50:42.551138Z","shell.execute_reply":"2025-05-20T10:50:44.276030Z"}},"outputs":[{"name":"stdout","text":"\n # wLight2 shape: (664, 18)\n","output_type":"stream"},{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  wlight_afternoon_mean  wlight_afternoon_std  \\\n0       id01   2024-06-26               394.5251             1458.7346   \n\n   wlight_afternoon_max  wlight_afternoon_min  wlight_evening_mean  \\\n0            20874.0000                0.0000              89.0202   \n\n   wlight_evening_std  wlight_evening_max  wlight_evening_min  \\\n0            101.6844            264.0000              0.0000   \n\n   wlight_early_morning_mean  wlight_early_morning_std  \\\n0                        NaN                       NaN   \n\n   wlight_early_morning_max  wlight_early_morning_min  wlight_morning_mean  \\\n0                       NaN                       NaN                  NaN   \n\n   wlight_morning_std  wlight_morning_max  wlight_morning_min  \n0                 NaN                 NaN                 NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>wlight_afternoon_mean</th>\n      <th>wlight_afternoon_std</th>\n      <th>wlight_afternoon_max</th>\n      <th>wlight_afternoon_min</th>\n      <th>wlight_evening_mean</th>\n      <th>wlight_evening_std</th>\n      <th>wlight_evening_max</th>\n      <th>wlight_evening_min</th>\n      <th>wlight_early_morning_mean</th>\n      <th>wlight_early_morning_std</th>\n      <th>wlight_early_morning_max</th>\n      <th>wlight_early_morning_min</th>\n      <th>wlight_morning_mean</th>\n      <th>wlight_morning_std</th>\n      <th>wlight_morning_max</th>\n      <th>wlight_morning_min</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>394.5251</td>\n      <td>1458.7346</td>\n      <td>20874.0000</td>\n      <td>0.0000</td>\n      <td>89.0202</td>\n      <td>101.6844</td>\n      <td>264.0000</td>\n      <td>0.0000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"","metadata":{"id":"aAiZk_kWfR8m","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"OcU6IavGfSAw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"kp0et2XoiBZ7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"eX2gVvMzcF7h","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚úîÔ∏è wPedo Í±∏ÏùåÏàò\n- Step data recorded by the smartwatch.","metadata":{"id":"tQvyhHhBbmzN"}},{"cell_type":"code","source":"wPedo['lifelog_date'] = wPedo['timestamp'].astype(str).str[:10]\nwPedo.head(1)","metadata":{"id":"3poFH3LmiBc2","outputId":"1ab190bb-5ba8-47f1-85e0-86341913eaf1","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:44.278358Z","iopub.execute_input":"2025-05-20T10:50:44.278605Z","iopub.status.idle":"2025-05-20T10:50:45.499225Z","shell.execute_reply.started":"2025-05-20T10:50:44.278586Z","shell.execute_reply":"2025-05-20T10:50:45.498354Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"  subject_id           timestamp  step  step_frequency  running_step  \\\n0       id01 2024-06-26 12:09:00    10          0.1667             0   \n\n   walking_step  distance  speed  burned_calories lifelog_date  \n0             0    8.3300 0.1388           0.0000   2024-06-26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>timestamp</th>\n      <th>step</th>\n      <th>step_frequency</th>\n      <th>running_step</th>\n      <th>walking_step</th>\n      <th>distance</th>\n      <th>speed</th>\n      <th>burned_calories</th>\n      <th>lifelog_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26 12:09:00</td>\n      <td>10</td>\n      <td>0.1667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.3300</td>\n      <td>0.1388</td>\n      <td>0.0000</td>\n      <td>2024-06-26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"def process_wPedo(df):\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n    df['lifelog_date'] = df['timestamp'].dt.date\n\n    summary = df.groupby(['subject_id', 'lifelog_date']).agg({\n        'step': 'sum',\n        'step_frequency': 'mean',\n        'distance': 'sum',\n        'speed': ['mean', 'max'],\n        'burned_calories': 'sum'\n    }).reset_index()\n\n    # Ïª¨Îüº Ïù¥Î¶Ñ Ï†ïÎ¶¨\n    summary.columns = ['subject_id', 'lifelog_date',\n                       'step_sum', 'step_frequency_mean',\n                       'distance_sum', 'speed_mean', 'speed_max',\n                       'burned_calories_sum']\n\n    return summary","metadata":{"id":"48ljm6voiBfd","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.500316Z","iopub.execute_input":"2025-05-20T10:50:45.500691Z","iopub.status.idle":"2025-05-20T10:50:45.507091Z","shell.execute_reply.started":"2025-05-20T10:50:45.500659Z","shell.execute_reply":"2025-05-20T10:50:45.506120Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"wPedo2 = process_wPedo(wPedo)\n\n# check\nprint(f'\\n # wPedo2 shape: {wPedo2.shape}')\nwPedo2.head(1)","metadata":{"id":"Z3kBqrgNhfXN","outputId":"d2b18581-ae64-4f5a-dff8-de5d1ce3d34b","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.508021Z","iopub.execute_input":"2025-05-20T10:50:45.508307Z","iopub.status.idle":"2025-05-20T10:50:45.961254Z","shell.execute_reply.started":"2025-05-20T10:50:45.508284Z","shell.execute_reply":"2025-05-20T10:50:45.960395Z"}},"outputs":[{"name":"stdout","text":"\n # wPedo2 shape: (653, 8)\n","output_type":"stream"},{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  step_sum  step_frequency_mean  distance_sum  \\\n0       id01   2024-06-26      3578               0.0927     2782.1901   \n\n   speed_mean  speed_max  burned_calories_sum  \n0      0.0721     1.5882             189.3191  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>step_sum</th>\n      <th>step_frequency_mean</th>\n      <th>distance_sum</th>\n      <th>speed_mean</th>\n      <th>speed_max</th>\n      <th>burned_calories_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>3578</td>\n      <td>0.0927</td>\n      <td>2782.1901</td>\n      <td>0.0721</td>\n      <td>1.5882</td>\n      <td>189.3191</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"id":"msyUxfoLgpq1","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YLPmg7oWhFMa","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Db44ae3XDtKE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"4L_sSEhnDtN5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üî• Ïö¥Îèô Ï∂îÏ†ï ÌååÏÉùÎ≥ÄÏàò\n\n- mActivity Ï∂îÏ†ïÌñâÎèô\n- mGps, Ìï∏ÎìúÌè∞ ÏúÑÏπò\n- wHr Ïã¨Î∞ïÎèôÏàò\n- wPedo Í±∏ÏùåÏàò","metadata":{"id":"io-bh_LODuyv"}},{"cell_type":"code","source":"def average_list_columns(df, list_columns, pk_cols=['subject_id', 'lifelog_date']):\n\n    for col in list_columns:\n\n        def safe_mean(x):\n            if isinstance(x, list):\n                return np.mean(x) if len(x) > 0 else np.nan\n            elif isinstance(x, (int, float, np.integer, np.floating, type(None))):\n                return x\n            elif isinstance(x, (np.ndarray, pd.Series)):\n                return np.mean(x)\n            elif pd.api.types.is_scalar(x) and pd.isna(x):\n                return np.nan\n            else:\n                return np.nan\n\n        df[col] = df[col].apply(safe_mean)\n\n    return df\n\ndef compute_estimated_exercise(mActivity, mGps, wHr, wPedo, minutes):\n\n    # Î¶¨Ïä§Ìä∏ ÌèâÍ∑† Ï≤òÎ¶¨\n    mGps = mGps.copy()\n    wHr = wHr.copy()\n    mGps = average_list_columns(mGps, ['speed'])\n    Hr = average_list_columns(wHr, ['heart_rate'])\n\n    for df in [mActivity, mGps, wHr, wPedo]:\n        df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    # 5Î∂Ñ ÏßÄÏÜç Ï°∞Í±¥ ÌåêÎã® Ìï®Ïàò\n    def sustained_condition(df, cond_col,minutes):\n        df = df[df[cond_col]].sort_values('timestamp')\n        times = df['timestamp']\n        start = prev = None\n        for t in times:\n            if start is None:\n                start = prev = t\n            elif t <= prev + timedelta(minutes=1):\n                prev = t\n            else:\n                if prev - start >= timedelta(minutes=minutes):\n                    return True\n                start = prev = t\n        return (prev - start) >= timedelta(minutes=minutes) if start else False\n\n    # mActivity: m_activity == 7 ÏßÄÏÜç\n    mActivity['m_cond'] = mActivity['m_activity'] == 7\n    act_flag = mActivity.groupby(['subject_id', 'lifelog_date']) \\\n                        .apply(lambda df: sustained_condition(df, 'm_cond',40)) \\\n                        .reset_index(name='act_exe_flag')\n\n    # mGps: speed ‚àà [2.5, 5.5] ÏßÄÏÜç\n    mGps['gps_cond'] = mGps['speed'].between(2.5, 5.5)\n    gps_flag = mGps.groupby(['subject_id', 'lifelog_date']) \\\n                   .apply(lambda df: sustained_condition(df, 'gps_cond',minutes)) \\\n                   .reset_index(name='gps_exe_flag')\n\n    # wHr: hr ‚â• 133 ÏÉÅÌÉúÍ∞Ä 5Î∂Ñ Ïù¥ÏÉÅ Ïú†ÏßÄ\n    wHr['whr_cond'] = wHr['heart_rate'] >= 133\n    hr_flag = wHr.groupby(['subject_id', 'lifelog_date']) \\\n                   .apply(lambda df: sustained_condition(df, 'whr_cond',minutes)) \\\n                   .reset_index(name='hr_exe_flag')\n\n    # wPedo: step ‚â• 10000 ÎòêÎäî running_step ‚â• 1Ïù¥ 5Î∂Ñ Ïù¥ÏÉÅ\n    pedo_daily = wPedo.groupby(['subject_id', 'lifelog_date'])['step'].sum().reset_index(name='total_steps')\n    pedo_daily['step_flag'] = pedo_daily['total_steps'] >= 10000\n\n    wPedo['r_cond'] = wPedo['running_step'] >= 1\n    run_flag = wPedo.groupby(['subject_id', 'lifelog_date']) \\\n                    .apply(lambda df: sustained_condition(df, 'r_cond', minutes)) \\\n                    .reset_index(name='run_flag')\n\n    pedo_flag = pedo_daily.merge(run_flag, on=['subject_id', 'lifelog_date'], how='outer')\n    pedo_flag['step_flag'] = pedo_flag['step_flag'].fillna(False)\n    pedo_flag['run_flag'] = pedo_flag['run_flag'].fillna(False)\n    pedo_flag['pedo_exe_flag'] = pedo_flag[['step_flag', 'run_flag']].any(axis=1)\n\n    # Î≥ëÌï© Î∞è ÏµúÏ¢Ö ÌåêÎã®\n    result = act_flag.merge(gps_flag, on=['subject_id', 'lifelog_date'], how='outer') \\\n                     .merge(hr_flag, on=['subject_id', 'lifelog_date'], how='outer') \\\n                     .merge(pedo_flag[['subject_id', 'lifelog_date', 'pedo_exe_flag']], on=['subject_id', 'lifelog_date'], how='outer')\n\n    # NaN Ï≤òÎ¶¨ Î∞è 1/0 Î≥ÄÌôò\n    for col in ['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']:\n        result[col] = result[col].fillna(False)\n\n    result['pred_exe_flag'] = result[['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']].any(axis=1)\n\n    # üëâ 1/0 Î≥ÄÌôò\n    for col in ['act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag', 'pred_exe_flag']:\n        result[col] = result[col].astype(int)\n\n    display(result[['pred_exe_flag', 'act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']].sum())\n\n    return result[['subject_id', 'lifelog_date', 'pred_exe_flag', 'act_exe_flag', 'gps_exe_flag', 'hr_exe_flag', 'pedo_exe_flag']]","metadata":{"id":"b8Nz9fSTDtWu","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.962299Z","iopub.execute_input":"2025-05-20T10:50:45.962612Z","iopub.status.idle":"2025-05-20T10:50:45.979685Z","shell.execute_reply.started":"2025-05-20T10:50:45.962588Z","shell.execute_reply":"2025-05-20T10:50:45.978809Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"# Ï∂îÏ†ïÏö¥ÎèôÏó¨Î∂Ä\nexeFlag = compute_estimated_exercise(mActivity, mGps, wHr, wPedo,10)\n\n# check\nprint(f'\\n # exeFlag shape: {exeFlag.shape}')\nexeFlag.head(1)","metadata":{"id":"mE0523emDta_","outputId":"79b19748-03c8-47d2-a66f-6ff141b5a938","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:50:45.980567Z","iopub.execute_input":"2025-05-20T10:50:45.981010Z","iopub.status.idle":"2025-05-20T10:51:00.002892Z","shell.execute_reply.started":"2025-05-20T10:50:45.980972Z","shell.execute_reply":"2025-05-20T10:51:00.002020Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pred_exe_flag    66\nact_exe_flag     31\ngps_exe_flag      5\nhr_exe_flag      18\npedo_exe_flag    19\ndtype: int64"},"metadata":{}},{"name":"stdout","text":"\n # exeFlag shape: (700, 7)\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  pred_exe_flag  act_exe_flag  gps_exe_flag  \\\n0       id01   2024-06-26              0             0             0   \n\n   hr_exe_flag  pedo_exe_flag  \n0            0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>pred_exe_flag</th>\n      <th>act_exe_flag</th>\n      <th>gps_exe_flag</th>\n      <th>hr_exe_flag</th>\n      <th>pedo_exe_flag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"id":"Di5WcfQSDtfQ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"YnVbACW6DtkE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"dofyaM3mDtpH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Zbaes4GnDtuy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üî• Sleeptime ÏùºÏñ¥ÎÇú Í±¥Ïàò\n\n- SleeptimeÏóê (mLight Ï£ºÎ≥Ä Î∞ùÍ∏∞), (wLight Ïï∞ÎπÑÏñ∏Ìä∏ ÎùºÏù¥Ìä∏) Î≥ÄÌôî Í±¥Ïàò","metadata":{"id":"ahIQqHGXGSez"}},{"cell_type":"code","source":"def compute_night_awake_features(df, prefix):\n\n    df = df.copy()\n    df['timestamp'] = pd.to_datetime(df['timestamp'])\n\n    # 00Ïãú~06Ïãú ÌïÑÌÑ∞\n    df['hour'] = df['timestamp'].dt.hour\n    df_night = df[(df['hour'] >= 0) & (df['hour'] < 6)].copy()\n\n    # Íπ®Ïñ¥ÏûàÎäî Î∂Ñ Í≥ÑÏÇ∞\n    df_night['awake_minute'] = (df_night[prefix] > 0).astype(int)\n\n    # Íπ®Ïñ¥ÎÇú ÌöüÏàò Í≥ÑÏÇ∞ (0 ‚Üí ÏñëÏàò Ï†ÑÌôò)\n    def count_awake_blocks(x):\n        return ((x > 0) & (x.shift(fill_value=0) == 0)).sum()\n\n    # Í∑∏Î£πÎ≥Ñ ÏßëÍ≥Ñ\n    result = df_night.groupby(['subject_id', 'lifelog_date']).agg(\n        awake_minutes=('awake_minute', 'sum'),\n        awake_blocks=(prefix, count_awake_blocks)\n    ).reset_index()\n\n    # Ïª¨ÎüºÎ™Ö Î≥ÄÍ≤Ω\n    result = result.rename(columns={\n        'awake_minutes': f'{prefix}_awake_minutes',\n        'awake_blocks': f'{prefix}_awake_blocks'\n    })\n\n    # trainÏóê Í≤∞Í≥º Ìï©ÏπòÍ∏∞ ÏúÑÌï¥ÏÑú -1 day ÌïòÍ∏∞\n    result['lifelog_date'] = pd.to_datetime(result['lifelog_date'])\n    result['lifelog_date'] = result['lifelog_date'] + pd.Timedelta(days=-1)\n\n    result['lifelog_date'] = result['lifelog_date'].astype(str)\n\n    return result","metadata":{"id":"AFvyBXsEGPXi","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.004181Z","iopub.execute_input":"2025-05-20T10:51:00.004778Z","iopub.status.idle":"2025-05-20T10:51:00.012444Z","shell.execute_reply.started":"2025-05-20T10:51:00.004753Z","shell.execute_reply":"2025-05-20T10:51:00.011408Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"a1 = compute_night_awake_features(mLight,'m_light')\na2 = compute_night_awake_features(wLight,'w_light')\nsleepWakeCnt = train[['subject_id','lifelog_date']].copy()\n\nsleepWakeCnt = sleepWakeCnt.merge(a1, on=['subject_id','lifelog_date'], how='left')\nsleepWakeCnt = sleepWakeCnt.merge(a2, on=['subject_id','lifelog_date'], how='left')\n\nsleepWakeCnt['awake_minutes'] = sleepWakeCnt[['m_light_awake_minutes','w_light_awake_minutes']].max(axis=1)\nsleepWakeCnt['awake_blocks'] = sleepWakeCnt[['m_light_awake_blocks','w_light_awake_blocks']].max(axis=1)\n\n# check\nsleepWakeCnt.head()","metadata":{"id":"-CpwIQM4GPbo","outputId":"2b1b110a-68d1-4a0d-9a93-73dd8c773bdc","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.013464Z","iopub.execute_input":"2025-05-20T10:51:00.014263Z","iopub.status.idle":"2025-05-20T10:51:00.593742Z","shell.execute_reply.started":"2025-05-20T10:51:00.014237Z","shell.execute_reply":"2025-05-20T10:51:00.592968Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"  subject_id lifelog_date  m_light_awake_minutes  m_light_awake_blocks  \\\n0       id01   2024-06-26                 4.0000                1.0000   \n1       id01   2024-06-27                 4.0000                1.0000   \n2       id01   2024-06-28                 4.0000                1.0000   \n3       id01   2024-06-29                 1.0000                1.0000   \n4       id01   2024-06-30                 2.0000                1.0000   \n\n   w_light_awake_minutes  w_light_awake_blocks  awake_minutes  awake_blocks  \n0                17.0000                3.0000        17.0000        3.0000  \n1                14.0000                3.0000        14.0000        3.0000  \n2                 0.0000                0.0000         4.0000        1.0000  \n3                 0.0000                0.0000         1.0000        1.0000  \n4                 0.0000                0.0000         2.0000        1.0000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject_id</th>\n      <th>lifelog_date</th>\n      <th>m_light_awake_minutes</th>\n      <th>m_light_awake_blocks</th>\n      <th>w_light_awake_minutes</th>\n      <th>w_light_awake_blocks</th>\n      <th>awake_minutes</th>\n      <th>awake_blocks</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id01</td>\n      <td>2024-06-26</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>17.0000</td>\n      <td>3.0000</td>\n      <td>17.0000</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id01</td>\n      <td>2024-06-27</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>14.0000</td>\n      <td>3.0000</td>\n      <td>14.0000</td>\n      <td>3.0000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id01</td>\n      <td>2024-06-28</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>4.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id01</td>\n      <td>2024-06-29</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>1.0000</td>\n      <td>1.0000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id01</td>\n      <td>2024-06-30</td>\n      <td>2.0000</td>\n      <td>1.0000</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>2.0000</td>\n      <td>1.0000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"id":"v2Br3gMtGPfP","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Wkad6IThGPi5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"SSPT0v_uGPnj","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"p2hYN0XqGPsD","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Ka4Vyd0DGPwO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"XgEdUjOEDt0j","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"LMlyCuPPDt5i","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zE-06HN6gtqy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"b0ICeW88gttt","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üì¶ merge Îç∞Ïù¥ÌÑ∞\n- train, test Í∏∞Í∞Ñ ÏÑúÎ°ú Í≤πÏπ®","metadata":{"id":"YhcVIyeuguwP"}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\ntest = pd.read_csv('/kaggle/input/dacon-etri-lifelog/ETRI_lifelog_dataset/ch2025_submission_sample.csv')\n\n# ÏùºÏûêÎ≥ÄÏàò ÌÉÄÏûÖ Î≥ÄÌôò\nmACStatus2['lifelog_date'] = mACStatus2['lifelog_date'].astype(str)\nmActivity2['lifelog_date'] = mActivity2['lifelog_date'].astype(str)\nmAmbience2['lifelog_date'] = mAmbience2['lifelog_date'].astype(str)\nmBle2['lifelog_date'] = mBle2['lifelog_date'].astype(str)\nmGps2['lifelog_date'] = mGps2['lifelog_date'].astype(str)\nmLight2['lifelog_date'] = mLight2['lifelog_date'].astype(str)\nmScreenStatus2['lifelog_date'] = mScreenStatus2['lifelog_date'].astype(str)\nmUsageStats2['lifelog_date'] = mUsageStats2['lifelog_date'].astype(str)\nmWifi2['lifelog_date'] = mWifi2['lifelog_date'].astype(str)\nwHr2['lifelog_date'] = wHr2['lifelog_date'].astype(str)\nwLight2['lifelog_date'] = wLight2['lifelog_date'].astype(str)\nwPedo2['lifelog_date'] = wPedo2['lifelog_date'].astype(str)\n\n# ---- new ----\n\nexeFlag['lifelog_date'] = exeFlag['lifelog_date'].astype(str)\nsleepWakeCnt['lifelog_date'] = sleepWakeCnt['lifelog_date'].astype(str)","metadata":{"id":"ylxgRVjO0cPS","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.594558Z","iopub.execute_input":"2025-05-20T10:51:00.595005Z","iopub.status.idle":"2025-05-20T10:51:00.626409Z","shell.execute_reply.started":"2025-05-20T10:51:00.594976Z","shell.execute_reply":"2025-05-20T10:51:00.625654Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"df_list = [\n    mACStatus2,       # 1\n    mActivity2,       # 2\n    mAmbience2,       # 3\n    mBle2,            # 4\n    mGps2,            # 5\n    mLight2,          # 6\n    mScreenStatus2,   # 7\n    mUsageStats2,     # 8\n    mWifi2,           # 9\n    wHr2,             # 10\n    wLight2,          # 11\n    wPedo2,           # 12\n    # ---- new ----\n    sleepWakeCnt,\n    exeFlag\n]\n\ndata = reduce(lambda left, right: pd.merge(left, right, on=['subject_id', 'lifelog_date'], how='outer'), df_list)\ndata['lifelog_date'] = data['lifelog_date'].astype(str)\n\n# Ï§ëÎ≥µÏ≤¥ÌÅ¨\nprint(data.shape)\nprint(data[['subject_id','lifelog_date']].drop_duplicates().shape)\n\n# merge\ntrain2 = train.merge(data, on=['subject_id','lifelog_date'], how='left')\ntest2 = test.merge(data, on=['subject_id','lifelog_date'], how='left')\n\n# Ï†ÄÏû•\nprint('# train  shape:',train.shape)\nprint('# train2 shape:',test2.shape)\nprint('# test   shape:',test.shape)\nprint('# test2  shape:',test2.shape)","metadata":{"id":"wyqyR1HyKtYM","outputId":"34fe6de5-75ad-4d39-9526-22bba0447e80","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.627379Z","iopub.execute_input":"2025-05-20T10:51:00.627647Z","iopub.status.idle":"2025-05-20T10:51:00.692714Z","shell.execute_reply.started":"2025-05-20T10:51:00.627626Z","shell.execute_reply":"2025-05-20T10:51:00.691720Z"}},"outputs":[{"name":"stdout","text":"(700, 166)\n(700, 2)\n# train  shape: (450, 9)\n# train2 shape: (250, 173)\n# test   shape: (250, 9)\n# test2  shape: (250, 173)\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"# Ï†ÄÏû•\ntrain2.to_parquet(f\"train_0512.parquet\")\ntest2.to_parquet(f\"test_0512.parquet\")","metadata":{"id":"FJHeu7wQpSdL","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.693779Z","iopub.execute_input":"2025-05-20T10:51:00.694455Z","iopub.status.idle":"2025-05-20T10:51:00.761839Z","shell.execute_reply.started":"2025-05-20T10:51:00.694422Z","shell.execute_reply":"2025-05-20T10:51:00.760770Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"","metadata":{"id":"JApa_DpNpSf8","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"KCkzm9hupSoY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"JBZKGmxSRBQW","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### üìå Î™®Îç∏ ÌïôÏäµ","metadata":{"id":"QO4m6vmGjlkC"}},{"cell_type":"code","source":"# train2 = pd.read_parquet(f\"/content/drive/MyDrive/data/train_v07141.parquet\")\n# test2 = pd.read_parquet(f\"/content/drive/MyDrive/data/test_v07141.parquet\")","metadata":{"id":"l4qv4t3ULZsR","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.763715Z","iopub.execute_input":"2025-05-20T10:51:00.763984Z","iopub.status.idle":"2025-05-20T10:51:00.767646Z","shell.execute_reply.started":"2025-05-20T10:51:00.763963Z","shell.execute_reply":"2025-05-20T10:51:00.766912Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# train = pd.read_parquet(f\"{path}/train2.parquet\")\n# test = pd.read_parquet(f\"{path}/test2.parquet\")\ntrain = train2.copy()\ntest = test2.copy()\n\n# drop_features = ['afterwork_max_label','sleeptime_max_label','worktime_max_label']\ndrop_features = ['top_bssid'] # ,'week_type','week_type_lag1'\ndrop_features = [i for i in drop_features if i in train.columns.tolist()]\nprint('# drop_features:',drop_features)\ntrain = train.drop(columns=drop_features)\ntest = test.drop(columns=drop_features)","metadata":{"id":"FqlfmXYOyXOE","outputId":"08199b45-dd1b-4690-fe08-8907cde8f14a","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.768505Z","iopub.execute_input":"2025-05-20T10:51:00.768797Z","iopub.status.idle":"2025-05-20T10:51:00.791730Z","shell.execute_reply.started":"2025-05-20T10:51:00.768776Z","shell.execute_reply":"2025-05-20T10:51:00.790850Z"}},"outputs":[{"name":"stdout","text":"# drop_features: ['top_bssid']\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"train[['week_type','week_type_lag1']].dtypes","metadata":{"id":"T_q9fmnlCQeo","outputId":"b63c4101-775d-446b-f13d-b8914e00677f","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.792648Z","iopub.execute_input":"2025-05-20T10:51:00.793047Z","iopub.status.idle":"2025-05-20T10:51:00.811252Z","shell.execute_reply.started":"2025-05-20T10:51:00.793013Z","shell.execute_reply":"2025-05-20T10:51:00.810427Z"}},"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"week_type         object\nweek_type_lag1    object\ndtype: object"},"metadata":{}}],"execution_count":57},{"cell_type":"code","source":"# sleep duration\n\n# train['sleep_duration_min_max'] = train[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].max(axis=1)\n# train['sleep_duration_min_min'] = train[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].min(axis=1)\n\n# train['sleep_duration_hour_max'] = train[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].max(axis=1)\n# train['sleep_duration_hour_min'] = train[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].min(axis=1)\n\n# train['sleep_duration_min_interp_max'] = train[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].max(axis=1)\n# train['sleep_duration_min_interp_min'] = train[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].min(axis=1)\n\n# train['sleep_time_min_max'] = train[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].max(axis=1)\n# train['sleep_time_min_min'] = train[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].min(axis=1)\n\n# test['sleep_duration_min_max'] = test[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].max(axis=1)\n# test['sleep_duration_min_min'] = test[['sleep_duration_min_mScreenStatus','sleep_duration_min_mLight']].min(axis=1)\n\n# test['sleep_duration_hour_max'] = test[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].max(axis=1)\n# test['sleep_duration_hour_min'] = test[['sleep_duration_hour_mScreenStatus','sleep_duration_hour_mLight']].min(axis=1)\n\n# test['sleep_duration_min_interp_max'] = test[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].max(axis=1)\n# test['sleep_duration_min_interp_min'] = test[['sleep_duration_interp_mScreenStatus','sleep_duration_interp_mLight']].min(axis=1)\n\n# test['sleep_time_min_max'] = test[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].max(axis=1)\n# test['sleep_time_min_min'] = test[['sleep_time_min_mScreenStatus','sleep_time_min_mLight']].min(axis=1)\n\n# ÏöîÏùº Ïª¨Îüº Ï∂îÍ∞Ä (Ïòà: ÏõîÏöîÏùº, ÌôîÏöîÏùº, ...)\ntrain['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\ntest['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n\n# ÏöîÏùº\nweekday_map = {\n    0: 'ÏõîÏöîÏùº', 1: 'ÌôîÏöîÏùº', 2: 'ÏàòÏöîÏùº', 3: 'Î™©ÏöîÏùº',\n    4: 'Í∏àÏöîÏùº', 5: 'ÌÜ†ÏöîÏùº', 6: 'ÏùºÏöîÏùº'\n}\ntrain['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\ntest['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n\n# Ïõî\ntrain['month'] = train['lifelog_date'].dt.month\ntest['month'] = test['lifelog_date'].dt.month\n\n# weekend\ntrain['weekend'] = np.where(train['weekday'].isin(['ÌÜ†ÏöîÏùº','ÏùºÏöîÏùº']),1,0)\ntest['weekend'] = np.where(test['weekday'].isin(['ÌÜ†ÏöîÏùº','ÏùºÏöîÏùº']),1,0)\n\n# Í≥µÌú¥Ïùº\nÍ≥µÌú¥Ïùº = [\n     '2024-08-15'\n    ,'2024-09-16'\n    ,'2024-09-17'\n    ,'2024-09-18'\n    ,'2024-10-03'\n    ,'2024-10-09'\n]\ntrain['Í≥µÌú¥Ïùº'] = np.where(train['lifelog_date'].isin(Í≥µÌú¥Ïùº),1,0)\ntest['Í≥µÌú¥Ïùº'] = np.where(test['lifelog_date'].isin(Í≥µÌú¥Ïùº),1,0)\n\n# Ï£ºÎßê + Í≥µÌú¥Ïùº Î¨∂Ïñ¥Ï£ºÍ∏∞\n# train['weekend'] = np.where( ((train['weekend']==0) & (train['Í≥µÌú¥Ïùº']==1)), 1, train['weekend'])\n# test['weekend'] = np.where( ((test['weekend']==0) & (test['Í≥µÌú¥Ïùº']==1)), 1, test['weekend'])","metadata":{"id":"lI616WgshZtT","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.812146Z","iopub.execute_input":"2025-05-20T10:51:00.812420Z","iopub.status.idle":"2025-05-20T10:51:00.844281Z","shell.execute_reply.started":"2025-05-20T10:51:00.812400Z","shell.execute_reply":"2025-05-20T10:51:00.843273Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"# Ïà´ÏûêÌòï Ïª¨ÎüºÎßå ÏÑ†ÌÉùÌï¥ÏÑú Í≤∞Ï∏°Í∞í -1Î°ú Ï±ÑÏö∞Í∏∞\ntrain[train.select_dtypes(include='number').columns] = train.select_dtypes(include='number').fillna(-1)\ntest[test.select_dtypes(include='number').columns] = test.select_dtypes(include='number').fillna(-1)","metadata":{"id":"UZoZJcI-1b9r","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:51:00.845476Z","iopub.execute_input":"2025-05-20T10:51:00.845769Z","iopub.status.idle":"2025-05-20T10:51:00.902606Z","shell.execute_reply.started":"2025-05-20T10:51:00.845747Z","shell.execute_reply":"2025-05-20T10:51:00.901551Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:55:54.028231Z","iopub.execute_input":"2025-05-20T10:55:54.029236Z","iopub.status.idle":"2025-05-20T10:55:54.392249Z","shell.execute_reply.started":"2025-05-20T10:55:54.029190Z","shell.execute_reply":"2025-05-20T10:55:54.391131Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"# def get_oof_predictions(X, y, params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n\n#     oof_preds = np.zeros(len(X))  # ‚úÖ 1Ï∞®ÏõêÏúºÎ°ú Î≥ÄÍ≤Ω\n#     skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n#     for train_idx, valid_idx in skf.split(X, y):\n#         X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n#         y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n#         if is_multiclass:\n#             model = LGBMClassifier(**params, objective='multiclass', num_class=num_class)\n#         else:\n#             model = LGBMClassifier(**params)\n\n#         if early_stop:\n#             model.fit(\n#                 X_train, y_train,\n#                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#                 callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n#             )\n#         else:\n#             model.fit(X_train, y_train)\n\n#         preds = model.predict(X_valid)  # ‚úÖ returns 1D array\n#         oof_preds[valid_idx] = preds  # ‚úÖ 1D -> 1D Ï†ÄÏû•\n\n#     return oof_preds","metadata":{"id":"VuirfLhGp4o0","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T10:55:54.393913Z","iopub.execute_input":"2025-05-20T10:55:54.394996Z","iopub.status.idle":"2025-05-20T10:55:54.400182Z","shell.execute_reply.started":"2025-05-20T10:55:54.394965Z","shell.execute_reply":"2025-05-20T10:55:54.399105Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"lgb_A = 0.3\nxgb_B = 0.3\ncat_C = 0.4","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.107804Z","iopub.execute_input":"2025-05-20T11:55:41.108204Z","iopub.status.idle":"2025-05-20T11:55:41.115126Z","shell.execute_reply.started":"2025-05-20T11:55:41.108179Z","shell.execute_reply":"2025-05-20T11:55:41.113216Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"def get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n    oof_preds_lgb = np.zeros(len(X))\n    oof_preds_xgb = np.zeros(len(X))\n    oof_preds_cat = np.zeros(len(X))\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n    for train_idx, valid_idx in skf.split(X, y):\n        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n\n        # LightGBM\n        if is_multiclass:\n            lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=num_class)\n        else:\n            lgb_model = LGBMClassifier(**lgb_params)\n\n        # XGBoost\n        if is_multiclass:\n            xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=num_class)\n        else:\n            xgb_model = XGBClassifier(**xgb_params)\n\n        # CatBoost\n        if is_multiclass:\n            cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=num_class)\n        else:\n            cat_model = CatBoostClassifier(**common_params_cat)\n\n        if early_stop:\n            lgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n            )\n            xgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n            cat_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            lgb_model.fit(X_train, y_train)\n            xgb_model.fit(X_train, y_train)\n            cat_model.fit(X_train, y_train)\n\n        # Get predictions\n        lgb_preds = lgb_model.predict(X_valid)\n        xgb_preds = xgb_model.predict(X_valid)\n        cat_preds = cat_model.predict(X_valid).ravel()  # ‚úÖ 2Ï∞®Ïõê ‚Üí 1Ï∞®Ïõê\n        \n        # Store predictions\n        oof_preds_lgb[valid_idx] = lgb_preds\n        oof_preds_xgb[valid_idx] = xgb_preds\n        oof_preds_cat[valid_idx] = cat_preds\n\n    # Ensemble predictions (7:3 ratio)\n    oof_preds = lgb_A * oof_preds_lgb + xgb_B * oof_preds_xgb + cat_C * oof_preds_cat\n    \n    if not is_multiclass:\n        oof_preds = (oof_preds > 0.5).astype(int)\n    else:\n        oof_preds = np.round(oof_preds).astype(int)\n\n    return oof_preds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.116677Z","iopub.execute_input":"2025-05-20T11:55:41.117061Z","iopub.status.idle":"2025-05-20T11:55:41.139194Z","shell.execute_reply.started":"2025-05-20T11:55:41.117034Z","shell.execute_reply":"2025-05-20T11:55:41.138196Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n\n#     train_df = train.copy()\n#     test_df = test.copy()\n\n#     submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n#     submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n\n#     # ÌÉÄÍ≤ü\n#     targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n#     targets_binary_name = ['Í∏∞ÏÉÅÏßÅÌõÑÏàòÎ©¥Ïßà','Ï∑®Ïπ®Ï†ÑÏã†Ï≤¥Ï†ÅÌîºÎ°ú','Ï∑®Ïπ®Ï†ÑÏä§Ìä∏Î†àÏä§','ÏàòÎ©¥Ìö®Ïú®','ÏàòÎ©¥Ïû†Îì§Í∏∞ÏãúÍ∞Ñ']\n#     target_multiclass = 'S1'\n#     all_targets = targets_binary + [target_multiclass]\n\n#     # ÎÖ∏Ïù¥Ï¶à ÏàòÏ§Ä ÏÑ§Ï†ï\n#     def add_noise(series, noise_level, seed=3):\n#         rng = np.random.default_rng(seed)\n#         return series * (1 + noise_level * rng.standard_normal(len(series)))\n\n#     noise_level = 0.015  # ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ï\n\n#     # ÌÉÄÍ≤üÏù∏ÏΩîÎî©\n#     # m = 0: Ïä§Î¨¥Îî© ÏóÜÏù¥ Î≤îÏ£ºÎ≥Ñ ÌèâÍ∑†Îßå ÏÇ¨Ïö©Ìï©ÎãàÎã§. Í¥ÄÏ∏° ÏàòÍ∞Ä ÎßéÏùÄ Î≤îÏ£ºÏóêÎäî Ï†ÅÌï©ÌïòÏßÄÎßå, Ï†ÅÏùÄ Í≤ΩÏö∞ Í≥ºÏ†ÅÌï© ÏúÑÌóòÏù¥ ÏûàÏäµÎãàÎã§.\n#     # m = 1~10: ÏùºÎ∞òÏ†ÅÏù∏ Í∏∞Î≥∏Í∞íÏúºÎ°ú, ÎåÄÎ∂ÄÎ∂ÑÏùò ÏÉÅÌô©ÏóêÏÑú ÏïàÏ†ïÏ†ÅÏù∏ ÏÑ±Îä•ÏùÑ Î≥¥ÏûÖÎãàÎã§.\n#     # m = 50~300: Í¥ÄÏ∏° ÏàòÍ∞Ä Îß§Ïö∞ Ï†ÅÏùÄ Î≤îÏ£ºÍ∞Ä ÎßéÍ±∞ÎÇò Îç∞Ïù¥ÌÑ∞Í∞Ä Ìù¨ÏÜåÌïú Í≤ΩÏö∞Ïóê Ïú†Ïö©Ìï©ÎãàÎã§.\n#     for tgt in all_targets:\n\n#       encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n\n#       #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©1\n\n#       subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n#       train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n#       test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n#       global_mean = train_df[tgt].mean()\n#       test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n\n#       # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n#       train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n#       test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n\n#       #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©2\n\n#       # ÏÉàÎ°úÏö¥ Î≤îÏ£ºÌòï Ïó¥ ÏÉùÏÑ±\n#       train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n#       test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n\n#       # Ïù∏ÏΩîÎçî\n#       encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n#       encoder.fit(train_df[['TMP']], train_df[tgt])\n\n#       # Ïù∏ÏΩîÎî© Í≤∞Í≥ºÎ•º ÏÉàÎ°úÏö¥ Ïó¥Ïóê Ï†ÄÏû•\n#       train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n#       test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n\n#       # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n#       train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n#       test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n\n#       # Î∂àÌïÑÏöîÌïú Î≥ÄÏàò Ï†úÍ±∞\n#       train_df = train_df.drop(columns=['TMP'])\n#       test_df = test_df.drop(columns=['TMP'])\n\n\n#     # Ïù∏ÏΩîÎî©\n#     PK = ['sleep_date', 'lifelog_date', 'subject_id']\n#     encoder = LabelEncoder()\n#     categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n#     for col in categorical_features:\n#         print(col)\n#         train_df[col] = encoder.fit_transform(train_df[col])\n#         test_df[col] = encoder.fit_transform(test_df[col])\n\n\n#     # X\n#     X = train_df.drop(columns=PK + all_targets)\n#     test_X = test_df.drop(columns=PK + all_targets)\n#     print(f'# X shape: {X.shape}')\n#     print(f'# test_X shape: {test_X.shape}')\n\n#     print('\\n STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏')\n#     print(\"=============== Validation Results ==============\")\n#     total_avg_f1s = []\n#     best_iteration_temp = {k: [] for k in all_targets}\n\n#     val_f1 = []\n#     for col in targets_binary:\n\n#         # binary\n#         y = train_df[col]\n\n#         valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n#         train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n\n#         X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#         X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#         y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#         y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#         # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n\n#         best_param = best_param_dict[col].copy()\n#         best_param['random_state'] = random_state\n#         model = LGBMClassifier(**best_param)\n\n#         if early_stop:\n#             model.fit(\n#                 X_train, y_train,\n#                 eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#                 callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n#             )\n#             best_iteration_temp[col].append(model.best_iteration_)\n#         else:\n#             model.fit(X_train, y_train)\n#             best_iteration_temp[col].append(1000)\n\n#         pred_valid = model.predict(X_valid)\n#         f1 = f1_score(y_valid, pred_valid, average='macro') ### ÏàòÏ†ï\n#         val_f1.append(f1)\n\n#     # multi\n#     y = train_df[target_multiclass]\n\n#     X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#     X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n#     y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#     y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n#     # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n\n#     best_param = best_param_dict['S1'].copy()\n#     best_param['random_state'] = random_state\n#     model = LGBMClassifier(**best_param, objective='multiclass', num_class=3)\n\n#     if early_stop:\n#         model.fit(\n#             X_train, y_train,\n#             eval_set=[(X_train, y_train), (X_valid, y_valid)],\n#             callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n#         )\n#         best_iteration_temp[target_multiclass].append(model.best_iteration_)\n#     else:\n#         model.fit(X_train, y_train)\n#         best_iteration_temp[target_multiclass].append(1000)\n\n#     pred_valid = model.predict(X_valid)\n#     f1 = f1_score(y_valid, pred_valid, average='macro')\n#     val_f1.append(f1)\n\n\n#     avg_f1 = np.mean(val_f1)\n#     total_avg_f1s.append(avg_f1)\n#     detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n#     print(f\" ÌèâÍ∑† F1: {avg_f1:.4f} / [ÏÉÅÏÑ∏] {detail}\")\n\n#     best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n\n#     if early_stop==True:\n#       print(\"\\n[best_iteration_dict]\")\n#       for k, v in best_iteration_dict.items():\n#           print(f\"{k}: {v}\")\n\n\n#     print(f\"# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: {np.mean(total_avg_f1s):.4f}\")\n#     print(\"================================================\")\n\n#     # modoling with 100% train & no valid\n#     print('\\n STEP2: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Î™®Îç∏ Ïû¨ÌïôÏäµ')\n#     print(\"====== modoling with 100% train & no valid =====\")\n\n#     # binary\n#     binary_preds = {}\n#     binary_preds_proba = {}  # ÌôïÎ•† Ï†ÄÏû•Ïö©\n#     for col in targets_binary:\n#         binary_params = best_param_dict[col].copy()\n#         binary_params['random_state'] = random_state\n#         y = train_df[col]\n\n#         if early_stop:\n#           binary_params['n_estimators']=best_iteration_dict[col]\n#           model = LGBMClassifier(**binary_params)\n#           model.fit(X, y)\n#         else:\n#           model = LGBMClassifier(**binary_params)\n#           model.fit(X, y)\n\n#         binary_preds[col] = model.predict(test_X)\n#         binary_preds_proba[col] = model.predict_proba(test_X)\n#         fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n#         top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n#         feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n#         print(f\"[{col}] {feat_str}\")\n\n#     # multiclass\n#     y = train_df['S1']\n#     binary_params = best_param_dict['S1'].copy()\n#     binary_params['random_state'] = random_state\n\n#     if early_stop:\n#       binary_params['n_estimators']=best_iteration_dict['S1']\n#       model = LGBMClassifier(**binary_params)\n#       model.fit(X, y)\n#     else:\n#       model = LGBMClassifier(**binary_params)\n#       model.fit(X, y)\n\n#     multiclass_pred = model.predict(test_X)\n#     multiclass_pred_proba = model.predict_proba(test_X)  # 2D: (N, 3)\n#     fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n#     top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n#     feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n#     print(f\"[S1] {feat_str}\")\n\n#     # ÏòàÏ∏° Ï†ÄÏû•\n#     submission_final['S1'] = multiclass_pred\n#     for col in targets_binary:\n#       submission_final[col] = binary_preds[col]\n#     submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n#     fname = f\"submission_{np.mean(total_avg_f1s)}.csv\"\n#     submission_final.to_csv(fname, index=False)\n#     print(f\"# {fname} Ï†ÄÏû• ÏôÑÎ£å\")\n#     print(f\"# submission shape:{submission_final.shape}\")\n#     print(\"================================================\")\n\n#     # ÌôïÎ•† Í≤∞Í≥º Ï∂îÍ∞Ä\n#     submission_proba = submission_final.copy()\n#     for col in targets_binary:\n#         for i in range(2):\n#             submission_proba[f'{col}_class{i}_proba'] = binary_preds_proba[col][:, i]\n#     for i in range(3):\n#         submission_proba[f'S1_class{i}_proba'] = multiclass_pred_proba[:, i]\n    \n#     # Ï†ÄÏû•\n#     fname_proba = f\"submission_with_proba_{np.mean(total_avg_f1s):.4f}.csv\"\n#     submission_proba.to_csv(fname_proba, index=False)\n#     print(f\"# {fname_proba} Ï†ÄÏû• ÏôÑÎ£å (ÌôïÎ•† Ìè¨Ìï®)\")\n\n#     # Î™®Îç∏Î≥Ñ ÏòàÏ∏°Í≤∞Í≥º ÎπÑÏú® ÎπÑÍµê\n#     a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n#     a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n#     a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n#     a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n#     a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n#     a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n#     result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n#     result.columns = ['ÌïôÏäµsum','ÌïôÏäµlen','ÌïôÏäµmean','ÌÖåÏä§Ìä∏sum','ÌÖåÏä§Ìä∏len','ÌÖåÏä§Ìä∏mean']\n#     print('\\n STEP3: ÏòàÏ∏°Í≤∞Í≥º ÎπÑÍµêÌëú')\n#     display(result)\n\n#     # === STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ± (train setÏóê ÎåÄÌï¥) ===\n\n#     # n_splits = 10\n#     mask = train['month'] != 6\n#     print(f'# k-fold: {n_splits}')\n#     print(f'# train: {len(y[mask])}')\n\n#     oof_f1 = []\n#     print('\\n STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ±')\n#     oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n#     for col in targets_binary:\n#         params = best_param_dict[col].copy()\n#         params['random_state'] = random_state\n#         y = train_df[col]\n#         oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n#         oof_result[col] = oof_preds\n#         f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n#         oof_f1.append(f1)\n#         print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n\n#     # multiclass\n#     col = 'S1'\n#     params = best_param_dict[col].copy()\n#     params['random_state'] = random_state\n#     y = train_df[col]\n#     oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n#     oof_result[col] = oof_preds\n#     f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n#     oof_f1.append(f1)\n#     print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n#     print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n\n#     # oof_result Ï†ÄÏû•\n#     fname = f\"oof_result_{np.mean(total_avg_f1s)}.csv\"\n#     oof_result.to_csv(fname, index=False)\n#     print(f\"# {fname} Ï†ÄÏû• ÏôÑÎ£å\")\n\n#     return submission_final, oof_result","metadata":{"id":"llyNammy2Q4n","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.297042Z","iopub.execute_input":"2025-05-20T11:55:41.297385Z","iopub.status.idle":"2025-05-20T11:55:41.309931Z","shell.execute_reply.started":"2025-05-20T11:55:41.297357Z","shell.execute_reply":"2025-05-20T11:55:41.308518Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n\n    train_df = train.copy()\n    test_df = test.copy()\n\n    submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n    submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n\n    # ÌÉÄÍ≤ü\n    targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n    targets_binary_name = ['Í∏∞ÏÉÅÏßÅÌõÑÏàòÎ©¥Ïßà','Ï∑®Ïπ®Ï†ÑÏã†Ï≤¥Ï†ÅÌîºÎ°ú','Ï∑®Ïπ®Ï†ÑÏä§Ìä∏Î†àÏä§','ÏàòÎ©¥Ìö®Ïú®','ÏàòÎ©¥Ïû†Îì§Í∏∞ÏãúÍ∞Ñ']\n    target_multiclass = 'S1'\n    all_targets = targets_binary + [target_multiclass]\n\n    # ÎÖ∏Ïù¥Ï¶à ÏàòÏ§Ä ÏÑ§Ï†ï\n    def add_noise(series, noise_level, seed=3):\n        rng = np.random.default_rng(seed)\n        return series * (1 + noise_level * rng.standard_normal(len(series)))\n\n    noise_level = 0.015  # ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ï\n\n    # ÌÉÄÍ≤üÏù∏ÏΩîÎî©\n    # m = 0: Ïä§Î¨¥Îî© ÏóÜÏù¥ Î≤îÏ£ºÎ≥Ñ ÌèâÍ∑†Îßå ÏÇ¨Ïö©Ìï©ÎãàÎã§. Í¥ÄÏ∏° ÏàòÍ∞Ä ÎßéÏùÄ Î≤îÏ£ºÏóêÎäî Ï†ÅÌï©ÌïòÏßÄÎßå, Ï†ÅÏùÄ Í≤ΩÏö∞ Í≥ºÏ†ÅÌï© ÏúÑÌóòÏù¥ ÏûàÏäµÎãàÎã§.\n    # m = 1~10: ÏùºÎ∞òÏ†ÅÏù∏ Í∏∞Î≥∏Í∞íÏúºÎ°ú, ÎåÄÎ∂ÄÎ∂ÑÏùò ÏÉÅÌô©ÏóêÏÑú ÏïàÏ†ïÏ†ÅÏù∏ ÏÑ±Îä•ÏùÑ Î≥¥ÏûÖÎãàÎã§.\n    # m = 50~300: Í¥ÄÏ∏° ÏàòÍ∞Ä Îß§Ïö∞ Ï†ÅÏùÄ Î≤îÏ£ºÍ∞Ä ÎßéÍ±∞ÎÇò Îç∞Ïù¥ÌÑ∞Í∞Ä Ìù¨ÏÜåÌïú Í≤ΩÏö∞Ïóê Ïú†Ïö©Ìï©ÎãàÎã§.\n    for tgt in all_targets:\n\n      encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n\n      #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©1\n\n      subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n      train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n      test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n      global_mean = train_df[tgt].mean()\n      test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n\n      # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n      train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n      test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n\n      #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©2\n\n      # ÏÉàÎ°úÏö¥ Î≤îÏ£ºÌòï Ïó¥ ÏÉùÏÑ±\n      train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n      test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n\n      # Ïù∏ÏΩîÎçî\n      encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n      encoder.fit(train_df[['TMP']], train_df[tgt])\n\n      # Ïù∏ÏΩîÎî© Í≤∞Í≥ºÎ•º ÏÉàÎ°úÏö¥ Ïó¥Ïóê Ï†ÄÏû•\n      train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n      test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n\n      # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n      train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n      test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n\n      # Î∂àÌïÑÏöîÌïú Î≥ÄÏàò Ï†úÍ±∞\n      train_df = train_df.drop(columns=['TMP'])\n      test_df = test_df.drop(columns=['TMP'])\n\n\n    # Ïù∏ÏΩîÎî©\n    PK = ['sleep_date', 'lifelog_date', 'subject_id']\n    encoder = LabelEncoder()\n    categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n    for col in categorical_features:\n        print(col)\n        train_df[col] = encoder.fit_transform(train_df[col])\n        test_df[col] = encoder.fit_transform(test_df[col])\n\n\n    # X\n    X = train_df.drop(columns=PK + all_targets)\n    test_X = test_df.drop(columns=PK + all_targets)\n    print(f'# X shape: {X.shape}')\n    print(f'# test_X shape: {test_X.shape}')\n\n    print('\\n STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏')\n    print(\"=============== Validation Results ==============\")\n    total_avg_f1s = []\n    best_iteration_temp = {k: [] for k in all_targets}\n\n    val_f1 = []\n    for col in targets_binary:\n        # binary\n        y = train_df[col]\n\n        valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n        train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n\n        X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n        X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n        y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n        y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n\n        # Get parameters for both models\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n            'n_estimators': 1000,\n            'learning_rate': 0.01,\n            'max_depth': 6,\n            'min_child_weight': 1,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'random_state': random_state\n        }\n\n        # Train LightGBM\n        lgb_model = LGBMClassifier(**lgb_params)\n        if early_stop:\n            lgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n                callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n            )\n            best_iteration_temp[col].append(lgb_model.best_iteration_)\n        else:\n            lgb_model.fit(X_train, y_train)\n            best_iteration_temp[col].append(1000)\n\n        # Train XGBoost\n        xgb_model = XGBClassifier(**xgb_params)\n        if early_stop:\n            xgb_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            xgb_model.fit(X_train, y_train)\n\n        # Train Catboost\n        cat_model = CatBoostClassifier(**common_params_cat, loss_function='Logloss')\n        if early_stop:\n            cat_model.fit(\n                X_train, y_train,\n                eval_set=[(X_valid, y_valid)],\n                early_stopping_rounds=100,\n                verbose=False\n            )\n        else:\n            cat_model.fit(X_train, y_train)\n\n        # Get predictions and ensemble\n        lgb_pred_valid = lgb_model.predict_proba(X_valid)[:, 1]\n        xgb_pred_valid = xgb_model.predict_proba(X_valid)[:, 1]\n        cat_pred_valid = cat_model.predict_proba(X_valid)[:, 1]\n        pred_valid = (lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid  > 0.5).astype(int)\n        \n        f1 = f1_score(y_valid, pred_valid, average='macro')\n        val_f1.append(f1)\n\n    # multiclass\n    y = train_df[target_multiclass]\n\n    X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n    X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n    y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n    y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n\n    # Get parameters for both models\n    lgb_params = common_params['S1'].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n        'n_estimators': 1000,\n        'learning_rate': 0.01,\n        'max_depth': 6,\n        'min_child_weight': 1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': random_state\n    }\n\n    # Train LightGBM\n    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n    if early_stop:\n        lgb_model.fit(\n            X_train, y_train,\n            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n            callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n        )\n        best_iteration_temp[target_multiclass].append(lgb_model.best_iteration_)\n    else:\n        lgb_model.fit(X_train, y_train)\n        best_iteration_temp[target_multiclass].append(1000)\n\n    # Train XGBoost\n    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n    if early_stop:\n        xgb_model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            early_stopping_rounds=100,\n            verbose=False\n        )\n    else:\n        xgb_model.fit(X_train, y_train)\n\n    # Train Catboost\n    cat_model = CatBoostClassifier(**common_params_cat2, loss_function='MultiClass', classes_count=3)\n    if early_stop:\n        cat_model.fit(\n            X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            early_stopping_rounds=100,\n            verbose=False\n        )\n    else:\n        cat_model.fit(X_train, y_train)\n\n    # Get predictions and ensemble\n    lgb_pred_valid = lgb_model.predict_proba(X_valid)\n    xgb_pred_valid = xgb_model.predict_proba(X_valid)\n    cat_pred_valid = cat_model.predict_proba(X_valid)\n    pred_valid = np.argmax(lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid, axis=1)\n    \n    f1 = f1_score(y_valid, pred_valid, average='macro')\n    val_f1.append(f1)\n\n    avg_f1 = np.mean(val_f1)\n    total_avg_f1s.append(avg_f1)\n    detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n    print(f\" ÌèâÍ∑† F1: {avg_f1:.4f} / [ÏÉÅÏÑ∏] {detail}\")\n\n    best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n\n    if early_stop==True:\n      print(\"\\n[best_iteration_dict]\")\n      for k, v in best_iteration_dict.items():\n          print(f\"{k}: {v}\")\n\n\n    print(f\"# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: {np.mean(total_avg_f1s):.4f}\")\n    print(\"================================================\")\n\n    # modoling with 100% train & no valid\n    print('\\n STEP2: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Î™®Îç∏ Ïû¨ÌïôÏäµ')\n    print(\"====== modoling with 100% train & no valid =====\")\n\n    # binary\n    binary_preds = {}\n    binary_preds_proba = {}\n    for col in targets_binary:\n        # Get parameters for both models\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n            'n_estimators': 1000,\n            'learning_rate': 0.01,\n            'max_depth': 6,\n            'min_child_weight': 1,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'random_state': random_state\n        }\n\n        y = train_df[col]\n\n        if early_stop:\n            lgb_params['n_estimators'] = best_iteration_dict[col]\n            xgb_params['n_estimators'] = best_iteration_dict[col]\n\n        # Train LightGBM\n        lgb_model = LGBMClassifier(**lgb_params)\n        lgb_model.fit(X, y)\n\n        # Train XGBoost\n        xgb_model = XGBClassifier(**xgb_params)\n        xgb_model.fit(X, y)\n\n        # Train CatBoost\n        cat_model = CatBoostClassifier(**common_params_cat)\n        cat_model.fit(X, y)\n\n        # Get predictions and ensemble\n        lgb_pred = lgb_model.predict_proba(test_X)[:, 1]\n        xgb_pred = xgb_model.predict_proba(test_X)[:, 1]\n        cat_pred = cat_model.predict_proba(test_X)[:, 1]\n        binary_preds[col] = (lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred > 0.5).astype(int)\n        binary_preds_proba[col] = lgb_A * lgb_model.predict_proba(test_X) + xgb_B * xgb_model.predict_proba(test_X) + cat_C * cat_model.predict_proba(test_X)\n\n        # Feature importance (using LightGBM's importance)\n        fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n        top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n        feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n        print(f\"[{col}] {feat_str}\")\n\n    # multiclass\n    y = train_df['S1']\n    \n    # Get parameters for both models\n    lgb_params = common_params['S1'].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n        'n_estimators': 1000,\n        'learning_rate': 0.01,\n        'max_depth': 6,\n        'min_child_weight': 1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': random_state\n    }\n\n    if early_stop:\n        lgb_params['n_estimators'] = best_iteration_dict['S1']\n        xgb_params['n_estimators'] = best_iteration_dict['S1']\n\n    # Train LightGBM\n    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n    lgb_model.fit(X, y)\n\n    # Train XGBoost\n    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n    xgb_model.fit(X, y)\n\n    # Train CatBoost\n    cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=3)\n    cat_model.fit(X, y)\n\n    # Get predictions and ensemble\n    lgb_pred = lgb_model.predict_proba(test_X)\n    xgb_pred = xgb_model.predict_proba(test_X)\n    cat_pred = cat_model.predict_proba(test_X)\n    multiclass_pred = np.argmax(lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred, axis=1)\n    multiclass_pred_proba = lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred\n\n    # Feature importance\n    fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n    top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n    feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n    print(f\"[S1] {feat_str}\")\n\n    # ÏòàÏ∏° Ï†ÄÏû•\n    submission_final['S1'] = multiclass_pred\n    for col in targets_binary:\n      submission_final[col] = binary_preds[col]\n    submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n    fname = f\"submission_{np.mean(total_avg_f1s)}.csv\"\n    submission_final.to_csv(fname, index=False)\n    print(f\"# {fname} Ï†ÄÏû• ÏôÑÎ£å\")\n    print(f\"# submission shape:{submission_final.shape}\")\n    print(\"================================================\")\n\n    # ÌôïÎ•† Í≤∞Í≥º Ï∂îÍ∞Ä\n    submission_proba = submission_final.copy()\n    for col in targets_binary:\n        for i in range(2):\n            submission_proba[f'{col}_class{i}_proba'] = binary_preds_proba[col][:, i]\n    for i in range(3):\n        submission_proba[f'S1_class{i}_proba'] = multiclass_pred_proba[:, i]\n    \n    # Ï†ÄÏû•\n    fname_proba = f\"submission_with_proba_{np.mean(total_avg_f1s):.4f}.csv\"\n    submission_proba.to_csv(fname_proba, index=False)\n    print(f\"# {fname_proba} Ï†ÄÏû• ÏôÑÎ£å (ÌôïÎ•† Ìè¨Ìï®)\")\n\n    # Î™®Îç∏Î≥Ñ ÏòàÏ∏°Í≤∞Í≥º ÎπÑÏú® ÎπÑÍµê\n    a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n    a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n    a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n    a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n    a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n    a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n    result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n    result.columns = ['ÌïôÏäµsum','ÌïôÏäµlen','ÌïôÏäµmean','ÌÖåÏä§Ìä∏sum','ÌÖåÏä§Ìä∏len','ÌÖåÏä§Ìä∏mean']\n    print('\\n STEP3: ÏòàÏ∏°Í≤∞Í≥º ÎπÑÍµêÌëú')\n    display(result)\n\n    # === STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ± (train setÏóê ÎåÄÌï¥) ===\n\n    # n_splits = 10\n    mask = train['month'] != 6\n    print(f'# k-fold: {n_splits}')\n    print(f'# train: {len(y[mask])}')\n\n    oof_f1 = []\n    print('\\n STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ±')\n    oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n    for col in targets_binary:\n        lgb_params = common_params[col].copy()\n        lgb_params['random_state'] = random_state\n        \n        xgb_params = {\n          'n_estimators': 1000,\n          \"learning_rate\": 0.01,\n          'reg_lambda': 1,\n          'max_depth': 6,\n          'n_jobs': -1,\n          'subsample': 0.8,\n          'colsample_bylevel': 0.8,\n          'min_child_weight': 1,\n          'max_bin': 200,\n          'tree_method': 'hist',\n          'random_state': random_state,\n        }\n        \n        y = train_df[col]\n        oof_preds = get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n        oof_result[col] = oof_preds\n        f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n        oof_f1.append(f1)\n        print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n\n    # multiclass\n    col = 'S1'\n    lgb_params = common_params[col].copy()\n    lgb_params['random_state'] = random_state\n    \n    xgb_params = {\n      'n_estimators': 1000,\n      \"learning_rate\": 0.01,\n      'reg_lambda': 1,\n      'max_depth': 6,\n      'n_jobs': -1,\n      'subsample': 0.8,\n      'colsample_bylevel': 0.8,\n      'min_child_weight': 1,\n      'max_bin': 200,\n      'tree_method': 'hist',\n      'random_state': random_state,\n    }\n    \n    \n    y = train_df[col]\n    oof_preds = get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n    oof_result[col] = oof_preds\n    f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n    oof_f1.append(f1)\n    print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n    print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n\n    # oof_result Ï†ÄÏû•\n    fname = f\"oof_result_{np.mean(total_avg_f1s)}.csv\"\n    oof_result.to_csv(fname, index=False)\n    print(f\"# {fname} Ï†ÄÏû• ÏôÑÎ£å\")\n\n    return submission_final, oof_result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.328489Z","iopub.execute_input":"2025-05-20T11:55:41.329504Z","iopub.status.idle":"2025-05-20T11:55:41.382818Z","shell.execute_reply.started":"2025-05-20T11:55:41.329431Z","shell.execute_reply":"2025-05-20T11:55:41.381724Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"\"\"\"\nweek_type\nweek_type_lag1\nweekday\n# X shape: (450, 168)\n# test_X shape: (250, 168)\n\n STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏\n=============== Validation Results ==============\n ÌèâÍ∑† F1: 0.6322 / [ÏÉÅÏÑ∏] Q1(Í∏∞ÏÉÅÏßÅÌõÑÏàòÎ©¥Ïßà):0.7278 Q2(Ï∑®Ïπ®Ï†ÑÏã†Ï≤¥Ï†ÅÌîºÎ°ú):0.7122 Q3(Ï∑®Ïπ®Ï†ÑÏä§Ìä∏Î†àÏä§):0.6830 S2(ÏàòÎ©¥Ìö®Ïú®):0.5726 S3(ÏàòÎ©¥Ïû†Îì§Í∏∞ÏãúÍ∞Ñ):0.6686 S1(S1):0.4293\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6322\n================================================\n\n STEP2: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Î™®Îç∏ Ïû¨ÌïôÏäµ\n====== modoling with 100% train & no valid =====\n[Q1] Q1_te2(557), light_night_mean(469), wake_time_ratio(405), wake_time_diff_lag1(340), ÌÜµÌôî_time(326), Q1_te(325), sleep_duration_diff(242), activehour_unique_label_count(200), ble_class_others_ratio_worktime(175), wake_time(155)\n[Q2] Q2_te2(2791), total_screen_time(351), wake_up_early_minutes(331), speed_le5_max(307), rolling_wake_time_3d(288), rolling_sleep_time_3d(233), sleep_time_diff(224), Q2_te(198), wlight_evening_mean(182), hr_evening_std(176)\n[Q3] Q3_te2(2199), light_max(366), sleep_duration_diff_lag1(274), sleep_duration_min(227), sleep_duration_ratio(211), screen_time_vs_avg_pct(187), lat_change(181), all_VEHICLE_minutes(179), sleep_time(177), ÌÜµÌôî_time(167)\n[S2] S2_te(3725), S2_te2(2773), wake_time_diff_lag1(340), light_max(292), light_night_mean(245), S1_te2(189), ble_class_unknwn_ratio_sleeptime(179), ÌÜµÌôî_time(175), sleep_duration_lag1(171), sleep_duration_min(170)\n[S3] S3_te(639), light_night_mean(443), S3_te2(336), ble_rssi_mean_afterwork(256), hr_evening_min(242), activehour_unique_label_count(242), ble_class_unknwn_ratio_sleeptime(235), wlight_evening_mean(231), sleep_time_diff_lag1(230), vehicle_minutes(180)\n[S1] S1_te2(3990), S1_te(661), sleep_duration_ratio(646), wake_time_ratio(554), sleep_duration_diff(452), sleep_duration_min(429), vehicle_minutes(427), rolling_wake_time_3d(410), speed_le5_max(408), hour_span_minutes(379)\n# /content/drive/MyDrive/data/submission_0.6322252622334963.csv Ï†ÄÏû• ÏôÑÎ£å\n# submission shape:(250, 9)\n================================================\n\n STEP3: ÏòàÏ∏°Í≤∞Í≥º ÎπÑÍµêÌëú\nÌïôÏäµsum\tÌïôÏäµlen\tÌïôÏäµmean\tÌÖåÏä§Ìä∏sum\tÌÖåÏä§Ìä∏len\tÌÖåÏä§Ìä∏mean\nQ1\t223\t450\t0.4956\t131\t250\t0.5240\nQ2\t253\t450\t0.5622\t150\t250\t0.6000\nQ3\t270\t450\t0.6000\t173\t250\t0.6920\nS1\t390\t450\t0.8667\t202\t250\t0.8080\nS2\t293\t450\t0.6511\t170\t250\t0.6800\nS3\t298\t450\t0.6622\t171\t250\t0.6840\n\n\n# k-fold: 5\n# train: 392\n\n STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ±\n[OOF - Q1] F1 score: 0.6976\n[OOF - Q2] F1 score: 0.7041\n[OOF - Q3] F1 score: 0.6605\n[OOF - S2] F1 score: 0.6610\n[OOF - S3] F1 score: 0.7106\n[OOF - S1] F1 score: 0.5233\n[OOF] F1 score: 0.6595\n# /content/drive/MyDrive/data/oof_result_0.6322252622334963.csv Ï†ÄÏû• ÏôÑÎ£å\n\"\"\"\n\n# Í≥µÌÜµ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\ncommon_params = {\n  'n_estimators': 5000,\n  \"learning_rate\": 0.01,\n  # \"shrinkage_rate\": 0.12,\n  # 'min_data_in_leaf':2,\n  # 'bagging_fraction':0.9,\n  # 'feature_fraction':0.6,\n  'lambda_l1': 5,\n  'lambda_l2': 1,\n  # 'max_depth': 4,\n  'n_jobs': -1,\n  'verbosity': -1\n}\n\n# Î™®Îç∏Î≥Ñ ÏÑ∏Î∂Ä ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\nbest_param_dict = {'Q1': {'learning_rate': 0.1473150575266255,\n  'shrinkage_rate': 0.08585454450680065,\n  'min_data_in_leaf': 13,\n  'bagging_fraction': 0.5900885111562433,\n  'feature_fraction': 0.7398526832500182,\n  'lambda_l1': 0.7309384079752819,\n  'lambda_l2': 0.010419978985191203,\n  'max_depth': 2},\n 'Q2': {'learning_rate': 0.1433742819325529,\n  'shrinkage_rate': 0.4777741359643458,\n  'min_data_in_leaf': 11,\n  'bagging_fraction': 0.8942012129234453,\n  'feature_fraction': 0.3442323511952453,\n  'lambda_l1': 0.11108296857244106,\n  'lambda_l2': 0.5000682520529595,\n  'max_depth': 11},\n 'Q3': {'learning_rate': 0.005440413154494791,\n  'shrinkage_rate': 0.4869550654391126,\n  'min_data_in_leaf': 5,\n  'bagging_fraction': 0.992720410336095,\n  'feature_fraction': 0.10854085794750301,\n  'lambda_l1': 8.765258863766789,\n  'lambda_l2': 0.010911793484805324,\n  'max_depth': -1},\n 'S1': {'learning_rate': 0.19808502263166988,\n  'shrinkage_rate': 0.3292477285579064,\n  'min_data_in_leaf': 9,\n  'bagging_fraction': 0.5929013243246726,\n  'feature_fraction': 0.8481981135327139,\n  'lambda_l1': 0.010377995886618164,\n  'lambda_l2': 0.6226891522266145,\n  'max_depth': 10},\n 'S2': {'learning_rate': 0.27099064035077214,\n  'shrinkage_rate': 0.028901883938906636,\n  'min_data_in_leaf': 9,\n  'bagging_fraction': 0.8134249396247819,\n  'feature_fraction': 0.2321570003912355,\n  'lambda_l1': 8.780092357464005,\n  'lambda_l2': 9.605716023562762,\n  'max_depth': 7},\n 'S3': {'learning_rate': 0.14542046442644,\n  'shrinkage_rate': 0.3047247759570036,\n  'min_data_in_leaf': 10,\n  'bagging_fraction': 0.8493532899163512,\n  'feature_fraction': 0.7940889257506005,\n  'lambda_l1': 9.299803284110112,\n  'lambda_l2': 0.12938944891518922,\n  'max_depth': 6}\n}\n\n# Í≥µÌÜµ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÎåÄÏ≤¥ (Ïù¥ÏÉÅÌïú Î™®Îç∏Ïùò Í≤ΩÏö∞)\nbest_param_dict['Q3'] = common_params\nbest_param_dict['S1'] = common_params\nbest_param_dict['S2'] = common_params\nbest_param_dict['S3'] = common_params\nbest_param_dict['Q1'] = common_params\nbest_param_dict['Q2'] = common_params\n\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6069\n# [OOF] F1 score: 0.6491\n# [OOF - Q1] F1 score: 0.6913\n# [OOF - Q2] F1 score: 0.7078\n# [OOF - Q3] F1 score: 0.6432\n# [OOF - S2] F1 score: 0.6542\n# [OOF - S3] F1 score: 0.7088\n# [OOF - S1] F1 score: 0.4895\n\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6109\n# [OOF] F1 score: 0.6575\n\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6172\n# [OOF] F1 score: 0.6463\n\n# [ÏàòÏ†ï Ï†Ñ]\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6308\n# [OOF] F1 score: 0.6526\n\n# [ÏàòÏ†ï ÌõÑ]\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6322\n# [OOF] F1 score: 0.6595\n\n\ncommon_params_cat = {\n    'iterations': 1000,           # n_estimatorsÏóê Ìï¥Îãπ\n    'learning_rate': 0.01,\n    'l2_leaf_reg': 1,             # reg_lambdaÏóê Ìï¥Îãπ\n    'depth': 6,                   # max_depthÏóê Ìï¥Îãπ\n    'thread_count': -1,           # n_jobsÏóê Ìï¥Îãπ\n    # 'subsample': 0.8,\n    'rsm': 0.8,                   # colsample_bylevelÏóê Ìï¥Îãπ\n    'min_data_in_leaf': 1,        # min_child_weightÏóê Ïú†ÏÇ¨\n    'border_count': 200,          # max_binÏóê Ìï¥Îãπ\n    'task_type': 'CPU',           # 'hist'Ïóê ÎåÄÏùë\n    'random_state' : 41,\n    'verbose' : False\n}\n\ncommon_params_cat2 = {\n    'iterations': 1000,           # n_estimatorsÏóê Ìï¥Îãπ\n    'learning_rate': 0.01,\n    'class_weights': [1.048, 0.670, 1.807],  # [0, 1, 2] ÏàúÏÑú\n    'l2_leaf_reg': 1,             # reg_lambdaÏóê Ìï¥Îãπ\n    'depth': 6,                   # max_depthÏóê Ìï¥Îãπ\n    'thread_count': -1,           # n_jobsÏóê Ìï¥Îãπ\n    # 'subsample': 0.8,\n    'rsm': 0.8,                   # colsample_bylevelÏóê Ìï¥Îãπ\n    'min_data_in_leaf': 1,        # min_child_weightÏóê Ïú†ÏÇ¨\n    'border_count': 200,          # max_binÏóê Ìï¥Îãπ\n    'task_type': 'CPU',           # 'hist'Ïóê ÎåÄÏùë\n    'random_state' : 41,\n    'verbose' : False\n}\n\nsubmission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)","metadata":{"id":"M7sjChm1-ZaF","outputId":"2b847b8e-2d61-4c99-d254-ff950b2719c8","trusted":true,"execution":{"iopub.status.busy":"2025-05-20T11:55:41.478197Z","iopub.execute_input":"2025-05-20T11:55:41.479278Z","iopub.status.idle":"2025-05-20T12:15:05.549458Z","shell.execute_reply.started":"2025-05-20T11:55:41.479244Z","shell.execute_reply":"2025-05-20T12:15:05.548487Z"}},"outputs":[{"name":"stdout","text":"week_type\nweek_type_lag1\nweekday\n# X shape: (450, 179)\n# test_X shape: (250, 179)\n\n STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏\n=============== Validation Results ==============\n ÌèâÍ∑† F1: 0.6451 / [ÏÉÅÏÑ∏] Q1(Í∏∞ÏÉÅÏßÅÌõÑÏàòÎ©¥Ïßà):0.7229 Q2(Ï∑®Ïπ®Ï†ÑÏã†Ï≤¥Ï†ÅÌîºÎ°ú):0.7588 Q3(Ï∑®Ïπ®Ï†ÑÏä§Ìä∏Î†àÏä§):0.6520 S2(ÏàòÎ©¥Ìö®Ïú®):0.5881 S3(ÏàòÎ©¥Ïû†Îì§Í∏∞ÏãúÍ∞Ñ):0.6822 S1(S1):0.4665\n# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: 0.6451\n================================================\n\n STEP2: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Î™®Îç∏ Ïû¨ÌïôÏäµ\n====== modoling with 100% train & no valid =====\n[Q1] Q1_te2(590), wake_time_ratio(412), light_night_mean(352), Q1_te(288), wake_time_diff_lag1(244), sleep_duration_ratio(218), beforebed_Ï†ÑÌôî_time(215), sleep_duration_diff(203), beforebed_ÌÜµÌôî_time(200), hr_evening_std(193)\n[Q2] Q2_te2(1992), rolling_wake_time_3d(295), wake_up_early_minutes(262), wlight_evening_mean(262), avg_rssi(226), Q2_te(221), sleep_time_diff(200), activehour_total_screen_time(180), speed_le5_max(167), rolling_sleep_time_3d(165)\n[Q3] Q3_te2(3370), light_max(384), sleep_duration_diff_lag1(255), sleep_duration_min(235), activehour_ÌÜµÌôî_time(227), lat_change(163), Q3_te(160), sleep_time(151), hr_evening_max(149), wake_time_diff_lag1(144)\n[S2] S2_te2(1968), S2_te(1638), beforebed_total_screen_time(389), wake_time_diff_lag1(294), light_max(255), sleep_duration_min(205), sleep_duration_ratio(200), S1_te2(196), avg_rssi(189), light_night_mean(185)\n[S3] S3_te(2008), light_night_mean(444), S3_te2(369), ble_rssi_mean_afterwork(246), ble_class_unknwn_ratio_sleeptime(231), sleep_time_diff_lag1(231), activehour_unique_label_count(229), hr_evening_min(221), wlight_early_morning_max(200), vehicle_minutes(187)\n[S1] S1_te2(3985), S1_te(939), beforebed_screen_time_vs_avg_pct(866), sleep_duration_min(722), wake_time_ratio(709), sleep_duration_ratio(578), beforebed_total_screen_time(488), hour_span_minutes(450), sleep_duration_diff(408), rolling_wake_time_3d(381)\n# submission_0.6450682487167021.csv Ï†ÄÏû• ÏôÑÎ£å\n# submission shape:(250, 9)\n================================================\n# submission_with_proba_0.6451.csv Ï†ÄÏû• ÏôÑÎ£å (ÌôïÎ•† Ìè¨Ìï®)\n\n STEP3: ÏòàÏ∏°Í≤∞Í≥º ÎπÑÍµêÌëú\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"    ÌïôÏäµsum  ÌïôÏäµlen  ÌïôÏäµmean  ÌÖåÏä§Ìä∏sum  ÌÖåÏä§Ìä∏len  ÌÖåÏä§Ìä∏mean\nQ1    223    450  0.4956     130     250   0.5200\nQ2    253    450  0.5622     155     250   0.6200\nQ3    270    450  0.6000     173     250   0.6920\nS1    390    450  0.8667     208     250   0.8320\nS2    293    450  0.6511     170     250   0.6800\nS3    298    450  0.6622     169     250   0.6760","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ÌïôÏäµsum</th>\n      <th>ÌïôÏäµlen</th>\n      <th>ÌïôÏäµmean</th>\n      <th>ÌÖåÏä§Ìä∏sum</th>\n      <th>ÌÖåÏä§Ìä∏len</th>\n      <th>ÌÖåÏä§Ìä∏mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Q1</th>\n      <td>223</td>\n      <td>450</td>\n      <td>0.4956</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0.5200</td>\n    </tr>\n    <tr>\n      <th>Q2</th>\n      <td>253</td>\n      <td>450</td>\n      <td>0.5622</td>\n      <td>155</td>\n      <td>250</td>\n      <td>0.6200</td>\n    </tr>\n    <tr>\n      <th>Q3</th>\n      <td>270</td>\n      <td>450</td>\n      <td>0.6000</td>\n      <td>173</td>\n      <td>250</td>\n      <td>0.6920</td>\n    </tr>\n    <tr>\n      <th>S1</th>\n      <td>390</td>\n      <td>450</td>\n      <td>0.8667</td>\n      <td>208</td>\n      <td>250</td>\n      <td>0.8320</td>\n    </tr>\n    <tr>\n      <th>S2</th>\n      <td>293</td>\n      <td>450</td>\n      <td>0.6511</td>\n      <td>170</td>\n      <td>250</td>\n      <td>0.6800</td>\n    </tr>\n    <tr>\n      <th>S3</th>\n      <td>298</td>\n      <td>450</td>\n      <td>0.6622</td>\n      <td>169</td>\n      <td>250</td>\n      <td>0.6760</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"# k-fold: 5\n# train: 392\n\n STEP4: OOF ÏòàÏ∏° ÏÉùÏÑ±\n[OOF - Q1] F1 score: 0.7185\n[OOF - Q2] F1 score: 0.6855\n[OOF - Q3] F1 score: 0.6542\n[OOF - S2] F1 score: 0.6712\n[OOF - S3] F1 score: 0.6949\n[OOF - S1] F1 score: 0.5423\n[OOF] F1 score: 0.6611\n# oof_result_0.6450682487167021.csv Ï†ÄÏû• ÏôÑÎ£å\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"","metadata":{"id":"JB23rMBGBDD6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"biUlibpQBDHH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"-omUNJKu4FQ2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"kXkq6d_UZvW2","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"6OtuWwCdZvjl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Tizi0KM8ZvxZ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"oAy96acfohaC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ccOGl_LVohd3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"7_alWM8Rohih","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zYhYMpt9ohm_","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"pI8vcwS0ohrk","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2KeVlJrCohwO","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zhYJGws1oh1b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"0GhN3UK5Zv2H","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"3WcoqLu_2Kpl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"EOL5Sj6aCMXz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"C4wkMmnRwRQV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"OmKky7O2wRSx","trusted":true},"outputs":[],"execution_count":null}]}