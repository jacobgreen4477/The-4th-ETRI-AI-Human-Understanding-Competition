{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 7210916,
          "sourceId": 12085434,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 4148.996629,
      "end_time": "2025-06-07T13:22:50.273930",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-06-07T12:13:41.277301",
      "version": "2.6.0"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "29e359c93ef544c880fa7376e2a0c735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8de0d6259153448a9b28cf00068fefe9",
              "IPY_MODEL_c7ff75c2a87c4abeb49452cd1b8c16fa",
              "IPY_MODEL_91ca2f98da924ae79280824e94c4e8ce"
            ],
            "layout": "IPY_MODEL_6201b62abe444c499aec398aab387292"
          }
        },
        "8de0d6259153448a9b28cf00068fefe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4c1f8c91b14817aae0b2ba1ea5ce4d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_00baeb430eb34ffa87e6f4d28831832c",
            "value": "tabpfn-v2-classifier.ckpt:‚Äá100%"
          }
        },
        "c7ff75c2a87c4abeb49452cd1b8c16fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9344c0ba3d60411aa538cc438e0c658a",
            "max": 29016968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_711bb611dca84a1c9dd76cb81f107a75",
            "value": 29016968
          }
        },
        "91ca2f98da924ae79280824e94c4e8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_074ae2faf5534d6f9959bc680f3405b4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e4c296aece2c49678eaa763c928c1854",
            "value": "‚Äá29.0M/29.0M‚Äá[00:00&lt;00:00,‚Äá195MB/s]"
          }
        },
        "6201b62abe444c499aec398aab387292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc4c1f8c91b14817aae0b2ba1ea5ce4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00baeb430eb34ffa87e6f4d28831832c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9344c0ba3d60411aa538cc438e0c658a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "711bb611dca84a1c9dd76cb81f107a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "074ae2faf5534d6f9959bc680f3405b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c296aece2c49678eaa763c928c1854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da1fb4f84f8b45bbb49592abc206e5bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f79d004737f644339d2a4caa5010e8a2",
              "IPY_MODEL_c2a321503e9c40298f7ccb96c0c64e3f",
              "IPY_MODEL_a005e8e605b145d3be2c19a374c9df1c"
            ],
            "layout": "IPY_MODEL_98cbd9e28ec2447389528f78fedc01f2"
          }
        },
        "f79d004737f644339d2a4caa5010e8a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a479cca4a72b409b9aa3e87f5523cd3f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fcff32737f8b434f94308abf8830fa30",
            "value": "config.json:‚Äá100%"
          }
        },
        "c2a321503e9c40298f7ccb96c0c64e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_401231f393eb4341b87fe30a75757c6b",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76b9bc340a004912b1219429e37c1163",
            "value": 37
          }
        },
        "a005e8e605b145d3be2c19a374c9df1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb3a615839e5497e92a7777e3f7474f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_69e30a389fdb4aa9b5bf204a1056e876",
            "value": "‚Äá37.0/37.0‚Äá[00:00&lt;00:00,‚Äá4.56kB/s]"
          }
        },
        "98cbd9e28ec2447389528f78fedc01f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a479cca4a72b409b9aa3e87f5523cd3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcff32737f8b434f94308abf8830fa30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "401231f393eb4341b87fe30a75757c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76b9bc340a004912b1219429e37c1163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb3a615839e5497e92a7777e3f7474f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e30a389fdb4aa9b5bf204a1056e876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/The-4th-ETRI-AI-Human-Understanding-Competition/blob/main/etri_template_vF1_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "id": "5e04b986",
      "cell_type": "markdown",
      "source": [
        "> title : Ï†ú 4Ìöå ETRI Ìú¥Î®ºÏù¥Ìï¥ Ïù∏Í≥µÏßÄÎä• ÎÖºÎ¨∏Í≤ΩÏßÑÎåÄÌöå <br>\n",
        "> author : hjy,byc <br>"
      ],
      "metadata": {
        "id": "5e04b986",
        "papermill": {
          "duration": 0.03258,
          "end_time": "2025-06-07T12:13:45.373144",
          "exception": false,
          "start_time": "2025-06-07T12:13:45.340564",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "id": "21389cf1",
      "cell_type": "markdown",
      "source": [
        "### üì¶ ÎùºÏù¥Î∏åÎü¨Î¶¨"
      ],
      "metadata": {
        "id": "21389cf1",
        "papermill": {
          "duration": 0.024258,
          "end_time": "2025-06-07T12:13:45.567349",
          "exception": false,
          "start_time": "2025-06-07T12:13:45.543091",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "id": "aca4f97e-8957-48ee-8927-9f27e8046cfc",
      "cell_type": "code",
      "source": [
        "! pip install haversine >/dev/null\n",
        "! pip install optuna  >/dev/null\n",
        "! pip install category_encoders >/dev/null\n",
        "! pip install tabpfn  >/dev/null\n",
        "! pip install catboost >/dev/null\n",
        "! pip install torchmetrics >/dev/null"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-09T10:02:33.636701Z",
          "iopub.execute_input": "2025-06-09T10:02:33.637229Z",
          "iopub.status.idle": "2025-06-09T10:03:51.959026Z",
          "shell.execute_reply.started": "2025-06-09T10:02:33.637203Z",
          "shell.execute_reply": "2025-06-09T10:03:51.958005Z"
        },
        "id": "aca4f97e-8957-48ee-8927-9f27e8046cfc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4f2a25a5",
      "cell_type": "code",
      "source": [
        "# Í∏∞Î≥∏ Î™®Îìà\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import ast\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "from collections import Counter\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from functools import reduce\n",
        "from datetime import datetime, timedelta, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Î®∏Ïã†Îü¨Îãù\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "from category_encoders import TargetEncoder\n",
        "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "import lightgbm as lgb\n",
        "from tabpfn import TabPFNClassifier\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Hugging Face\n",
        "from huggingface_hub import login\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    LlamaTokenizer,\n",
        "    LlamaForCausalLM,\n",
        "    LlamaForSequenceClassification\n",
        ")\n",
        "\n",
        "# PEFT (Parameter-Efficient Fine-Tuning)\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    get_peft_model_state_dict,\n",
        "    TaskType\n",
        ")\n",
        "\n",
        "# Evaluation & Utilities\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# Í∏∞ÌÉÄ\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm as auto_tqdm  # ÌïÑÏöî Ïãú Íµ¨Î∂Ñ\n",
        "from scipy.stats import entropy\n",
        "from haversine import haversine\n",
        "from io import StringIO\n",
        "import gc\n",
        "\n",
        "# wandb\n",
        "import wandb\n",
        "wandb.login(key=\"5fa8dfb2c5be3c888bfe0101437a8fa22fbdf0e0\")\n",
        "wandb.init(project=\"etri_lifelog\", entity=\"byc3230\")\n",
        "\n",
        "# ÏòµÏÖò\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "pd.set_option('display.max_columns', 999)\n",
        "pd.set_option('display.max_rows', 999)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '%0.4f' % x)\n",
        "\n",
        "# Í∏∞ÌÉÄ\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:04:07.518875Z",
          "iopub.execute_input": "2025-06-09T10:04:07.519245Z",
          "iopub.status.idle": "2025-06-09T10:04:11.631632Z",
          "shell.execute_reply.started": "2025-06-09T10:04:07.519221Z",
          "shell.execute_reply": "2025-06-09T10:04:11.630856Z"
        },
        "id": "4f2a25a5",
        "papermill": {
          "duration": 9.504513,
          "end_time": "2025-06-07T12:14:09.193071",
          "exception": false,
          "start_time": "2025-06-07T12:13:59.688558",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "1dcebc6f-ea97-48d0-f640-39eae05bcb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbyc3230\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250610_022734-t1bllt0p</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/byc3230/etri_lifelog/runs/t1bllt0p' target=\"_blank\">toasty-cloud-103</a></strong> to <a href='https://wandb.ai/byc3230/etri_lifelog' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/byc3230/etri_lifelog' target=\"_blank\">https://wandb.ai/byc3230/etri_lifelog</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/byc3230/etri_lifelog/runs/t1bllt0p' target=\"_blank\">https://wandb.ai/byc3230/etri_lifelog/runs/t1bllt0p</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "id": "3a1fa201",
      "cell_type": "code",
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:04:11.639009Z",
          "iopub.execute_input": "2025-06-09T10:04:11.639333Z",
          "iopub.status.idle": "2025-06-09T10:04:11.665674Z",
          "shell.execute_reply.started": "2025-06-09T10:04:11.639307Z",
          "shell.execute_reply": "2025-06-09T10:04:11.664912Z"
        },
        "id": "3a1fa201",
        "papermill": {
          "duration": 0.034185,
          "end_time": "2025-06-07T12:14:09.307748",
          "exception": false,
          "start_time": "2025-06-07T12:14:09.273563",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "de5b6541",
      "cell_type": "code",
      "source": [
        "string = \"\"\"\n",
        "subject_id,sleep_date\n",
        "id01,2024-07-24\n",
        "id01,2024-08-26\n",
        "id01,2024-08-28\n",
        "id01,2024-08-29\n",
        "id02,2024-08-23\n",
        "id02,2024-09-24\n",
        "id02,2024-09-26\n",
        "id02,2024-09-27\n",
        "id03,2024-08-30\n",
        "id03,2024-09-01\n",
        "id03,2024-09-02\n",
        "id03,2024-09-06\n",
        "id04,2024-09-03\n",
        "id04,2024-10-10\n",
        "id04,2024-10-12\n",
        "id04,2024-10-13\n",
        "id05,2024-10-19\n",
        "id05,2024-10-23\n",
        "id05,2024-10-24\n",
        "id05,2024-10-27\n",
        "id06,2024-07-25\n",
        "id06,2024-07-26\n",
        "id06,2024-07-27\n",
        "id06,2024-07-30\n",
        "id07,2024-07-07\n",
        "id07,2024-08-02\n",
        "id07,2024-08-04\n",
        "id07,2024-08-05\n",
        "id08,2024-08-28\n",
        "id08,2024-08-29\n",
        "id08,2024-08-30\n",
        "id08,2024-09-02\n",
        "id09,2024-08-02\n",
        "id09,2024-08-31\n",
        "id09,2024-09-02\n",
        "id09,2024-09-03\n",
        "id10,2024-08-28\n",
        "id10,2024-08-30\n",
        "id10,2024-08-31\n",
        "id10,2024-09-03\n",
        "\"\"\"\n",
        "\n",
        "# DataFrame ÏÉùÏÑ±\n",
        "valid_ids = pd.read_csv(StringIO(string), sep=',')\n",
        "valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:04:11.885710Z",
          "iopub.execute_input": "2025-06-09T10:04:11.885950Z",
          "iopub.status.idle": "2025-06-09T10:04:11.912994Z",
          "shell.execute_reply.started": "2025-06-09T10:04:11.885930Z",
          "shell.execute_reply": "2025-06-09T10:04:11.912416Z"
        },
        "papermill": {
          "duration": 0.043443,
          "end_time": "2025-06-07T12:14:10.163174",
          "exception": false,
          "start_time": "2025-06-07T12:14:10.119731",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "de5b6541"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0a6ab82b",
      "cell_type": "markdown",
      "source": [
        "### üì¶ Îç∞Ïù¥ÌÑ∞ ÏùΩÍ∏∞"
      ],
      "metadata": {
        "id": "0a6ab82b",
        "papermill": {
          "duration": 0.025083,
          "end_time": "2025-06-07T12:14:10.280870",
          "exception": false,
          "start_time": "2025-06-07T12:14:10.255787",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "id": "39d79d1f",
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = '/content/drive/MyDrive/data/ch2025_data_items/share/'\n",
        "\n",
        "train = pd.read_parquet(f'{path}train_63775.parquet')\n",
        "test = pd.read_parquet(f'{path}test_63775.parquet')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:04:11.942259Z",
          "iopub.execute_input": "2025-06-09T10:04:11.942590Z",
          "iopub.status.idle": "2025-06-09T10:04:28.573464Z",
          "shell.execute_reply.started": "2025-06-09T10:04:11.942574Z",
          "shell.execute_reply": "2025-06-09T10:04:28.572850Z"
        },
        "id": "39d79d1f",
        "papermill": {
          "duration": 17.107506,
          "end_time": "2025-06-07T12:14:27.413399",
          "exception": false,
          "start_time": "2025-06-07T12:14:10.305893",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a035c91-7327-4c31-9921-bbfc736f6e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "id": "5396de95",
      "cell_type": "code",
      "source": [
        "# drop_features = ['afterwork_max_label','sleeptime_max_label','worktime_max_label']\n",
        "drop_features = ['top_bssid'] # ,'week_type','week_type_lag1'\n",
        "drop_features = [i for i in drop_features if i in train.columns.tolist()]\n",
        "print('# drop_features:',drop_features)\n",
        "train = train.drop(columns=drop_features)\n",
        "test = test.drop(columns=drop_features)"
      ],
      "metadata": {
        "id": "5396de95",
        "papermill": {
          "duration": 0.024498,
          "end_time": "2025-06-07T12:14:27.463751",
          "exception": false,
          "start_time": "2025-06-07T12:14:27.439253",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04f88e6-0b26-4b39-80ae-17e44dae7fb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# drop_features: []\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "id": "e31852ee",
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®\n",
        "# ---\n",
        "\n",
        "def calculate_sleep_duration_min(sleep_time, wake_time):\n",
        "    \"\"\"\n",
        "    Ï∑®Ïπ® ÏãúÍ∞Å(sleep_time)Í≥º Í∏∞ÏÉÅ ÏãúÍ∞Å(wake_time)ÏùÑ ÏûÖÎ†•Î∞õÏïÑ ÏàòÎ©¥ ÏãúÍ∞Ñ(Î∂Ñ) Î∞òÌôò\n",
        "    Îã®ÏúÑÎäî float ÏãúÍ∞Ñ (Ïòà: 23.5, 6.25)\n",
        "    \"\"\"\n",
        "    if pd.isna(sleep_time) or pd.isna(wake_time):\n",
        "        return None\n",
        "    if wake_time < sleep_time:\n",
        "        wake_time += 24  # ÏûêÏ†ï ÎÑòÍ∏¥ Í≤ΩÏö∞ Î≥¥Ï†ï\n",
        "    duration = (wake_time - sleep_time) * 60\n",
        "    return round(duration)\n",
        "\n",
        "train['Î∂àÎÅàÏãúÍ∞ÑÎ∂ÄÌÑ∞Í∏∞ÏÉÅÏãúÍ∞Ñ'] = train.apply(lambda x: calculate_sleep_duration_min(x['lights_off_time'],x['wake_time']),axis=1)\n",
        "test['Î∂àÎÅàÏãúÍ∞ÑÎ∂ÄÌÑ∞Í∏∞ÏÉÅÏãúÍ∞Ñ'] = test.apply(lambda x: calculate_sleep_duration_min(x['lights_off_time'],x['wake_time']),axis=1)\n",
        "\n",
        "train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = train['Î∂àÎÅàÏãúÍ∞ÑÎ∂ÄÌÑ∞Í∏∞ÏÉÅÏãúÍ∞Ñ']/train['sleep_duration_min']\n",
        "test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = test['Î∂àÎÅàÏãúÍ∞ÑÎ∂ÄÌÑ∞Í∏∞ÏÉÅÏãúÍ∞Ñ']/test['sleep_duration_min']\n",
        "\n",
        "# Ïù¥ÏÉÅÍ∞í Ï†úÍ±∞\n",
        "train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = np.where(train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®']<-5,np.nan,train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'])\n",
        "test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = np.where(test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®']<-5,np.nan,test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'])\n",
        "train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = np.where(train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®']>5,np.nan,train['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'])\n",
        "test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'] = np.where(test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®']>55,np.nan,test['Ï∂îÏ†ïÏàòÎ©¥Ìö®Ïú®'])"
      ],
      "metadata": {
        "id": "e31852ee",
        "papermill": {
          "duration": 0.024197,
          "end_time": "2025-06-07T12:14:27.561133",
          "exception": false,
          "start_time": "2025-06-07T12:14:27.536936",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a50b8b13",
      "cell_type": "code",
      "source": [
        "# ÏöîÏùº Ïª¨Îüº Ï∂îÍ∞Ä (Ïòà: ÏõîÏöîÏùº, ÌôîÏöîÏùº, ...)\n",
        "train['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\n",
        "test['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n",
        "\n",
        "# ÏöîÏùº\n",
        "weekday_map = {\n",
        "    0: 'ÏõîÏöîÏùº', 1: 'ÌôîÏöîÏùº', 2: 'ÏàòÏöîÏùº', 3: 'Î™©ÏöîÏùº',\n",
        "    4: 'Í∏àÏöîÏùº', 5: 'ÌÜ†ÏöîÏùº', 6: 'ÏùºÏöîÏùº'\n",
        "}\n",
        "train['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "test['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "\n",
        "# Ïõî\n",
        "train['month'] = train['lifelog_date'].dt.month\n",
        "test['month'] = test['lifelog_date'].dt.month\n",
        "\n",
        "# weekend\n",
        "train['weekend'] = np.where(train['weekday'].isin(['ÌÜ†ÏöîÏùº','ÏùºÏöîÏùº']),1,0)\n",
        "test['weekend'] = np.where(test['weekday'].isin(['ÌÜ†ÏöîÏùº','ÏùºÏöîÏùº']),1,0)\n",
        "\n",
        "# Í≥µÌú¥Ïùº\n",
        "Í≥µÌú¥Ïùº = [\n",
        "     '2024-08-15'\n",
        "    ,'2024-09-16'\n",
        "    ,'2024-09-17'\n",
        "    ,'2024-09-18'\n",
        "    ,'2024-10-03'\n",
        "    ,'2024-10-09'\n",
        "]\n",
        "train['Í≥µÌú¥Ïùº'] = np.where(train['lifelog_date'].isin(Í≥µÌú¥Ïùº),1,0)\n",
        "test['Í≥µÌú¥Ïùº'] = np.where(test['lifelog_date'].isin(Í≥µÌú¥Ïùº),1,0)\n",
        "\n",
        "# Ï£ºÎßê + Í≥µÌú¥Ïùº Î¨∂Ïñ¥Ï£ºÍ∏∞\n",
        "train['weekend_holilday'] = np.where( ((train['weekend']==0) & (train['Í≥µÌú¥Ïùº']==1)), 1, train['weekend'])\n",
        "test['weekend_holilday'] = np.where( ((test['weekend']==0) & (test['Í≥µÌú¥Ïùº']==1)), 1, test['weekend'])"
      ],
      "metadata": {
        "id": "a50b8b13",
        "papermill": {
          "duration": 0.030378,
          "end_time": "2025-06-07T12:16:37.977745",
          "exception": false,
          "start_time": "2025-06-07T12:16:37.947367",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "24228ae9",
      "cell_type": "code",
      "source": [
        "def add_prev_day_flag(df):\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    # Í∞Å subject_idÎ≥ÑÎ°ú Ï†ÑÎÇ† ÎÇ†Ïßú ÎßåÎì§Í∏∞\n",
        "    df['prev_day'] = df['lifelog_date'] - pd.Timedelta(days=1)\n",
        "\n",
        "    # subject_id + ÎÇ†Ïßú Í∏∞Ï§ÄÏúºÎ°ú ÏõêÎ≥∏ ÌÇ§ Íµ¨ÏÑ±\n",
        "    key_set = set(zip(df['subject_id'], df['lifelog_date']))\n",
        "\n",
        "    # Ï†ÑÎÇ† Îç∞Ïù¥ÌÑ∞Í∞Ä Ï°¥Ïû¨ÌïòÎ©¥ 1, ÏóÜÏúºÎ©¥ 0\n",
        "    df['has_prev_day_data'] = df[['subject_id', 'prev_day']].apply(\n",
        "        lambda row: 1 if (row['subject_id'], row['prev_day']) in key_set else 0, axis=1\n",
        "    )\n",
        "\n",
        "    return df.drop(columns=['prev_day'])\n",
        "\n",
        "train = add_prev_day_flag(train)\n",
        "test = add_prev_day_flag(test)"
      ],
      "metadata": {
        "id": "24228ae9",
        "papermill": {
          "duration": 0.029598,
          "end_time": "2025-06-07T12:16:38.037013",
          "exception": false,
          "start_time": "2025-06-07T12:16:38.007415",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "938b961c",
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Ï∂îÏ†ïÌú¥Í∞Ä\n",
        "# ---\n",
        "\n",
        "def rule_based_sum(x):\n",
        "    rules = (\n",
        "        # (x['sleep_duration_min'] > (x['avg_sleep_duration']+30))\n",
        "          (x['sleep_duration_min'] > (x['avg_sleep_duration']+60))\n",
        "        & (x['week_type'] == 'weekday')\n",
        "        # & (x['month'].isin([7,8]))\n",
        "    )\n",
        "    return rules\n",
        "\n",
        "train['vacation'] = train.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "test['vacation'] = test.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "\n",
        "# check\n",
        "test.groupby(['subject_id'])['vacation'].sum().head()"
      ],
      "metadata": {
        "id": "938b961c",
        "papermill": {
          "duration": 0.030928,
          "end_time": "2025-06-07T12:16:39.830264",
          "exception": false,
          "start_time": "2025-06-07T12:16:39.799336",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "67e6cdbe-4ff9-4b65-e567-acb8f4fc37b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject_id\n",
              "id01    2\n",
              "id02    3\n",
              "id03    4\n",
              "id04    9\n",
              "id05    4\n",
              "Name: vacation, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id01</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id02</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id03</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id04</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id05</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "execution_count": null
    },
    {
      "id": "cb9fd81b",
      "cell_type": "code",
      "source": [
        "# Ïà´ÏûêÌòï Ïª¨ÎüºÎßå ÏÑ†ÌÉùÌï¥ÏÑú Í≤∞Ï∏°Í∞í -1Î°ú Ï±ÑÏö∞Í∏∞\n",
        "train[train.select_dtypes(include='number').columns] = train.select_dtypes(include='number').fillna(-1)\n",
        "test[test.select_dtypes(include='number').columns] = test.select_dtypes(include='number').fillna(-1)"
      ],
      "metadata": {
        "id": "cb9fd81b",
        "papermill": {
          "duration": 0.030522,
          "end_time": "2025-06-07T12:16:39.892368",
          "exception": false,
          "start_time": "2025-06-07T12:16:39.861846",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvMT9FPwoz-x"
      },
      "id": "qvMT9FPwoz-x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OUzhBfxNo3J0"
      },
      "id": "OUzhBfxNo3J0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gTVVBAHko3bs"
      },
      "id": "gTVVBAHko3bs",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "01bd961f",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01bd961f",
        "papermill": {
          "duration": 0.030376,
          "end_time": "2025-06-07T12:16:39.953263",
          "exception": false,
          "start_time": "2025-06-07T12:16:39.922887",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ============================"
      ],
      "metadata": {
        "id": "S_syDjeiMnUN"
      },
      "id": "S_syDjeiMnUN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CustomDataset"
      ],
      "metadata": {
        "id": "8vf0ZMACdkKw"
      },
      "id": "8vf0ZMACdkKw"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, twitterDF):\n",
        "        self.twitterDF = twitterDF\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.twitterDF.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return np.array([idx])"
      ],
      "metadata": {
        "id": "rsxWCnqubwLW"
      },
      "id": "rsxWCnqubwLW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train_iter"
      ],
      "metadata": {
        "id": "42PyqJW_dsaE"
      },
      "id": "42PyqJW_dsaE"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_iter(model, loader, optimizer, criterion, twitterDFTrain_clean):\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    pred = []\n",
        "    label = []\n",
        "    for batchIdx, sampledIdx in enumerate(tqdm(loader, position=0, leave=True)):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #text\n",
        "        sampledIdx = sampledIdx.cpu().data.numpy()\n",
        "        sampledRowText = list(twitterDFTrain_clean[\"text\"].iloc[list(sampledIdx.flatten())])\n",
        "\n",
        "        #label\n",
        "        sampledRowLabels = torch.tensor(list(twitterDFTrain_clean[\"label\"].iloc[list(sampledIdx.flatten())])).to(device)\n",
        "\n",
        "        #encoded\n",
        "        encoded_input = tokenizer(sampledRowText, truncation=True, padding=True, return_tensors='pt').to(device) # Output shape: [bs, num_Labels]\n",
        "        encoded_inputIds = encoded_input[\"input_ids\"].to(device)\n",
        "        encoded_attnMask = encoded_input[\"attention_mask\"].to(device)\n",
        "\n",
        "        #model\n",
        "        outputs = model(input_ids=encoded_inputIds, attention_mask=encoded_attnMask)\n",
        "\n",
        "        # label type change\n",
        "        sampledRowLabels = sampledRowLabels.to(outputs.logits.device).long()  # shape: [1]\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(outputs.logits, sampledRowLabels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        #acurracy\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(outputs.logits, dim=-1)\n",
        "        pred.extend(predicted_class.flatten().cpu().data.numpy())\n",
        "        label.extend(sampledRowLabels.cpu().data.numpy())\n",
        "\n",
        "        #back propagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    train_accuracy_score = metrics.f1_score(label,pred, average='macro')\n",
        "    return total_loss / len(loader), train_accuracy_score"
      ],
      "metadata": {
        "id": "ylIL6t80bwOw"
      },
      "id": "ylIL6t80bwOw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bQypUeAjitl8"
      },
      "id": "bQypUeAjitl8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdBTVfFVit1k"
      },
      "id": "CdBTVfFVit1k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### valid_iter"
      ],
      "metadata": {
        "id": "LnDkdYBIdxFB"
      },
      "id": "LnDkdYBIdxFB"
    },
    {
      "cell_type": "code",
      "source": [
        "def valid_iter(model, valid_loader, criterion, twitterDFVal_clean):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        pred = []\n",
        "        label = []\n",
        "        for batchIdx, sampledIdx in enumerate(tqdm(valid_loader, position=0, leave=True)):\n",
        "\n",
        "            sampledRowText = list(twitterDFVal_clean[\"text\"].iloc[list(sampledIdx.flatten())])\n",
        "            sampledRowLabels = torch.tensor(list(twitterDFVal_clean[\"label\"].iloc[list(sampledIdx.flatten())]))\n",
        "            encoded_input = tokenizer(sampledRowText, truncation=True, padding=True, return_tensors='pt').to(device) # Output shape: [bs, num_Labels]\n",
        "            encoded_inputIds = encoded_input[\"input_ids\"].to(device)\n",
        "            encoded_attnMask = encoded_input[\"attention_mask\"].to(device)\n",
        "\n",
        "            #model\n",
        "            outputs = model(input_ids=encoded_inputIds, attention_mask=encoded_attnMask)\n",
        "\n",
        "            # label type change\n",
        "            sampledRowLabels = sampledRowLabels.to(outputs.logits.device).long()  # shape: [1]\n",
        "\n",
        "            # loss\n",
        "            loss = criterion(outputs.logits, sampledRowLabels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            #acurracy\n",
        "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "            predicted_class = torch.argmax(outputs.logits, dim=-1)\n",
        "            pred.extend(predicted_class.flatten().cpu().data.numpy())\n",
        "            label.extend(sampledRowLabels.cpu().data.numpy())\n",
        "\n",
        "        valid_accuracy_score = metrics.f1_score(label,pred, average='macro')\n",
        "\n",
        "    return total_loss/len(valid_loader), valid_accuracy_score"
      ],
      "metadata": {
        "id": "IXjsYSkTbwSN"
      },
      "id": "IXjsYSkTbwSN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sGP7uU8Ciwz9"
      },
      "id": "sGP7uU8Ciwz9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gvlquu8HixEX"
      },
      "id": "Gvlquu8HixEX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FocalLoss"
      ],
      "metadata": {
        "id": "rOP3i8zcd0pW"
      },
      "id": "rOP3i8zcd0pW"
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha  # optional: list or tensor of class weights\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)  # prevents nans when probability is 0\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ],
      "metadata": {
        "id": "T0KVW9RNbwWT"
      },
      "id": "T0KVW9RNbwWT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wui1Jma8N9u5"
      },
      "id": "Wui1Jma8N9u5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfE-fWh-isFP"
      },
      "id": "nfE-fWh-isFP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### get_oof_predictions"
      ],
      "metadata": {
        "id": "Pjza8IgOLvDP"
      },
      "id": "Pjza8IgOLvDP"
    },
    {
      "id": "d450852a",
      "cell_type": "code",
      "source": [
        "def get_oof_predictions(X, y, lgb_params, xgb_params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n",
        "    oof_preds_lgb = np.zeros(len(X))\n",
        "    oof_preds_xgb = np.zeros(len(X))\n",
        "    oof_preds_cat = np.zeros(len(X))\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_idx, valid_idx in skf.split(X, y):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        if is_multiclass:\n",
        "            llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=3, torch_dtype=torch.float16, device_map='auto')\n",
        "            lora_model = get_peft_model(llm_model, config)\n",
        "        else:\n",
        "            llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=2, torch_dtype=torch.float16, device_map='auto')\n",
        "            lora_model = get_peft_model(llm_model, config)\n",
        "        # LightGBM\n",
        "        if is_multiclass:\n",
        "            lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=num_class)\n",
        "        else:\n",
        "            lgb_model = LGBMClassifier(**lgb_params)\n",
        "\n",
        "        # XGBoost\n",
        "        if is_multiclass:\n",
        "            xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=num_class)\n",
        "        else:\n",
        "            xgb_model = XGBClassifier(**xgb_params)\n",
        "\n",
        "        # CatBoost\n",
        "        if is_multiclass:\n",
        "            cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=num_class)\n",
        "        else:\n",
        "            cat_model = CatBoostClassifier(**common_params_cat)\n",
        "\n",
        "        if early_stop:\n",
        "            lgb_model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n",
        "            )\n",
        "            xgb_model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_valid, y_valid)],\n",
        "                early_stopping_rounds=100,\n",
        "                verbose=False\n",
        "            )\n",
        "            cat_model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_valid, y_valid)],\n",
        "                early_stopping_rounds=100,\n",
        "                verbose=False\n",
        "            )\n",
        "        else:\n",
        "            X_train_llm = X_train\n",
        "            X_valid_llm = X_valid\n",
        "\n",
        "            def prepare_input_text(row):\n",
        "                target_cols = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
        "                feature_cols = [col for col in X_train.columns if col not in target_cols]\n",
        "\n",
        "                instruct_txt = \"\"\n",
        "                if is_multiclass:\n",
        "                    instruct_txt = \"Classify 0 or 1 or 2. ###DATA### \"\n",
        "                else:\n",
        "                    instruct_txt = \"Classify 0 or 1. ###DATA### \"\n",
        "\n",
        "                for clm in feature_cols:\n",
        "                    instruct_txt += f\"{clm} : {row[clm]}, \"\n",
        "\n",
        "                return instruct_txt.strip()[:-1]+'.'\n",
        "\n",
        "            X_train_llm['input'] = X_train_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "            X_valid_llm['input'] = X_valid_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "\n",
        "            X_train_llm[\"label\"] = y_train\n",
        "            X_valid_llm['label'] = y_valid\n",
        "            X_train_llm[\"text\"] = X_train_llm[\"input\"]\n",
        "            X_valid_llm[\"text\"] = X_valid_llm[\"input\"]\n",
        "\n",
        "            training_data = CustomDataset(X_train_llm)\n",
        "            validation_data = CustomDataset(X_valid_llm)\n",
        "\n",
        "            train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "            val_dataloader = DataLoader(validation_data, batch_size=1, shuffle=False)\n",
        "\n",
        "            twitterDFTrain_clean = X_train_llm\n",
        "            twitterDFVal_clean = X_valid_llm\n",
        "\n",
        "            if is_multiclass:\n",
        "                total_loss = 0\n",
        "                correct = 0\n",
        "                bad_counter = 0\n",
        "                #best model Î•º Ï∞æÍ∏∞ ÏúÑÌïú\n",
        "                best = np.inf\n",
        "\n",
        "                for epoch in range(epochs):\n",
        "                    avg_train_loss, avg_train_acc  = train_iter(llm_model, train_dataloader, optimizer, criterion, twitterDFTrain_clean)\n",
        "\n",
        "                    avg_vaild_loss, avg_vaild_acc = valid_iter(llm_model, val_dataloader, criterion, twitterDFVal_clean)\n",
        "\n",
        "                    if avg_vaild_loss < best:\n",
        "                        best = avg_vaild_loss\n",
        "                        torch.save(llm_model.state_dict(), best_model_path)\n",
        "                        bad_counter = 0\n",
        "                    else:\n",
        "                        bad_counter += 1\n",
        "\n",
        "                    if bad_counter == patience:\n",
        "                        break\n",
        "\n",
        "                    print(f'Epoch: {str(epoch+1)}: t_loss:{avg_train_loss:.3f} t_acc:{avg_train_acc:.3f} v_loss:{avg_vaild_loss:.3f} v_acc:{avg_vaild_acc:.3f}')\n",
        "\n",
        "                    wandb.log({\"train\": {'epoch': epoch, \"acc\": avg_train_acc, \"loss\": avg_train_loss}, \"val\": {'epoch': epoch, \"acc\": avg_vaild_acc, \"loss\": avg_vaild_loss}})\n",
        "            else:\n",
        "                total_loss = 0\n",
        "                correct = 0\n",
        "                bad_counter = 0\n",
        "                #best model Î•º Ï∞æÍ∏∞ ÏúÑÌïú\n",
        "                best = np.inf\n",
        "                for epoch in range(epochs):\n",
        "                    avg_train_loss, avg_train_acc  = train_iter(llm_model, train_dataloader, optimizer, criterion, twitterDFTrain_clean)\n",
        "\n",
        "                    avg_vaild_loss, avg_vaild_acc = valid_iter(llm_model, val_dataloader, criterion, twitterDFVal_clean)\n",
        "\n",
        "                    if avg_vaild_loss < best:\n",
        "                        best = avg_vaild_loss\n",
        "                        torch.save(llm_model.state_dict(), best_model_path)\n",
        "                        bad_counter = 0\n",
        "                    else:\n",
        "                        bad_counter += 1\n",
        "\n",
        "                    if bad_counter == patience:\n",
        "                        break\n",
        "\n",
        "                    print(f'Epoch: {str(epoch+1)}: t_loss:{avg_train_loss:.3f} t_acc:{avg_train_acc:.3f} v_loss:{avg_vaild_loss:.3f} v_acc:{avg_vaild_acc:.3f}')\n",
        "\n",
        "                    wandb.log({\"train\": {'epoch': epoch, \"acc\": avg_train_acc, \"loss\": avg_train_loss}, \"val\": {'epoch': epoch, \"acc\": avg_vaild_acc, \"loss\": avg_vaild_loss}})\n",
        "\n",
        "            if is_multiclass:\n",
        "\n",
        "                # ÌÅ¥ÎûòÏä§ weight Í≥ÑÏÇ∞\n",
        "                classes = np.unique(y_train)\n",
        "                weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "                class_weights = dict(zip(classes, weights))\n",
        "\n",
        "                # Í∞Å ÏÉòÌîåÏóê ÎåÄÌï¥ weight Îß§Ìïë\n",
        "                w_train = pd.Series(y_train).map(class_weights)\n",
        "                #print(w_train)\n",
        "\n",
        "                w_train = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "                print(w_train)\n",
        "\n",
        "                lgb_model.fit(X_train, y_train, sample_weight=w_train)\n",
        "                xgb_model.fit(X_train, y_train, sample_weight=w_train)\n",
        "                cat_model.fit(X_train, y_train)\n",
        "            else:\n",
        "                lgb_model.fit(X_train, y_train)\n",
        "                xgb_model.fit(X_train, y_train)\n",
        "                cat_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "        # Get predictions\n",
        "        lgb_preds = lgb_model.predict(X_valid)\n",
        "        xgb_preds = xgb_model.predict(X_valid)\n",
        "        cat_preds = cat_model.predict(X_valid).ravel()  # ‚úÖ 2Ï∞®Ïõê ‚Üí 1Ï∞®Ïõê\n",
        "\n",
        "        # Store predictions\n",
        "        oof_preds_lgb[valid_idx] = lgb_preds\n",
        "        oof_preds_xgb[valid_idx] = xgb_preds\n",
        "        oof_preds_cat[valid_idx] = cat_preds\n",
        "\n",
        "    # Ensemble predictions (7:3 ratio)\n",
        "    oof_preds = lgb_A * oof_preds_lgb + xgb_B * oof_preds_xgb + cat_C * oof_preds_cat\n",
        "\n",
        "    if not is_multiclass:\n",
        "        oof_preds = (oof_preds > 0.5).astype(int)\n",
        "    else:\n",
        "        oof_preds = np.round(oof_preds).astype(int)\n",
        "\n",
        "    return oof_preds"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:07:20.395196Z",
          "iopub.execute_input": "2025-06-09T10:07:20.395389Z",
          "iopub.status.idle": "2025-06-09T10:07:20.415563Z",
          "shell.execute_reply.started": "2025-06-09T10:07:20.395374Z",
          "shell.execute_reply": "2025-06-09T10:07:20.415029Z"
        },
        "papermill": {
          "duration": 0.051786,
          "end_time": "2025-06-07T12:17:15.042857",
          "exception": false,
          "start_time": "2025-06-07T12:17:14.991071",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "d450852a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8f722905",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:07:20.454607Z",
          "iopub.execute_input": "2025-06-09T10:07:20.454899Z",
          "iopub.status.idle": "2025-06-09T10:07:20.471905Z",
          "shell.execute_reply.started": "2025-06-09T10:07:20.454875Z",
          "shell.execute_reply": "2025-06-09T10:07:20.471372Z"
        },
        "papermill": {
          "duration": 0.035819,
          "end_time": "2025-06-07T12:17:15.252559",
          "exception": false,
          "start_time": "2025-06-07T12:17:15.216740",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "8f722905"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "faNn2UU7NBye"
      },
      "id": "faNn2UU7NBye",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inference"
      ],
      "metadata": {
        "id": "5zKywL38L092"
      },
      "id": "5zKywL38L092"
    },
    {
      "id": "1f8b6d63",
      "cell_type": "code",
      "source": [
        "def inference(model, loader, test_data, col):\n",
        "    #best model Î∂àÎü¨ÏôÄÏÑú call ÌïòÍ∏∞\n",
        "    model.load_state_dict(torch.load(col+\"_\"+best_model_path))\n",
        "    model.eval()\n",
        "\n",
        "    preds = []\n",
        "    preds_prob = []\n",
        "    with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        pred = []\n",
        "        label = []\n",
        "\n",
        "        for batchIdx, sampledIdx in enumerate(tqdm(loader, position=0, leave=True)):\n",
        "\n",
        "            sampledRowText = list(test_data[\"text\"].iloc[list(sampledIdx.flatten())])\n",
        "\n",
        "            encoded_input = tokenizer(sampledRowText, truncation=True, padding=True, return_tensors='pt').to(\"cuda\") # Output shape: [bs, num_Labels]\n",
        "            encoded_inputIds = encoded_input[\"input_ids\"].to(\"cuda\")\n",
        "            encoded_attnMask = encoded_input[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "            outputs = model(input_ids=encoded_inputIds, attention_mask=encoded_attnMask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "\n",
        "            #acurracy\n",
        "            probs = torch.nn.functional.softmax(outputs.logits.cpu(), dim=-1)\n",
        "\n",
        "            #ÌôïÎ•†Íµ¨ÌïòÍ∏∞\n",
        "            preds_prob.extend(probs.cpu().data.numpy())\n",
        "\n",
        "            #acurracy\n",
        "            pred.extend(torch.argmax(logits, dim=1).flatten().cpu().data.numpy())\n",
        "\n",
        "    return pred, preds_prob"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:07:20.472683Z",
          "iopub.execute_input": "2025-06-09T10:07:20.472948Z",
          "iopub.status.idle": "2025-06-09T10:07:20.488693Z",
          "shell.execute_reply.started": "2025-06-09T10:07:20.472926Z",
          "shell.execute_reply": "2025-06-09T10:07:20.488109Z"
        },
        "papermill": {
          "duration": 0.039323,
          "end_time": "2025-06-07T12:17:15.323360",
          "exception": false,
          "start_time": "2025-06-07T12:17:15.284037",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "1f8b6d63"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "cdb39051",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "papermill": {
          "duration": 0.03138,
          "end_time": "2025-06-07T12:17:15.386092",
          "exception": false,
          "start_time": "2025-06-07T12:17:15.354712",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "cdb39051"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1RguvTBLkx8"
      },
      "id": "L1RguvTBLkx8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run_basemodel"
      ],
      "metadata": {
        "id": "HtiE52IWK_nd"
      },
      "id": "HtiE52IWK_nd"
    },
    {
      "id": "8822c602",
      "cell_type": "code",
      "source": [
        "def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n",
        "\n",
        "    #version 33Î°ú ÏßÑÌñâÏôÑÎ£å Best\n",
        "    lgb_A = 0.3\n",
        "    xgb_B = 0.3\n",
        "    cat_C = 0.3\n",
        "    llm_D = 0.1\n",
        "\n",
        "    print(\"=========valid_ids==========\")\n",
        "    # print(valid_ids)\n",
        "    train_df = train.copy()\n",
        "    test_df = test.copy()\n",
        "\n",
        "    submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "    submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n",
        "\n",
        "    # ÌÉÄÍ≤ü\n",
        "    targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n",
        "    targets_binary_name = ['Í∏∞ÏÉÅÏßÅÌõÑÏàòÎ©¥Ïßà','Ï∑®Ïπ®Ï†ÑÏã†Ï≤¥Ï†ÅÌîºÎ°ú','Ï∑®Ïπ®Ï†ÑÏä§Ìä∏Î†àÏä§','ÏàòÎ©¥Ìö®Ïú®','ÏàòÎ©¥Ïû†Îì§Í∏∞ÏãúÍ∞Ñ']\n",
        "    target_multiclass = 'S1'\n",
        "    all_targets = targets_binary + [target_multiclass]\n",
        "\n",
        "    # ÎÖ∏Ïù¥Ï¶à ÏàòÏ§Ä ÏÑ§Ï†ï\n",
        "    def add_noise(series, noise_level, seed=3):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        return series * (1 + noise_level * rng.standard_normal(len(series)))\n",
        "\n",
        "    noise_level = 0.015  # ÌïÑÏöîÏóê Îî∞Îùº Ï°∞Ï†ï\n",
        "\n",
        "    # ÌÉÄÍ≤üÏù∏ÏΩîÎî©\n",
        "    for tgt in all_targets:\n",
        "\n",
        "      encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n",
        "\n",
        "      #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©1\n",
        "\n",
        "      subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n",
        "      train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      global_mean = train_df[tgt].mean()\n",
        "      test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n",
        "\n",
        "      # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
        "      train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n",
        "      test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n",
        "\n",
        "      #### ÌÉÄÍ≤üÏù∏ÏΩîÎî©2\n",
        "\n",
        "      # ÏÉàÎ°úÏö¥ Î≤îÏ£ºÌòï Ïó¥ ÏÉùÏÑ±\n",
        "      train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "      test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "\n",
        "      # Ïù∏ÏΩîÎçî\n",
        "      encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n",
        "      encoder.fit(train_df[['TMP']], train_df[tgt])\n",
        "\n",
        "      # Ïù∏ÏΩîÎî© Í≤∞Í≥ºÎ•º ÏÉàÎ°úÏö¥ Ïó¥Ïóê Ï†ÄÏû•\n",
        "      train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n",
        "      test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n",
        "\n",
        "      # ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
        "      train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n",
        "      test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n",
        "\n",
        "      # Î∂àÌïÑÏöîÌïú Î≥ÄÏàò Ï†úÍ±∞\n",
        "      train_df = train_df.drop(columns=['TMP'])\n",
        "      test_df = test_df.drop(columns=['TMP'])\n",
        "\n",
        "\n",
        "    # Ïù∏ÏΩîÎî©\n",
        "    PK = ['sleep_date', 'lifelog_date', 'subject_id']\n",
        "    encoder = LabelEncoder()\n",
        "    categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n",
        "    for col in categorical_features:\n",
        "        print(col)\n",
        "        train_df[col] = encoder.fit_transform(train_df[col])\n",
        "        test_df[col] = encoder.fit_transform(test_df[col])\n",
        "\n",
        "\n",
        "    # X\n",
        "    X = train_df.drop(columns=PK + all_targets)\n",
        "    test_X = test_df.drop(columns=PK + all_targets)\n",
        "    print(f'# X shape: {X.shape}')\n",
        "    print(f'# test_X shape: {test_X.shape}')\n",
        "\n",
        "    print('\\n STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏')\n",
        "    print(\"=============== Validation Results ==============\")\n",
        "    total_avg_f1s = []\n",
        "    best_iteration_temp = {k: [] for k in all_targets}\n",
        "\n",
        "    val_f1 = []\n",
        "\n",
        "    binary_val_preds = {}\n",
        "    multiclass_val_preds = {}\n",
        "\n",
        "    binary_test_preds = {}\n",
        "    multiclass_test_preds = {}\n",
        "\n",
        "    test_preds = {}\n",
        "\n",
        "    # Find optimal weights\n",
        "    best_weights = []\n",
        "    best_scores = []\n",
        "\n",
        "    for col in targets_binary:\n",
        "        # binary\n",
        "        y = train_df[col]\n",
        "\n",
        "        valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n",
        "        train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n",
        "\n",
        "        X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "        y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "\n",
        "        # Get parameters for both models\n",
        "        lgb_params = common_params[col].copy()\n",
        "        lgb_params['random_state'] = random_state\n",
        "\n",
        "        xgb_params = {\n",
        "            'n_estimators': 1000,\n",
        "            'learning_rate': 0.01,\n",
        "            'max_depth': 6,\n",
        "            'min_child_weight': 1,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'random_state': random_state\n",
        "        }\n",
        "\n",
        "        # Train LLM\n",
        "        is_multiclass = False\n",
        "        llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=2, torch_dtype=torch.float16, device_map='auto')\n",
        "        lora_model = get_peft_model(llm_model, config)\n",
        "        # print(llm_model)\n",
        "        # optimizer = torch.optim.AdamW(llm_model.parameters(), lr=1e-6, weight_decay=1e-4)\n",
        "        optimizer = torch.optim.AdamW(llm_model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "        criterion = FocalLoss(gamma=2.0)\n",
        "\n",
        "        # Add learning rate scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer,\n",
        "            mode='min',\n",
        "            factor=0.5,\n",
        "            patience=2,\n",
        "            verbose=True,\n",
        "            min_lr=1e-6\n",
        "        )\n",
        "\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        bad_counter = 0\n",
        "        #best model Î•º Ï∞æÍ∏∞ ÏúÑÌïú\n",
        "        best = np.inf\n",
        "\n",
        "        X_train_llm = X_train.copy()\n",
        "        X_valid_llm = X_valid.copy()\n",
        "\n",
        "        X_train_llm = X_train_llm[X_Feature[col]]\n",
        "        X_valid_llm = X_valid_llm[X_Feature[col]]\n",
        "\n",
        "        def prepare_input_text(row):\n",
        "            target_cols = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
        "            feature_cols = [col for col in X_Feature[col] if col not in target_cols]\n",
        "\n",
        "\n",
        "            # ÌîÑÎ°¨ÌîÑÌä∏ ÏãúÏûë Î¨∏Ïû•Ïóê Í≤∞Ï∏°Ïπò ÏÑ§Î™Ö Ï∂îÍ∞Ä\n",
        "            base_prompt = Prompt[\"S1\"] if is_multiclass else Prompt[col]\n",
        "            instruct_txt = base_prompt.strip() + \"\\n(Note: -1.0 indicates missing value in the data)\\n###DATA###\\n\"\n",
        "\n",
        "            if is_multiclass:\n",
        "                # feature Í∞íÏùÑ alias Ïù¥Î¶ÑÍ≥º Ìï®Íªò ÌÖçÏä§Ìä∏Î°ú Íµ¨ÏÑ±\n",
        "                for orig_name, alias_name in zip(X_Feature[\"S1\"], X_Feature_alias[\"S1\"]):\n",
        "                    if orig_name not in target_cols:\n",
        "                        instruct_txt += f\"{alias_name} : {row[orig_name]}, \"\n",
        "            else:\n",
        "                # feature Í∞íÏùÑ alias Ïù¥Î¶ÑÍ≥º Ìï®Íªò ÌÖçÏä§Ìä∏Î°ú Íµ¨ÏÑ±\n",
        "                for orig_name, alias_name in zip(X_Feature[col], X_Feature_alias[col]):\n",
        "                    if orig_name not in target_cols:\n",
        "                        instruct_txt += f\"{alias_name} : {row[orig_name]}, \"\n",
        "\n",
        "            #print(instruct_txt)\n",
        "            return instruct_txt.strip()[:-1]+'.'\n",
        "\n",
        "        # ---------------------------------- llm ÌïôÏäµ ÏãúÏûë ----------------------------------\n",
        "        is_multiclass = False\n",
        "        X_train_llm['input'] = X_train_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "        #print(X_train_llm.head(1))\n",
        "        X_valid_llm['input'] = X_valid_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "\n",
        "        # X_train_llm[\"label\"] = y_train[:15]\n",
        "        # X_valid_llm[\"label\"] = y_valid[:15]\n",
        "        X_train_llm[\"label\"] = y_train\n",
        "        X_valid_llm[\"label\"] = y_valid\n",
        "        X_train_llm[\"text\"] = X_train_llm[\"input\"]\n",
        "        X_valid_llm[\"text\"] = X_valid_llm[\"input\"]\n",
        "\n",
        "        training_data = CustomDataset(X_train_llm)\n",
        "        validation_data = CustomDataset(X_valid_llm)\n",
        "\n",
        "        train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True,worker_init_fn=seed_worker, generator=g)\n",
        "        val_dataloader = DataLoader(validation_data, batch_size=1, shuffle=False)\n",
        "\n",
        "        # twitterDFTrain_clean = X_train_llm[:15]\n",
        "        # twitterDFVal_clean = X_valid_llm[:15]\n",
        "\n",
        "        twitterDFTrain_clean = X_train_llm\n",
        "        twitterDFVal_clean = X_valid_llm\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            avg_train_loss, avg_train_acc  = train_iter(llm_model, train_dataloader, optimizer, criterion, twitterDFTrain_clean)\n",
        "\n",
        "            avg_vaild_loss, avg_vaild_acc = valid_iter(llm_model, val_dataloader, criterion, twitterDFVal_clean)\n",
        "\n",
        "            # Update learning rate based on validation loss\n",
        "            scheduler.step(avg_vaild_loss)\n",
        "\n",
        "            if avg_vaild_loss < best:\n",
        "                best = avg_vaild_loss\n",
        "                # torch.save(llm_model.state_dict(), col+\"_\"+best_model_path)\n",
        "                # torch.save(llm_model.cpu().state_dict(), col+\"_\"+ best_model_path)\n",
        "\n",
        "                # ÎîîÎ†âÌÜ†Î¶¨ ÏûêÎèô ÏÉùÏÑ±\n",
        "                filename = f\"{col}_{best_model_path}\"\n",
        "                os.makedirs(os.path.dirname(filename) or \".\", exist_ok=True)  # ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±\n",
        "\n",
        "                torch.save(llm_model.cpu().state_dict(), filename)\n",
        "                llm_model.cuda()\n",
        "\n",
        "                bad_counter = 0\n",
        "            else:\n",
        "                bad_counter += 1\n",
        "\n",
        "            if bad_counter == patience:\n",
        "                break\n",
        "\n",
        "            print(f'{col} Epoch: {str(epoch+1)}: t_loss:{avg_train_loss:.3f} t_acc:{avg_train_acc:.3f} v_loss:{avg_vaild_loss:.3f} v_acc:{avg_vaild_acc:.3f}')\n",
        "\n",
        "            wandb.log({\"train\": {'epoch': epoch, \"acc\": avg_train_acc, \"loss\": avg_train_loss}, \"val\": {'epoch': epoch, \"acc\": avg_vaild_acc, \"loss\": avg_vaild_loss}})\n",
        "\n",
        "            # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
        "            del avg_train_loss, avg_train_acc, avg_vaild_loss, avg_vaild_acc\n",
        "            gc.collect()\n",
        "            torch.cuda.empty_cache()\n",
        "        # ---------------------------------- llm ÌïôÏäµ ÎÅù ----------------------------------\n",
        "\n",
        "        # Train LightGBM\n",
        "        lgb_model = LGBMClassifier(**lgb_params)\n",
        "        if early_stop:\n",
        "            lgb_model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n",
        "            )\n",
        "            best_iteration_temp[col].append(lgb_model.best_iteration_)\n",
        "        else:\n",
        "            lgb_model.fit(X_train, y_train)\n",
        "            best_iteration_temp[col].append(1000)\n",
        "\n",
        "        # Train XGBoost\n",
        "        xgb_model = XGBClassifier(**xgb_params)\n",
        "        if early_stop:\n",
        "            xgb_model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_valid, y_valid)],\n",
        "                early_stopping_rounds=100,\n",
        "                verbose=False\n",
        "            )\n",
        "        else:\n",
        "            xgb_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "        tabpfn_params = {\n",
        "            'device': 'cuda'\n",
        "        }\n",
        "\n",
        "        # Train TabPFN\n",
        "        tabpfn_model = TabPFNClassifier(**tabpfn_params)\n",
        "        tabpfn_model.fit(X_train, y_train)\n",
        "\n",
        "        # Get predictions and ensemble\n",
        "        _, llm_pred_valid = inference(llm_model, val_dataloader, X_valid_llm, col)\n",
        "\n",
        "        lgb_pred_valid = lgb_model.predict_proba(X_valid)[:, 1]\n",
        "        xgb_pred_valid = xgb_model.predict_proba(X_valid)[:, 1]\n",
        "        # cat_pred_valid = cat_model.predict_proba(X_valid)[:, 1]\n",
        "        # tabnet_pred_valid = tabpfn_model.predict_proba(X_valid.values)[:, 1]\n",
        "        cat_pred_valid = tabpfn_model.predict_proba(X_valid.values)[:, 1]\n",
        "\n",
        "        llm_pred_valid = np.array([arr[1] for arr in llm_pred_valid], dtype=np.float32)\n",
        "        # print(llm_pred_valid)\n",
        "        pred_valid = (lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid + llm_D * llm_pred_valid  > 0.5).astype(int)\n",
        "\n",
        "        f1 = f1_score(y_valid, pred_valid, average='macro')\n",
        "        val_f1.append(f1)\n",
        "\n",
        "        # Store predictions\n",
        "        binary_val_preds[col] = {\n",
        "            'llm': llm_pred_valid,\n",
        "            'lgb': lgb_pred_valid,\n",
        "            'xgb': xgb_pred_valid,\n",
        "            'cat': cat_pred_valid,\n",
        "            'true': y_valid\n",
        "        }\n",
        "\n",
        "    # multiclass\n",
        "    y = train_df[target_multiclass]\n",
        "\n",
        "    X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "    y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "\n",
        "    # Get parameters for both models\n",
        "    lgb_params = common_params['S1'].copy()\n",
        "    lgb_params['random_state'] = random_state\n",
        "\n",
        "    xgb_params = {\n",
        "        'n_estimators': 1000,\n",
        "        'learning_rate': 0.01,\n",
        "        'max_depth': 6,\n",
        "        'min_child_weight': 1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': random_state\n",
        "    }\n",
        "\n",
        "    # ÌÅ¥ÎûòÏä§ weight Í≥ÑÏÇ∞\n",
        "    classes = np.unique(y_train)\n",
        "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
        "    class_weights = dict(zip(classes, weights))\n",
        "\n",
        "    # Í∞Å ÏÉòÌîåÏóê ÎåÄÌï¥ weight Îß§Ìïë\n",
        "    w_train = pd.Series(y_train).map(class_weights)\n",
        "    # print(\"----compute_class_weight:\")\n",
        "    # print(w_train)\n",
        "\n",
        "    w_train = compute_sample_weight(class_weight='balanced', y=y_train)\n",
        "    # print(\"----compute_sample_weight:\")\n",
        "    # print(w_train)\n",
        "\n",
        "    # ---------------------------------- llm ÌïôÏäµ ÏãúÏûë ----------------------------------\n",
        "    is_multiclass = True\n",
        "    llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=3, torch_dtype=torch.float16, device_map='auto')\n",
        "    lora_model = get_peft_model(llm_model, config)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(llm_model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "    #optimizer = torch.optim.AdamW(llm_model.parameters(), lr=1e-5, weight_decay=1e-4)\n",
        "    # alpha = torch.tensor([1.048, 0.670, 1.807], dtype=torch.float16, device=device)\n",
        "    # criterion = FocalLoss(gamma=2.0,alpha=alpha)\n",
        "    criterion = FocalLoss(gamma=2.0)\n",
        "\n",
        "    # Add learning rate scheduler\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=2,\n",
        "        verbose=True,\n",
        "        min_lr=1e-6\n",
        "    )\n",
        "\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    bad_counter = 0\n",
        "\n",
        "    #best model Î•º Ï∞æÍ∏∞ ÏúÑÌïú\n",
        "    best = np.inf\n",
        "\n",
        "    X_train_llm = X_train.copy()\n",
        "    X_valid_llm = X_valid.copy()\n",
        "\n",
        "    X_train_llm = X_train_llm[X_Feature[\"S1\"]]\n",
        "    X_valid_llm = X_valid_llm[X_Feature[\"S1\"]]\n",
        "\n",
        "    X_train_llm['input'] = X_train_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "    #print(X_train_llm.head(1))\n",
        "    X_valid_llm['input'] = X_valid_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "\n",
        "    # X_train_llm[\"label\"] = y_train[:15]\n",
        "    # X_valid_llm[\"label\"] = y_valid[:15]\n",
        "    X_train_llm[\"label\"] = y_train\n",
        "    X_valid_llm[\"label\"] = y_valid\n",
        "    X_train_llm[\"text\"] = X_train_llm[\"input\"]\n",
        "    X_valid_llm[\"text\"] = X_valid_llm[\"input\"]\n",
        "\n",
        "    training_data = CustomDataset(X_train_llm)\n",
        "    validation_data = CustomDataset(X_valid_llm)\n",
        "\n",
        "    #train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True,worker_init_fn=seed_worker, generator=g)\n",
        "    train_dataloader = DataLoader(training_data, batch_size=1, shuffle=True)\n",
        "    val_dataloader = DataLoader(validation_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    # twitterDFTrain_clean = X_train_llm[:15]\n",
        "    # twitterDFVal_clean = X_valid_llm[:15]\n",
        "\n",
        "    twitterDFTrain_clean = X_train_llm\n",
        "    twitterDFVal_clean = X_valid_llm\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        avg_train_loss, avg_train_acc  = train_iter(llm_model, train_dataloader, optimizer, criterion, twitterDFTrain_clean)\n",
        "\n",
        "        avg_vaild_loss, avg_vaild_acc = valid_iter(llm_model, val_dataloader, criterion, twitterDFVal_clean)\n",
        "\n",
        "        # Update learning rate based on validation loss\n",
        "        scheduler.step(avg_vaild_loss)\n",
        "\n",
        "        if avg_vaild_loss < best:\n",
        "            best = avg_vaild_loss\n",
        "            # torch.save(llm_model.state_dict(), \"S1_\"+best_model_path)\n",
        "            # torch.save(llm_model.cpu().state_dict(), \"S1_\" + best_model_path)\n",
        "\n",
        "            # ÎîîÎ†âÌÜ†Î¶¨ ÏûêÎèô ÏÉùÏÑ±\n",
        "            filename = f\"S1_{best_model_path}\"\n",
        "            os.makedirs(os.path.dirname(filename) or \".\", exist_ok=True)  # ÎîîÎ†âÌÜ†Î¶¨Í∞Ä ÏóÜÏúºÎ©¥ ÏÉùÏÑ±\n",
        "\n",
        "            torch.save(llm_model.cpu().state_dict(), filename)\n",
        "            llm_model.cuda()\n",
        "            bad_counter = 0\n",
        "        else:\n",
        "            bad_counter += 1\n",
        "\n",
        "        if bad_counter == patience:\n",
        "            break\n",
        "\n",
        "        print(f'S1 Epoch: {str(epoch+1)}: t_loss:{avg_train_loss:.3f} t_acc:{avg_train_acc:.3f} v_loss:{avg_vaild_loss:.3f} v_acc:{avg_vaild_acc:.3f}')\n",
        "\n",
        "        wandb.log({\"train\": {'epoch': epoch, \"acc\": avg_train_acc, \"loss\": avg_train_loss}, \"val\": {'epoch': epoch, \"acc\": avg_vaild_acc, \"loss\": avg_vaild_loss}})\n",
        "\n",
        "        # ‚úÖ Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
        "        del avg_train_loss, avg_train_acc, avg_vaild_loss, avg_vaild_acc\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # ---------------------------------- llm ÌïôÏäµ ÎÅù ----------------------------------\n",
        "\n",
        "    # Train LightGBM\n",
        "    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n",
        "    if early_stop:\n",
        "        lgb_model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "            callbacks=[early_stopping(stopping_rounds=100,verbose=False)], sample_weight=w_train\n",
        "        )\n",
        "        best_iteration_temp[target_multiclass].append(lgb_model.best_iteration_)\n",
        "    else:\n",
        "        lgb_model.fit(X_train, y_train, sample_weight=w_train)\n",
        "        best_iteration_temp[target_multiclass].append(1000)\n",
        "\n",
        "    # Train XGBoost\n",
        "    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n",
        "    if early_stop:\n",
        "        xgb_model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_valid, y_valid)],\n",
        "            early_stopping_rounds=100,\n",
        "            verbose=False, sample_weight=w_train\n",
        "        )\n",
        "    else:\n",
        "        xgb_model.fit(X_train, y_train,sample_weight=w_train)\n",
        "\n",
        "\n",
        "    tabpfn_params = {\n",
        "        'device': 'cuda'\n",
        "    }\n",
        "\n",
        "    # Train TabPFN\n",
        "    tabpfn_model = TabPFNClassifier(**tabpfn_params)\n",
        "    tabpfn_model.fit(X_train, y_train)\n",
        "\n",
        "    # Get predictions and ensemble\n",
        "    _, llm_pred_valid = inference(llm_model, val_dataloader, X_valid_llm, \"S1\")\n",
        "    lgb_pred_valid = lgb_model.predict_proba(X_valid)\n",
        "    xgb_pred_valid = xgb_model.predict_proba(X_valid)\n",
        "    #cat_pred_valid = cat_model.predict_proba(X_valid)\n",
        "    #tabnet_pred_valid = tabpfn_model.predict_proba(X_valid.values)\n",
        "    cat_pred_valid = tabpfn_model.predict_proba(X_valid.values)\n",
        "    # print(llm_pred_valid)\n",
        "    # print(lgb_pred_valid)\n",
        "    llm_pred_valid = np.array(llm_pred_valid, dtype=np.float32)\n",
        "    #print(llm_pred_valid)\n",
        "    pred_valid = np.argmax(lgb_A * lgb_pred_valid + xgb_B * xgb_pred_valid + cat_C * cat_pred_valid + llm_D * llm_pred_valid, axis=1)\n",
        "\n",
        "    f1 = f1_score(y_valid, pred_valid, average='macro')\n",
        "    val_f1.append(f1)\n",
        "\n",
        "    multiclass_val_preds = {\n",
        "        'llm': llm_pred_valid,\n",
        "        'lgb': lgb_pred_valid,\n",
        "        'xgb': xgb_pred_valid,\n",
        "        'cat': cat_pred_valid,\n",
        "        'true': y_valid\n",
        "    }\n",
        "\n",
        "    # Generate all possible weight combinations that sum to 1\n",
        "    step = 0.1\n",
        "    for lgb_A in np.arange(0, 1.1, step):\n",
        "        for xgb_B in np.arange(0, 1.1 - lgb_A, step):\n",
        "            for cat_C in np.arange(0, 1.1 - lgb_A - xgb_B, step):\n",
        "                llm_D = 1 - (lgb_A + xgb_B + cat_C)\n",
        "                if llm_D >= 0:\n",
        "                    weights = (lgb_A, xgb_B, cat_C, llm_D)\n",
        "                    print(\"========================================\")\n",
        "                    print(f\"\\nTrying weights: lgb_A={lgb_A:.1f}, xgb_B={xgb_B:.1f}, cat_C={cat_C:.1f}, llm_D={llm_D:.1f}\")\n",
        "\n",
        "                    # Calculate validation score with current weights\n",
        "                    val_scores = []\n",
        "\n",
        "                    # Binary targets\n",
        "                    for col in targets_binary:\n",
        "                        preds = binary_val_preds[col]\n",
        "\n",
        "                        ensemble_pred = (lgb_A * preds['lgb'] + xgb_B * preds['xgb'] +\n",
        "                                      cat_C * preds['cat'] + llm_D * preds['llm'] > 0.5).astype(int)\n",
        "                        f1 = f1_score(preds['true'], ensemble_pred, average='macro')\n",
        "                        val_scores.append(f1)\n",
        "                        print(f\" Validation Score {col}:{f1:.4f}\")\n",
        "\n",
        "                    # Multiclass target\n",
        "                    preds = multiclass_val_preds\n",
        "                    ensemble_pred = np.argmax(lgb_A * preds['lgb'] + xgb_B * preds['xgb'] +\n",
        "                                           cat_C * preds['cat'] + llm_D * preds['llm'], axis=1)\n",
        "                    f1 = f1_score(preds['true'], ensemble_pred, average='macro')\n",
        "                    print(f\" Validation Score S1:{f1:.4f}\")\n",
        "                    val_scores.append(f1)\n",
        "\n",
        "                    avg_score = np.mean(val_scores)\n",
        "                    best_weights.append(weights)\n",
        "                    best_scores.append(avg_score)\n",
        "\n",
        "                    print(f\"Average Validation Score: {avg_score:.4f}\")\n",
        "\n",
        "    # Sort results and get top 3\n",
        "    #sorted_indices = np.argsort(best_scores)[::-1][:3]\n",
        "    sorted_indices = np.argsort(best_scores)[::-1]\n",
        "    top_3_weights = [best_weights[i] for i in sorted_indices]\n",
        "    top_3_scores = [best_scores[i] for i in sorted_indices]\n",
        "\n",
        "    print(\"\\nTop All Weight Combinations:\")\n",
        "    for i, (weights, score) in enumerate(zip(top_3_weights, top_3_scores)):\n",
        "        print(f\"Rank {i+1}: lgb_A={weights[0]:.1f}, xgb_B={weights[1]:.1f}, cat_C={weights[2]:.1f}, llm_D={weights[3]:.1f} - Score: {score:.4f}\")\n",
        "\n",
        "    avg_f1 = np.mean(val_f1)\n",
        "    total_avg_f1s.append(avg_f1)\n",
        "    detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n",
        "    print(f\" ÌèâÍ∑† F1: {avg_f1:.4f} / [ÏÉÅÏÑ∏] {detail}\")\n",
        "\n",
        "    best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n",
        "\n",
        "    if early_stop==True:\n",
        "      print(\"\\n[best_iteration_dict]\")\n",
        "      for k, v in best_iteration_dict.items():\n",
        "          print(f\"{k}: {v}\")\n",
        "\n",
        "    print(f\"# Ï†ÑÏ≤¥ ÌèâÍ∑† F1: {np.mean(total_avg_f1s):.4f}\")\n",
        "    print(\"================================================\")\n",
        "\n",
        "    # modoling with 100% train & no valid\n",
        "    print('\\n STEP2: Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞Î°ú Î™®Îç∏ Ïû¨ÌïôÏäµ')\n",
        "    print(\"====== modeling with 100% train & no valid =====\")\n",
        "\n",
        "    # binary\n",
        "    binary_preds = {}\n",
        "    binary_preds_proba = {}\n",
        "    for col in targets_binary:\n",
        "        # Get parameters for both models\n",
        "        lgb_params = common_params[col].copy()\n",
        "        lgb_params['random_state'] = random_state\n",
        "\n",
        "        xgb_params = {\n",
        "            'n_estimators': 1000,\n",
        "            'learning_rate': 0.01,\n",
        "            'max_depth': 6,\n",
        "            'min_child_weight': 1,\n",
        "            'subsample': 0.8,\n",
        "            'colsample_bytree': 0.8,\n",
        "            'random_state': random_state\n",
        "        }\n",
        "\n",
        "        y = train_df[col]\n",
        "\n",
        "        if early_stop:\n",
        "            lgb_params['n_estimators'] = best_iteration_dict[col]\n",
        "            xgb_params['n_estimators'] = best_iteration_dict[col]\n",
        "\n",
        "        # LLM Valid Model load and Inference\n",
        "\n",
        "        is_multiclass = False\n",
        "        test_X_llm = test_X.copy()\n",
        "        test_X_llm = test_X_llm[X_Feature[col]]\n",
        "        test_X_llm['input'] = test_X_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "        test_X_llm[\"text\"] = test_X_llm[\"input\"]\n",
        "        test_data = CustomDataset(test_X_llm)\n",
        "        test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "        llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=2, torch_dtype=torch.float16, device_map='auto')\n",
        "        lora_model = get_peft_model(llm_model, config)\n",
        "        _, llm_pred = inference(llm_model, test_dataloader, test_X_llm, col)\n",
        "        llm_pred = np.array([arr[1] for arr in llm_pred], dtype=np.float32)\n",
        "\n",
        "        # Train LightGBM\n",
        "        lgb_model = LGBMClassifier(**lgb_params)\n",
        "        lgb_model.fit(X, y)\n",
        "\n",
        "        # Train XGBoost\n",
        "        xgb_model = XGBClassifier(**xgb_params)\n",
        "        xgb_model.fit(X, y)\n",
        "\n",
        "        # Train CatBoost\n",
        "        # cat_model = CatBoostClassifier(**common_params_cat)\n",
        "        # cat_model.fit(X, y)\n",
        "\n",
        "        tabpfn_params = {\n",
        "            'device': 'cuda'\n",
        "        }\n",
        "\n",
        "        # Train TabPFN\n",
        "        tabpfn_model = TabPFNClassifier(**tabpfn_params)\n",
        "        tabpfn_model.fit(X, y)\n",
        "\n",
        "        # Get predictions and ensemble\n",
        "        #_, llm_pred_vaild = inference(llm_model, val_dataloader, X_valid_llm, \"S1\")\n",
        "        lgb_pred = lgb_model.predict_proba(test_X)[:, 1]\n",
        "        xgb_pred = xgb_model.predict_proba(test_X)[:, 1]\n",
        "        #cat_pred = cat_model.predict_proba(test_X)[:, 1]\n",
        "        cat_pred = tabpfn_model.predict_proba(test_X)[:, 1]\n",
        "\n",
        "        binary_preds[col] = (lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred + llm_D * llm_pred  > 0.5).astype(int)\n",
        "        #binary_preds_proba[col] = lgb_A * lgb_model.predict_proba(test_X) + xgb_B * xgb_model.predict_proba(test_X) + cat_C * cat_model.predict_proba(test_X)\n",
        "\n",
        "        # Store predictions\n",
        "        binary_test_preds[col] = {\n",
        "            'llm': llm_pred,\n",
        "            'lgb': lgb_pred,\n",
        "            'xgb': xgb_pred,\n",
        "            'cat': cat_pred\n",
        "        }\n",
        "\n",
        "        # Feature importance (using LightGBM's importance)\n",
        "        fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n",
        "        top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "        feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "        print(f\"[{col}] {feat_str}\")\n",
        "\n",
        "    # multiclass\n",
        "    y = train_df['S1']\n",
        "\n",
        "    # Get parameters for both models\n",
        "    lgb_params = common_params['S1'].copy()\n",
        "    lgb_params['random_state'] = random_state\n",
        "\n",
        "    xgb_params = {\n",
        "        'n_estimators': 1000,\n",
        "        'learning_rate': 0.01,\n",
        "        'max_depth': 6,\n",
        "        'min_child_weight': 1,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'random_state': random_state\n",
        "    }\n",
        "\n",
        "    if early_stop:\n",
        "        lgb_params['n_estimators'] = best_iteration_dict['S1']\n",
        "        xgb_params['n_estimators'] = best_iteration_dict['S1']\n",
        "\n",
        "    # ÌÅ¥ÎûòÏä§ weight Í≥ÑÏÇ∞\n",
        "    classes = np.unique(y)\n",
        "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
        "    class_weights = dict(zip(classes, weights))\n",
        "\n",
        "    # Í∞Å ÏÉòÌîåÏóê ÎåÄÌï¥ weight Îß§Ìïë\n",
        "    w_train = pd.Series(y).map(class_weights)\n",
        "    # print(\"----compute_class_weight:\")\n",
        "    # print(w_train)\n",
        "\n",
        "    w_train = compute_sample_weight(class_weight='balanced', y=y)\n",
        "    # print(\"----compute_sample_weight:\")\n",
        "    # print(w_train)\n",
        "\n",
        "    # LLM Valid Model load and Inference\n",
        "\n",
        "    is_multiclass = True\n",
        "    test_X_llm = test_X.copy()\n",
        "    test_X_llm = test_X_llm[X_Feature[\"S1\"]]\n",
        "    test_X_llm['input'] = test_X_llm.apply(lambda x: prepare_input_text(x),axis=1)\n",
        "    test_X_llm[\"text\"] = test_X_llm[\"input\"]\n",
        "    test_data = CustomDataset(test_X_llm)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
        "\n",
        "    llm_model = AutoModelForSequenceClassification.from_pretrained(llm_model_path, num_labels=3, torch_dtype=torch.float16, device_map='auto')\n",
        "    lora_model = get_peft_model(llm_model, config)\n",
        "    _, llm_pred = inference(llm_model, test_dataloader, test_X_llm, \"S1\")\n",
        "    llm_pred = np.array(llm_pred, dtype=np.float32)\n",
        "    #print(llm_pred)\n",
        "\n",
        "    # Train LightGBM\n",
        "    lgb_model = LGBMClassifier(**lgb_params, objective='multiclass', num_class=3)\n",
        "    lgb_model.fit(X, y, sample_weight=w_train)\n",
        "\n",
        "    # Train XGBoost\n",
        "    xgb_model = XGBClassifier(**xgb_params, objective='multi:softmax', num_class=3)\n",
        "    xgb_model.fit(X, y, sample_weight=w_train)\n",
        "\n",
        "    # Train CatBoost\n",
        "    # cat_model = CatBoostClassifier(**common_params_cat2, objective='MultiClass', classes_count=3)\n",
        "    # cat_model.fit(X, y)\n",
        "\n",
        "    tabpfn_params = {\n",
        "        'device': 'cuda'\n",
        "    }\n",
        "\n",
        "     # Train TabPFN\n",
        "    tabpfn_model = TabPFNClassifier(**tabpfn_params)\n",
        "    tabpfn_model.fit(X, y)\n",
        "\n",
        "    # Get predictions and ensemble\n",
        "    lgb_pred = lgb_model.predict_proba(test_X)\n",
        "    xgb_pred = xgb_model.predict_proba(test_X)\n",
        "    #cat_pred = cat_model.predict_proba(test_X)\n",
        "    cat_pred = tabpfn_model.predict_proba(test_X)\n",
        "\n",
        "    multiclass_test_preds = {\n",
        "        'llm': llm_pred,\n",
        "        'lgb': lgb_pred,\n",
        "        'xgb': xgb_pred,\n",
        "        'cat': cat_pred\n",
        "    }\n",
        "\n",
        "    multiclass_pred = np.argmax(lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred +llm_D * llm_pred, axis=1)\n",
        "    multiclass_pred_proba = lgb_A * lgb_pred + xgb_B * xgb_pred + cat_C * cat_pred + llm_D * llm_pred\n",
        "\n",
        "    # Feature importance\n",
        "    fi_df = pd.DataFrame({'feature': X.columns, 'importance': lgb_model.feature_importances_})\n",
        "    top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "    feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "    print(f\"[S1] {feat_str}\")\n",
        "\n",
        "    # ÏòàÏ∏° Ï†ÄÏû•\n",
        "    submission_final['S1'] = multiclass_pred\n",
        "    for col in targets_binary:\n",
        "      submission_final[col] = binary_preds[col]\n",
        "    submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n",
        "    fname = f\"submission_{np.mean(total_avg_f1s)}.csv\"\n",
        "    submission_final.to_csv(fname, index=False)\n",
        "    print(f\"# {fname} Ï†ÄÏû• ÏôÑÎ£å\")\n",
        "    print(f\"# submission shape:{submission_final.shape}\")\n",
        "    print(\"================================================\")\n",
        "    print(\"\\nTop 3 Weight Combinations:\")\n",
        "    for i, (weights, score) in enumerate(zip(top_3_weights, top_3_scores)):\n",
        "        print(f\"Rank {i+1}: lgb_A={weights[0]:.1f}, xgb_B={weights[1]:.1f}, cat_C={weights[2]:.1f}, llm_D={weights[3]:.1f} - Score: {score:.4f}\")\n",
        "\n",
        "        # Generate submission with these weights\n",
        "        lgb_A, xgb_B, cat_C, llm_D = weights\n",
        "\n",
        "        # Binary predictions\n",
        "        for col in targets_binary:\n",
        "            preds = binary_test_preds[col]\n",
        "            ensemble_pred = (lgb_A * preds['lgb'] + xgb_B * preds['xgb'] +\n",
        "                          cat_C * preds['cat'] + llm_D * preds['llm'] > 0.5).astype(int)\n",
        "            submission_final[col] = ensemble_pred\n",
        "\n",
        "        # Multiclass prediction\n",
        "        preds = multiclass_test_preds\n",
        "        ensemble_pred = np.argmax(lgb_A * preds['lgb'] + xgb_B * preds['xgb'] +\n",
        "                               cat_C * preds['cat'] + llm_D * preds['llm'], axis=1)\n",
        "        submission_final['S1'] = ensemble_pred\n",
        "\n",
        "        fname = f\"submission_top{i+1}_{score:.4f}.csv\"\n",
        "        submission_final.to_csv(fname, index=False)\n",
        "        print(f\"Saved submission to {fname}\")\n",
        "\n",
        "    # Use the best weights for final submission\n",
        "    best_weights = top_3_weights[0]\n",
        "    lgb_A, xgb_B, cat_C, llm_D = best_weights\n",
        "\n",
        "    # Î™®Îç∏Î≥Ñ ÏòàÏ∏°Í≤∞Í≥º ÎπÑÏú® ÎπÑÍµê\n",
        "    a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n",
        "    result.columns = ['ÌïôÏäµsum','ÌïôÏäµlen','ÌïôÏäµmean','ÌÖåÏä§Ìä∏sum','ÌÖåÏä§Ìä∏len','ÌÖåÏä§Ìä∏mean']\n",
        "    print('\\n STEP3: ÏòàÏ∏°Í≤∞Í≥º ÎπÑÍµêÌëú')\n",
        "    display(result)\n",
        "    oof_result = []\n",
        "    return submission_final, oof_result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:07:20.489489Z",
          "iopub.execute_input": "2025-06-09T10:07:20.489732Z",
          "iopub.status.idle": "2025-06-09T10:07:20.555004Z",
          "shell.execute_reply.started": "2025-06-09T10:07:20.489717Z",
          "shell.execute_reply": "2025-06-09T10:07:20.554207Z"
        },
        "papermill": {
          "duration": 0.095319,
          "end_time": "2025-06-07T12:17:15.512394",
          "exception": false,
          "start_time": "2025-06-07T12:17:15.417075",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "8822c602"
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ============================"
      ],
      "metadata": {
        "id": "YwAwlzKLORvV"
      },
      "id": "YwAwlzKLORvV"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kbYLCFJLpQ5"
      },
      "id": "2kbYLCFJLpQ5",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7vvLSkwooZ0h"
      },
      "id": "7vvLSkwooZ0h",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U36LFTRioZ-g"
      },
      "id": "U36LFTRioZ-g",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sg6Eiq-vOTr1"
      },
      "id": "sg6Eiq-vOTr1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ Î™®Îç∏ ÌïôÏäµ"
      ],
      "metadata": {
        "id": "HwoUMZO4LMb1"
      },
      "id": "HwoUMZO4LMb1"
    },
    {
      "cell_type": "code",
      "source": [
        "X_Feature = {\n",
        "    \"Q1\": [\n",
        "        \"Q1_te2\",\n",
        "        \"wake_time_ratio\",\n",
        "        \"mlight_first_wakeup_minutes\",\n",
        "        \"wake_time_diff\",\n",
        "        \"Q1_te\",\n",
        "        \"lights_off_time\",\n",
        "        \"sleep_duration_ratio\",\n",
        "        \"active_hour_mean_speed\",\n",
        "        \"beforebed_ÌÜµÌôî_time\",\n",
        "        \"rolling_sleep_time_2d\",\n",
        "        \"activehour_NAVER_time\"\n",
        "    ],\n",
        "    \"Q2\": [\n",
        "        \"Q2_te\",\n",
        "        \"Q2_te2\",\n",
        "        \"activehour_total_screen_time\",\n",
        "        \"beforebed_unique_bssid_count\",\n",
        "        \"wake_time_lag1\",\n",
        "        \"light_rolling_wake_time_2d\",\n",
        "        \"beforebed_max_rssi\",\n",
        "        \"active_hour_std_hr\",\n",
        "        \"beforebed_top_bssid_count\",\n",
        "        \"activehour_screen_time_vs_avg_pct\",\n",
        "        \"activehour_Î©îÏã†Ï†Ä_time\"\n",
        "    ],\n",
        "    \"Q3\": [\n",
        "        \"Q3_te2\",\n",
        "        \"light_sleep_time_lag2\",\n",
        "        \"mlight_first_wakeup_minutes\",\n",
        "        \"rolling_sleep_time_3d\",\n",
        "        \"light_rolling_sleep_duration_3d\",\n",
        "        \"Q3_te\",\n",
        "        \"beforebed_scan_count\",\n",
        "        \"active_hour_distance_x\",\n",
        "        \"activehour_ÌÜµÌôî_time\",\n",
        "        \"walking_minutes\"\n",
        "    ],\n",
        "    \"S1\": [\n",
        "        \"S1_te\",\n",
        "        \"wake_time_diff\",\n",
        "        \"S1_te2\",\n",
        "        \"sleep_duration_ratio\",\n",
        "        \"m_activity_met@240min@sum@04h00m\",\n",
        "        \"beforebed_screen_time_vs_avg_pct\",\n",
        "        \"wake_time_ratio\",\n",
        "        \"rolling_wake_time_3d\",\n",
        "        \"m_activity_0@240min@std@20h00m\",\n",
        "        \"m_activity@240min@std@12h00m\",\n",
        "        \"beforebed_Î©îÏã†Ï†Ä_time\",\n",
        "        \"sleep_duration_diff\",\n",
        "        \"light_sleep_time_diff\",\n",
        "        \"active_hour_min_hr\"\n",
        "    ],\n",
        "    \"S2\": [\n",
        "        \"S2_te2\",\n",
        "        \"S2_te\",\n",
        "        \"light_sleep_time_lag1\",\n",
        "        \"work_hour_unknown_ratio\",\n",
        "        \"m_activity@240min@std@12h00m\",\n",
        "        \"beforebed_strong_signal_ratio\",\n",
        "        \"light_rolling_wake_time_2d\",\n",
        "        \"free_hour_rssi_mean\",\n",
        "        \"activehour_Ï†ÑÌôî_time\",\n",
        "        \"sleep_hour_mean_speed\",\n",
        "        \"activehour_screen_time_vs_avg_pct\",\n",
        "        \"light_wake_time_diff_lag2\",\n",
        "        \"beforebed_max_rssi\",\n",
        "        \"avg_charging_duration\",\n",
        "        \"m_activity_met@240min@std@12h00m\"\n",
        "    ],\n",
        "    \"S3\": [\n",
        "        \"S3_te\",\n",
        "        \"S3_te2\",\n",
        "        \"beforebed_Î©îÏã†Ï†Ä_time\",\n",
        "        \"light_wake_time_diff\",\n",
        "        \"sleep_time_diff_lag1\",\n",
        "        \"light_sleep_time_lag2\",\n",
        "        \"m_activity_met@240min@sum@16h00m\",\n",
        "        \"free_hour_rssi_max\",\n",
        "        \"light_weekday_avg_sleep\",\n",
        "        \"Î∂àÎÅàÏãúÍ∞ÑÎ∂ÄÌÑ∞Í∏∞ÏÉÅÏãúÍ∞Ñ\",\n",
        "        \"sleep_hour_distance_x\",\n",
        "        \"activehour_scan_count\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "X_Feature_alias = {\n",
        "    \"Q1\": [\n",
        "        \"Q1_encoded_time_2\",\n",
        "        \"wake_time_to_baseline_ratio\",\n",
        "        \"minutes_to_first_wake_after_light\",\n",
        "        \"wake_time_difference\",\n",
        "        \"Q1_encoded_time\",\n",
        "        \"lights_off_clock_time\",\n",
        "        \"sleep_duration_ratio_to_guideline\",\n",
        "        \"mean_speed_during_active_hours\",\n",
        "        \"call_duration_before_bed\",\n",
        "        \"sleep_time_rolling_avg_2d\",\n",
        "        \"NAVER_time_active_hours\"\n",
        "    ],\n",
        "    \"Q2\": [\n",
        "        \"Q2_encoded_time\",\n",
        "        \"Q2_encoded_time_2\",\n",
        "        \"total_screen_time_active_hours\",\n",
        "        \"unique_wifi_count_before_bed\",\n",
        "        \"previous_day_wake_time\",\n",
        "        \"light_based_wake_time_rolling_avg_2d\",\n",
        "        \"max_wifi_signal_before_bed\",\n",
        "        \"std_heart_rate_active_hours\",\n",
        "        \"frequent_wifi_count_before_bed\",\n",
        "        \"screen_time_vs_avg_pct_active_hours\",\n",
        "        \"messenger_usage_time_active_hours\"\n",
        "    ],\n",
        "    \"Q3\": [\n",
        "        \"Q3_encoded_time_2\",\n",
        "        \"light_sleep_duration_lag2\",\n",
        "        \"minutes_to_first_wake_after_light\",\n",
        "        \"sleep_time_rolling_avg_3d\",\n",
        "        \"light_based_sleep_duration_rolling_avg_3d\",\n",
        "        \"Q3_encoded_time\",\n",
        "        \"wifi_scan_count_before_bed\",\n",
        "        \"distance_traveled_active_hours\",\n",
        "        \"call_duration_active_hours\",\n",
        "        \"total_walking_minutes\"\n",
        "    ],\n",
        "    \"S1\": [\n",
        "        \"S1_encoded_time\",\n",
        "        \"wake_time_difference\",\n",
        "        \"S1_encoded_time_2\",\n",
        "        \"sleep_duration_ratio_to_guideline\",\n",
        "        \"met_sum_0to4am\",\n",
        "        \"screen_time_vs_avg_pct_before_bed\",\n",
        "        \"wake_time_to_baseline_ratio\",\n",
        "        \"wake_time_rolling_avg_3d\",\n",
        "        \"activity_std_8pm_to_midnight\",\n",
        "        \"activity_std_12pm_to_4pm\"\n",
        "        \"messenger_usage_time_before_bed\",\n",
        "        \"sleep_time_difference\",\n",
        "        \"light_based_sleep_time_difference\",\n",
        "        \"activity_time_mininum_hours\"\n",
        "\n",
        "    ],\n",
        "    \"S2\": [\n",
        "        \"S2_encoded_time_2\",\n",
        "        \"S2_encoded_time\",\n",
        "        \"light_sleep_duration_lag1\",\n",
        "        \"unknown_activity_ratio_work_hours\",\n",
        "        \"activity_std_12pm_to_4pm\",\n",
        "        \"strong_wifi_signal_ratio_before_bed\",\n",
        "        \"light_based_wake_time_rolling_avg_2d\",\n",
        "        \"avg_wifi_signal_strength_free_hours\",\n",
        "        \"phone_call_time_active_hours\",\n",
        "        \"mean_movement_speed_sleep_hours\",\n",
        "        \"activity_time_screen_hour_vs_avg_pct\",\"light_wake_time_diff_lag2\",\"beforebed_max_rssi\",\"avg_charging_duration\",\"m_activity_met@240min@std@12h00m\"\n",
        "    ],\n",
        "    \"S3\": [\n",
        "        \"S3_encoded_time\",\n",
        "        \"S3_encoded_time_2\",\n",
        "        \"messenger_usage_time_before_bed\",\n",
        "        \"light_based_wake_time_difference\",\n",
        "        \"sleep_time_difference_lag1\",\n",
        "        \"light_sleep_duration_lag2\",\n",
        "        \"met_sum_4pm_to_8pm\",\n",
        "        \"max_wifi_signal_strength_free_hours\",\n",
        "        \"light_based_weekday_avg_sleep_duration\",\n",
        "        \"time_from_first_movement_to_final_wake\",\n",
        "        \"sleep_hour_distance_x\",\"active_hour_scan_count\"\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "vurJ7RvTpwPz"
      },
      "id": "vurJ7RvTpwPz",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Prompt = {\n",
        "    \"Q1\": \"Based on the following sleep-related information, classify the overall perceived sleep quality upon waking as either below or above the individual‚Äôs average. (0: Below average, 1: Above average) \",\n",
        "    \"Q2\": \"Using the following data, determine the level of physical fatigue the individual felt before sleep. (0: High fatigue, 1: Low fatigue) \",\n",
        "    \"Q3\": \"Based on the information below, classify the stress level the individual experienced before going to bed. (0: High stress, 1: Low stress) \",\n",
        "    \"S1\": \"Based on the provided information, classify how well the individual's total sleep time (TST) aligns with recommended sleep guidelines. (0: Not met, 1: Partially met, 2: Fully met) \",\n",
        "    \"S2\": \"Using the following indicators, determine whether the individual met the guideline for sleep efficiency (SE). (0: Not met, 1: Met) \",\n",
        "    \"S3\": \"From the data provided, assess if the sleep onset latency (SOL) guideline was met. (0: Not met, 1: Met) \"\n",
        "}"
      ],
      "metadata": {
        "id": "eLTpYi4bpzoI"
      },
      "id": "eLTpYi4bpzoI",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_worker(worker_id):\n",
        "    worker_seed = 42 + worker_id\n",
        "    np.random.seed(worker_seed)\n",
        "    random.seed(worker_seed)\n",
        "\n",
        "g = torch.Generator()\n",
        "g.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXE7mLSTiVtQ",
        "outputId": "042dd5e6-8cf0-4fad-db98-f613ec990e85"
      },
      "id": "nXE7mLSTiVtQ",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7e7b6c5dc830>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Define llm_model\n",
        "# --\n",
        "\n",
        "#llm_model_path = 'Qwen/Qwen2.5-0.5B'\n",
        "#llm_model_path = \"Qwen/Qwen3-0.6B-Base\" #ÎòëÍ∞ôÏùå\n",
        "#llm_model_path = \"Qwen/Qwen3-1.7B\" # ÏÑ±Í≥µ Ï¢ãÏùå\n",
        "#llm_model_path = \"EleutherAI/pythia-70m\"\n",
        "#llm_model_path = \"facebook/opt-125m\" # Í¥úÏ∞ÆÏùå\n",
        "#llm_model_path = \"openai-community/gpt2\"\n",
        "#llm_model_path = 'Qwen/Qwen2.5-0.5B-Instruct'\n",
        "#llm_model_path = \"distilbert/distilgpt2\"\n",
        "llm_model_path = \"Qwen/Qwen3-0.6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_model_path, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ],
      "metadata": {
        "id": "SakYkG9PiV5w"
      },
      "id": "SakYkG9PiV5w",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Define LoraConfig\n",
        "# ---\n",
        "\n",
        "config = LoraConfig(\n",
        "    # r=16,\n",
        "    # lora_alpha=32,\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],#Best\n",
        "    #target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    # task_type=\"SEQ_CLS\",\n",
        "    #task_type=TaskType.SEQ_CLS,\n",
        "    modules_to_save=[\"classifier\"],\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9x7wYGlihTm",
        "outputId": "674e55e8-529e-47d4-f232-3a927e122a5a"
      },
      "id": "_9x7wYGlihTm",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# Define your training loop\n",
        "# ---\n",
        "\n",
        "epochs = 16 # 5\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "#criterion = nn.BCEWithLogitsLoss()\n",
        "total_loss = 0\n",
        "correct = 0\n",
        "best = np.inf # best model Î•º Ï∞æÍ∏∞ ÏúÑÌïú\n",
        "patience = 3  # 3Î≤àÍπåÏßÄ validation loss ÌÑ∞ÏßÄÎ©¥ stop ÏãúÌÇ¥\n",
        "\n",
        "# best model save\n",
        "result_path = \"./\"\n",
        "best_model_path = os.path.join(result_path, 'best_model.pt')\n",
        "# best_model_path = 'best_model.pt'\n",
        "bad_counter = 0"
      ],
      "metadata": {
        "id": "g6X0CRgviWAu"
      },
      "id": "g6X0CRgviWAu",
      "execution_count": 34,
      "outputs": []
    },
    {
      "id": "bf3543b7",
      "cell_type": "code",
      "source": [
        "# Í≥µÌÜµ ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "common_params = {\n",
        "  'n_estimators': 5000,\n",
        "  \"learning_rate\": 0.01,\n",
        "  # 'min_data_in_leaf':2,\n",
        "  # 'bagging_fraction':0.9,\n",
        "  # 'feature_fraction':0.6,\n",
        "  'lambda_l1': 5,\n",
        "  'lambda_l2': 1,\n",
        "  # 'max_depth': 4,\n",
        "  'n_jobs': -1,\n",
        "  'verbosity': -1\n",
        "}\n",
        "\n",
        "# Î™®Îç∏Î≥Ñ ÏÑ∏Î∂Ä ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
        "best_param_dict = {}\n",
        "best_param_dict['Q3'] = common_params\n",
        "best_param_dict['S1'] = common_params\n",
        "best_param_dict['S2'] = common_params\n",
        "best_param_dict['S3'] = common_params\n",
        "best_param_dict['Q1'] = common_params\n",
        "best_param_dict['Q2'] = common_params\n",
        "\n",
        "\"\"\"\n",
        "// submission_top1_0.6492.csv\n",
        "\n",
        "# submission_0.6261336267831857.csv Ï†ÄÏû• ÏôÑÎ£å\n",
        "# submission shape:(250, 9)\n",
        "\n",
        "Top 3 Weight Combinations:\n",
        "Rank 1: lgb_A=0.2, xgb_B=0.4, cat_C=0.0, llm_D=0.4 - Score: 0.6492\n",
        "Saved submission to submission_top1_0.6492.csv\n",
        "Rank 2: lgb_A=0.1, xgb_B=0.5, cat_C=0.2, llm_D=0.2 - Score: 0.6487\n",
        "Saved submission to submission_top2_0.6487.csv\n",
        "Rank 3: lgb_A=0.1, xgb_B=0.5, cat_C=0.1, llm_D=0.3 - Score: 0.6478\n",
        "Saved submission to submission_top282_0.5889.csv\n",
        "\"\"\"\n",
        "\n",
        "submission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T10:07:20.556024Z",
          "iopub.execute_input": "2025-06-09T10:07:20.556507Z",
          "iopub.status.idle": "2025-06-09T11:12:01.530621Z",
          "shell.execute_reply.started": "2025-06-09T10:07:20.556482Z",
          "shell.execute_reply": "2025-06-09T11:12:01.530084Z"
        },
        "id": "bf3543b7",
        "outputId": "18c9a688-75ba-4340-e53e-da04b112204e",
        "papermill": {
          "duration": 3899.13927,
          "end_time": "2025-06-07T13:22:14.745074",
          "exception": false,
          "start_time": "2025-06-07T12:17:15.605804",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 724,
          "referenced_widgets": [
            "29e359c93ef544c880fa7376e2a0c735",
            "8de0d6259153448a9b28cf00068fefe9",
            "c7ff75c2a87c4abeb49452cd1b8c16fa",
            "91ca2f98da924ae79280824e94c4e8ce",
            "6201b62abe444c499aec398aab387292",
            "cc4c1f8c91b14817aae0b2ba1ea5ce4d",
            "00baeb430eb34ffa87e6f4d28831832c",
            "9344c0ba3d60411aa538cc438e0c658a",
            "711bb611dca84a1c9dd76cb81f107a75",
            "074ae2faf5534d6f9959bc680f3405b4",
            "e4c296aece2c49678eaa763c928c1854",
            "da1fb4f84f8b45bbb49592abc206e5bc",
            "f79d004737f644339d2a4caa5010e8a2",
            "c2a321503e9c40298f7ccb96c0c64e3f",
            "a005e8e605b145d3be2c19a374c9df1c",
            "98cbd9e28ec2447389528f78fedc01f2",
            "a479cca4a72b409b9aa3e87f5523cd3f",
            "fcff32737f8b434f94308abf8830fa30",
            "401231f393eb4341b87fe30a75757c6b",
            "76b9bc340a004912b1219429e37c1163",
            "fb3a615839e5497e92a7777e3f7474f1",
            "69e30a389fdb4aa9b5bf204a1056e876"
          ]
        },
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=========valid_ids==========\n",
            "light_week_type_lag1\n",
            "weekday\n",
            "week_type\n",
            "week_type_lag1\n",
            "activehour_top_bssid\n",
            "beforebed_top_bssid\n",
            "# X shape: (450, 247)\n",
            "# test_X shape: (250, 247)\n",
            "\n",
            " STEP1: Ïã§Ìóò Í≤∞Í≥º ÌôïÏù∏\n",
            "=============== Validation Results ==============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:13<00:00,  5.59it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 15.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Epoch: 1: t_loss:0.265 t_acc:0.552 v_loss:0.211 v_acc:0.286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:12<00:00,  5.65it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Epoch: 2: t_loss:0.189 t_acc:0.555 v_loss:0.191 v_acc:0.440\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:12<00:00,  5.66it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Epoch: 3: t_loss:0.181 t_acc:0.583 v_loss:0.168 v_acc:0.365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:13<00:00,  5.57it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Epoch: 4: t_loss:0.186 t_acc:0.552 v_loss:0.236 v_acc:0.286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:12<00:00,  5.64it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1 Epoch: 5: t_loss:0.179 t_acc:0.572 v_loss:0.169 v_acc:0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 410/410 [01:13<00:00,  5.60it/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.33it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tabpfn-v2-classifier.ckpt:   0%|          | 0.00/29.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29e359c93ef544c880fa7376e2a0c735"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da1fb4f84f8b45bbb49592abc206e5bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 40/40 [00:02<00:00, 16.48it/s]\n",
            "Some weights of Qwen3ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen3-0.6B and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 270/410 [00:47<00:24,  5.67it/s]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLfJfeuJLge-"
      },
      "id": "FLfJfeuJLge-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s5N7SlvaLgh-"
      },
      "id": "s5N7SlvaLgh-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EHSoZgGiLgsd"
      },
      "id": "EHSoZgGiLgsd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ Ïù¥Ï†ÑÏ†úÏ∂úÍ≥º ÎπÑÍµê"
      ],
      "metadata": {
        "id": "nsZ0kEKjLerl"
      },
      "id": "nsZ0kEKjLerl"
    },
    {
      "id": "8d5e619e",
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Reference file\n",
        "reference_file = '/content/drive/MyDrive/data/ch2025_data_items/share/submissions/submission_top1_0.6492.csv'\n",
        "ref_df = pd.read_csv(reference_file)\n",
        "\n",
        "# Get all CSV files in data directory\n",
        "data_dir = Path('./')\n",
        "csv_files = list(data_dir.glob('*.csv'))\n",
        "\n",
        "# Store differences for each file\n",
        "differences = []\n",
        "\n",
        "for csv_file in csv_files:\n",
        "    if csv_file.name == os.path.basename(reference_file):\n",
        "        continue\n",
        "\n",
        "    # Read current file\n",
        "    current_df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Calculate differences in specified columns\n",
        "    diff_count = 0\n",
        "    for col in ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']:\n",
        "        diff_count += (ref_df[col] != current_df[col]).sum()\n",
        "\n",
        "    differences.append((csv_file.name, diff_count))\n",
        "    print(f\"File: {csv_file.name}, Differences: {diff_count}\")\n",
        "\n",
        "# Sort by difference count and get top 20\n",
        "differences.sort(key=lambda x: x[1])\n",
        "print(\"\\nTop 20 files with smallest differences:\")\n",
        "for i, (file_name, diff_count) in enumerate(differences[:20], 1):\n",
        "    print(f\"{i}. {file_name}: {diff_count} differences\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-06-09T11:12:01.531879Z",
          "iopub.execute_input": "2025-06-09T11:12:01.532138Z",
          "iopub.status.idle": "2025-06-09T11:12:02.226631Z",
          "shell.execute_reply.started": "2025-06-09T11:12:01.532114Z",
          "shell.execute_reply": "2025-06-09T11:12:02.225851Z"
        },
        "papermill": {
          "duration": 1.499871,
          "end_time": "2025-06-07T13:22:16.987261",
          "exception": false,
          "start_time": "2025-06-07T13:22:15.487390",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "collapsed": true,
        "id": "8d5e619e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d2b24160",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2b24160",
        "papermill": {
          "duration": 0.824718,
          "end_time": "2025-06-07T13:22:18.546842",
          "exception": false,
          "start_time": "2025-06-07T13:22:17.722124",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "29b4a176",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "29b4a176",
        "papermill": {
          "duration": 0.807425,
          "end_time": "2025-06-07T13:22:20.162916",
          "exception": false,
          "start_time": "2025-06-07T13:22:19.355491",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "79079453",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "79079453",
        "papermill": {
          "duration": 0.798956,
          "end_time": "2025-06-07T13:22:21.696789",
          "exception": false,
          "start_time": "2025-06-07T13:22:20.897833",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee90ed8f",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ee90ed8f",
        "papermill": {
          "duration": 0.793927,
          "end_time": "2025-06-07T13:22:23.231197",
          "exception": false,
          "start_time": "2025-06-07T13:22:22.437270",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "694fc8ae",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "694fc8ae",
        "papermill": {
          "duration": 0.76363,
          "end_time": "2025-06-07T13:22:24.800508",
          "exception": false,
          "start_time": "2025-06-07T13:22:24.036878",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8744d38a",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8744d38a",
        "papermill": {
          "duration": 0.848681,
          "end_time": "2025-06-07T13:22:26.511822",
          "exception": false,
          "start_time": "2025-06-07T13:22:25.663141",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e496fd76",
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e496fd76",
        "papermill": {
          "duration": 0.732686,
          "end_time": "2025-06-07T13:22:45.734001",
          "exception": false,
          "start_time": "2025-06-07T13:22:45.001315",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
