{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/The-4th-ETRI-AI-Human-Understanding-Competition/blob/main/201_%EC%9D%B4%EB%AF%B8%EC%A7%80_%ED%95%99%EC%8A%B5_v1_0_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTgURBTcpY0Q"
      },
      "source": [
        "> title : ì œ 4íšŒ ETRI íœ´ë¨¼ì´í•´ ì¸ê³µì§€ëŠ¥ ë…¼ë¬¸ê²½ì§„ëŒ€íšŒ <br>\n",
        "> author : hjy <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QhncbejZIfV"
      },
      "source": [
        "In our study, we used smartphones, smartwatches, sleep sensors, and self-recording apps to collect daily life logs and sleep health records of study participants in 2024.The data collection procedures and methods followed a similar approach to those used in previous studies. Here, we puï»¿blicly provide the following 12 data items, which comprise a total of 700 days' worth of lifelog data, strictly for non-commercial and academic research purposes only.\n",
        "- mACStatus: Indicates whether the smartphone is currently being charged.\n",
        "- mActivity: Value calculated by the Google Activity Recognition API.\n",
        "- mAmbience: Ambient sound identification labels and their respective probabilities.\n",
        "- mBle: Bluetooth devices around individual subject.\n",
        "- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n",
        "- mLight: Ambient light measured by the smartphone.\n",
        "- mScreenStatus: Indicates whether the smartphone screen is in use.\n",
        "- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n",
        "- mWifi: Wifi devices around individual subject.\n",
        "- wHr: Heart rate readings recorded by the smartwatch.\n",
        "- wLight: Ambient light measured by the smartwatch.\n",
        "- wPedo: Step data recorded by the smartwatch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkY5S7k0ZLFG"
      },
      "source": [
        "For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records. Each metric consists of values categorized into either two levels (0, 1) or three levels (0, 1, 2), depending on the specific metric. The detailed classification criteria for each metric's levels will be provided in a separate document.These\n",
        "metrics assign a value of 0 for sleep records that do not meet the recommended guidelines.For instance, the first questionnaire metric (Q1) is assigned a value of 1 on days when an\n",
        "individualâ€™s self-reported sleep quality exceeds their average over the experimental period, and 0 when it\n",
        "falls below that average. Similarly, the second and third metrics (Q2 and Q3) are assigned a value of 0\n",
        "on days when the participantâ€™s fatigue and stress levels, respectively, exceed their average, and a value of\n",
        "1 when these levels are below average.\n",
        "\n",
        "- Q1: Overall sleep quality as perceived by a subject immediately after waking up.\n",
        "- Q2: Physical fatigue of a subject just before sleep.\n",
        "- Q3: Stress level experienced by a subject just before sleep.\n",
        "- S1: Adherence to sleep guidelines for total sleep time (TST).\n",
        "- S2: Adherence to sleep guidelines for sleep efficiency (SE).\n",
        "- S3: Adherence to sleep guidelines for sleep onset latency (SOL, or SL).\n",
        "\n",
        "ìˆ˜ë©´ ê±´ê°•, í”¼ë¡œ, ìŠ¤íŠ¸ë ˆìŠ¤ ì˜ˆì¸¡ì„ ìœ„í•œ í•™ìŠµ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´, ìˆ˜ë©´ ì„¼ì„œ ë°ì´í„°ì™€ ìê¸° ë³´ê³ ì‹ ì„¤ë¬¸ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì˜ 6ê°€ì§€ ì§€í‘œë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.\n",
        "ê° ì§€í‘œëŠ” í•´ë‹¹ í•­ëª©ì— ë”°ë¼ ë‘ ìˆ˜ì¤€(0, 1) ë˜ëŠ” ì„¸ ìˆ˜ì¤€(0, 1, 2)ìœ¼ë¡œ êµ¬ë¶„ëœ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
        "ê° ì§€í‘œì˜ ì„¸ë¶€ ë¶„ë¥˜ ê¸°ì¤€ì€ ë³„ë„ì˜ ë¬¸ì„œì—ì„œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "\n",
        "- Q1: ê¸°ìƒ ì§í›„ ë³¸ì¸ì´ ì¸ì§€í•œ ì „ë°˜ì ì¸ ìˆ˜ë©´ì˜ ì§ˆ\n",
        " - 0: ê°œì¸ í‰ê·  ì´í•˜\n",
        " - 1: ê°œì¸ í‰ê·  ì´ìƒ\n",
        "- Q2: ì·¨ì¹¨ ì§ì „ ë³¸ì¸ì´ ëŠë‚€ ì‹ ì²´ì  í”¼ë¡œ ìˆ˜ì¤€\n",
        " - 0: ë†’ì€ í”¼ë¡œ ìˆ˜ì¤€\n",
        " - 1: ë‚®ì€ í”¼ë¡œ ìˆ˜ì¤€\n",
        "- Q3: ì·¨ì¹¨ ì§ì „ ë³¸ì¸ì´ ëŠë‚€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        " - 0: ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        " - 1: ë‚®ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        "- S1: ì´ ìˆ˜ë©´ ì‹œê°„(TST) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ 3LEVELS\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ë¶€ë¶„ì  ì¤€ìˆ˜\n",
        " - 2: ê°€ì´ë“œë¼ì¸ ì™„ì „ ì¤€ìˆ˜\n",
        "- S2: ìˆ˜ë©´ íš¨ìœ¨(SE) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ ì—¬ë¶€\n",
        "- (SE: ì ìë¦¬ì— ëˆ„ì›Œ ìˆì—ˆë˜ ì „ì²´ ì‹œê°„ ëŒ€ë¹„, ì‹¤ì œë¡œ ì ë“  ì‹œê°„ì˜ ë¹„ìœ¨)\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜\n",
        "- S3: ìˆ˜ë©´ ì ë“¤ê¸° ì§€ì—° ì‹œê°„(SOL ë˜ëŠ” SL) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ ì—¬ë¶€\n",
        "- (SOL: ì ìë¦¬ì— ëˆ„ìš´ ìˆœê°„ë¶€í„° ì‹¤ì œë¡œ ì ë“œëŠ” ë°ê¹Œì§€ ê±¸ë¦° ì‹œê°„)\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVNXLQtLU6X"
      },
      "source": [
        "### ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN6iwVhQpR_a",
        "outputId": "50408569-dd59-4e2f-a506-a986b8bcd444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: haversine in /usr/local/lib/python3.11/dist-packages (2.9.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.11/dist-packages (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m215.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install haversine\n",
        "! pip install optuna\n",
        "! pip install category_encoders\n",
        "! pip install timm\n",
        "import timm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "from scipy.stats import entropy\n",
        "from haversine import haversine  # ì„¤ì¹˜ í•„ìš”: pip install haversine\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cFvEVmxWsRH4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "from tqdm import tqdm  # â† ì¶”ê°€\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from datetime import time\n",
        "from datetime import timedelta\n",
        "from functools import reduce\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
        "import lightgbm as lgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from category_encoders import TargetEncoder\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# seed ê³ ì •\n",
        "SD = 42\n",
        "random.seed(SD)\n",
        "np.random.seed(SD)\n",
        "os.environ['PYTHONHASHSEED'] = str(SD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iVOoFq7pSCM",
        "outputId": "c17f423f-4946-4b80-b41a-69134f6edae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gIbC9LQkv6T4"
      },
      "outputs": [],
      "source": [
        "# pandas ì˜µì…˜\n",
        "pd.set_option('display.max_columns', 999)\n",
        "pd.set_option('display.max_rows', 999)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '%0.4f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "38uzdH-UYh_3"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S_ZQfubWYiCk"
      },
      "outputs": [],
      "source": [
        "def correct_lifelog_date_for_midnight(df, timestamp_col='timestamp', lifelog_col='lifelog_date'):\n",
        "    df = df.copy()\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
        "    df[lifelog_col] = pd.to_datetime(df[lifelog_col])\n",
        "\n",
        "    # ì¡°ê±´: timestampì˜ ì‹œ(hour)ê°€ 0~5ì‹œì¸ ê²½ìš°ë§Œ í•˜ë£¨ ì°¨ê°\n",
        "    mask = (df[timestamp_col].dt.hour >= 0) & (df[timestamp_col].dt.hour < 6)\n",
        "    df.loc[mask, lifelog_col] = df.loc[mask, lifelog_col] - pd.Timedelta(days=1)\n",
        "\n",
        "    # lifelog_dateë¥¼ ë¬¸ìì—´ë¡œ ë°”ê¾¸ëŠ” ê²½ìš°\n",
        "    df[lifelog_col] = df[lifelog_col].dt.date.astype(str)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8ikO0GN_KxyQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7EvDe55ejzKR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GQgtvPb3jzQv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEHsA6naKx0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodxdJFiv_DJ"
      },
      "source": [
        "### ğŸ“¦ ë°ì´í„° ì½ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw0cx3wwpSE2"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/data/ch2025_data_items/'\n",
        "\n",
        "# 1\n",
        "mACStatus = pd.read_parquet(path+'ch2025_mACStatus.parquet')\n",
        "mActivity = pd.read_parquet(path+'ch2025_mActivity.parquet')\n",
        "mAmbience = pd.read_parquet(path+'ch2025_mAmbience.parquet')\n",
        "mBle = pd.read_parquet(path+'ch2025_mBle.parquet')\n",
        "mGps = pd.read_parquet(path+'ch2025_mGps.parquet')\n",
        "mLight = pd.read_parquet(path+'ch2025_mLight.parquet')\n",
        "mScreenStatus = pd.read_parquet(path+'ch2025_mScreenStatus.parquet')\n",
        "mUsageStats = pd.read_parquet(path+'ch2025_mUsageStats.parquet')\n",
        "mWifi = pd.read_parquet(path+'ch2025_mWifi.parquet')\n",
        "wHr = pd.read_parquet(path+'ch2025_wHr.parquet')\n",
        "wLight = pd.read_parquet(path+'ch2025_wLight.parquet')\n",
        "wPedo = pd.read_parquet(path+'ch2025_wPedo.parquet')\n",
        "\n",
        "# 2\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/ch2025_metrics_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/ch2025_submission_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk45v0V5xiay"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "mACStatus['lifelog_date'] = mACStatus['timestamp'].astype(str).str[:10]\n",
        "mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_labels_and_probs(row):\n",
        "#     items = row['m_ambience']\n",
        "#     labels = [item[0] for item in items]\n",
        "#     probs = [item[1] for item in items]\n",
        "#     return pd.Series({'labels': labels, 'prob': probs})\n",
        "\n",
        "# mAmbience[['labels', 'prob']]  = mAmbience.apply(extract_labels_and_probs, axis=1)\n",
        "# mAmbience['lifelog_date'] = mAmbience['timestamp'].astype(str).str[:10]\n",
        "# mAmbience = mAmbience.drop(columns=['m_ambience'])\n",
        "\n",
        "# def extract_mble_info(row):\n",
        "#     m_data = row['m_ble']\n",
        "#     address = [item['address'] for item in m_data]\n",
        "#     device_class = [item['device_class'] for item in m_data]\n",
        "#     rssi = [item['rssi'] for item in m_data]\n",
        "#     return pd.Series({'address': address, 'device_class': device_class, 'rssi': rssi})\n",
        "\n",
        "# mBle[['address','device_class','rssi']] = mBle.apply(extract_mble_info, axis=1)\n",
        "# mBle['lifelog_date'] = mBle['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_gps_info(row):\n",
        "#     m_data = row['m_gps']\n",
        "#     altitude = [item['altitude'] for item in m_data]\n",
        "#     latitude = [item['latitude'] for item in m_data]\n",
        "#     longitude = [item['longitude'] for item in m_data]\n",
        "#     speed = [item['speed'] for item in m_data]\n",
        "#     return pd.Series({'altitude': altitude, 'latitude': latitude, 'longitude': longitude, 'speed': speed})\n",
        "\n",
        "# mGps[['altitude','latitude','longitude','speed']] = mGps.apply(extract_gps_info, axis=1)\n",
        "# mGps['lifelog_date'] = mGps['timestamp'].astype(str).str[:10]\n",
        "# mGps = mGps.drop(columns=['m_gps'])\n",
        "\n",
        "mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\n",
        "mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_mUsageStats_info(row):\n",
        "#     m_data = row['m_usage_stats']\n",
        "#     app_name = [item['app_name'] for item in m_data]\n",
        "#     total_time = [item['total_time'] for item in m_data]\n",
        "#     return pd.Series({'app_name': app_name, 'total_time': total_time})\n",
        "\n",
        "# mUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\n",
        "# mUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_wifi_info(row):\n",
        "#     wifi_data = row['m_wifi']\n",
        "#     bssids = [item['bssid'] for item in wifi_data]\n",
        "#     rssis = [item['rssi'] for item in wifi_data]\n",
        "#     return pd.Series({'bssid': bssids, 'rssi': rssis})\n",
        "\n",
        "# mWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\n",
        "# mWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\n",
        "\n",
        "wHr['lifelog_date'] = wHr['timestamp'].astype(str).str[:10]\n",
        "wLight['lifelog_date'] = wLight['timestamp'].astype(str).str[:10]\n",
        "wPedo['lifelog_date'] = wPedo['timestamp'].astype(str).str[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp0et2XoiBZ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE-06HN6gtqy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBZKGmxSRBQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAyS_RTHjjp3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp40u0R88PY_"
      },
      "source": [
        "### ğŸ“Œ ì´ë¯¸ì§€ ìƒì„±\n",
        "- spleeptimeë§Œ ì¶”ì¶œ (00ì‹œë¶€í„° 06ì‹œê¹Œì§€)\n",
        "- ì°¸ê³  : https://github.com/seongjiko/Pixleep/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-qgvZd-8cir"
      },
      "outputs": [],
      "source": [
        "def filter_by_group_size(df, group_cols=['subject_id', 'lifelog_date']):\n",
        "    # ê·¸ë£¹ë³„ ê±´ìˆ˜ ê³„ì‚°\n",
        "    group_counts = df.groupby(group_cols).size().reset_index(name='count')\n",
        "    # í‰ê·  ê±´ìˆ˜ ê³„ì‚°\n",
        "    mean_count = group_counts['count'].mean()\n",
        "    # í‰ê·  ì´ˆê³¼ ê·¸ë£¹ë§Œ ì¶”ì¶œ\n",
        "    valid_groups = group_counts[group_counts['count'] > mean_count*0.5][group_cols]\n",
        "    # ì›ë³¸ê³¼ inner joinìœ¼ë¡œ í•„í„°ë§\n",
        "    return df.merge(valid_groups, on=group_cols, how='inner')\n",
        "\n",
        "def make_timestamps_unique(df, timestamp_col='timestamp'):\n",
        "    # 'timestamp' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    df = df.sort_values(by=[timestamp_col])\n",
        "    # ê° 'timestamp'ê°€ ì¤‘ë³µëœ íšŸìˆ˜ë¥¼ ì„¸ì–´ ë‚˜ë…¸ì´ˆ ë‹¨ìœ„ë¡œ ì¦ê°€ì‹œí‚´\n",
        "    df[timestamp_col] = df[timestamp_col] + pd.to_timedelta(df.groupby(timestamp_col).cumcount(), unit='ns')\n",
        "    return df\n",
        "\n",
        "def average_list_columns(df, list_columns, pk_cols=['subject_id', 'lifelog_date']):\n",
        "\n",
        "    for col in list_columns:\n",
        "\n",
        "        def safe_mean(x):\n",
        "            if isinstance(x, list):\n",
        "                return np.mean(x) if len(x) > 0 else np.nan\n",
        "            elif isinstance(x, (int, float, np.integer, np.floating, type(None))):\n",
        "                return x\n",
        "            elif isinstance(x, (np.ndarray, pd.Series)):\n",
        "                return np.mean(x)\n",
        "            elif pd.api.types.is_scalar(x) and pd.isna(x):\n",
        "                return np.nan\n",
        "            else:\n",
        "                return np.nan\n",
        "\n",
        "        df[col] = df[col].apply(safe_mean)\n",
        "\n",
        "    return df\n",
        "\n",
        "def center_list_values(df, list_columns):\n",
        "    for col in list_columns:\n",
        "        def center(x):\n",
        "            if isinstance(x, list) and len(x) > 0:\n",
        "                mean = np.mean(x)\n",
        "                return [np.round(v - mean,3) for v in x]\n",
        "            return x  # NaNì´ë‚˜ ë¹„ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "        df[col] = df[col].apply(center)\n",
        "    return df\n",
        "\n",
        "def sleeptime_cutter(data): # ì ìëŠ” ì‹œê°„ ë°ì´í„°ê°€ ë” ì¤‘ìš”í•œì§€ ì‹¤í—˜(ğŸ”¥ğŸ”¥ğŸ”¥)\n",
        "\n",
        "    data_filtered = data.copy()\n",
        "    data_filtered['timestamp'] = pd.to_datetime(data_filtered['timestamp'])\n",
        "    data_filtered['lifelog_date'] = pd.to_datetime(data_filtered['lifelog_date'])\n",
        "\n",
        "    # spleeptimeë§Œ ì¶”ì¶œ (00ì‹œë¶€í„° 06ì‹œê¹Œì§€)\n",
        "    data_filtered = data_filtered[(data_filtered['timestamp'].dt.hour >= 0) & (data_filtered['timestamp'].dt.hour < 6)]\n",
        "\n",
        "    # í•˜ë£¨ ì°¨ê°\n",
        "    data_filtered['timestamp'] = data_filtered['timestamp'] - pd.Timedelta(days=1)\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'] - pd.Timedelta(days=1)\n",
        "    # print('>> D-1 í•˜ë£¨ ì°¨ê°! (lifelog_date ì‹¤ì œ ì¼ìëŠ” D+1 ìƒˆë²½(0~6ì‹œ) ë°ì´í„°ì„)')\n",
        "\n",
        "    # lifelog_dateë¥¼ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'].dt.date.astype(str)\n",
        "\n",
        "    return data_filtered\n",
        "\n",
        "def merge_data_for_group(user, date):\n",
        "\n",
        "    # ë°ì´í„° ë¡œë“œ\n",
        "    # acc_group = mGps.copy()\n",
        "    activity_group = mActivity.copy()\n",
        "    hr_group = wHr.copy()\n",
        "    wPedo_group = wPedo[['subject_id','timestamp','lifelog_date','step']].copy()\n",
        "    mLight_group = mLight[['subject_id','timestamp','lifelog_date','m_light']].copy()\n",
        "    wLight_group = wLight[['subject_id','timestamp','lifelog_date','w_light']].copy()\n",
        "\n",
        "    # ê±´ìˆ˜ê°€ ì—†ëŠ” ì¼ì ì´ìƒì¹˜ë¡œ íŒë‹¨í•˜ê³  ì œì™¸\n",
        "    activity_group = filter_by_group_size(activity_group)\n",
        "    hr_group = filter_by_group_size(hr_group)\n",
        "    wPedo_group = filter_by_group_size(wPedo_group)\n",
        "    mLight_group = filter_by_group_size(mLight_group)\n",
        "    wLight_group = filter_by_group_size(wLight_group)\n",
        "\n",
        "    # sleeptimeë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ (ğŸ”¥ğŸ”¥ğŸ”¥)\n",
        "    # activity_group = sleeptime_cutter(activity_group)\n",
        "    # hr_group = sleeptime_cutter(hr_group)\n",
        "    # wPedo_group = sleeptime_cutter(wPedo_group)\n",
        "    # mLight_group = sleeptime_cutter(mLight_group)\n",
        "    # wLight_group = sleeptime_cutter(wLight_group)\n",
        "\n",
        "    # í•„í„°\n",
        "    activity_group = activity_group.loc[(activity_group['subject_id']==user) & (activity_group['lifelog_date']==date),:]\n",
        "    hr_group = hr_group.loc[(hr_group['subject_id']==user) & (hr_group['lifelog_date']==date),:]\n",
        "    wPedo_group = wPedo_group.loc[(wPedo_group['subject_id']==user) & (wPedo_group['lifelog_date']==date),:]\n",
        "    mLight_group = mLight_group.loc[(mLight_group['subject_id']==user) & (mLight_group['lifelog_date']==date),:]\n",
        "    wLight_group = wLight_group.loc[(wLight_group['subject_id']==user) & (wLight_group['lifelog_date']==date),:]\n",
        "\n",
        "    # ë¦¬ìŠ¤íŠ¸ í‰ê· ê°’ìœ¼ë¡œ ë³€í™˜\n",
        "    # acc_group = average_list_columns(acc_group, ['altitude', 'latitude', 'longitude','speed'])\n",
        "    hr_group = average_list_columns(hr_group, ['heart_rate'])\n",
        "\n",
        "    # 'timestamp'ë¥¼ ê³ ìœ í•˜ê²Œ ë§Œë“¦\n",
        "    # acc_group = make_timestamps_unique(acc_group)\n",
        "    activity_group = make_timestamps_unique(activity_group)\n",
        "    hr_group = make_timestamps_unique(hr_group)\n",
        "    wPedo_group = make_timestamps_unique(wPedo_group)\n",
        "    mLight_group = make_timestamps_unique(mLight_group)\n",
        "    wLight_group = make_timestamps_unique(wLight_group)\n",
        "\n",
        "    # 'timestamp'ë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ê³  'subject_id'ì™€ 'date' ì»¬ëŸ¼ ì œê±°\n",
        "    # mAcc_data = acc_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    activity_data = activity_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    e4Hr_data = hr_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wPedo_data = wPedo_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    mLight_data = mLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wLight_data = wLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "\n",
        "    # í•˜ë£¨ 86400ì´ˆì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
        "    start_time = datetime.strptime(date, '%Y-%m-%d')\n",
        "    end_time = start_time + timedelta(days=1)\n",
        "    all_timestamps = pd.date_range(start=start_time, end=end_time, freq='S', inclusive='left')\n",
        "    merged_data = pd.DataFrame(index=all_timestamps)\n",
        "    merged_data.index.name = 'timestamp'\n",
        "\n",
        "    # ë°ì´í„° ë³‘í•©\n",
        "    # if not mAcc_data.empty:\n",
        "    #     merged_data = merged_data.join(mAcc_data, how='left')\n",
        "    if not e4Hr_data.empty:\n",
        "        merged_data = merged_data.join(e4Hr_data, how='left')\n",
        "    if not activity_data.empty:\n",
        "        merged_data = merged_data.join(activity_data, how='left')\n",
        "    if not wPedo_data.empty:\n",
        "        merged_data = merged_data.join(wPedo_data, how='left')\n",
        "    if not mLight_data.empty:\n",
        "        merged_data = merged_data.join(mLight_data, how='left')\n",
        "    if not wLight_data.empty:\n",
        "        merged_data = merged_data.join(wLight_data, how='left')\n",
        "\n",
        "    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìœ ì§€í•˜ê³  NaN ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
        "    # merged_data = merged_data.reindex(columns=['altitude', 'latitude', 'longitude', 'speed', 'heart_rate', 'm_activity', 'step'])\n",
        "    merged_data = merged_data.reindex(columns=['heart_rate', 'm_activity', 'step', 'm_light', 'w_light'])\n",
        "\n",
        "    # ì„ í˜• ë³´ê°„ ì ìš©\n",
        "    merged_data = merged_data.interpolate(method='time')\n",
        "\n",
        "    ### Activity ë°ì´í„°ì˜ ê·¸ë£¹í™” ì ìš©\n",
        "    # group0 : 0 (IN_VEHICLE), 1 (ON_BICYCLE), 2 (ON_FOOT), 7 (WALKING), 8 (RUNNING), 5 (TILTING)\n",
        "    # group1 : 3 (STILL)\n",
        "    # group2 : 4 (UNKNOWN)\n",
        "    activity_mapping = {\n",
        "        0: 1,\n",
        "        1: 1,\n",
        "        2: 1,\n",
        "        7: 1,\n",
        "        8: 2,\n",
        "        5: 1,\n",
        "        3: 0,\n",
        "        4: 0\n",
        "    }\n",
        "    merged_data['m_activity'] = merged_data['m_activity'].map(activity_mapping)\n",
        "\n",
        "    # subject_idì™€ dateë¥¼ ì¶”ê°€\n",
        "    merged_data['subject_id'] = user\n",
        "    merged_data['lifelog_date'] = date\n",
        "\n",
        "    return merged_data\n",
        "\n",
        "def plot_time_series(data, user, date, channel_name):\n",
        "\n",
        "    # xì¶•ì„ 00:00:00ë¶€í„° 23:59:59ê¹Œì§€ ê³ ì •\n",
        "    total_seconds = 86400\n",
        "    time_range = pd.date_range(start=datetime.strptime(date, '%Y-%m-%d'), periods=total_seconds, freq='S')\n",
        "\n",
        "    # ë°ì´í„°ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ì •ë ¬\n",
        "    data = data.reindex(time_range)\n",
        "\n",
        "    # ì‹œê³„ì—´ ì´ë¯¸ì§€ ìƒì„±\n",
        "    fig, axes = plt.subplots(5, 1, figsize=(5, 5), sharex=True, facecolor='black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_facecolor('black')\n",
        "        ax.spines['top'].set_visible(False)           # Hide the top spine\n",
        "        ax.spines['right'].set_visible(False)         # Hide the right spine\n",
        "        ax.spines['left'].set_visible(False)          # Hide the left spine\n",
        "        ax.spines['bottom'].set_visible(False)        # Hide the bottom spine\n",
        "\n",
        "    # ì„¤ì •í•œ ì‹œê°„ ë²”ìœ„ì— ë§ê²Œ xì¶• ì„¤ì •\n",
        "    for ax in axes:\n",
        "        ax.set_xlim([time_range[0], time_range[-1]])\n",
        "\n",
        "    # plot\n",
        "    if 'heart_rate' in data.columns:\n",
        "        axes[0].plot(data.index, data['heart_rate'], color='white')\n",
        "    if 'm_activity' in data.columns:\n",
        "        axes[1].plot(data.index, data['m_activity'], color='white')\n",
        "    if 'step' in data.columns:\n",
        "        axes[2].plot(data.index, data['step'], color='white')\n",
        "    if 'm_light' in data.columns:\n",
        "        axes[3].plot(data.index, data['m_light'], color='white')\n",
        "    if 'w_light' in data.columns:\n",
        "        axes[4].plot(data.index, data['w_light'], color='white')\n",
        "\n",
        "    plt.tight_layout()  # Make the layout tight\n",
        "    fname = f'{path}{channel_name}/user{user}_{date}_{channel_name}.png'\n",
        "    plt.savefig(fname)\n",
        "    # print(fname)\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdMb8wEs8c74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "channel_name = 'ch5_sleeptime'\n",
        "\n",
        "# train test ë°ì´í„° í•©ì¹˜ê¸°\n",
        "a1 = train[['subject_id', 'lifelog_date']].copy()\n",
        "a2 = test[['subject_id', 'lifelog_date']].copy()\n",
        "val_df = pd.concat([a1,a2]).reset_index(drop=True)\n",
        "print('# train:',len(train))\n",
        "print('# test:',len(test))\n",
        "print('# ì „ì²´ ë°ì´í„°:',len(val_df))\n",
        "\n",
        "# íŒŒì¼ëª…\n",
        "val_df = val_df[['subject_id', 'lifelog_date']].copy()\n",
        "val_df['filename'] = val_df.apply(lambda x: f\"user{x['subject_id']}_{x['lifelog_date']}_{channel_name}.png\", axis=1)\n",
        "\n",
        "# ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€\n",
        "image_dir = f'{path}{channel_name}'\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith(f'_{channel_name}.png')]\n",
        "\n",
        "# ë‚¨ì€ ìƒ˜í”Œ\n",
        "val_df = val_df.loc[~val_df['filename'].isin(image_files),:].reset_index(drop=True)\n",
        "print('# ë‚¨ì€ ìƒ˜í”Œìˆ˜:',len(val_df))\n",
        "\n",
        "# ====================================\n",
        "# ìƒ˜í”Œ í…ŒìŠ¤íŠ¸\n",
        "# ====================================\n",
        "# rules = (\n",
        "#   (val_df['subject_id']=='id01') & (val_df['lifelog_date'].isin(['2024-07-01']))\n",
        "# )\n",
        "# val_df = val_df.loc[rules,:].copy().head(1)\n",
        "\n",
        "# ì´ë¯¸ì§€ ìƒì„±\n",
        "bar = tqdm(range(val_df.shape[0]))\n",
        "for idx in bar:\n",
        "    user, date, *rest = val_df.iloc[idx].values\n",
        "    bar.set_description(f'user: {user}, date: {date}')\n",
        "    merged_data = merge_data_for_group(user, date)\n",
        "    plot_time_series(merged_data, user, date, channel_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5_sNQjeX8Zb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNSFIDUvX8dG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hC3NWqhDybU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FHA2ZwrDyuf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“Œ ëª¨ë¸ í•™ìŠµ"
      ],
      "metadata": {
        "id": "8qrXzX72JA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •\n",
        "dataset_path = f'{path}{channel_name}'\n",
        "\n",
        "# ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • (Resizeì— ì‚¬ìš©í•  ê°’)\n",
        "image_size = 500\n",
        "\n",
        "def find_img_mean_std(dataset_path,image_size):\n",
        "\n",
        "  import torch\n",
        "  import os\n",
        "  from torchvision import transforms\n",
        "  from PIL import Image\n",
        "\n",
        "  # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (Normalize ì œì™¸)\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.ToTensor(),  # [0, 255] -> [0, 1]ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "  ])\n",
        "\n",
        "  # PNG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "  image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
        "\n",
        "  # ì´ë¯¸ì§€ ë¡œë“œ ë° í…ì„œ ë³€í™˜\n",
        "  images = []\n",
        "  for img_file in image_files:\n",
        "      try:\n",
        "          img = Image.open(img_file).convert('RGB')  # RGBë¡œ ê°•ì œ ë³€í™˜\n",
        "          tensor_img = transform(img)  # [C, H, W] í˜•íƒœ\n",
        "          images.append(tensor_img)\n",
        "      except Exception as e:\n",
        "          print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_file} - {e}\")\n",
        "\n",
        "  # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ ê²°í•©\n",
        "  # shape: [N, C, H, W] (N: ì´ë¯¸ì§€ ìˆ˜, C: ì±„ë„, H: ë†’ì´, W: ë„ˆë¹„)\n",
        "  all_images = torch.stack(images, dim=0)\n",
        "\n",
        "  # ì±„ë„ë³„ í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
        "  # í‰ê· : [N, C, H, W] â†’ [C,] (ëª¨ë“  ì´ë¯¸ì§€, ëª¨ë“  í”½ì…€ì— ëŒ€í•œ í‰ê· )\n",
        "  # í‘œì¤€í¸ì°¨: ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê³„ì‚°\n",
        "  mean = all_images.mean(dim=[0, 2, 3])  # [C,] (ì˜ˆ: [R, G, B])\n",
        "  std = all_images.std(dim=[0, 2, 3])    # [C,] (ì˜ˆ: [R, G, B])\n",
        "\n",
        "  # ê²°ê³¼ ì¶œë ¥\n",
        "  print(\"í‰ê· (mean):\", mean.tolist())\n",
        "  print(\"í‘œì¤€í¸ì°¨(std):\", std.tolist())\n",
        "\n",
        "  return mean.tolist(), std.tolist()\n",
        "\n",
        "img_mean, img_std = find_img_mean_std(dataset_path,image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd5VbPgmnRZC",
        "outputId": "75de7f1e-9bee-4dc2-cabf-8a81a59d7cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í‰ê· (mean): [0.04598776996135712, 0.04598776996135712, 0.04598776996135712]\n",
            "í‘œì¤€í¸ì°¨(std): [0.1984541118144989, 0.1984541118144989, 0.1984541118144989]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTHFNnZH2HJy"
      },
      "outputs": [],
      "source": [
        "def extract_cnn_features(\n",
        "    image_root_dir,\n",
        "    img_mean, img_std,\n",
        "    nfeatures,\n",
        "    batch_size=32,\n",
        "    image_size=(500, 500),\n",
        "    model_name='resnet50'\n",
        "):\n",
        "    # ì´ë¯¸ì§€ í™•ì¥ì í—ˆìš© ëª©ë¡\n",
        "    valid_exts = {'.png'}\n",
        "\n",
        "    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘\n",
        "    def collect_image_paths(root_dir):\n",
        "        image_paths = []\n",
        "        for root, _, files in os.walk(root_dir):\n",
        "            for fname in files:\n",
        "                if os.path.splitext(fname)[1].lower() in valid_exts:\n",
        "                    image_paths.append(os.path.join(root, fname))\n",
        "        return image_paths\n",
        "\n",
        "    # Dataset ì •ì˜\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_paths, transform=None):\n",
        "            self.image_paths = image_paths\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.image_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            path = self.image_paths[idx]\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.relpath(path)\n",
        "\n",
        "    # Transform & ëª¨ë¸\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=img_mean, std=img_std)\n",
        "    ])\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # ëª¨ë¸ ì„ íƒ\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "    # feature_extractor = torch.nn.Sequential(*list(model.children())[:-1]).to(device)\n",
        "    # feature_extractor.eval()\n",
        "\n",
        "    # # ëª¨ë¸ ì„¤ì • ë¶€ë¶„ ìˆ˜ì •\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "\n",
        "    # # ResNet50ì˜ ê²½ìš°, ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±° í›„ Linear(2048 â†’ 10) ì¶”ê°€\n",
        "    # features = list(model.children())[:-1]  # ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±°\n",
        "    # features.extend([\n",
        "    #     torch.nn.Flatten(),  # [B, 2048, 1, 1] â†’ [B, 2048]\n",
        "    #     torch.nn.Linear(2048, nfeatures)  # 2048 â†’ 10 ì°¨ì›\n",
        "    # ])\n",
        "\n",
        "    # Xception ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model = timm.create_model('xception', pretrained=True)\n",
        "\n",
        "    # ëª¨ë“  ë ˆì´ì–´ fine-tuning ê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # feature extractor ë§Œë“¤ê¸° (íŠ¹ì§• ì¶”ì¶œ ì „ë‹¨ë§Œ ì‚¬ìš© ì‹œ)\n",
        "    features = list(model.children())[:-1]  # ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° ì œê±°\n",
        "    features.extend([\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(model.num_features, nfeatures)  # model.num_features â†’ 2048\n",
        "    ])\n",
        "\n",
        "    feature_extractor = torch.nn.Sequential(*features).to(device)\n",
        "    feature_extractor.eval()\n",
        "\n",
        "    # ë°ì´í„°ë¡œë” ìƒì„±\n",
        "    image_paths = collect_image_paths(image_root_dir)\n",
        "    dataset = ImageDataset(image_paths, transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Feature ì¶”ì¶œ\n",
        "    all_features = []\n",
        "    all_names = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(dataloader):\n",
        "            imgs = imgs.to(device)\n",
        "            feats = feature_extractor(imgs)\n",
        "            feats = feats.view(feats.size(0), -1).cpu()\n",
        "            all_features.append(feats)\n",
        "            all_names.extend(names)\n",
        "\n",
        "    features_tensor = torch.cat(all_features, dim=0)\n",
        "    df = pd.DataFrame(features_tensor.numpy())\n",
        "    df.insert(0, 'image_path', all_names)\n",
        "    fname = f\"{path}img_features_{channel_name}.csv\"\n",
        "    df.to_csv(fname, index=False)\n",
        "    print(f\">> Features saved to: {fname}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "channel_name = 'ch5_sleeptime' # ch5, ch5_sleeptime\n",
        "\n",
        "# backbone_name='resnext101_32x32d'\n",
        "# backbone_name='resnet18'\n",
        "# resnet34\tresnet18ë³´ë‹¤ ê¹Šì§€ë§Œ ì†ë„ ì†í•´ ì ìŒ\n",
        "# resnet50\të„ë¦¬ ê²€ì¦ëœ ëª¨ë¸, ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì‘ì—…ì— ë§¤ìš° ì•ˆì •ì \n",
        "# efficientnet_b0\tíŒŒë¼ë¯¸í„° ìˆ˜ ì ê³  ì •í™•ë„ ë†’ìŒ, ëª¨ë°”ì¼/ê²½ëŸ‰ í™˜ê²½ì— ì í•©\n",
        "# convnext_tiny\tìµœì‹  ConvNet êµ¬ì¡°ë¡œ ì„±ëŠ¥ ë†’ê³  ì—°ì‚° íš¨ìœ¨ì \n",
        "# resnet101\të” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¡œ ë³µì¡í•œ íŒ¨í„´ì— ê°•í•¨\n",
        "# efficientnet_b3 ~ b5\tì„±ëŠ¥ì€ ë›°ì–´ë‚˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ë” í¼\n",
        "# convnext_base\tConvNet ì¤‘ ìµœê·¼ ê°€ì¥ ë†’ì€ ì„±ëŠ¥\n",
        "# beit_base_patch16_224\tVision Transformer ê¸°ë°˜, ì‚¬ì „í•™ìŠµ í•„ìˆ˜\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒìƒë³€ìˆ˜ ìƒì„±\n",
        "img_features = extract_cnn_features(\n",
        "    image_root_dir=f'{path}{channel_name}',\n",
        "    img_mean=img_mean, img_std=img_std,\n",
        "    nfeatures = 10,\n",
        "    batch_size = 32,\n",
        "    image_size = (500, 500),\n",
        "    model_name = 'resnet50'  # ë‹¤ë¥¸ ëª¨ë¸: resnet50, resnet18, resnet101, efficientnet_b0' ë“±ë„ ê°€ëŠ¥\n",
        ")\n",
        "\n",
        "# check\n",
        "print('# img_features.shape:',img_features.shape)\n",
        "img_features.head()"
      ],
      "metadata": {
        "id": "z-IZ_vjQJEcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd81a45f-0937-4728-caeb-81bc5aac8bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [04:50<00:00, 13.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Features saved to: /content/drive/MyDrive/data/ch2025_data_items/img_features_ch5_sleeptime.csv\n",
            "# img_features.shape: (700, 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                 image_path  \\\n",
              "0  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png   \n",
              "1  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png   \n",
              "2  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png   \n",
              "3  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png   \n",
              "4  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png   \n",
              "\n",
              "        0       1       2      3       4       5       6      7       8  \\\n",
              "0  0.0305 -0.4241 -0.3273 0.1114 -0.2143  0.0431 -0.1275 0.1787 -0.1559   \n",
              "1  0.0359 -0.4194 -0.3131 0.1998 -0.1446  0.0098 -0.1130 0.1962 -0.0906   \n",
              "2 -0.0964 -0.3371 -0.2800 0.1635 -0.1065 -0.0821 -0.2850 0.2315 -0.1274   \n",
              "3 -0.1094 -0.3490 -0.3077 0.1594 -0.1044 -0.0449 -0.3279 0.2359 -0.1373   \n",
              "4 -0.0570 -0.3589 -0.3013 0.1650 -0.0932 -0.0651 -0.1920 0.2224 -0.0594   \n",
              "\n",
              "        9  \n",
              "0 -0.0657  \n",
              "1 -0.0882  \n",
              "2 -0.0010  \n",
              "3 -0.0292  \n",
              "4 -0.0192  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-115a8db0-4729-4bb3-8ded-0cfb8281479d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png</td>\n",
              "      <td>0.0305</td>\n",
              "      <td>-0.4241</td>\n",
              "      <td>-0.3273</td>\n",
              "      <td>0.1114</td>\n",
              "      <td>-0.2143</td>\n",
              "      <td>0.0431</td>\n",
              "      <td>-0.1275</td>\n",
              "      <td>0.1787</td>\n",
              "      <td>-0.1559</td>\n",
              "      <td>-0.0657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png</td>\n",
              "      <td>0.0359</td>\n",
              "      <td>-0.4194</td>\n",
              "      <td>-0.3131</td>\n",
              "      <td>0.1998</td>\n",
              "      <td>-0.1446</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>-0.1130</td>\n",
              "      <td>0.1962</td>\n",
              "      <td>-0.0906</td>\n",
              "      <td>-0.0882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png</td>\n",
              "      <td>-0.0964</td>\n",
              "      <td>-0.3371</td>\n",
              "      <td>-0.2800</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>-0.1065</td>\n",
              "      <td>-0.0821</td>\n",
              "      <td>-0.2850</td>\n",
              "      <td>0.2315</td>\n",
              "      <td>-0.1274</td>\n",
              "      <td>-0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png</td>\n",
              "      <td>-0.1094</td>\n",
              "      <td>-0.3490</td>\n",
              "      <td>-0.3077</td>\n",
              "      <td>0.1594</td>\n",
              "      <td>-0.1044</td>\n",
              "      <td>-0.0449</td>\n",
              "      <td>-0.3279</td>\n",
              "      <td>0.2359</td>\n",
              "      <td>-0.1373</td>\n",
              "      <td>-0.0292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png</td>\n",
              "      <td>-0.0570</td>\n",
              "      <td>-0.3589</td>\n",
              "      <td>-0.3013</td>\n",
              "      <td>0.1650</td>\n",
              "      <td>-0.0932</td>\n",
              "      <td>-0.0651</td>\n",
              "      <td>-0.1920</td>\n",
              "      <td>0.2224</td>\n",
              "      <td>-0.0594</td>\n",
              "      <td>-0.0192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-115a8db0-4729-4bb3-8ded-0cfb8281479d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-115a8db0-4729-4bb3-8ded-0cfb8281479d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-115a8db0-4729-4bb3-8ded-0cfb8281479d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-73277c46-38de-476e-aa6c-12a449e637af\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-73277c46-38de-476e-aa6c-12a449e637af')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-73277c46-38de-476e-aa6c-12a449e637af button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "img_features",
              "summary": "{\n  \"name\": \"img_features\",\n  \"rows\": 700,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 700,\n        \"samples\": [\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid04_2024-09-17_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid02_2024-10-06_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid09_2024-07-25_ch5_sleeptime.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.13607418537139893,\n          -0.10836177319288254,\n          -0.1248292326927185\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.36262884736061096,\n          -0.3417295217514038,\n          -0.3556533455848694\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.25975456833839417,\n          -0.3140070140361786,\n          -0.2596516013145447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.12446907162666321,\n          0.18116992712020874,\n          0.09713625907897949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.055908288806676865,\n          -0.0782686397433281,\n          -0.06543032824993134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.030199408531188965,\n          -0.05519149824976921,\n          -0.045240435749292374\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 478,\n        \"samples\": [\n          -0.16330018639564514,\n          -0.28412485122680664,\n          -0.2662018835544586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.20511427521705627,\n          0.21392612159252167,\n          0.22181323170661926\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.11929342150688171,\n          -0.10819419473409653,\n          -0.11528736352920532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.013156767934560776,\n          -0.01250495295971632,\n          -0.025315793231129646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FCrgC4pSJEpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7PZUo6TVJEun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RLT2TiKsJExf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Uxh9Ff72G9cW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H401mU5CJEzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EckHVeXuJE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Toukt4KNJE58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rdo8wqFTJFA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x4rBoUTMJFDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YrOr4zTNJFHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiMLigXg-ZuE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCYE6A1N6foi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPsKA2XDSRjF2WH26T7M+ad",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
