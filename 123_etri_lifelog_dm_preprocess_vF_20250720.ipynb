{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/The-4th-ETRI-AI-Human-Understanding-Competition/blob/main/etri_baseline_v5_0_4(%EC%A6%9D%EA%B0%95).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTgURBTcpY0Q"
      },
      "source": [
        "> title : 111_etri_lifelog_dm_llm-impute_vF (LLM impute)  <br>\n",
        " -  코드 실행 전 PATH 변경하세요.\n",
        "  - PATH  =  '/content/drive/MyDrive/data/ch2025_data_items/share/submissions/input'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔨 PATH 설정"
      ],
      "metadata": {
        "id": "gv7qtgKD0q35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH  =  '/content/drive/MyDrive/data/ch2025_data_items/share/submissions/input' ### <---- 코드 실행 전 PATH 변경하세요."
      ],
      "metadata": {
        "id": "24XvbBI00Q_A"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터는 구글드라이브에 저장되어 있어서 구글드라이브 마운트를 합니다.\n",
        "# 데이터 저장 PATH를 변경하시면 아래 구글드라이브 마운트를 주석처리하시면 됩니다.\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf8L2VLm0RCr",
        "outputId": "b5e716ad-f58b-43f6-8d1a-6923a7cf82b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2k-8IGKV0NZM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HM-tV1OX0Ncp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVNXLQtLU6X"
      },
      "source": [
        "### 📦 LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTardcDyUPKX"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# CPU times: user 1.19 s, sys: 188 ms, total: 1.37 s\n",
        "# Wall time: 4min 36s\n",
        "\n",
        "try:\n",
        "  from vllm import LLM, SamplingParams\n",
        "except:\n",
        "  !pip install -U langchain-community  >/dev/null\n",
        "  !pip install bitsandbytes >/dev/null\n",
        "  !pip install -U transformers accelerate >/dev/null\n",
        "  !pip install faiss-gpu-cu12 --no-deps >/dev/null\n",
        "  !pip install datasets >/dev/null\n",
        "  !pip install vllm >/dev/null\n",
        "  !pip install --upgrade transformers >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YpKr0iTUXT-"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# CPU times: user 12.7 s, sys: 1.53 s, total: 14.2 s\n",
        "# Wall time: 3min 24s\n",
        "\n",
        "import os\n",
        "os.environ[\"VLLM_WORKER_MULTIPROC_METHOD\"] = \"spawn\"\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from huggingface_hub import login\n",
        "login(token = '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')\n",
        "\n",
        "from vllm import LLM, SamplingParams\n",
        "\n",
        "# 경로\n",
        "drive_path = \"/content/drive/MyDrive/models2\"\n",
        "\n",
        "# 모델명\n",
        "# model_id  = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
        "# model_id  = 'Qwen/Qwen2.5-14B-Instruct-1M'\n",
        "model_id   = 'Qwen/Qwen3-8B'\n",
        "\n",
        "\n",
        "# vllm\n",
        "llm = LLM(\n",
        "    model=f\"{drive_path}/{model_id}\",\n",
        "    tokenizer=f\"{drive_path}/{model_id}\",\n",
        "    tensor_parallel_size=1,\n",
        "    dtype=\"bfloat16\",     # \"bfloat16\"\n",
        "    # quantization=\"fp8\",   # fp8\n",
        "    load_format=\"auto\",\n",
        "    gpu_memory_utilization=0.8,\n",
        "    max_model_len=38960, # 6144,12288,38960,32768,40960\n",
        "    enforce_eager=True,  ## 실행 시점에서 즉시 연산을 수행하는 방식(싱크방식)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VnBvvgmUZ-K"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# model_id = \"/content/drive/MyDrive/models2/Qwen/Qwen3-8B\"\n",
        "\n",
        "# Tokenizer 로드\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2aCgkAtfc1N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jfv9EJqMUafW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvWaOHaPUkrA"
      },
      "source": [
        "### 📦 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN6iwVhQpR_a"
      },
      "outputs": [],
      "source": [
        "# 패키지 설치\n",
        "! pip install haversine >/dev/null\n",
        "! pip install optuna >/dev/null\n",
        "! pip install imbalanced-learn >/dev/null\n",
        "! pip install category_encoders >/dev/null\n",
        "! pip install catboost >/dev/null\n",
        "! pip install h2o >/dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvEVmxWsRH4"
      },
      "outputs": [],
      "source": [
        "# Core Libraries\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import ast\n",
        "import glob\n",
        "import random\n",
        "from functools import reduce\n",
        "from io import StringIO\n",
        "from collections import Counter\n",
        "from datetime import datetime, timedelta, time\n",
        "\n",
        "# Numerical Operations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Math & Geospatial\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from scipy.stats import entropy\n",
        "from haversine import haversine\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, KFold, StratifiedKFold, cross_val_score\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, log_loss, accuracy_score, precision_score, recall_score\n",
        "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Deep Learning (PyTorch)\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Progress Tracking\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm\n",
        "from category_encoders import TargetEncoder\n",
        "from enum import Enum\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# seed 고정\n",
        "SD = 42\n",
        "random.seed(SD)\n",
        "np.random.seed(SD)\n",
        "os.environ['PYTHONHASHSEED'] = str(SD)\n",
        "\n",
        "# pandas 옵션\n",
        "pd.set_option('display.max_columns', 999)\n",
        "pd.set_option('display.max_rows', 999)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '%0.4f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfNPPtgCGTk8"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from six.moves import xrange\n",
        "from catboost import Pool, CatBoostClassifier\n",
        "\n",
        "class FocalLossObjective(object):\n",
        "    def calc_ders_range(self, approxes, targets, weights):\n",
        "        # approxes, targets, weights are indexed containers of floats\n",
        "        # (containers with only __len__ and __getitem__ defined).\n",
        "        # weights parameter can be None.\n",
        "        # Returns list of pairs (der1, der2)\n",
        "        gamma = 2.\n",
        "        # alpha = 1.\n",
        "        assert len(approxes) == len(targets)\n",
        "        if weights is not None:\n",
        "            assert len(weights) == len(approxes)\n",
        "\n",
        "        exponents = []\n",
        "        for index in xrange(len(approxes)):\n",
        "            exponents.append(math.exp(approxes[index]))\n",
        "\n",
        "        result = []\n",
        "        for index in xrange(len(targets)):\n",
        "            p = exponents[index] / (1 + exponents[index])\n",
        "\n",
        "            if targets[index] > 0.0:\n",
        "                der1 = -((1-p)**(gamma-1))*(gamma * math.log(p) * p + p - 1)/p\n",
        "                der2 = gamma*((1-p)**gamma)*((gamma*p-1)*math.log(p)+2*(p-1))\n",
        "            else:\n",
        "                der1 = (p**(gamma-1)) * (gamma * math.log(1 - p) - p)/(1 - p)\n",
        "                der2 = p**(gamma-2)*((p*(2*gamma*(p-1)-p))/(p-1)**2 + (gamma-1)*gamma*math.log(1 - p))\n",
        "\n",
        "            if weights is not None:\n",
        "                der1 *= weights[index]\n",
        "                der2 *= weights[index]\n",
        "\n",
        "            result.append((der1, der2))\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcU4bIojfP2g"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnDtHMLz42G_"
      },
      "outputs": [],
      "source": [
        "def add_noise(series, noise_level, seed=3):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    return series * (1 + noise_level * rng.standard_normal(len(series)))\n",
        "\n",
        "def calculate_averages(data,name):\n",
        "    variables = ['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']\n",
        "    variable_averages = {}\n",
        "    total_sum = 0\n",
        "    total_count = 0\n",
        "\n",
        "    for var in variables:\n",
        "        values = []\n",
        "        for entry in data.values():\n",
        "            if var in entry:  # 키가 존재하는 경우에만 추가\n",
        "                values.append(entry[var])\n",
        "        avg = sum(values) / len(values) if values else None  # 누락된 변수 처리\n",
        "        variable_averages[var] = round(avg, 6) if avg is not None else 'Missing'\n",
        "        total_sum += sum(values)\n",
        "        total_count += len(values)\n",
        "\n",
        "    overall_avg = round(total_sum / total_count, 6) if total_count > 0 else None\n",
        "    print(f'# 전체 평균 {name}: {overall_avg} {variable_averages}')\n",
        "\n",
        "    return variable_averages, overall_avg\n",
        "\n",
        "def calculate_circular_mean_sleep_time(sleep_times):\n",
        "    sleep_times = pd.Series(sleep_times).dropna()\n",
        "    if len(sleep_times) == 0:\n",
        "        return np.nan  # 혹은 return 0.0 등 기본값 설정 가능\n",
        "\n",
        "    def hour_to_radian(hour):\n",
        "        return (hour % 24) / 24 * 2 * np.pi\n",
        "\n",
        "    radians = np.array([hour_to_radian(t) for t in sleep_times])\n",
        "    mean_radian = np.arctan2(np.mean(np.sin(radians)), np.mean(np.cos(radians)))\n",
        "    mean_hour = (mean_radian / (2 * np.pi)) * 24 % 24\n",
        "\n",
        "    return mean_hour\n",
        "\n",
        "def circular_mean_sleep_time(times):\n",
        "\n",
        "    # 결측치 제거\n",
        "    valid_times = [t for t in times if pd.notna(t)]\n",
        "\n",
        "    # 유효 데이터 개수 확인\n",
        "    if len(valid_times) == 0:\n",
        "        return None  # 결측치만 있는 경우\n",
        "\n",
        "    # 시간 → 라디안 변환\n",
        "    radians = [(t % 24) / 24 * 2 * np.pi for t in valid_times]\n",
        "\n",
        "    # 사인/코사인 평균 계산\n",
        "    sin_sum = np.mean(np.sin(radians))\n",
        "    cos_sum = np.mean(np.cos(radians))\n",
        "\n",
        "    # 평균 각도 계산\n",
        "    if sin_sum == 0 and cos_sum == 0:\n",
        "        return np.nan  # 불가능한 경우\n",
        "\n",
        "    mean_radian = np.arctan2(sin_sum, cos_sum)\n",
        "\n",
        "    # 평균 시간으로 변환\n",
        "    mean_hour = (mean_radian / (2 * np.pi)) * 24\n",
        "    if mean_hour < 0:\n",
        "        mean_hour += 24\n",
        "\n",
        "    return f'{int(mean_hour):02d}:{int((mean_hour % 1) * 60):02d}'\n",
        "\n",
        "def calculate_sleep_duration_min(sleep_time, wake_time):\n",
        "    \"\"\"\n",
        "    취침 시각(sleep_time)과 기상 시각(wake_time)을 입력받아 수면 시간(분) 반환\n",
        "    단위는 float 시간 (예: 23.5, 6.25)\n",
        "    \"\"\"\n",
        "    if pd.isna(sleep_time) or pd.isna(wake_time):\n",
        "        return None\n",
        "    if wake_time < sleep_time:\n",
        "        wake_time += 24  # 자정 넘긴 경우 보정\n",
        "    duration = (wake_time - sleep_time) * 60\n",
        "    return round(duration)\n",
        "\n",
        "def fill_missing_dates_by_subject(df, date_col='lifelog_date'):\n",
        "\n",
        "    df = df.copy()\n",
        "    df[date_col] = pd.to_datetime(df[date_col])\n",
        "    result = []\n",
        "\n",
        "    for sid, group in df.groupby('subject_id'):\n",
        "        group = group.sort_values(date_col)\n",
        "\n",
        "        # 연속 날짜 생성\n",
        "        full_dates = pd.date_range(start=group[date_col].min(), end=group[date_col].max())\n",
        "        full_df = pd.DataFrame({date_col: full_dates})\n",
        "        full_df['subject_id'] = sid\n",
        "\n",
        "        # 병합\n",
        "        merged = pd.merge(full_df, group, on=['subject_id', date_col], how='left')\n",
        "\n",
        "        result.append(merged)\n",
        "\n",
        "    # 병합 및 정렬\n",
        "    final_df = pd.concat(result, ignore_index=True).sort_values(['subject_id', date_col])\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0rlS5k7e5jw"
      },
      "outputs": [],
      "source": [
        "def get_time_block(hour):\n",
        "    if 1 <= hour < 5:\n",
        "        return 'sleeptime'\n",
        "    else:\n",
        "        return 'activehour'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gltffbQuggnv"
      },
      "outputs": [],
      "source": [
        "SLEEP_HOURS = tuple(range(0, 5)) ### 수정\n",
        "MIGHT_GO_TO_SLEEP_HOURS = tuple(range(20, 24)) + tuple(range(0, 2))\n",
        "MIGHT_WAKEUP_HOURS = tuple(range(6, 10))\n",
        "ACTIVE_HOURS = tuple(range(7, 24))\n",
        "WORK_HOURS = tuple(range(7, 19))\n",
        "FREE_HOURS = tuple(range(19, 24))\n",
        "\n",
        "HOLIDAY_DATES = [\n",
        "    pd.Timestamp('2024-08-15'),\n",
        "    pd.Timestamp('2024-09-16'),\n",
        "    pd.Timestamp('2024-09-17'),\n",
        "    pd.Timestamp('2024-09-18'),\n",
        "    pd.Timestamp('2024-10-03'),\n",
        "    pd.Timestamp('2024-10-09'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPGtpuhQeWPV"
      },
      "outputs": [],
      "source": [
        "class DataType(Enum):\n",
        "    mACStatus = \"mACStatus\"\n",
        "    mActivity = \"mActivity\"\n",
        "    mAmbience = \"mAmbience\"\n",
        "    mBle = \"mBle\"\n",
        "    mGps = \"mGps\"\n",
        "    mLight = \"mLight\"\n",
        "    mScreenStatus = \"mScreenStatus\"\n",
        "    mUsageStats = \"mUsageStats\"\n",
        "    mWifi = \"mWifi\"\n",
        "    wHr = \"wHr\"\n",
        "    wLight = \"wLight\"\n",
        "    wPedo = \"wPedo\"\n",
        "\n",
        "def load_data(data_type: DataType):\n",
        "    file_path = f\"{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_{data_type.value}.parquet\"\n",
        "    df = pd.read_parquet(file_path)\n",
        "    df[\"subject_id\"] = df[\"subject_id\"].astype(\"category\")\n",
        "    df[\"lifelog_date\"] = df[\"timestamp\"].dt.normalize()\n",
        "    df[\"month\"] = df[\"timestamp\"].dt.month\n",
        "    df[\"day\"] = df[\"timestamp\"].dt.day\n",
        "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "    df[\"minute\"] = df[\"timestamp\"].dt.minute\n",
        "    df[\"weekday\"] = df[\"timestamp\"].dt.weekday\n",
        "    fixed_columns = [\"subject_id\", \"timestamp\", \"lifelog_date\", \"month\", \"day\", \"hour\", \"minute\", \"weekday\"]\n",
        "    columns = df.columns.tolist()\n",
        "    columns = fixed_columns + [col for col in columns if col not in fixed_columns]\n",
        "    df = df[columns]\n",
        "    df = df.sort_values(by=[\"subject_id\", \"timestamp\"])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lf2AzkuceDMI"
      },
      "outputs": [],
      "source": [
        "def describe_df(df):\n",
        "    print(f\"# shape:\\n{df.shape}\\n\")\n",
        "    print(f\"# dtypes:\\n{df.dtypes}\\n\")\n",
        "    # print(f\"# head:\\n{df.head(3)}\\n\")\n",
        "    display(df.head(3))\n",
        "    nan_stats = df.isna().sum().to_frame(name='missing_count')\n",
        "    nan_stats['missing_ratio(%)'] = (df.isna().mean() * 100).round(2)\n",
        "    print(f\"# nan_stats:\\n\" + nan_stats.to_string() + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tlsrq10eDP1"
      },
      "outputs": [],
      "source": [
        "def shift_lifelog_date(df, target_hours):\n",
        "    df = df.copy()\n",
        "    mask = df[\"hour\"].isin(target_hours) & df[\"hour\"].lt(12)\n",
        "    df.loc[mask, \"lifelog_date\"] = df.loc[mask, \"lifelog_date\"] - pd.Timedelta(days=1)\n",
        "    df.loc[mask, \"day\"] = df.loc[mask, \"day\"] - 1\n",
        "    df = df.sort_values(by=[\"subject_id\", \"lifelog_date\", \"timestamp\"])\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBjO4zn95wjJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJUqYMh-5wqH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodxdJFiv_DJ"
      },
      "source": [
        "### 📦 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw0cx3wwpSE2"
      },
      "outputs": [],
      "source": [
        "# 1\n",
        "mACStatus = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mACStatus.parquet')\n",
        "mActivity = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mActivity.parquet')\n",
        "mAmbience = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mAmbience.parquet')\n",
        "mBle = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mBle.parquet')\n",
        "mGps = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mGps.parquet')\n",
        "mLight = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mLight.parquet')\n",
        "mScreenStatus = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mScreenStatus.parquet')\n",
        "mUsageStats = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mUsageStats.parquet')\n",
        "mWifi = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mWifi.parquet')\n",
        "wHr = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_wHr.parquet')\n",
        "wLight = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_wLight.parquet')\n",
        "wPedo = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_wPedo.parquet')\n",
        "\n",
        "# 2\n",
        "train = pd.read_csv(f'{PATH}/ETRI_lifelog_dataset/ch2025_metrics_train.csv')\n",
        "test = pd.read_csv(f'{PATH}/ETRI_lifelog_dataset/ch2025_submission_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jONSq3_oqdid"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHfbbw3bbVgR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKJkE3P_vTv"
      },
      "source": [
        "## 📦 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W53JPEe7Oq9"
      },
      "source": [
        "### ✔️ mACStatus 핸드폰 충전상태\n",
        "- Indicates whether the smartphone is currently being charged.\n",
        "- m_charging : 0/1 상태\n",
        "- 핸드폰이 오랫 동안 충전했다는 의미?\n",
        " - 한 자리에 장시간 머물러 있었다.\n",
        " - 핸드폰을 장시간 사용하지 않았다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbbCp8nmfwCH"
      },
      "outputs": [],
      "source": [
        "def run_length_encoding(arr):\n",
        "    \"\"\"Run-Length Encoding\"\"\"\n",
        "    if len(arr) == 0:\n",
        "        return []\n",
        "\n",
        "    diffs = np.diff(np.concatenate(([0], arr, [0])))\n",
        "    run_starts = np.where(diffs == 1)[0]\n",
        "    run_ends = np.where(diffs == -1)[0]\n",
        "    return run_ends - run_starts\n",
        "\n",
        "def process_mACStatus(df):\n",
        "    status = df[\"m_charging\"].values\n",
        "\n",
        "    def _process_feature(status):\n",
        "        if len(status) == 0:\n",
        "            return 0., 0., 0., 0., 0.\n",
        "\n",
        "        # charging 상태 비율, 합\n",
        "        ratio_charging = status.mean()\n",
        "        sum_charging = status.sum()\n",
        "\n",
        "        # 상태전이 횟수\n",
        "        transitions = (status[1:] != status[:-1]).sum()\n",
        "\n",
        "        lengths = run_length_encoding(status)\n",
        "        avg_charging_duration = np.mean(lengths) if len(lengths) > 0 else 0\n",
        "        max_charging_duration = np.max(lengths) if len(lengths) > 0 else 0\n",
        "\n",
        "        return ratio_charging, sum_charging, transitions, avg_charging_duration, max_charging_duration\n",
        "\n",
        "    # 하루\n",
        "    charging_ratio, charging_sum, chargning_transitions, avg_charging_duration, max_charging_duration = _process_feature(status)\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_status = status[df[\"hour\"].isin(SLEEP_HOURS)]\n",
        "    sleep_charging_ratio, sleep_charging_sum, sleep_charging_transitions, sleep_avg_charging_duration, sleep_max_charging_duration = _process_feature(sleep_status)\n",
        "\n",
        "    return pd.Series({\n",
        "        'charging_ratio': charging_ratio,\n",
        "        'charging_sum': charging_sum,\n",
        "        'charging_transitions': chargning_transitions,\n",
        "        'avg_charging_duration': avg_charging_duration,\n",
        "        'max_charging_duration': max_charging_duration,\n",
        "        'sleep_charging_ratio': sleep_charging_ratio,\n",
        "        'sleep_charging_sum': sleep_charging_sum,\n",
        "        'sleep_charging_transitions': sleep_charging_transitions,\n",
        "        'sleep_avg_charging_duration': sleep_avg_charging_duration,\n",
        "        'sleep_max_charging_duration': sleep_max_charging_duration,\n",
        "    })\n",
        "\n",
        "mACStatus_ori = load_data(DataType.mACStatus)\n",
        "mACStatus_ori = shift_lifelog_date(mACStatus_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "mACStatus2  = (\n",
        "    mACStatus_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mACStatus)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(mACStatus2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uvGhvN07Z4l"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D09tdsYf7Z7R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHrp0dO_--pm"
      },
      "source": [
        "### ✔️ mActivity 추정행동\n",
        "- Value calculated by the Google Activity Recognition API.\n",
        " - 0 : IN_VEHICLE\n",
        " - 1 : ON_BICYCLE\n",
        " - 2 : ON_FOOT\n",
        " - 3 : STILL (not moving)\n",
        " - 4 : UNKNOWN\n",
        " - 5 : TILTING (This often occurs when a device is picked up from a desk or a user who is sitting stands up.)\n",
        " - 7 : WALKING\n",
        " - 8 : RUNNING\n",
        "- 근무시간   : 오전 7시부터 오후 6시까지\n",
        "- 근무외시간 : 오후6시부터 12시까지"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qy8JcbJfwEA"
      },
      "outputs": [],
      "source": [
        "def process_mActivity(df):\n",
        "    activity = df[\"m_activity\"].values.astype(\"int8\")\n",
        "\n",
        "    EXCLUDE_ACTIVITY = [3, 4]\n",
        "    WALKING_ACTIVITY = [1, 2, 7, 8]\n",
        "    VEHICLE_ACTIVITY = [0]\n",
        "\n",
        "    def _process_feature(activity):\n",
        "        if len(activity) == 0:\n",
        "            return 0., 0., 0.\n",
        "\n",
        "        # Walking minutes\n",
        "        walking_minutes = np.isin(activity, WALKING_ACTIVITY).sum()\n",
        "\n",
        "        # Vehicle minutes\n",
        "        vehicle_minutes = np.isin(activity, VEHICLE_ACTIVITY).sum()\n",
        "\n",
        "        # Activity minutes\n",
        "        activity_minutes = (1 - np.isin(activity, EXCLUDE_ACTIVITY)).sum()\n",
        "\n",
        "        return walking_minutes, vehicle_minutes, activity_minutes\n",
        "\n",
        "    # 하루\n",
        "    walking_minutes, vehicle_minutes, activity_minutes = _process_feature(activity)\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_walking_minutes, sleep_vehicle_minutes, sleep_activity_minutes = _process_feature(activity[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    return pd.Series({\n",
        "        'walking_minutes': walking_minutes,\n",
        "        'vehicle_minutes': vehicle_minutes,\n",
        "        'activity_minutes': activity_minutes,\n",
        "        'sleep_walking_minutes': sleep_walking_minutes,\n",
        "        'sleep_vehicle_minutes': sleep_vehicle_minutes,\n",
        "        'sleep_activity_minutes': sleep_activity_minutes,\n",
        "    })\n",
        "\n",
        "mActivity_ori = load_data(DataType.mActivity)\n",
        "mActivity_ori = shift_lifelog_date(mActivity_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "mActivity21 = (\n",
        "    mActivity_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mActivity)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(mActivity21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVoCLn4lb8bZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjtYW0clb8fQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN91Gb-kb4bV"
      },
      "source": [
        "### ✔️ mActivity 추정행동2 (NEW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U23OujeaZXRR"
      },
      "outputs": [],
      "source": [
        "mActivity = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mActivity.parquet')\n",
        "mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOdmdtx9ZXW3"
      },
      "outputs": [],
      "source": [
        "# 활동 데이터 원-핫 인코딩\n",
        "\"\"\"활동 코드(m_activity)를 원-핫 인코딩하여 각 활동 유형별 컬럼 생성\"\"\"\n",
        "\n",
        "mActivity = pd.merge(\n",
        "    mActivity,\n",
        "    pd.get_dummies(mActivity, columns=[\"m_activity\"], prefix=\"m_activity\", dtype=int),\n",
        "    how=\"left\",\n",
        "    on=[\"subject_id\", \"timestamp\",\"lifelog_date\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIowSdSDxq1M"
      },
      "outputs": [],
      "source": [
        "# 데이터 집계 함수 정의\n",
        "def fn_love_aespa(\n",
        "    df_input: pd.DataFrame, # 입력 데이터프레임\n",
        "    str_value_col: str, # 집계할 컬럼명\n",
        "    str_agg_func: str = \"mean\", # 집계 함수 (mean, median, mode, min, max, std, sum)\n",
        "    str_freq: str = \"30min\", # 시간 간격 (30min, 60min, 120min, 240min, 360min 등)\n",
        ") -> pd.DataFrame:\n",
        "    # 데이터프레임 복사 및 timestamp 열을 datetime 형식으로 변환\n",
        "    df_input_copy = df_input.copy()\n",
        "    df_input_copy[\"timestamp\"] = pd.to_datetime(df_input_copy[\"timestamp\"])\n",
        "\n",
        "    # 집계 결과 컬럼명 생성: @컬럼명@시간간격@집계함수\n",
        "    str_agg_col_name = f\"@{str_value_col}@{str_freq}@{str_agg_func}\"\n",
        "\n",
        "    # 집계 함수 설정 (mode는 별도 처리 필요)\n",
        "    dict_aggregation = {}\n",
        "    if str_agg_func == \"mode\":\n",
        "        mode_agg_func = lambda x: (x.mode().iloc[0] if not x.mode().empty else np.nan)\n",
        "        dict_aggregation[str_agg_col_name] = (str_value_col, mode_agg_func)\n",
        "    else:\n",
        "        dict_aggregation[str_agg_col_name] = (str_value_col, str_agg_func)\n",
        "\n",
        "    # 그룹별 데이터 집계 수행\n",
        "    df_agg = (\n",
        "        df_input_copy.groupby([\"subject_id\", pd.Grouper(key=\"timestamp\", freq=str_freq)]).agg(**dict_aggregation).reset_index()\n",
        "    )\n",
        "\n",
        "    # 날짜 및 시간 정보 추출\n",
        "    df_agg[\"lifelog_date\"] = df_agg[\"timestamp\"].dt.date.astype(str)\n",
        "    df_agg[\"hh24mi\"] = df_agg[\"timestamp\"].dt.strftime(\"%Hh%Mm\")\n",
        "\n",
        "    # 피벗 테이블로 데이터 재구성 (subject_id, lifelog_date 기준으로 시간대별 값 배치)\n",
        "    df_pivot = df_agg.pivot_table(\n",
        "        index=[\"subject_id\", \"lifelog_date\"],\n",
        "        columns=\"hh24mi\",\n",
        "        values=str_agg_col_name,\n",
        "    )\n",
        "\n",
        "    # 컬럼 이름 재구성 및 인덱스 초기화\n",
        "    list_hh23mi_col = list(df_pivot.columns)\n",
        "    df_pivot = df_pivot.reindex(columns=list_hh23mi_col).reset_index()\n",
        "    list_hour_col = {hh24mi: f\"{str_value_col}@{str_freq}@{str_agg_func}@{hh24mi}\" for hh24mi in list_hh23mi_col}\n",
        "    df_pivot = df_pivot.rename(columns=list_hour_col)\n",
        "\n",
        "    return df_pivot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGkwDwF0Xxmf"
      },
      "outputs": [],
      "source": [
        "# MET 값 매핑\n",
        "\"\"\"\n",
        "각 활동 코드에 해당하는 MET(Metabolic Equivalent of Task) 값 할당\n",
        "MET는 신체 활동의 에너지 소비량을 측정하는 단위\n",
        "\n",
        "활동 코드별 MET 값:\n",
        "    0: 1.3 MET (가벼운 좌식 활동)\n",
        "    1: 8.0 MET (격렬한 활동)\n",
        "    3: 1.2 MET (매우 가벼운 활동)\n",
        "    4: 3.0 MET (중간 강도 활동)\n",
        "    7: 3.5 MET (중간 강도 활동)\n",
        "    8: 10.0 MET (매우 격렬한 활동)\n",
        "\"\"\"\n",
        "\n",
        "dict_met_value = {0: 1.3, 1: 8.0, 3: 1.2, 4: 3.0, 7: 3.5, 8: 10.0}\n",
        "for activity, met in dict_met_value.items():\n",
        "    mActivity.loc[mActivity[\"m_activity\"].isin([activity]), \"m_activity_met\"] = met\n",
        "\n",
        "mActivity.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpQgcJ5WXXF_"
      },
      "outputs": [],
      "source": [
        "# 활동 데이터 집계\n",
        "df_agg_activity_std = fn_love_aespa(df_input=mActivity,\n",
        "                                    str_value_col=\"m_activity\",\n",
        "                                    # \"mean\", \"median\", \"mode\", \"min\", \"max\", \"std\"\n",
        "                                    str_agg_func=\"std\",\n",
        "                                    # \"30min\", \"60min\", \"120min\", \"240min\", \"360min\", \"480min\", \"720min\", \"1440min\"\n",
        "                                    str_freq=\"240min\",\n",
        "                                    )\n",
        "\n",
        "df_agg_activity_met_std = fn_love_aespa(df_input=mActivity,\n",
        "                                    str_value_col=\"m_activity_met\",\n",
        "                                    # \"mean\", \"median\", \"mode\", \"sum\", \"min\", \"max\", \"std\"\n",
        "                                    str_agg_func=\"std\",\n",
        "                                    # \"30min\", \"60min\", \"120min\", \"240min\", \"360min\", \"480min\", \"720min\", \"1440min\"\n",
        "                                    str_freq=\"240min\",\n",
        "                                    )\n",
        "\n",
        "df_agg_activity_met_sum = fn_love_aespa(df_input=mActivity,\n",
        "                                    str_value_col=\"m_activity_met\",\n",
        "                                    # \"mean\", \"median\", \"mode\", \"sum\", \"min\", \"max\", \"std\"\n",
        "                                    str_agg_func=\"sum\",\n",
        "                                    # \"30min\", \"60min\", \"120min\", \"240min\", \"360min\", \"480min\", \"720min\", \"1440min\"\n",
        "                                    str_freq=\"240min\",\n",
        "                                    )\n",
        "\n",
        "df_agg_activity_0_std = fn_love_aespa(df_input=mActivity,\n",
        "                                    str_value_col=\"m_activity_0\",\n",
        "                                    # \"mean\", \"median\", \"mode\", \"sum\", \"min\", \"max\", \"std\"\n",
        "                                    str_agg_func=\"std\",\n",
        "                                    # \"30min\", \"60min\", \"120min\", \"240min\", \"360min\", \"480min\", \"720min\", \"1440min\"\n",
        "                                    str_freq=\"240min\",\n",
        "                                    )\n",
        "\n",
        "df_agg_activity_0_sum = fn_love_aespa(df_input=mActivity,\n",
        "                                    str_value_col=\"m_activity_0\",\n",
        "                                    # \"mean\", \"median\", \"mode\", \"sum\", \"min\", \"max\", \"std\"\n",
        "                                    str_agg_func=\"sum\",\n",
        "                                    # \"30min\", \"60min\", \"120min\", \"240min\", \"360min\", \"480min\", \"720min\", \"1440min\"\n",
        "                                    str_freq=\"240min\",\n",
        "                                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KR_SFDDUZsZc"
      },
      "outputs": [],
      "source": [
        "# 병합 기준 key\n",
        "merge_keys = ['subject_id', 'lifelog_date']\n",
        "\n",
        "# 세 개 데이터프레임 순차 병합\n",
        "mActivity22 = (\n",
        "    df_agg_activity_std\n",
        "    .merge(df_agg_activity_met_std, on=merge_keys, how='outer')\n",
        "    .merge(df_agg_activity_met_sum, on=merge_keys, how='outer')\n",
        "    .merge(df_agg_activity_0_std, on=merge_keys, how='outer')\n",
        "    .merge(df_agg_activity_0_sum, on=merge_keys, how='outer')\n",
        ")\n",
        "\n",
        "# check\n",
        "print(mActivity22.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5FJK5PXXXOr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMLE3NPHW5uV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEu5F-6-hmgI"
      },
      "source": [
        "### ✔️ mAmbience 주변소리 (수정)\n",
        "- Ambient sound identification labels and their respective probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snxx7CH6gtif"
      },
      "outputs": [],
      "source": [
        "def process_mAmbience(df):\n",
        "    ambience = df[\"m_ambience\"].values  # [[label, prob], ...], [[label, prob], ...]\n",
        "\n",
        "    def _process_feature(ambience):\n",
        "        labels = set()\n",
        "\n",
        "        for amb in ambience:\n",
        "            labels_, _ = zip(*amb)\n",
        "            labels.update(labels_)\n",
        "\n",
        "        unique_label_count = len(labels)\n",
        "        snor_count = len(list(filter(lambda x: \"snor\" in x.lower(), labels)))\n",
        "\n",
        "        return unique_label_count, snor_count\n",
        "\n",
        "    # 활동시간\n",
        "    active_hour_unique_label_count, active_hour_snor_count = _process_feature(ambience[df[\"hour\"].isin(ACTIVE_HOURS)])\n",
        "\n",
        "    # 잠자는시간\n",
        "    sleep_hour_unique_label_count, sleep_hour_snor_count = _process_feature(ambience[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    return pd.Series({\n",
        "        'active_hour_unique_label_count': active_hour_unique_label_count,\n",
        "        'active_hour_snor_count': active_hour_snor_count,\n",
        "        'sleep_hour_unique_label_count': sleep_hour_unique_label_count,\n",
        "        'sleep_hour_snor_count': sleep_hour_snor_count,\n",
        "    })\n",
        "\n",
        "mAmbience_ori = load_data(DataType.mAmbience)\n",
        "mAmbience_ori = shift_lifelog_date(mAmbience_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "mAmbience2 = (\n",
        "    mAmbience_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mAmbience)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(mAmbience2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCxHeB836ekw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QnUfNL-ceIA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfbNZ1WsceMN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yh2wt8LycePt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyS90xE7WAJV"
      },
      "source": [
        "### ✔️ mBle 블루투스 (수정)\n",
        "- Bluetooth devices around individual subject.\n",
        " - 7936 : Wearable, Headset, AV Device\n",
        " - 1796 : Peripheral (입력장치) 계열\n",
        " - 0 : 정보 없음 또는 알 수 없음(Unknown)\n",
        " - 1084 : Audio/Video (스피커, 헤드셋, 이어폰, TV 등)\n",
        " - 524 : Phone (휴대폰, 스마트폰)\n",
        " - 1060 : Headphones\n",
        " - 284 : commputer (PC, 노트북, PDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKFv8buPkLEG"
      },
      "outputs": [],
      "source": [
        "def process_mBle(df):\n",
        "    ble = df[\"m_ble\"].values  # [[{\"address\": \"xx:xx:xx:xx:xx:xx\", \"device_class\": \"0\", \"rssi\": -70}, ...], [...], ...]\n",
        "\n",
        "    def _process_feature(ble):\n",
        "        if len(ble) == 0:\n",
        "            return 0., 0., 0., 0., 0.\n",
        "\n",
        "        rssi = []\n",
        "        devices = []\n",
        "        for ble_data in ble:\n",
        "            for device in ble_data:\n",
        "                rssi.append(device[\"rssi\"])\n",
        "                devices.append(device[\"device_class\"])\n",
        "\n",
        "        rssi = np.array(rssi)\n",
        "        rssi_mean = rssi.mean() if len(rssi) > 0 else 0\n",
        "        rssi_min = rssi.min() if len(rssi) > 0 else 0\n",
        "        rssi_max = rssi.max() if len(rssi) > 0 else 0\n",
        "\n",
        "        unknown_count = devices.count(\"0\")\n",
        "        others_count = len(devices) - unknown_count\n",
        "        others_ratio = others_count / len(devices) if len(devices) > 0 else 0\n",
        "        unknown_ratio = unknown_count / len(devices) if len(devices) > 0 else 0\n",
        "\n",
        "        return rssi_mean, rssi_min, rssi_max, others_ratio, unknown_ratio\n",
        "\n",
        "    # 일할때\n",
        "    work_hour_rssi_mean, work_hour_rssi_min, work_hour_rssi_max, work_hour_others_ratio, work_hour_unknown_ratio = _process_feature(ble[df[\"hour\"].isin(WORK_HOURS)])\n",
        "\n",
        "    # 퇴근후\n",
        "    free_hour_rssi_mean, free_hour_rssi_min, free_hour_rssi_max, free_hour_others_ratio, free_hour_unknown_ratio = _process_feature(ble[df[\"hour\"].isin(FREE_HOURS)])\n",
        "\n",
        "    # 잠자는시간\n",
        "    sleep_hour_rssi_mean, sleep_hour_rssi_min, sleep_hour_rssi_max, sleep_hour_others_ratio, sleep_hour_unknown_ratio = _process_feature(ble[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    return pd.Series({\n",
        "        'work_hour_rssi_mean': work_hour_rssi_mean,\n",
        "        'work_hour_rssi_min': work_hour_rssi_min,\n",
        "        'work_hour_rssi_max': work_hour_rssi_max,\n",
        "        'work_hour_others_ratio': work_hour_others_ratio,\n",
        "        'work_hour_unknown_ratio': work_hour_unknown_ratio,\n",
        "        'free_hour_rssi_mean': free_hour_rssi_mean,\n",
        "        'free_hour_rssi_min': free_hour_rssi_min,\n",
        "        'free_hour_rssi_max': free_hour_rssi_max,\n",
        "        'free_hour_others_ratio': free_hour_others_ratio,\n",
        "        'free_hour_unknown_ratio': free_hour_unknown_ratio,\n",
        "        'sleep_hour_rssi_mean': sleep_hour_rssi_mean,\n",
        "        'sleep_hour_rssi_min': sleep_hour_rssi_min,\n",
        "        'sleep_hour_rssi_max': sleep_hour_rssi_max,\n",
        "        'sleep_hour_others_ratio': sleep_hour_others_ratio,\n",
        "        'sleep_hour_unknown_ratio': sleep_hour_unknown_ratio\n",
        "    })\n",
        "\n",
        "mBle_ori = load_data(DataType.mBle)\n",
        "mBle_ori = shift_lifelog_date(mBle_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "mBle2 = (\n",
        "    mBle_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mBle)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(mBle2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak08iDZ1kLHh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WQEISbYkLRW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiCtsengLveO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5vsYKHoH8lz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOiajFjeRFi-"
      },
      "source": [
        "### ✔️ mGps, GPS 기반 핸드폰 위치\n",
        "- Multiple GPS coordinates measured within a single minute using the smartphone.\n",
        "- speed가 1보다 큰경우 정지 상태가 아니고 움직이고 있다고 판단\n",
        " - 0.5-2 : 걸어서 이동하는 경우  \n",
        " - 2-5 : 조깅\n",
        " - 5 이상 : 차를 타고 이동하는 경우"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hV_VT5fZH8rj"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def haversine_np(lon1, lat1, lon2, lat2, radius=6371):\n",
        "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "\n",
        "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "\n",
        "    return radius * c\n",
        "\n",
        "def process_mGps(df):\n",
        "    gps = df[\"m_gps\"].values  # [[{'altitude': 110.6, 'latitude': 0.2077385, 'longitude': 0.170027, 'speed': 0.0}, ...], ...]\n",
        "    timestamps = df[\"timestamp\"].values\n",
        "\n",
        "    def _process_feature(gps, timestamps):\n",
        "        if len(gps) == 0:\n",
        "            return 0., 0., 0., 0., 0., 0., 0., np.array([])\n",
        "\n",
        "        # n-분 단위\n",
        "        latitudes = []\n",
        "        longitudes = []\n",
        "        altitudes = []\n",
        "        speeds = []\n",
        "        minutes = []  # 누적 분\n",
        "\n",
        "        for i, (gps_data, timestamp) in enumerate(zip(gps, timestamps)):\n",
        "            _latitudes = []\n",
        "            _longitudes = []\n",
        "            _altitudes = []\n",
        "            _speeds = []\n",
        "            for data in gps_data:\n",
        "                _latitudes.append(data[\"latitude\"])\n",
        "                _longitudes.append(data[\"longitude\"])\n",
        "                _altitudes.append(data[\"altitude\"])\n",
        "                _speeds.append(data[\"speed\"])\n",
        "\n",
        "            latitudes.append(np.mean(_latitudes))\n",
        "            longitudes.append(np.mean(_longitudes))\n",
        "            altitudes.append(np.mean(_altitudes))\n",
        "            speeds.append(np.mean(_speeds))\n",
        "            minutes.append(1 if i == 0 else pd.Timedelta(timestamps[i] - timestamps[i-1]).total_seconds() / 60)\n",
        "\n",
        "        latitudes = np.array(latitudes)\n",
        "        longitudes = np.array(longitudes)\n",
        "        altitudes = np.array(altitudes)\n",
        "        speeds = np.array(speeds)\n",
        "        minutes = np.array(minutes)\n",
        "\n",
        "        walk_minutes = minutes[(speeds >= 0.5) & (speeds < 2.0)].sum()\n",
        "        jog_minutes = minutes[(2.0 <= speeds) & (speeds < 5.0)].sum()\n",
        "        vehicle_minutes = minutes[(5.0 <= speeds)].sum()\n",
        "\n",
        "        # 속도\n",
        "        mean_speed = speeds.mean() if len(speeds) > 0 else 0\n",
        "        max_speed = speeds.max() if len(speeds) > 0 else 0\n",
        "        min_speed = speeds.min() if len(speeds) > 0 else 0\n",
        "\n",
        "        # 이동거리\n",
        "        distance = haversine_np(longitudes[:-1], latitudes[:-1], longitudes[1:], latitudes[1:]).sum()\n",
        "\n",
        "        return walk_minutes, jog_minutes, vehicle_minutes, mean_speed, max_speed, min_speed, distance, speeds\n",
        "\n",
        "    # 하루\n",
        "    active_hour_walk_minutes, active_hour_jog_minutes, active_hour_vehicle_minutes, active_hour_mean_speed, active_hour_max_speed, active_hour_min_speed, active_hour_distance, _ = _process_feature(gps[df[\"hour\"].isin(ACTIVE_HOURS)], timestamps[df[\"hour\"].isin(ACTIVE_HOURS)])\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_hour_walk_minutes, sleep_hour_jog_minutes, sleep_hour_vehicle_minutes, sleep_hour_mean_speed, sleep_hour_max_speed, sleep_hour_min_speed, sleep_hour_distance, _ = _process_feature(gps[df[\"hour\"].isin(SLEEP_HOURS)], timestamps[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    # 일어날 때\n",
        "    _, _, _, _, _, _, _, might_wakeup_speeds = _process_feature(gps[df[\"hour\"].isin(MIGHT_WAKEUP_HOURS)], timestamps[df[\"hour\"].isin(MIGHT_WAKEUP_HOURS)])\n",
        "    might_wakeup_timestamps = timestamps[df[\"hour\"].isin(MIGHT_WAKEUP_HOURS)]\n",
        "    wakeup_timestamps = might_wakeup_timestamps[(might_wakeup_speeds > 1.0)]\n",
        "    first_move_datetime = (\n",
        "        pd.to_datetime(wakeup_timestamps[0]) if len(wakeup_timestamps) > 0\n",
        "        else pd.to_datetime(might_wakeup_timestamps[-1]) if len(might_wakeup_timestamps) > 0\n",
        "        else pd.to_datetime(datetime(2024, 1, 1, MIGHT_WAKEUP_HOURS[-1], 0, 0))  # default to the last hour of the range\n",
        "    )\n",
        "    first_wakeup_minutes = (first_move_datetime.hour if first_move_datetime.hour > 12 else first_move_datetime.hour + 24) * 60 + first_move_datetime.minute\n",
        "\n",
        "    return pd.Series({\n",
        "        'active_hour_walk_minutes': active_hour_walk_minutes,\n",
        "        'active_hour_jog_minutes': active_hour_jog_minutes,\n",
        "        'active_hour_vehicle_minutes': active_hour_vehicle_minutes,\n",
        "        'active_hour_mean_speed': active_hour_mean_speed,\n",
        "        'active_hour_max_speed': active_hour_max_speed,\n",
        "        'active_hour_min_speed': active_hour_min_speed,\n",
        "        'active_hour_distance': active_hour_distance,\n",
        "        'exercise_flag': 1 if active_hour_jog_minutes > 10 else 0,  # n분 이상 조깅한 경우\n",
        "        'sleep_hour_walk_minutes': sleep_hour_walk_minutes,\n",
        "        'sleep_hour_jog_minutes': sleep_hour_jog_minutes,\n",
        "        'sleep_hour_vehicle_minutes': sleep_hour_vehicle_minutes,\n",
        "        'sleep_hour_mean_speed': sleep_hour_mean_speed,\n",
        "        'sleep_hour_max_speed': sleep_hour_max_speed,\n",
        "        'sleep_hour_min_speed': sleep_hour_min_speed,\n",
        "        'sleep_hour_distance': sleep_hour_distance,\n",
        "        \"mgps_first_wakeup_minutes\": first_wakeup_minutes,\n",
        "    })\n",
        "\n",
        "\n",
        "mGps_ori = load_data(DataType.mGps)\n",
        "mGps_ori = shift_lifelog_date(mGps_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "mGps2 = (\n",
        "    mGps_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mGps)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(mGps2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riN0msO6wodn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTvpgUsLwvNU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oHiJLPfaoSw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0k3YkQqaodZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSRRKaDlaorj"
      },
      "source": [
        "### ✔️ mLight 주변 밝기\n",
        "- Ambient light measured by the smartphone.\n",
        " - 어두운 밤\t0.1 ~ 1 lux\t캄캄한 방, 달빛 없는 밤\n",
        " - 가로등 켜진 거리\t10 ~ 20 lux\t흐릿한 외부 조명\n",
        " - 실내 조명\t100 ~ 500 lux\t사무실, 일반 거실\n",
        " - 밝은 실외\t10,000 ~ 25,000 lux\t맑은 날 햇빛\n",
        " - 직사광선 아래\t30,000 ~ 100,000 lux\t여름 한낮, 매우 강한 햇빛"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0PzJaYUWfVZ"
      },
      "outputs": [],
      "source": [
        "mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\n",
        "# mLight = fill_missing_dates_by_subject(mLight)\n",
        "mLight.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIGfYpnFufpT"
      },
      "outputs": [],
      "source": [
        "def process_mLight(df):\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['lifelog_date'] = df['timestamp'].dt.date\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['is_night'] = df['hour'].apply(lambda h: h >= 22 or h < 6)\n",
        "\n",
        "    # 하루 요약 통계\n",
        "    daily_light = df.groupby(['subject_id', 'lifelog_date']).agg(\n",
        "        light_mean=('m_light', 'mean'),\n",
        "        light_std=('m_light', 'std'),\n",
        "        light_max=('m_light', 'max'),\n",
        "        light_min=('m_light', 'min'),\n",
        "        light_night_mean=('m_light', lambda x: x[df.loc[x.index, 'is_night']].mean()),\n",
        "        light_day_mean=('m_light', lambda x: x[~df.loc[x.index, 'is_night']].mean()),\n",
        "        light_night_ratio=('is_night', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for subject_id, group in tqdm(df.groupby('subject_id'), desc=\"Processing light-based sleep detection\"):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        recorded_dates = set()\n",
        "        sleeping = False\n",
        "        zero_count = 0\n",
        "        first_zero_time = None\n",
        "\n",
        "        for i in range(len(group)):\n",
        "            light = group.loc[i, 'm_light']\n",
        "            hour = group.loc[i, 'hour']\n",
        "\n",
        "            if light == 0:\n",
        "                zero_count += 1\n",
        "                if zero_count == 1:\n",
        "                    first_zero_time = group.loc[i, 'timestamp']\n",
        "                if zero_count >= 6 and not sleeping:\n",
        "                    sleep_hour = first_zero_time.hour\n",
        "                    if (sleep_hour >= 21 or sleep_hour <= 2):\n",
        "                        sleeping = True\n",
        "            else:\n",
        "                if sleeping:\n",
        "                    candidate_wakeup = group.loc[i, 'timestamp']\n",
        "                    wake_hour = candidate_wakeup.hour\n",
        "\n",
        "                    if 5 <= wake_hour <= 9 and first_zero_time is not None:\n",
        "                        wake_time = candidate_wakeup\n",
        "                        sleep_time = first_zero_time\n",
        "                        duration_min = (wake_time - sleep_time).total_seconds() / 60\n",
        "\n",
        "                        if 0 < duration_min <= 840:\n",
        "                            sleep_duration = duration_min\n",
        "                        else:\n",
        "                            sleep_duration = np.nan\n",
        "\n",
        "                        lifelog_date = wake_time.date() + pd.Timedelta(days=-1)\n",
        "\n",
        "                        if lifelog_date not in recorded_dates:\n",
        "                            results.append({\n",
        "                                'subject_id': subject_id,\n",
        "                                'lifelog_date': lifelog_date,\n",
        "                                'sleep_duration_min_mLight': sleep_duration,\n",
        "                                'sleep_time_min_mLight': sleep_time.hour * 60 + sleep_time.minute,\n",
        "                                'wake_time_min_mLight': wake_time.hour * 60 + wake_time.minute,\n",
        "                                'hour_slept_mLight': sleep_time.hour + sleep_time.minute / 60,\n",
        "                                'hour_woke_up_mLight': wake_time.hour + wake_time.minute / 60\n",
        "                            })\n",
        "                            recorded_dates.add(lifelog_date)\n",
        "\n",
        "                        sleeping = False\n",
        "                        zero_count = 0\n",
        "                        first_zero_time = None\n",
        "\n",
        "            if light > 0:\n",
        "                zero_count = 0\n",
        "                first_zero_time = None\n",
        "\n",
        "    sleep_df = pd.DataFrame(results)\n",
        "\n",
        "    # 정렬 + 보간\n",
        "    sleep_df = sleep_df.sort_values(['subject_id', 'lifelog_date'])\n",
        "    sleep_df['sleep_duration_interp_mLight'] = sleep_df.groupby('subject_id')['sleep_duration_min_mLight'].transform(lambda x: x.interpolate())\n",
        "\n",
        "    # 시간 단위 파생 컬럼\n",
        "    sleep_df['sleep_duration_hour_mLight'] = sleep_df['sleep_duration_min_mLight'] / 60\n",
        "    sleep_df['sleep_duration_interp_hour_mLight'] = sleep_df['sleep_duration_interp_mLight'] / 60\n",
        "\n",
        "    # 병합\n",
        "    final = pd.merge(daily_light, sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n",
        "\n",
        "    return final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gYPb8vQP5Ls"
      },
      "outputs": [],
      "source": [
        "def process_mLight2(df):\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    # m_light > 0 → m_screen_use로 변환\n",
        "    df['m_light_on'] = (df['m_light'] > 0).astype(int)\n",
        "\n",
        "    # base key 확보\n",
        "    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n",
        "    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n",
        "\n",
        "    # 밤 9시 ~ 다음날 오전 11시 필터링\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n",
        "    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n",
        "\n",
        "    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        # 1. 중간 각성 제거\n",
        "        prev = group['m_light_on'].shift(1)\n",
        "        next_ = group['m_light_on'].shift(-1)\n",
        "        mask = (group['m_light_on'] == 1) & (prev == 0) & (next_ == 0)\n",
        "        group.loc[mask, 'm_light_on'] = 0\n",
        "\n",
        "        # 2. 짧은 각성 블록 제거\n",
        "        group['is_sleep'] = group['m_light_on'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "        block_info = group.groupby('block').agg(\n",
        "            is_sleep=('is_sleep', 'first'),\n",
        "            size=('is_sleep', 'size')\n",
        "        )\n",
        "\n",
        "        for i in range(1, len(block_info) - 1):\n",
        "            if (\n",
        "                block_info.iloc[i]['is_sleep'] == False and\n",
        "                block_info.iloc[i]['size'] <= 2 and\n",
        "                block_info.iloc[i - 1]['is_sleep'] and\n",
        "                block_info.iloc[i + 1]['is_sleep']\n",
        "            ):\n",
        "                group.loc[group['block'] == block_info.index[i], 'm_light_on'] = 0\n",
        "\n",
        "        # 3. 수면 블록 추정\n",
        "        group['is_sleep'] = group['m_light_on'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n",
        "            sleep_start=('timestamp', 'first'),\n",
        "            sleep_end=('timestamp', 'last'),\n",
        "            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n",
        "        )\n",
        "\n",
        "        sleep_time = wake_time = duration_min = None\n",
        "        if not sleep_blocks.empty:\n",
        "            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n",
        "            sleep_time = longest_sleep['sleep_start'].time()\n",
        "            wake_time = longest_sleep['sleep_end'].time()\n",
        "            duration_min = longest_sleep['duration_min']\n",
        "\n",
        "            # 유효성 조건\n",
        "            if not (4 <= wake_time.hour < 11):\n",
        "                wake_time = None\n",
        "            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n",
        "                sleep_time = None\n",
        "            if duration_min < 100:\n",
        "                sleep_time = None\n",
        "                wake_time = None\n",
        "                duration_min = None\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': subject_id,\n",
        "            'lifelog_date': lifelog_date.date(),\n",
        "            'sleep_time': sleep_time,\n",
        "            'wake_time': wake_time,\n",
        "            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n",
        "        })\n",
        "\n",
        "    sleep_df = pd.DataFrame(results)\n",
        "    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n",
        "\n",
        "    # 시간 → 실수형 숫자 변환\n",
        "    def time_to_float(t):\n",
        "        if pd.isna(t):\n",
        "            return None\n",
        "        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n",
        "\n",
        "    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n",
        "    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n",
        "\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxL0TrRUTrhz"
      },
      "outputs": [],
      "source": [
        "def add_ratios(df):\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "    df['weekday'] = df['lifelog_date'].dt.weekday\n",
        "    df['week_type'] = df['weekday'].apply(lambda x: 'weekend' if x >= 5 else 'weekday')\n",
        "    df['month'] = df['lifelog_date'].dt.month\n",
        "\n",
        "    # 평균 계산\n",
        "    avg_duration = df.groupby(['subject_id', 'month', 'week_type'])['sleep_duration_min'].mean().reset_index(name='avg_sleep_duration')\n",
        "    sleep_time_avg = df.groupby(['subject_id', 'month', 'week_type'])['sleep_time'].apply(calculate_circular_mean_sleep_time).reset_index(name='avg_sleep_time')\n",
        "    wake_time_avg = df.groupby(['subject_id', 'month', 'week_type'])['wake_time'].apply(calculate_circular_mean_sleep_time).reset_index(name='avg_wake_time')\n",
        "    avg_df = sleep_time_avg.merge(wake_time_avg, on=['subject_id', 'month', 'week_type']).merge(avg_duration, on=['subject_id', 'month', 'week_type'])\n",
        "    df = df.merge(avg_df, on=['subject_id', 'month', 'week_type'], how='left')\n",
        "\n",
        "    # 비율 및 차이\n",
        "    df['sleep_time_diff'] = df['avg_sleep_time'] - df['sleep_time']\n",
        "    df['wake_time_diff'] = df['avg_wake_time'] - df['wake_time']\n",
        "    df['sleep_duration_diff'] = df['avg_sleep_duration'] - df['sleep_duration_min']\n",
        "    df['sleep_time_ratio'] = df['sleep_time'] / df['avg_sleep_time']\n",
        "    df['wake_time_ratio'] = df['wake_time'] / df['avg_wake_time']\n",
        "    df['sleep_duration_ratio'] = df['sleep_duration_min'] / df['avg_sleep_duration']\n",
        "\n",
        "    # 정렬 후 lag/변화량\n",
        "    df = df.sort_values(['subject_id', 'lifelog_date'])\n",
        "    for lag in [1, 2]:\n",
        "        df[f'sleep_time_lag{lag}'] = df.groupby('subject_id')['sleep_time'].shift(lag)\n",
        "        df[f'wake_time_lag{lag}'] = df.groupby('subject_id')['wake_time'].shift(lag)\n",
        "        df[f'sleep_duration_lag{lag}'] = df.groupby('subject_id')['sleep_duration_min'].shift(lag)\n",
        "        df[f'sleep_time_diff_lag{lag}'] = df.groupby('subject_id')['sleep_time'].diff(lag)\n",
        "        df[f'wake_time_diff_lag{lag}'] = df.groupby('subject_id')['wake_time'].diff(lag)\n",
        "        df[f'sleep_duration_diff_lag{lag}'] = df.groupby('subject_id')['sleep_duration_min'].diff(lag)\n",
        "    df['week_type_lag1'] = df.groupby('subject_id')['week_type'].shift(1)\n",
        "\n",
        "    # 이동 평균 (2,3)\n",
        "    for window in [2, 3]:\n",
        "        df[f'rolling_sleep_time_{window}d'] = df.groupby('subject_id')['sleep_time'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'rolling_wake_time_{window}d'] = df.groupby('subject_id')['wake_time'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'rolling_sleep_duration_{window}d'] = df.groupby('subject_id')['sleep_duration_min'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "    # 요일별 평균 수면 비교\n",
        "    weekday_avg = df.groupby(['subject_id', 'weekday'])['sleep_duration_min'].mean().reset_index(name='weekday_avg_sleep')\n",
        "    df = df.merge(weekday_avg, on=['subject_id', 'weekday'], how='left')\n",
        "    df['sleep_duration_vs_weekday_avg'] = df['sleep_duration_min'] - df['weekday_avg_sleep']\n",
        "\n",
        "    # 급격한 수면시간 변화 여부 (60분 이상 변화)\n",
        "    df['is_sleep_duration_change_large'] = (df['sleep_duration_diff_lag1'].abs() > 60).astype(int)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ7DnRKMQPax"
      },
      "outputs": [],
      "source": [
        "mLight21 = process_mLight(mLight)\n",
        "\n",
        "# check\n",
        "print(f'\\n # mLight21 shape: {mLight21.shape}')\n",
        "mLight21.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11K9FshnP5bF"
      },
      "outputs": [],
      "source": [
        "mLight22 = process_mLight2(mLight)\n",
        "mLight22['sleep_time'] = np.where(mLight22['sleep_time']<10,mLight22['sleep_time']+24,mLight22['sleep_time'])\n",
        "mLight22['sleep_duration_min'] = mLight22.apply(lambda x: calculate_sleep_duration_min(x['sleep_time'],x['wake_time']),axis=1)\n",
        "mLight22 = add_ratios(mLight22)\n",
        "mLight22 = mLight22.drop(columns=['week_type','wake_time_lag1'])\n",
        "mLight22.columns = ['subject_id', 'lifelog_date']+['light_'+i for i in mLight22.columns if i not in ['subject_id', 'lifelog_date']]\n",
        "mLight22['lifelog_date'] = mLight22['lifelog_date'].astype(str)\n",
        "\n",
        "# check\n",
        "# mLight22 shape: (700, 55)\n",
        "print(f'\\n # mLight22 shape: {mLight22.shape}')\n",
        "mLight22.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6Cb1b3RXHEY"
      },
      "outputs": [],
      "source": [
        "def estimate_lights_off_time(df, light_threshold=2):\n",
        "\n",
        "    # 시간 → 실수형 (예: 23:30 → 23.5)\n",
        "    def time_to_float(t):\n",
        "        if pd.isna(t):\n",
        "            return None\n",
        "        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n",
        "\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    # 밤 시간대 필터 (21시~23시 or 0~3시)\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df = df[(df['hour'] >= 21) | (df['hour'] <= 3)].copy()\n",
        "\n",
        "    # 자정 이후는 전날 night로 처리\n",
        "    df.loc[df['hour'] <= 3, 'lifelog_date'] -= pd.Timedelta(days=1)\n",
        "\n",
        "    # 낮은 조도 조건\n",
        "    df = df[df['m_light'] <= light_threshold]\n",
        "\n",
        "    # 각 (subject_id, lifelog_date)별 불 끈 시각 추출\n",
        "    lights_off_df = (\n",
        "        df.groupby(['subject_id', 'lifelog_date'])['timestamp']\n",
        "        .min()\n",
        "        .reset_index(name='lights_off_time')\n",
        "    )\n",
        "\n",
        "    # 실수형 시각으로 변환\n",
        "    lights_off_df['lights_off_time'] = lights_off_df['lights_off_time'].dt.time.apply(time_to_float)\n",
        "\n",
        "    return lights_off_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npFr7zVBXHHt"
      },
      "outputs": [],
      "source": [
        "mLight23 = estimate_lights_off_time(mLight)\n",
        "mLight23['lights_off_time'] = np.where(mLight23['lights_off_time']<10,mLight23['lights_off_time']+24,mLight23['lights_off_time'])\n",
        "mLight23.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5ZTeeq0XHLk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSosIjMtXHTs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgoIsV5bgXSA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHIH4SYXbHUK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUlU9AKma3Tg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHYijr_sa3sz"
      },
      "source": [
        "### 📌 mScreenStatus 화면 사용여부 (LLM impute)\n",
        "\n",
        "- Indicates whether the smartphone screen is in use.\n",
        " - 기상시간, 취침시간, 수면시간\n",
        " - 휴대폰 이용횟수, 이용시간\n",
        " - 00 - 05 사이에 휴대폰 이용한 건수\n",
        " - 결측치 처리 x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGEyFT4ha4bU"
      },
      "outputs": [],
      "source": [
        "mScreenStatus = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mScreenStatus.parquet')\n",
        "\n",
        "mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\n",
        "# mScreenStatus = fill_missing_dates_by_subject(mScreenStatus)\n",
        "mScreenStatus.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cWpAYZxy32U"
      },
      "outputs": [],
      "source": [
        "def preprocess_mScreenStatus(df):\n",
        "    from datetime import datetime, time as dtime, timedelta\n",
        "\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    # base key 확보\n",
        "    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n",
        "    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n",
        "\n",
        "    # 밤 9시부터 다음날 오전 11시 필터링\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n",
        "    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n",
        "\n",
        "    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        # 1. 중간 각성(앞뒤 0, 본인 1) 제거\n",
        "        prev = group['m_screen_use'].shift(1)\n",
        "        next_ = group['m_screen_use'].shift(-1)\n",
        "        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n",
        "        group.loc[mask, 'm_screen_use'] = 0\n",
        "\n",
        "        # 2. 블록 단위로 짧은 각성 블록 제거\n",
        "        group['is_sleep'] = group['m_screen_use'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "        block_info = group.groupby('block').agg(\n",
        "            is_sleep=('is_sleep', 'first'),\n",
        "            size=('is_sleep', 'size')\n",
        "        )\n",
        "\n",
        "        for i in range(1, len(block_info) - 1):\n",
        "            if (\n",
        "                block_info.iloc[i]['is_sleep'] == False and\n",
        "                block_info.iloc[i]['size'] <= 2 and\n",
        "                block_info.iloc[i - 1]['is_sleep'] and\n",
        "                block_info.iloc[i + 1]['is_sleep']\n",
        "            ):\n",
        "                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n",
        "\n",
        "        # 다시 블록 재계산 후 수면 추정\n",
        "        group['is_sleep'] = group['m_screen_use'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n",
        "            sleep_start=('timestamp', 'first'),\n",
        "            sleep_end=('timestamp', 'last'),\n",
        "            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n",
        "        )\n",
        "\n",
        "        sleep_time = wake_time = duration_min = None\n",
        "        if not sleep_blocks.empty:\n",
        "            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n",
        "            sleep_time = longest_sleep['sleep_start'].time()\n",
        "            wake_time = longest_sleep['sleep_end'].time()\n",
        "            duration_min = (\n",
        "                datetime.combine(datetime.today(), wake_time) - datetime.combine(datetime.today(), sleep_time)\n",
        "            ).total_seconds() / 60\n",
        "            if duration_min < 0:\n",
        "                duration_min += 1440\n",
        "\n",
        "            if not (4 <= wake_time.hour < 11):\n",
        "                wake_time = None\n",
        "            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n",
        "                sleep_time = None\n",
        "            if duration_min < 100:\n",
        "                sleep_time = None\n",
        "                wake_time = None\n",
        "                duration_min = None\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': subject_id,\n",
        "            'lifelog_date': lifelog_date.date(),\n",
        "            'sleep_time': sleep_time,\n",
        "            'wake_time': wake_time,\n",
        "            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n",
        "        })\n",
        "\n",
        "\n",
        "    sleep_df = pd.DataFrame(results)\n",
        "    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n",
        "\n",
        "    # 시간 → 실수형 숫자 (예: 23:30 → 23.5)\n",
        "    def time_to_float(t):\n",
        "        if pd.isna(t):\n",
        "            return None\n",
        "        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n",
        "\n",
        "    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n",
        "    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n",
        "\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5EqRmCxgYoq"
      },
      "outputs": [],
      "source": [
        "def preprocess_mScreenStatus(df):\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    df = df.copy()\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    base_keys = df[['subject_id', 'lifelog_date']].drop_duplicates()\n",
        "    base_keys['lifelog_date'] = base_keys['lifelog_date'].dt.date\n",
        "\n",
        "    # 밤 9시 ~ 다음날 오전 11시 필터링\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df = df[(df['hour'] >= 21) | (df['hour'] < 11)].copy()\n",
        "    df.loc[df['hour'] < 11, 'lifelog_date'] -= pd.Timedelta(days=1)\n",
        "    df.sort_values(['subject_id', 'timestamp'], inplace=True)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for (subject_id, lifelog_date), group in df.groupby(['subject_id', 'lifelog_date']):\n",
        "        group = group.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "        # 중간 각성 제거\n",
        "        prev = group['m_screen_use'].shift(1)\n",
        "        next_ = group['m_screen_use'].shift(-1)\n",
        "        mask = (group['m_screen_use'] == 1) & (prev == 0) & (next_ == 0)\n",
        "        group.loc[mask, 'm_screen_use'] = 0\n",
        "\n",
        "        # 짧은 각성 블록 제거\n",
        "        group['is_sleep'] = group['m_screen_use'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "        block_info = group.groupby('block').agg(\n",
        "            is_sleep=('is_sleep', 'first'),\n",
        "            size=('is_sleep', 'size')\n",
        "        )\n",
        "\n",
        "        for i in range(1, len(block_info) - 1):\n",
        "            if (\n",
        "                block_info.iloc[i]['is_sleep'] == False and\n",
        "                block_info.iloc[i]['size'] <= 2 and\n",
        "                block_info.iloc[i - 1]['is_sleep'] and\n",
        "                block_info.iloc[i + 1]['is_sleep']\n",
        "            ):\n",
        "                group.loc[group['block'] == block_info.index[i], 'm_screen_use'] = 0\n",
        "\n",
        "        # 블록 재계산\n",
        "        group['is_sleep'] = group['m_screen_use'] == 0\n",
        "        group['block'] = (group['is_sleep'] != group['is_sleep'].shift()).cumsum()\n",
        "\n",
        "        sleep_blocks = group[group['is_sleep']].groupby('block').agg(\n",
        "            sleep_start=('timestamp', 'first'),\n",
        "            sleep_end=('timestamp', 'last'),\n",
        "            duration_min=('timestamp', lambda x: (x.max() - x.min()).total_seconds() / 60)\n",
        "        )\n",
        "\n",
        "        sleep_time = wake_time = duration_min = None\n",
        "        if not sleep_blocks.empty:\n",
        "            longest_sleep = sleep_blocks.loc[sleep_blocks['duration_min'].idxmax()]\n",
        "            sleep_time = longest_sleep['sleep_start'].time()\n",
        "            wake_time = longest_sleep['sleep_end'].time()\n",
        "            duration_min = longest_sleep['duration_min']  # ✅ 정확하게 자정 넘는 경우도 반영됨\n",
        "\n",
        "            # 유효 시간 범위 조건\n",
        "            if not (4 <= wake_time.hour < 11):\n",
        "                wake_time = None\n",
        "            if not (sleep_time.hour >= 21 or sleep_time.hour < 3):\n",
        "                sleep_time = None\n",
        "            if duration_min < 100:\n",
        "                sleep_time = None\n",
        "                wake_time = None\n",
        "                duration_min = None\n",
        "\n",
        "        results.append({\n",
        "            'subject_id': subject_id,\n",
        "            'lifelog_date': lifelog_date.date(),\n",
        "            'sleep_time': sleep_time,\n",
        "            'wake_time': wake_time,\n",
        "            'sleep_duration_min': round(duration_min, 1) if duration_min is not None else None\n",
        "        })\n",
        "\n",
        "    sleep_df = pd.DataFrame(results)\n",
        "    result_df = base_keys.merge(sleep_df, on=['subject_id', 'lifelog_date'], how='left')\n",
        "\n",
        "    # 시간 → 실수형 숫자 변환\n",
        "    def time_to_float(t):\n",
        "        if pd.isna(t):\n",
        "            return None\n",
        "        return round(t.hour + t.minute / 60 + t.second / 3600, 4)\n",
        "\n",
        "    result_df['sleep_time'] = result_df['sleep_time'].apply(time_to_float)\n",
        "    result_df['wake_time'] = result_df['wake_time'].apply(time_to_float)\n",
        "\n",
        "    return result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upcw25BCASra"
      },
      "outputs": [],
      "source": [
        "def add_ratios(df):\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "    df['weekday'] = df['lifelog_date'].dt.weekday  # 0=월 ~ 6=일\n",
        "    df['week_type'] = df['weekday'].apply(lambda x: 'weekend' if x in [4,5] else 'weekday') # 금,토\n",
        "    df['month'] = df['lifelog_date'].dt.month\n",
        "\n",
        "    # 평균 계산\n",
        "    avg_duration = df.groupby(['subject_id', 'month', 'week_type'])['sleep_duration_min'].mean().reset_index(name='avg_sleep_duration')\n",
        "    sleep_time_avg = df.groupby(['subject_id', 'month', 'week_type'])['sleep_time'].apply(calculate_circular_mean_sleep_time).reset_index(name='avg_sleep_time')\n",
        "    wake_time_avg = df.groupby(['subject_id', 'month', 'week_type'])['wake_time'].apply(calculate_circular_mean_sleep_time).reset_index(name='avg_wake_time')\n",
        "    avg_df = sleep_time_avg.merge(wake_time_avg, on=['subject_id', 'month', 'week_type']).merge(avg_duration, on=['subject_id', 'month', 'week_type'])\n",
        "    df = df.merge(avg_df, on=['subject_id', 'month', 'week_type'], how='left')\n",
        "\n",
        "    # 비율 변수\n",
        "    df['sleep_time_diff'] = df['avg_sleep_time'] - df['sleep_time']\n",
        "    df['wake_time_diff'] = df['avg_wake_time'] - df['wake_time']\n",
        "    df['sleep_duration_diff'] = df['avg_sleep_duration'] - df['sleep_duration_min']\n",
        "    df['sleep_time_ratio'] = df['sleep_time'] / df['avg_sleep_time']\n",
        "    df['wake_time_ratio'] = df['wake_time'] / df['avg_wake_time']\n",
        "    df['sleep_duration_ratio'] = df['sleep_duration_min'] / df['avg_sleep_duration']\n",
        "\n",
        "    # 정렬 및 lag/변화량\n",
        "    df = df.sort_values(['subject_id', 'lifelog_date'])\n",
        "\n",
        "    # 시차 변수\n",
        "    for lag in [1, 2]:\n",
        "        df[f'sleep_time_lag{lag}'] = df.groupby('subject_id')['sleep_time'].shift(lag)\n",
        "        df[f'wake_time_lag{lag}'] = df.groupby('subject_id')['wake_time'].shift(lag)\n",
        "        df[f'sleep_duration_lag{lag}'] = df.groupby('subject_id')['sleep_duration_min'].shift(lag)\n",
        "\n",
        "        df[f'sleep_time_diff_lag{lag}'] = df.groupby('subject_id')['sleep_time_diff'].shift(lag)\n",
        "        df[f'wake_time_diff_lag{lag}'] = df.groupby('subject_id')['wake_time_diff'].shift(lag)\n",
        "        df[f'sleep_duration_diff_lag{lag}'] = df.groupby('subject_id')['sleep_duration_diff'].shift(lag)\n",
        "\n",
        "        df[f'sleep_time_ratio_lag{lag}'] = df.groupby('subject_id')['sleep_time_ratio'].shift(lag)\n",
        "        df[f'wake_time_ratio_lag{lag}'] = df.groupby('subject_id')['wake_time_ratio'].shift(lag)\n",
        "        df[f'sleep_duration_ratio_lag{lag}'] = df.groupby('subject_id')['sleep_duration_ratio'].shift(lag)\n",
        "\n",
        "    # 이동 평균\n",
        "    for window in [2,3,5,7]:\n",
        "        df[f'sleep_time_mean{window}d'] = df.groupby('subject_id')['sleep_time'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_mean{window}d'] = df.groupby('subject_id')['wake_time'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_min_mean{window}d'] = df.groupby('subject_id')['sleep_duration_min'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "        df[f'sleep_time_diff_mean{window}d'] = df.groupby('subject_id')['sleep_time_diff'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_diff_mean{window}d'] = df.groupby('subject_id')['wake_time_diff'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_diff_mean{window}d'] = df.groupby('subject_id')['sleep_duration_diff'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "        df[f'sleep_time_ratio_mean{window}d'] = df.groupby('subject_id')['sleep_time_ratio'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_ratio_mean{window}d'] = df.groupby('subject_id')['wake_time_ratio'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_ratio_mean{window}d'] = df.groupby('subject_id')['sleep_duration_ratio'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "        # ----\n",
        "\n",
        "        df[f'sleep_time_std{window}d'] = df.groupby('subject_id')['sleep_time'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_std{window}d'] = df.groupby('subject_id')['wake_time'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_min_std{window}d'] = df.groupby('subject_id')['sleep_duration_min'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "\n",
        "        df[f'sleep_time_diff_std{window}d'] = df.groupby('subject_id')['sleep_time_diff'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_diff_std{window}d'] = df.groupby('subject_id')['wake_time_diff'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_diff_std{window}d'] = df.groupby('subject_id')['sleep_duration_diff'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "\n",
        "        df[f'sleep_time_ratio_std{window}d'] = df.groupby('subject_id')['sleep_time_ratio'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'wake_time_ratio_std{window}d'] = df.groupby('subject_id')['wake_time_ratio'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "        df[f'sleep_duration_ratio_std{window}d'] = df.groupby('subject_id')['sleep_duration_ratio'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
        "\n",
        "    # 요일별 평균 수면 비교\n",
        "    weekday_avg = df.groupby(['subject_id', 'weekday'])['sleep_duration_min'].mean().reset_index(name='weekday_avg_sleep')\n",
        "    df = df.merge(weekday_avg, on=['subject_id', 'weekday'], how='left')\n",
        "    df['sleep_duration_weekday_avg_diff'] = df['sleep_duration_min'] - df['weekday_avg_sleep']\n",
        "    df['sleep_duration_weekday_avg_div'] = df['sleep_duration_min'] / df['weekday_avg_sleep']\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clNnftHfukWb"
      },
      "outputs": [],
      "source": [
        "mScreenStatus2 = preprocess_mScreenStatus(mScreenStatus)\n",
        "print(mScreenStatus2.shape)\n",
        "\n",
        "# mScreenStatus2 = fill_missing_dates_by_subject(mScreenStatus2)\n",
        "# print(mScreenStatus2.shape)\n",
        "\n",
        "# weekday_map = {\n",
        "#     0: '월요일', 1: '화요일', 2: '수요일', 3: '목요일',\n",
        "#     4: '금요일', 5: '토요일', 6: '일요일'\n",
        "# }\n",
        "# mScreenStatus2['weekday'] = mScreenStatus2['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "# mScreenStatus2['month'] = mScreenStatus2['lifelog_date'].dt.month\n",
        "\n",
        "# mScreenStatus2['lifelog_date'] = mScreenStatus2['lifelog_date'].astype(str)\n",
        "# train['lifelog_date'] = train['lifelog_date'].astype(str)\n",
        "\n",
        "# mScreenStatus2 = mScreenStatus2.merge(train[['subject_id','lifelog_date','Q1','Q2','Q3','S1','S2','S3']],on=['subject_id','lifelog_date'],how='left')\n",
        "# print(mScreenStatus2.shape)\n",
        "\n",
        "# a1_map = {\n",
        "#     'sleep_duration_min':'수면시간(분)',\n",
        "#     'sleep_time':'취침시간',\n",
        "#     'wake_time':'기상시간',\n",
        "#     'Q1':'Q1(기상직후 수면의질)',\n",
        "#     'Q2':'Q2(취침직전 신체적피로)',\n",
        "#     'Q3':'Q3(취침직전 스트레스)',\n",
        "#     'S1':'S1(기상직후 수면시간)',\n",
        "#     'S2':'S2(기상직후 수면효율)',\n",
        "#     'S3':'S3(기상직후 수면지연시간)',\n",
        "# }\n",
        "\n",
        "# mScreenStatus2 = mScreenStatus2.rename(columns=a1_map)\n",
        "mScreenStatus2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9VZmhGoPtbM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# CPU times: user 40.4 s, sys: 7.17 s, total: 47.6 s\n",
        "# Wall time: 59min 11s\n",
        "\n",
        "\"\"\"\n",
        "- mACStatus: Indicates whether the smartphone is currently being charged.\n",
        "- mActivity: Value calculated by the Google Activity Recognition API.\n",
        "- mAmbience: Ambient sound identification labels and their respective probabilities.\n",
        "- mBle: Bluetooth devices around individual subject.\n",
        "- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n",
        "- mLight: Ambient light measured by the smartphone.\n",
        "- (✔️) mScreenStatus: Indicates whether the smartphone screen is in use.\n",
        "- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n",
        "- mWifi: Wifi devices around individual subject.\n",
        "- wHr: Heart rate readings recorded by the smartwatch.\n",
        "- wLight: Ambient light measured by the smartwatch.\n",
        "- wPedo: Step data recorded by the smartwatch.\n",
        "\"\"\"\n",
        "\n",
        "system_message = f\"\"\"\n",
        "# 🔈지침: 당신은 데이터 분석 전문가입니다.\n",
        "- 모델 설명 : For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records.\n",
        "- [데이터]에는 [취침시간], [기상시간] 결측치가 존재합니다. 이를 채워야 합니다.\n",
        "- [취침시간]과 [기상시간]은 **24시간제를 기준으로 한 '소수 시간(decimal hour)' 형식**입니다.\n",
        "    예) 23.50 → 23시 30분, 0.75 → 0시 45분, 1.0 → 1시 0분\n",
        "\n",
        "# 🔍 평균값 설명\n",
        "- 평균 취침시간/기상시간은 `21.0~2.0` 또는 `3.0~11.0` 범위에서 나타나며, 이는 **다음날로 넘어가는 원형 시간 범위입니다**.\n",
        "    예) 1.4776은 1시 28분을 의미하며, 이는 24시를 넘어선 것이 아니라 **자정 이후 정상적인 시간대**입니다.\n",
        "\n",
        "# 🔈결측치 보완 규칙\n",
        "- 평균 취침시간/기상시간은 이미 올바른 포맷이며, 21.0~2.0(취침), 3.0~11.0(기상) 범위 내의 값입니다. **충분히 허용 가능한 값입니다. 혼란을 느끼지 말고 그대로 활용하세요.**\n",
        "- 평균값이 0보다 작은 경우는 없으며, 1.4와 같은 값은 1시 24분을 의미합니다.\n",
        "\n",
        "# 🔈금지 사항\n",
        "- 데이터 형식이나 범위를 의심하거나, 평균값이 허용 범위를 벗어난다고 가정하지 마세요.\n",
        "- 반복적으로 시간 포맷을 재해석하거나 '이 값이 잘못된 것 같다'는 내적 판단을 하지 마세요.\n",
        "\n",
        "# 🔈주의사항 (중요!!)\n",
        "- [취침시간] 결측값 추정 시, 21.0 ~ 2.0 범위 내의 값을 사용해야 합니다.\n",
        "- [기상시간] 결측값 추정 시, 3.0 ~ 11.0 범위 내의 값을 사용해야 합니다.\n",
        "- [취침시간], [기상시간] 결측값을 추정할 때 다양한 정보를 종합적으로 고려해야 합니다.\n",
        "  → 다양한 정보: 전일 학습데이터, 통계데이터, Q1~S1 정보, 주말 유무(금요일 포함), 7~8월 유무 등\n",
        "- [취침시간], [기상시간]의 **기존 값이 존재하는 경우 절대로 수정하지 마세요.**\n",
        "- 기존값이 있는 경우에는 **해당 셀을 그대로 유지**하며, **빈칸(null)**인 경우에만 보완합니다.\n",
        "- 입력으로 주어진 테이블의 다른 값들도 절대 수정하지 마세요. **오직 결측치만 채워야 합니다.**\n",
        "- 누락된 셀은 반드시 채워야 하며, **빈 셀 없이 모든 셀을 채워진 상태로 출력**해야 합니다.\n",
        "- 출력은 항상 **모든 셀에 값이 채워진 상태**여야 합니다. **빈칸을 남기지 마세요.**\n",
        "\n",
        "### 🔈답변 작성 양식\n",
        "- 답변에 지침내용을 포함하지 않습니다.\n",
        "- 결측치만 채우고 기존값이 존재하는을 그대로 사용합니다.\n",
        "\"\"\"\n",
        "\n",
        "# ================================================================\n",
        "# 설정값\n",
        "save_path = '/content/drive/MyDrive/data/ch2025_data_items/fillna'\n",
        "dataname  = 'mScreenStatus'\n",
        "version   = '20250607_v4'\n",
        "data      = mScreenStatus2.copy()\n",
        "# ================================================================\n",
        "\n",
        "# run\n",
        "parsed_results = []\n",
        "for subject_id in tqdm(data['subject_id'].unique(), desc=\"Processing each subject\"):\n",
        "# for subject_id in tqdm(['id06'], desc=\"Processing each subject\"):\n",
        "\n",
        "    print(f'# subject_id:{subject_id}')\n",
        "\n",
        "    sub1 = data[data['subject_id'] == subject_id]\n",
        "    sub1 = sub1.drop(columns=['수면시간(분)'])\n",
        "    학습데이터 = sub1.to_csv(index=False, sep=\"\\t\")\n",
        "\n",
        "    # ----------------------------------------------------------------------------------------------\n",
        "    # 통계데이터\n",
        "    a1 = data[data['subject_id'] == subject_id].groupby(['weekday']).apply(lambda x:pd.Series({\n",
        "    '평균취침시간': calculate_circular_mean_sleep_time(x['취침시간'])\n",
        "    ,'평균기상시간': calculate_circular_mean_sleep_time(x['기상시간'])\n",
        "    })).reset_index()\n",
        "\n",
        "    a2 = data[data['subject_id'] == subject_id].groupby(['month','weekday']).apply(lambda x:pd.Series({\n",
        "    '평균취침시간': calculate_circular_mean_sleep_time(x['취침시간'])\n",
        "    ,'평균기상시간': calculate_circular_mean_sleep_time(x['기상시간'])\n",
        "    })).reset_index()\n",
        "\n",
        "    # a1을 weekday 기준으로 merge\n",
        "    a2_filled = a2.merge(\n",
        "        a1,\n",
        "        on='weekday',\n",
        "        suffixes=('', '_a1'),\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # 결측값이 있는 경우 a1 값으로 대체\n",
        "    a2_filled['평균취침시간'] = a2_filled['평균취침시간'].fillna(a2_filled['평균취침시간_a1'])\n",
        "    a2_filled['평균기상시간'] = a2_filled['평균기상시간'].fillna(a2_filled['평균기상시간_a1'])\n",
        "\n",
        "    # 보조 컬럼 제거\n",
        "    sub2 = a2_filled.drop(columns=['평균취침시간_a1', '평균기상시간_a1'])\n",
        "    통계데이터 = sub2.to_csv(index=False, sep=\"\\t\")\n",
        "    # ----------------------------------------------------------------------------------------------\n",
        "\n",
        "    user_message = f\"\"\"\n",
        "    # 🔈작업 순서\n",
        "    1. 결측치 [취침시간]을 추정하시오.\n",
        "    2. 결측치 [기상시간]을 추정하시오 (추가지침: 전 단계에서 생성 된 [취침시간]을 참고해서 [기상시간] 결측값을 추정하시오.)\n",
        "\n",
        "    # 🔈 xdata 설명\n",
        "    - mScreenStatus(Indicates whether the smartphone screen is in use)기반으로 파생된 추정 [취침시간], [기상시간]\n",
        "    - [취침시간]과 [기상시간]은 소수점으로 표현된 24시간제 시간입니다. (예: 22.6500 → 22시 39분)\n",
        "\n",
        "    # 🔈 ydata 설명 (예측타겟)\n",
        "    - Q1: 기상 직후 수면의 질 (0: 평균 이하, 1: 평균 이상)\n",
        "    - Q2: 취침 직전 신체 피로 수준 (0: 높은 피로, 1: 낮은 피로)\n",
        "    - Q3: 취침 직전 스트레스 수준 (0: 높은 스트레스, 1: 낮은 스트레스)\n",
        "    - S1: 수면시간 가이드라인 준수여부 (0: 미준수, 1: 부분 준수, 2: 완전 준수)\n",
        "    - S2: 수면 효율 가이드라인 준수여부 (0: 미준수, 1: 준수)\n",
        "    - S3: 수면 잠들기 지연시간 가이드라인 준수여부 (0: 미준수, 1: 준수)\n",
        "\n",
        "    # 🔈도메인 지식\n",
        "    - S1(수면시간)이 2(완전준수)인 경우 -> 기상기상이 평소보다 늦어서 수면시간이 충분한 경우\n",
        "    - 금요일, 토요일에는 다음날이 휴일이기 때문에 기상시간을 평소보다 늦게 설정\n",
        "    - 7월, 8월에는 무더위(여름철 고온 시기)에는 기상시간이 일반적으로 더 빨라지는 경향 존재\n",
        "    - 전일 상태가 오늘 상태에 영향을 줄 수 있음 (전일 몸이 좋지 않으면 다음날도 몸이 좋지 않는 것과 동일한 원리)\n",
        "\n",
        "    # 🔈통계데이터\n",
        "    {통계데이터}\n",
        "\n",
        "    # 🔈데이터\n",
        "    {학습데이터}\n",
        "\n",
        "    # 🔈답변 출력 형식\n",
        "    lifelog_date\\tsubject_id\\t취침시간\\t기상시간\\n\n",
        "    2024-06-26\\tid01\\t23.4500\\t5.2500\\n\n",
        "    2024-06-27\\tid01\\t23.1333\\t5.3000\\n\n",
        "    2024-06-28\\tid01\\t23.0000\\t5.9167\\n\n",
        "\n",
        "    # 답변:\n",
        "    \"\"\"\n",
        "\n",
        "    # 최대 3회 시도\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            # 질의\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": system_message},\n",
        "                {\"role\": \"user\", \"content\": user_message}\n",
        "            ]\n",
        "\n",
        "            sampling_params = SamplingParams(max_tokens=37000, temperature=0, seed=42)\n",
        "            outputs = llm.chat(messages, sampling_params=sampling_params)\n",
        "\n",
        "            # 텍스트 추출 및 저장\n",
        "            result_text = outputs[0].outputs[0].text\n",
        "            with open(f\"{save_path}/{dataname}_{subject_id}_result_try{attempt+1}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(result_text)\n",
        "\n",
        "            # <think> 제거\n",
        "            cleaned_text = re.sub(r\"<think>.*?</think>\", \"\", result_text, flags=re.DOTALL).strip()\n",
        "\n",
        "            # 파싱\n",
        "            df_parsed = pd.read_csv(StringIO(cleaned_text), sep=\"\\t\")\n",
        "\n",
        "            # 결측이 많을 경우 재시도\n",
        "            # 1. 결측값이 10개 넘거나\n",
        "            # 2. 생성한 개수가 제공한 샘플보다 10개 이상 적을때\n",
        "            if (df_parsed['기상시간'].isna().sum() > 10) | ((len(sub1)-len(df_parsed)) > 10):\n",
        "                print(f\"[RETRY] 결측치 많음 → subject_id: {subject_id} (attempt {attempt+1})\")\n",
        "                continue\n",
        "\n",
        "            parsed_results.append(df_parsed)\n",
        "            break  # 성공하면 반복 종료\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Parsing failed for subject {subject_id} (attempt {attempt+1}): {e}\")\n",
        "            if attempt == 1:\n",
        "                print(f\"[FAIL] 최종 실패 → subject_id: {subject_id}\")\n",
        "            import time\n",
        "            time.sleep(2)  # 재시도 전에 대기\n",
        "\n",
        "# 모든 subject 결과 병합\n",
        "data_filled_na = pd.concat(parsed_results, ignore_index=True)\n",
        "data_filled_na = data_filled_na.rename(columns={'취침시간':'취침시간_llm','기상시간':'기상시간_llm'})\n",
        "data_filled_na.to_excel(f'{save_path}/{dataname}_llm_{version}.xlsx',index=False)\n",
        "\n",
        "# 비교검증데이터 저장\n",
        "data_filled_na['lifelog_date'] = data_filled_na['lifelog_date'].astype(str)\n",
        "data['lifelog_date'] = data['lifelog_date'].astype(str)\n",
        "data_filled_na['subject_id'] = data_filled_na['subject_id'].astype(str)\n",
        "data['subject_id'] = data['subject_id'].astype(str)\n",
        "data = data.merge(data_filled_na,on=['lifelog_date','subject_id'],how='left')\n",
        "data['수면시간_llm'] = data.apply(lambda x: calculate_sleep_duration_min(x['취침시간_llm'],x['기상시간_llm']),axis=1)\n",
        "data.to_excel(f'{save_path}/{dataname}_llm_check_{version}.xlsx',index=False)\n",
        "\n",
        "# check\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQ7ttdeHd-25"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbNH1smPd-9_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckIM5mjVd_F6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmNGOT1e6ww0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 LLM 결측값 대체"
      ],
      "metadata": {
        "id": "rVeJUPVQYUXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vl6PJvtVQkXA"
      },
      "outputs": [],
      "source": [
        "# 전처리\n",
        "\n",
        "mScreenStatus2_llm = pd.read_excel('/content/drive/MyDrive/data/ch2025_data_items/share/hjy/mScreenStatus_llm_20250607_v4.xlsx')\n",
        "mScreenStatus2_llm.head()\n",
        "\n",
        "mScreenStatus2_llm['pk'] = mScreenStatus2_llm['subject_id']+mScreenStatus2_llm['lifelog_date']\n",
        "mScreenStatus2_llm = mScreenStatus2_llm.set_index('pk')\n",
        "\n",
        "mScreenStatus2 = preprocess_mScreenStatus(mScreenStatus)\n",
        "\n",
        "# 취침시간, 기상시간 교체\n",
        "\n",
        "mScreenStatus2['lifelog_date'] = mScreenStatus2['lifelog_date'].astype(str)\n",
        "mScreenStatus2['pk'] = mScreenStatus2['subject_id']+mScreenStatus2['lifelog_date']\n",
        "\n",
        "a1_map = mScreenStatus2_llm['취침시간_llm'].to_dict()\n",
        "mScreenStatus2['sleep_time'] = np.where(mScreenStatus2['sleep_time'].isna(),mScreenStatus2['pk'].map(a1_map),mScreenStatus2['sleep_time'])\n",
        "\n",
        "a1_map = mScreenStatus2_llm['기상시간_llm'].to_dict()\n",
        "mScreenStatus2['wake_time'] = np.where(mScreenStatus2['wake_time'].isna(),mScreenStatus2['pk'].map(a1_map),mScreenStatus2['wake_time'])\n",
        "\n",
        "mScreenStatus2 = mScreenStatus2.drop(columns='pk')\n",
        "\n",
        "# 수면시간 재계산\n",
        "mScreenStatus2['sleep_time'] = np.where(mScreenStatus2['sleep_time']<10,mScreenStatus2['sleep_time']+24,mScreenStatus2['sleep_time'])         ### 수정\n",
        "mScreenStatus2['sleep_duration_min'] = mScreenStatus2.apply(lambda x: calculate_sleep_duration_min(x['sleep_time'],x['wake_time']),axis=1)\n",
        "\n",
        "# 비율 변수 추가\n",
        "\n",
        "mScreenStatus2 = add_ratios(mScreenStatus2)\n",
        "\n",
        "# check\n",
        "print(f'\\n # mScreenStatus2 shape: {mScreenStatus2.shape}')\n",
        "mScreenStatus2.head(1)\n",
        "\n",
        "# 평균수면시간\n",
        "mScreenStatus2평균수면시간 = mScreenStatus2.groupby(['subject_id','week_type']).apply(lambda x: pd.Series({\n",
        "     '평균 취침시간':circular_mean_sleep_time(x['sleep_time'])\n",
        "    ,'평균 기상시간':circular_mean_sleep_time(x['wake_time'])\n",
        "    ,'평균 수면시간':x['sleep_duration_min'].mean()\n",
        "})).reset_index()\n",
        "\n",
        "# 저장\n",
        "fname = f'{path}mScreenStatus2평균수면시간.xlsx'\n",
        "print(fname)\n",
        "mScreenStatus2평균수면시간.to_excel(fname, index=False)\n",
        "\n",
        "# check\n",
        "mScreenStatus2평균수면시간.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dvQ-tBxQx6n"
      },
      "outputs": [],
      "source": [
        "mScreenStatus2.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1rMa4hHZEJh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7_ExIp_brjK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUxk1jIqa4jT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orMu9LKiW58-"
      },
      "source": [
        "### ✔️ mUsageStats 앱사용통계\n",
        "- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n",
        "\n",
        " - 몇시까지 핸드폰 보다가 잠잤는지\n",
        " - 통화, 전화 얼마나 했는지\n",
        " - YouTube 얼마나 봤는지\n",
        " - 메시지, 카카오톡 얼마나 했는지\n",
        " - NAVER 얼마나 했는지\n",
        " - 평소보다 얼마나 많은 앱을 이용했는지\n",
        " - 제외? -> 시스템 UI,One UI 홈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zr1oENhJWfh0"
      },
      "outputs": [],
      "source": [
        "def extract_mUsageStats_info(row):\n",
        "    m_data = row['m_usage_stats']\n",
        "    app_name = [item['app_name'] for item in m_data]\n",
        "    total_time = [item['total_time'] for item in m_data]\n",
        "    return pd.Series({'app_name': app_name, 'total_time': total_time})\n",
        "\n",
        "mUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\n",
        "mUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\n",
        "# mUsageStats = fill_missing_dates_by_subject(mUsageStats)\n",
        "mUsageStats.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUX_rMJg4I0D"
      },
      "outputs": [],
      "source": [
        "def process_mUsageStats(df):\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['요일'] = df['lifelog_date'].dt.day_name()\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "\n",
        "    # 시간대 분류\n",
        "    def map_time_period(row):\n",
        "        if 20 <= row['hour'] <= 23:\n",
        "            return 'beforebed'\n",
        "        else:\n",
        "            return 'activehour'\n",
        "\n",
        "    df['time_period'] = df.apply(map_time_period, axis=1)\n",
        "\n",
        "    # 리스트 평탄화\n",
        "    exploded_df = df.explode(['app_name', 'total_time'])\n",
        "    exploded_df['total_time'] = exploded_df['total_time'].astype(float)\n",
        "    exploded_df['total_time'] = exploded_df['total_time'] * 0.001 / 60  # 밀리초 → 초 → 분 변환\n",
        "\n",
        "    # app_name 특수문자 제거\n",
        "    exploded_df['app_name'] = exploded_df['app_name'].astype(str).apply(\n",
        "        lambda x: re.sub(r'[^가-힣a-zA-Z0-9]', '', x)\n",
        "    )\n",
        "\n",
        "    # 시스템 앱 제거\n",
        "    filtered_df = exploded_df[~exploded_df['app_name'].isin(['시스템UI'])]\n",
        "\n",
        "    # 주요 파생변수 생성\n",
        "    def calculate_daily_metrics(group):\n",
        "        app_times = {\n",
        "\n",
        "            '통화&전화_앱이용시간': group[group['app_name'].isin(['통화','전화'])]['total_time'].sum(),\n",
        "            '메신저&카카오톡_앱이용시간': group[group['app_name'].isin(['메시지','카카오톡'])]['total_time'].sum(),\n",
        "            'YouTube_앱이용시간': group[group['app_name'] == 'YouTube']['total_time'].sum(),\n",
        "            'NAVER_앱이용시간': group[group['app_name'] == 'NAVER']['total_time'].sum(),\n",
        "            '캐시워크_앱이용시간': group[group['app_name'] == '캐시워크']['total_time'].sum(),\n",
        "            '성경일독Q_앱이용시간': group[group['app_name'] == '성경일독Q']['total_time'].sum(),\n",
        "        }\n",
        "\n",
        "        return pd.Series({\n",
        "            **app_times,\n",
        "            '이용앱개수': group['app_name'].nunique(),\n",
        "            '핸드폰사용시간': group['total_time'].sum()\n",
        "        })\n",
        "\n",
        "    # 일자/시간대별 요약\n",
        "    daily_stats = filtered_df.groupby(['subject_id', 'lifelog_date', 'time_period']).apply(calculate_daily_metrics).reset_index()\n",
        "\n",
        "    # subject_id별 평균 총화면시간\n",
        "    avg_screen_time = daily_stats.groupby('subject_id')['핸드폰사용시간'].mean().to_dict()\n",
        "\n",
        "    # 평균 대비 비율\n",
        "    def compute_screen_usage(row):\n",
        "        avg_time = avg_screen_time.get(row['subject_id'], np.nan)\n",
        "        if pd.isna(avg_time) or avg_time == 0:\n",
        "            return np.nan\n",
        "        return round((row['핸드폰사용시간'] / avg_time - 1) * 100, 1)\n",
        "\n",
        "    daily_stats['평균대비핸드폰사용시간'] = daily_stats.apply(compute_screen_usage, axis=1)\n",
        "\n",
        "    # 피벗\n",
        "    daily_stats = daily_stats.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n",
        "    daily_stats.columns = [f\"{tp}_{metric}\" for metric, tp in daily_stats.columns]\n",
        "    daily_stats = daily_stats.reset_index()\n",
        "\n",
        "    feats = [\n",
        "      'subject_id',\n",
        "      'lifelog_date',\n",
        "      'beforebed_통화&전화_앱이용시간',\n",
        "      'beforebed_메신저&카카오톡_앱이용시간',\n",
        "      'beforebed_YouTube_앱이용시간',\n",
        "      'beforebed_핸드폰사용시간',\n",
        "    ]\n",
        "\n",
        "    return daily_stats[feats]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8CRKpC4iDKa"
      },
      "outputs": [],
      "source": [
        "mUsageStats2 = process_mUsageStats(mUsageStats)\n",
        "\n",
        "# check\n",
        "print(f'\\n # mUsageStats2 shape: {mUsageStats2.shape}')\n",
        "mUsageStats2.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8uHsK9wc0Ls"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubjD-ZwOc0RP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ecpVUVhRo4e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1PcAUtkH81I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZHkETiDH84G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFVRGf8cbJMo"
      },
      "source": [
        "### ✔️ mWifi 주변wifi (수정)\n",
        "- Wifi devices around individual subject.\n",
        " - -30 ~ -50 dBm\t매우 강한 신호 (최적)\n",
        " - -51 ~ -60 dBm\t강한 신호 (문제 없음)\n",
        " - -61 ~ -70 dBm\t괜찮은 신호 (약간 느릴 수 있음)\n",
        " - -71 ~ -80 dBm\t약한 신호 (끊김 주의)\n",
        " - -81 dBm 이하\t매우 약한 신호 (거의 끊김)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCIgP5FaH86F"
      },
      "outputs": [],
      "source": [
        "def extract_wifi_info(row):\n",
        "    wifi_data = row['m_wifi']\n",
        "    bssids = [item['bssid'] for item in wifi_data]\n",
        "    rssis = [item['rssi'] for item in wifi_data]\n",
        "    return pd.Series({'bssid': bssids, 'rssi': rssis})\n",
        "\n",
        "mWifi = pd.read_parquet(f'{PATH}/ETRI_lifelog_dataset/ch2025_data_items/ch2025_mWifi.parquet')\n",
        "mWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\n",
        "mWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\n",
        "# mWifi = fill_missing_dates_by_subject(mWifi)\n",
        "mWifi.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeDXOGXDcYmo"
      },
      "outputs": [],
      "source": [
        "def process_mWifi(df,threshold):\n",
        "\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['요일'] = df['lifelog_date'].dt.day_name()\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "\n",
        "    # 시간대 분류\n",
        "    def map_time_period(row):\n",
        "        if 20 <= row['hour'] <= 23:\n",
        "            return 'beforebed'\n",
        "        else:\n",
        "            return 'activehour'\n",
        "\n",
        "    df['time_period'] = df.apply(map_time_period, axis=1)\n",
        "\n",
        "    features = []\n",
        "    grouped = df.groupby(['subject_id', 'lifelog_date','time_period'])\n",
        "\n",
        "    for (subject_id, date, period), group in grouped:\n",
        "        scan_count = len(group)\n",
        "        bssid_flat = sum(group['bssid'], [])  # flatten\n",
        "        rssi_flat = sum(group['rssi'], [])    # flatten\n",
        "\n",
        "        unique_bssid_count = len(set(bssid_flat))\n",
        "        avg_rssi = sum(rssi_flat) / len(rssi_flat) if rssi_flat else None\n",
        "        max_rssi = max(rssi_flat) if rssi_flat else None\n",
        "        min_rssi = min(rssi_flat) if rssi_flat else None\n",
        "        strong_rssi_ratio = sum(1 for r in rssi_flat if r > -60) / len(rssi_flat) if rssi_flat else 0\n",
        "        empty_scan_count = sum(1 for b in group['bssid'] if len(b) == 0)\n",
        "\n",
        "        # 가장 많이 탐지된 BSSID\n",
        "        bssid_counter = Counter(bssid_flat)\n",
        "        top_bssid, top_bssid_count = bssid_counter.most_common(1)[0] if bssid_counter else (None, 0)\n",
        "\n",
        "        first_time = group['timestamp'].min()\n",
        "        last_time = group['timestamp'].max()\n",
        "        hour_span = (last_time - first_time).total_seconds() / 60  # 분 단위\n",
        "\n",
        "        features.append({\n",
        "            'subject_id': subject_id,\n",
        "            'lifelog_date': date,\n",
        "            'time_period': period,  #\n",
        "            'scan_count': scan_count,\n",
        "            'unique_bssid_count': unique_bssid_count,\n",
        "            'avg_rssi': avg_rssi,\n",
        "            'max_rssi': max_rssi,\n",
        "            'min_rssi': min_rssi,\n",
        "            'strong_signal_ratio': strong_rssi_ratio,\n",
        "            'empty_scan_count': empty_scan_count,\n",
        "            'top_bssid': top_bssid,\n",
        "            'top_bssid_count': top_bssid_count,\n",
        "            'hour_span_minutes': hour_span\n",
        "        })\n",
        "\n",
        "    daily_stats = pd.DataFrame(features)\n",
        "\n",
        "    # 피벗\n",
        "    daily_stats = daily_stats.pivot(index=['subject_id', 'lifelog_date'], columns='time_period')\n",
        "    daily_stats.columns = [f\"{tp}_{metric}\" for metric, tp in daily_stats.columns]\n",
        "    daily_stats = daily_stats.reset_index()\n",
        "\n",
        "    return daily_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJujoyH8H9Cw"
      },
      "outputs": [],
      "source": [
        "mWifi2 = process_mWifi(mWifi,threshold=-60)\n",
        "\n",
        "# check\n",
        "print(f'\\n # mWifi2 shape: {mWifi2.shape}')\n",
        "mWifi2.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsAzWwCFYL2q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDYMQG6EYMVT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWKrkwFSiA3H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0TwqdaHiA6a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQkZX8zrb53H"
      },
      "source": [
        "### ✔️ wHr 심박동수 (수정)\n",
        "- Heart rate readings recorded by the smartwatch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQTSKYiTiA-D"
      },
      "outputs": [],
      "source": [
        "def process_wHr(df):\n",
        "    heart_rate = df[\"heart_rate\"].values  # [[0, 1, 2, ...], ...]\n",
        "\n",
        "    def _process_feature(heart_rate):\n",
        "        if len(heart_rate) == 0:\n",
        "            return 0., 0., 0., 0., 0.\n",
        "\n",
        "        heart_rate = np.array(sum(map(lambda x: x.tolist(), heart_rate), []))\n",
        "        mean_hr = heart_rate.mean() if len(heart_rate) > 0 else 0\n",
        "        min_hr = heart_rate.min() if len(heart_rate) > 0 else 0\n",
        "        max_hr = heart_rate.max() if len(heart_rate) > 0 else 0\n",
        "        std_hr = heart_rate.std() if len(heart_rate) > 0 else 0\n",
        "        high_hr = heart_rate[heart_rate > 100].sum()\n",
        "\n",
        "        return mean_hr, min_hr, max_hr, std_hr, high_hr\n",
        "\n",
        "    # 하루\n",
        "    active_hour_mean_hr, active_hour_min_hr, active_hour_max_hr, active_hour_std_hr, active_hour_high_hr = _process_feature(heart_rate[df[\"hour\"].isin(ACTIVE_HOURS)])\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_hour_mean_hr, sleep_hour_min_hr, sleep_hour_max_hr, sleep_hour_std_hr, sleep_hour_high_hr = _process_feature(heart_rate[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    return pd.Series({\n",
        "        'active_hour_mean_hr': active_hour_mean_hr,\n",
        "        'active_hour_min_hr': active_hour_min_hr,\n",
        "        'active_hour_max_hr': active_hour_max_hr,\n",
        "        'active_hour_std_hr': active_hour_std_hr,\n",
        "        'active_hour_high_hr': active_hour_high_hr,\n",
        "        'sleep_hour_mean_hr': sleep_hour_mean_hr,\n",
        "        'sleep_hour_min_hr': sleep_hour_min_hr,\n",
        "        'sleep_hour_max_hr': sleep_hour_max_hr,\n",
        "        'sleep_hour_std_hr': sleep_hour_std_hr,\n",
        "        'sleep_hour_high_hr': sleep_hour_high_hr\n",
        "    })\n",
        "\n",
        "wHr_ori = load_data(DataType.wHr)\n",
        "wHr_ori = shift_lifelog_date(wHr_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "wHr2 = (\n",
        "    wHr_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_wHr)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(wHr2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT7srO3MeuXD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0QjiWkCmPW6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koL6BKdTmPcY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRO-TD8_cEIH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYFlbAd_bYca"
      },
      "source": [
        "### ✔️ wLight 라이트 (수정)\n",
        "- Ambient light measured by the smartwatch.  \n",
        "  - 어두운 밤 0.1 ~ 1 lux 캄캄한 방, 달빛 없는 밤\n",
        "  - 가로등 켜진 거리 10 ~ 20 lux 흐릿한 외부 조명\n",
        "  - 실내 조명 100 ~ 500 lux 사무실, 일반 거실\n",
        "  - 밝은 실외 10,000 ~ 25,000 lux 맑은 날 햇빛\n",
        "  - 직사광선 아래 30,000 ~ 100,000 lux 여름 한낮, 매우 강한 햇빛"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfAGaJQ0iBHP"
      },
      "outputs": [],
      "source": [
        "def process_mLight(df):\n",
        "    light = df[\"m_light\"].values  # [534.0, 224, ...]\n",
        "\n",
        "    def _process_feature(light):\n",
        "        if len(light) == 0:\n",
        "            return 0., 0., 0., 0., np.array([])\n",
        "\n",
        "        ligths = np.array(light)\n",
        "        mean_light = ligths.mean() if len(ligths) > 0 else 0\n",
        "        min_light = ligths.min() if len(ligths) > 0 else 0\n",
        "        max_light = ligths.max() if len(ligths) > 0 else 0\n",
        "        std_light = ligths.std() if len(ligths) > 0 else 0\n",
        "\n",
        "        return mean_light, min_light, max_light, std_light, ligths\n",
        "\n",
        "    # 하루\n",
        "    active_hour_mean_light, active_hour_min_light, active_hour_max_light, active_hour_std_light, _ = _process_feature(light[df[\"hour\"].isin(ACTIVE_HOURS)])\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_hour_mean_light, sleep_hour_min_light, sleep_hour_max_light, sleep_hour_std_light, _= _process_feature(light[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    # 잠 자러갈 때\n",
        "    might_go_to_sleep_light = light[df[\"hour\"].isin(MIGHT_GO_TO_SLEEP_HOURS)]\n",
        "    might_go_to_sleep_timestamps = df[\"timestamp\"].values[df[\"hour\"].isin(MIGHT_GO_TO_SLEEP_HOURS)]\n",
        "    _, _, _, _, might_go_to_sleep_lights = _process_feature(might_go_to_sleep_light)\n",
        "    first_sleep_timestamps = might_go_to_sleep_timestamps[(might_go_to_sleep_lights < 10.0)]\n",
        "    first_sleep_datetime = (\n",
        "        pd.to_datetime(first_sleep_timestamps[0]) if len(first_sleep_timestamps) > 0\n",
        "        else pd.to_datetime(might_go_to_sleep_timestamps[-1]) if len(might_go_to_sleep_timestamps) > 0\n",
        "        else pd.to_datetime(datetime(2024, 1, 1, MIGHT_GO_TO_SLEEP_HOURS[-1], 0, 0))  # default to the last hour of the range\n",
        "    )\n",
        "    first_sleep_minutes = (first_sleep_datetime.hour * 60 if first_sleep_datetime.hour > 12 else (first_sleep_datetime.hour + 24) * 60) + first_sleep_datetime.minute\n",
        "\n",
        "    # 일어날 때\n",
        "    might_wakeup_light = light[df[\"hour\"].isin(MIGHT_WAKEUP_HOURS)]\n",
        "    might_wakeup_timestamps = df[\"timestamp\"].values[df[\"hour\"].isin(MIGHT_WAKEUP_HOURS)]\n",
        "    _, _, _, _, might_wakeup_lights = _process_feature(might_wakeup_light)\n",
        "    wakeup_timestamps = might_wakeup_timestamps[(might_wakeup_lights > 10.0)]\n",
        "    first_move_datetime = (\n",
        "        pd.to_datetime(wakeup_timestamps[0]) if len(wakeup_timestamps) > 0\n",
        "        else pd.to_datetime(might_wakeup_timestamps[-1]) if len(might_wakeup_timestamps) > 0\n",
        "        else pd.to_datetime(datetime(2024, 1, 1, MIGHT_WAKEUP_HOURS[-1], 0, 0))  # default to the last hour of the range\n",
        "    )\n",
        "    first_wakeup_minutes = (first_move_datetime.hour if first_move_datetime.hour > 12 else first_move_datetime.hour + 24) * 60 + first_move_datetime.minute\n",
        "\n",
        "    return pd.Series({\n",
        "        'active_hour_mean_light': active_hour_mean_light,\n",
        "        'active_hour_min_light': active_hour_min_light,\n",
        "        'active_hour_max_light': active_hour_max_light,\n",
        "        'active_hour_std_light': active_hour_std_light,\n",
        "        'sleep_hour_mean_light': sleep_hour_mean_light,\n",
        "        'sleep_hour_min_light': sleep_hour_min_light,\n",
        "        'sleep_hour_max_light': sleep_hour_max_light,\n",
        "        'sleep_hour_std_light': sleep_hour_std_light,\n",
        "        'mlight_first_sleep_minutes': first_sleep_minutes,\n",
        "        'mlight_first_wakeup_minutes': first_wakeup_minutes,\n",
        "    })\n",
        "\n",
        "wLight_ori = load_data(DataType.wLight)\n",
        "wLight_ori = shift_lifelog_date(wLight_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "wLight2 = (\n",
        "    wLight_ori\n",
        "    .rename(columns={\"w_light\": \"m_light\"})\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mLight)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "wLight2.rename(\n",
        "    columns={\n",
        "        col: \"w\" + col.replace(\"mlight_\", \"wlight_\")\n",
        "        for col in wLight.columns if col not in [\"subject_id\", \"lifelog_date\"]\n",
        "    }, inplace=True\n",
        ")\n",
        "\n",
        "describe_df(wLight2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAiZk_kWfR8m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcU6IavGfSAw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp0et2XoiBZ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX2gVvMzcF7h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQvyhHhBbmzN"
      },
      "source": [
        "### ✔️ wPedo 걸음수\n",
        "- Step data recorded by the smartwatch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3poFH3LmiBc2"
      },
      "outputs": [],
      "source": [
        "def process_mPedo(df):\n",
        "\n",
        "    def _process_feature(df):\n",
        "        if len(df) == 0:\n",
        "            return 0., 0., 0.\n",
        "\n",
        "        steps = df[\"step\"].values\n",
        "        distances = df[\"distance\"].values\n",
        "        calories = df[\"burned_calories\"].values\n",
        "\n",
        "        steps = steps.sum() if len(steps) > 0 else 0\n",
        "        distance = distances.sum() if len(distances) > 0 else 0\n",
        "        burned_calories = calories.sum() if len(calories) > 0 else 0\n",
        "\n",
        "        return steps, distance, burned_calories\n",
        "\n",
        "    # 하루\n",
        "    active_hour_steps, active_hour_distance, active_hour_burned_calories = _process_feature(df[df[\"hour\"].isin(ACTIVE_HOURS)])\n",
        "\n",
        "    # 잠자는 시간대\n",
        "    sleep_hour_steps, sleep_hour_distance, sleep_hour_burned_calories = _process_feature(df[df[\"hour\"].isin(SLEEP_HOURS)])\n",
        "\n",
        "    return pd.Series({\n",
        "        'active_hour_steps': active_hour_steps,\n",
        "        'active_hour_distance': active_hour_distance,\n",
        "        'active_hour_burned_calories': active_hour_burned_calories,\n",
        "        'sleep_hour_steps': sleep_hour_steps,\n",
        "        'sleep_hour_distance': sleep_hour_distance,\n",
        "        'sleep_hour_burned_calories': sleep_hour_burned_calories\n",
        "    })\n",
        "\n",
        "wPedo_ori = load_data(DataType.wPedo)\n",
        "wPedo_ori = shift_lifelog_date(wPedo_ori, target_hours=SLEEP_HOURS)\n",
        "\n",
        "wPedo2 = (\n",
        "    wPedo_ori\n",
        "    .groupby([\"subject_id\", \"lifelog_date\"], group_keys=False, as_index=False, sort=False, observed=True)\n",
        "    .apply(process_mPedo)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "describe_df(wPedo2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msyUxfoLgpq1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLPmg7oWhFMa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db44ae3XDtKE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_sSEhnDtN5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbaes4GnDtuy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahIQqHGXGSez"
      },
      "source": [
        "### ✔️ Sleeptime 일어난 건수\n",
        "\n",
        "- Sleeptime에 (mLight 주변 밝기), (wLight 앰비언트 라이트) 변화 건수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFvyBXsEGPXi"
      },
      "outputs": [],
      "source": [
        "def compute_night_awake_features(df, prefix):\n",
        "\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = df['timestamp'].astype(str).str[:10]\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "\n",
        "    # 00시~06시 필터\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df_night = df[(df['hour'] >= 0) & (df['hour'] < 6)].copy()\n",
        "\n",
        "    # 깨어있는 분 계산\n",
        "    df_night['awake_minute'] = (df_night[prefix] > 0).astype(int)\n",
        "\n",
        "    # 깨어난 횟수 계산 (0 → 양수 전환)\n",
        "    def count_awake_blocks(x):\n",
        "        return ((x > 0) & (x.shift(fill_value=0) == 0)).sum()\n",
        "\n",
        "    # 그룹별 집계\n",
        "    result = df_night.groupby(['subject_id', 'lifelog_date']).agg(\n",
        "        awake_minutes=('awake_minute', 'sum'),\n",
        "        awake_blocks=(prefix, count_awake_blocks)\n",
        "    ).reset_index()\n",
        "\n",
        "    # 컬럼명 변경\n",
        "    result = result.rename(columns={\n",
        "        'awake_minutes': f'{prefix}_awake_minutes',\n",
        "        'awake_blocks': f'{prefix}_awake_blocks'\n",
        "    })\n",
        "\n",
        "    # train에 결과 합치기 위해서 -1 day 하기\n",
        "    result['lifelog_date'] = pd.to_datetime(result['lifelog_date'])\n",
        "    result['lifelog_date'] = result['lifelog_date'] + pd.Timedelta(days=-1)\n",
        "    result['lifelog_date'] = result['lifelog_date'].astype(str)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CpwIQM4GPbo"
      },
      "outputs": [],
      "source": [
        "mAwakeBlocks = compute_night_awake_features(mLight,'m_light')\n",
        "wAwakeBlocks = compute_night_awake_features(wLight,'w_light')\n",
        "AwakeBlocks = mAwakeBlocks.merge(wAwakeBlocks, on=['subject_id','lifelog_date'], how='outer')\n",
        "AwakeBlocks['light_awake_minutes'] = AwakeBlocks[['m_light_awake_minutes','w_light_awake_minutes']].max(axis=1)\n",
        "AwakeBlocks['light_awake_blocks'] = AwakeBlocks[['m_light_awake_blocks','w_light_awake_blocks']].max(axis=1)\n",
        "\n",
        "# check\n",
        "print(mAwakeBlocks.shape)\n",
        "print(wAwakeBlocks.shape)\n",
        "print(AwakeBlocks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMlyCuPPDt5i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0ICeW88gttt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhcVIyeuguwP"
      },
      "source": [
        "### 📌 merge 데이터\n",
        "- train, test 기간 서로 겹침"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylxgRVjO0cPS"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/data/ch2025_metrics_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/ch2025_submission_sample.csv')\n",
        "\n",
        "# 일자변수 타입 변환\n",
        "mACStatus2['lifelog_date'] = mACStatus2['lifelog_date'].astype(str)\n",
        "mActivity21['lifelog_date'] = mActivity21['lifelog_date'].astype(str)\n",
        "mActivity22['lifelog_date'] = mActivity22['lifelog_date'].astype(str)\n",
        "mAmbience2['lifelog_date'] = mAmbience2['lifelog_date'].astype(str)\n",
        "mBle2['lifelog_date'] = mBle2['lifelog_date'].astype(str)\n",
        "mGps2['lifelog_date'] = mGps2['lifelog_date'].astype(str)\n",
        "mLight21['lifelog_date'] = mLight21['lifelog_date'].astype(str)\n",
        "mLight22['lifelog_date'] = mLight22['lifelog_date'].astype(str)\n",
        "mLight23['lifelog_date'] = mLight23['lifelog_date'].astype(str)\n",
        "mScreenStatus2['lifelog_date'] = mScreenStatus2['lifelog_date'].astype(str)\n",
        "mUsageStats2['lifelog_date'] = mUsageStats2['lifelog_date'].astype(str)\n",
        "mWifi2['lifelog_date'] = mWifi2['lifelog_date'].astype(str)\n",
        "wHr2['lifelog_date'] = wHr2['lifelog_date'].astype(str)\n",
        "wLight2['lifelog_date'] = wLight2['lifelog_date'].astype(str)\n",
        "wPedo2['lifelog_date'] = wPedo2['lifelog_date'].astype(str)\n",
        "\n",
        "# ---- new ----\n",
        "\n",
        "AwakeBlocks['lifelog_date'] = AwakeBlocks['lifelog_date'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyqyR1HyKtYM"
      },
      "outputs": [],
      "source": [
        "df_list = [\n",
        "    mACStatus2,       # 1\n",
        "    mActivity21,       # 2\n",
        "    mActivity22,       # 2\n",
        "    mAmbience2,       # 3\n",
        "    mBle2,            # 4\n",
        "    mGps2,            # 5\n",
        "    mLight21,          # 6\n",
        "    mLight22,          # 6\n",
        "    mLight23,          # 6\n",
        "    mScreenStatus2,   # 7\n",
        "    mUsageStats2,     # 8\n",
        "    mWifi2,           # 9\n",
        "    wHr2,             # 10\n",
        "    wLight2,          # 11\n",
        "    wPedo2,           # 12\n",
        "    # ---- new ----\n",
        "    AwakeBlocks\n",
        "]\n",
        "\n",
        "data = reduce(lambda left, right: pd.merge(left, right, on=['subject_id', 'lifelog_date'], how='outer'), df_list)\n",
        "data['lifelog_date'] = data['lifelog_date'].astype(str)\n",
        "\n",
        "# 중복체크\n",
        "print(data.shape)\n",
        "print(data[['subject_id','lifelog_date']].drop_duplicates().shape)\n",
        "\n",
        "# merge\n",
        "train2 = train.merge(data, on=['subject_id','lifelog_date'], how='left')\n",
        "test2 = test.merge(data, on=['subject_id','lifelog_date'], how='left')\n",
        "\n",
        "# 저장\n",
        "print('# train  shape:',train.shape)\n",
        "print('# train2 shape:',test2.shape)\n",
        "print('# test   shape:',test.shape)\n",
        "print('# test2  shape:',test2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJHeu7wQpSdL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JApa_DpNpSf8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFN_nDFO8bPE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO4m6vmGjlkC"
      },
      "source": [
        "## 📦 학습(전처리 파일 불러오기)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4qv4t3ULZsR"
      },
      "outputs": [],
      "source": [
        "train = train2.copy()\n",
        "test = test2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85lZxaHllP-B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DryVNJfxoP8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IStr2HXVgRd"
      },
      "source": [
        "### 🔥 이미지 파생변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ5plBR_Ve7k"
      },
      "outputs": [],
      "source": [
        "img_model = 'resnet50' # resnet50, xception, resnext101_32x32d efficientnet_b0 convnext_base convnext_tiny\n",
        "\n",
        "# 데이터 읽기\n",
        "img_features = pd.read_csv(f'{PATH}/img_features_ch5_sleeptime_{img_model}_5.csv')\n",
        "img_features = img_features[sorted(img_features.columns,reverse=True)]\n",
        "img_features.columns = ['image_path']+['img'+i for i in img_features.columns if i not in ['image_path']]\n",
        "\n",
        "# 정규표현식으로 추출\n",
        "img_features['subject_id'] = img_features['image_path'].str.extract(r'user(id\\d+)_')[0]\n",
        "img_features['lifelog_date'] = img_features['image_path'].str.extract(r'_(\\d{4}-\\d{2}-\\d{2})_')[0]\n",
        "\n",
        "# 정렬\n",
        "img_features = img_features.sort_values(['subject_id', 'lifelog_date'])\n",
        "\n",
        "# # lag\n",
        "# for lag in [1, 2]:\n",
        "#     img_features[f'img0_lag{lag}'] = img_features.groupby('subject_id')['img0'].shift(lag)\n",
        "#     img_features[f'img1_lag{lag}'] = img_features.groupby('subject_id')['img1'].shift(lag)\n",
        "\n",
        "# check\n",
        "img_features = img_features.drop(columns=['image_path'])\n",
        "print(len(img_features))\n",
        "display(img_features.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC-W7SFpVe_q"
      },
      "outputs": [],
      "source": [
        "# add img features\n",
        "train['lifelog_date'] = train['lifelog_date'].astype(str)\n",
        "test['lifelog_date'] = test['lifelog_date'].astype(str)\n",
        "train = train.merge(img_features,on=['subject_id','lifelog_date'],how='left')\n",
        "test = test.merge(img_features,on=['subject_id','lifelog_date'],how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptqByvx6K1Zz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st8rfdHRIV6i"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DW3hjnwSIXVt"
      },
      "source": [
        "### ✔️ 추정수면효율\n",
        "- 추정수면효율 (S2) : (불끈 시간 - 핸드폰 이용한 마지막 시간) / 추정수면시간"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_Q-BsnUIWIy"
      },
      "outputs": [],
      "source": [
        "def calculate_sleep_duration_min(sleep_time, wake_time):\n",
        "    \"\"\"\n",
        "    취침 시각(sleep_time)과 기상 시각(wake_time)을 입력받아 수면 시간(분) 반환\n",
        "    단위는 float 시간 (예: 23.5, 6.25)\n",
        "    \"\"\"\n",
        "    if pd.isna(sleep_time) or pd.isna(wake_time):\n",
        "        return None\n",
        "    if wake_time < sleep_time:\n",
        "        wake_time += 24  # 자정 넘긴 경우 보정\n",
        "    duration = (wake_time - sleep_time) * 60\n",
        "    return round(duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0syM1G_IWMJ"
      },
      "outputs": [],
      "source": [
        "train['불끈시간부터기상시간'] = train.apply(lambda x: calculate_sleep_duration_min(x['lights_off_time'],x['wake_time']),axis=1)\n",
        "test['불끈시간부터기상시간'] = test.apply(lambda x: calculate_sleep_duration_min(x['lights_off_time'],x['wake_time']),axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkjezDwrIWPd"
      },
      "outputs": [],
      "source": [
        "train['추정수면효율'] = train['불끈시간부터기상시간']/train['sleep_duration_min']\n",
        "test['추정수면효율'] = test['불끈시간부터기상시간']/test['sleep_duration_min']\n",
        "\n",
        "# 이상값 제거\n",
        "train['추정수면효율'] = np.where(train['추정수면효율']<-5,np.nan,train['추정수면효율'])\n",
        "test['추정수면효율'] = np.where(test['추정수면효율']<-5,np.nan,test['추정수면효율'])\n",
        "train['추정수면효율'] = np.where(train['추정수면효율']>5,np.nan,train['추정수면효율'])\n",
        "test['추정수면효율'] = np.where(test['추정수면효율']>55,np.nan,test['추정수면효율'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJEMl83rVwxq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYG8tHPsrogR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kQ_O5iAVpHH"
      },
      "source": [
        "### ✔️ 추가 파생변수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjG-oEFkDskF"
      },
      "outputs": [],
      "source": [
        "# sleep duration\n",
        "\n",
        "train['sleep_time_m_light_sleep_time'] = train['sleep_time'] - train['light_sleep_time']\n",
        "test['sleep_time_m_light_sleep_time'] = test['sleep_time'] - test['light_sleep_time']\n",
        "\n",
        "train['wake__time_m_light_wake__time'] = train['wake_time'] - train['light_wake_time']\n",
        "test['wake__time_m_light_wake__time'] = test['wake_time'] - test['light_wake_time']\n",
        "\n",
        "train['sleep_duration_min_m_light_sleep_duration_min'] = train['sleep_duration_min'] - train['light_sleep_duration_min']\n",
        "test['sleep_duration_min_m_light_sleep_duration_min'] = test['sleep_duration_min'] - test['light_sleep_duration_min']\n",
        "\n",
        "train['sleep_time_d_light_sleep_time'] = train['sleep_time'] / train['light_sleep_time']\n",
        "test['sleep_time_d_light_sleep_time'] = test['sleep_time'] / test['light_sleep_time']\n",
        "\n",
        "train['wake__time_d_light_wake__time'] = train['wake_time'] / train['light_wake_time']\n",
        "test['wake__time_d_light_wake__time'] = test['wake_time'] / test['light_wake_time']\n",
        "\n",
        "train['sleep_duration_min_d_light_sleep_duration_min'] = train['sleep_duration_min'] / train['light_sleep_duration_min']\n",
        "test['sleep_duration_min_d_light_sleep_duration_min'] = test['sleep_duration_min'] / test['light_sleep_duration_min']\n",
        "\n",
        "train['sleep_time_min'] = train[['sleep_time','light_sleep_time']].min(axis=1)\n",
        "train['sleep_time_max'] = train[['sleep_time','light_sleep_time']].max(axis=1)\n",
        "\n",
        "train['wake_time_min'] = train[['wake_time','light_wake_time']].min(axis=1)\n",
        "train['wake_time_max'] = train[['wake_time','light_wake_time']].max(axis=1)\n",
        "\n",
        "train['sleep_duration_min_min'] = train[['sleep_duration_min','light_sleep_duration_min']].min(axis=1)\n",
        "train['sleep_duration_min_max'] = train[['sleep_duration_min','light_sleep_duration_min']].max(axis=1)\n",
        "\n",
        "test['sleep_time_min'] = test[['sleep_time','light_sleep_time']].min(axis=1)\n",
        "test['sleep_time_max'] = test[['sleep_time','light_sleep_time']].max(axis=1)\n",
        "\n",
        "test['wake_time_min'] = test[['wake_time','light_wake_time']].min(axis=1)\n",
        "test['wake_time_max'] = test[['wake_time','light_wake_time']].max(axis=1)\n",
        "\n",
        "test['sleep_duration_min_min'] = test[['sleep_duration_min','light_sleep_duration_min']].min(axis=1)\n",
        "test['sleep_duration_min_max'] = test[['sleep_duration_min','light_sleep_duration_min']].max(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lI616WgshZtT"
      },
      "outputs": [],
      "source": [
        "# 요일 컬럼 추가 (예: 월요일, 화요일, ...)\n",
        "train['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\n",
        "test['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n",
        "\n",
        "# 요일\n",
        "weekday_map = {\n",
        "    0: '월요일', 1: '화요일', 2: '수요일', 3: '목요일',\n",
        "    4: '금요일', 5: '토요일', 6: '일요일'\n",
        "}\n",
        "train['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "test['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "\n",
        "# 월\n",
        "train['month'] = train['lifelog_date'].dt.month\n",
        "test['month'] = test['lifelog_date'].dt.month\n",
        "\n",
        "# weekend\n",
        "train['weekend'] = np.where(train['weekday'].isin(['토요일','일요일']),1,0)\n",
        "test['weekend'] = np.where(test['weekday'].isin(['토요일','일요일']),1,0)\n",
        "\n",
        "# weekend\n",
        "train['weekend2'] = np.where(train['weekday'].isin(['토요일','금요일']),1,0)\n",
        "test['weekend2'] = np.where(test['weekday'].isin(['토요일','금요일']),1,0)\n",
        "\n",
        "# weekend\n",
        "train['weekend3'] = np.where(train['weekday'].isin(['토요일','금요일','일요일']),1,0)\n",
        "test['weekend3'] = np.where(test['weekday'].isin(['토요일','금요일','일요일']),1,0)\n",
        "\n",
        "# 공휴일\n",
        "공휴일 = [\n",
        "     '2024-08-15'\n",
        "    ,'2024-09-16'\n",
        "    ,'2024-09-17'\n",
        "    ,'2024-09-18'\n",
        "    ,'2024-10-03'\n",
        "    ,'2024-10-09'\n",
        "]\n",
        "train['공휴일'] = np.where(train['lifelog_date'].isin(공휴일),1,0)\n",
        "test['공휴일'] = np.where(test['lifelog_date'].isin(공휴일),1,0)\n",
        "\n",
        "# 주말 + 공휴일 묶어주기\n",
        "train['weekend_holilday'] = np.where( ((train['weekend']==0) & (train['공휴일']==1)), 1, train['weekend'])\n",
        "test['weekend_holilday'] = np.where( ((test['weekend']==0) & (test['공휴일']==1)), 1, test['weekend'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5zBdTUNJAWD"
      },
      "outputs": [],
      "source": [
        "def add_prev_day_flag(df):\n",
        "    df = df.copy()\n",
        "    df['lifelog_date'] = pd.to_datetime(df['lifelog_date'])\n",
        "\n",
        "    # 각 subject_id별로 전날 날짜 만들기\n",
        "    df['prev_day'] = df['lifelog_date'] - pd.Timedelta(days=1)\n",
        "\n",
        "    # subject_id + 날짜 기준으로 원본 키 구성\n",
        "    key_set = set(zip(df['subject_id'], df['lifelog_date']))\n",
        "\n",
        "    # 전날 데이터가 존재하면 1, 없으면 0\n",
        "    df['has_prev_day_data'] = df[['subject_id', 'prev_day']].apply(\n",
        "        lambda row: 1 if (row['subject_id'], row['prev_day']) in key_set else 0, axis=1\n",
        "    )\n",
        "\n",
        "    return df.drop(columns=['prev_day'])\n",
        "\n",
        "train = add_prev_day_flag(train)\n",
        "test = add_prev_day_flag(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHTfSdRPV-7p"
      },
      "outputs": [],
      "source": [
        "# 추정휴가\n",
        "def rule_based_sum(x):\n",
        "    rules = (\n",
        "        #  (x['sleep_duration_min'] > (x['avg_sleep_duration']))\n",
        "        #  (x['sleep_duration_min'] > (x['avg_sleep_duration']+60))\n",
        "          (x['sleep_duration_diff']>0)\n",
        "        & (x['week_type'] == 'weekday')\n",
        "        # & (x['month'].isin([7,8]))\n",
        "    )\n",
        "    return rules\n",
        "\n",
        "train['vacation'] = train.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "test['vacation'] = test.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "\n",
        "# check\n",
        "test.groupby(['subject_id'])['vacation'].sum().head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNn-DwY620Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XpSKreip20JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📦 저장"
      ],
      "metadata": {
        "id": "xY4_Hcbp20eG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCKYiM1H0aGF"
      },
      "outputs": [],
      "source": [
        "# 저장\n",
        "train.to_parquet(f\"{PATH}/train_hjy_0603_v1.parquet\")\n",
        "test.to_parquet(f\"{PATH}/test_hjy_0603_v1.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r1qszJndpcg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ABtAS_Tg2eB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8Cy2M4Xg2iI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmKky7O2wRSx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}