{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/The-4th-ETRI-AI-Human-Understanding-Competition/blob/main/202_%EC%8B%A4%ED%97%98_v2_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTgURBTcpY0Q"
      },
      "source": [
        "> title : ì œ 4íšŒ ETRI íœ´ë¨¼ì´í•´ ì¸ê³µì§€ëŠ¥ ë…¼ë¬¸ê²½ì§„ëŒ€íšŒ <br>\n",
        "> author : hjy <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QhncbejZIfV"
      },
      "source": [
        "In our study, we used smartphones, smartwatches, sleep sensors, and self-recording apps to collect daily life logs and sleep health records of study participants in 2024.The data collection procedures and methods followed a similar approach to those used in previous studies. Here, we puï»¿blicly provide the following 12 data items, which comprise a total of 700 days' worth of lifelog data, strictly for non-commercial and academic research purposes only.\n",
        "- mACStatus: Indicates whether the smartphone is currently being charged.\n",
        "- mActivity: Value calculated by the Google Activity Recognition API.\n",
        "- mAmbience: Ambient sound identification labels and their respective probabilities.\n",
        "- mBle: Bluetooth devices around individual subject.\n",
        "- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n",
        "- mLight: Ambient light measured by the smartphone.\n",
        "- mScreenStatus: Indicates whether the smartphone screen is in use.\n",
        "- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n",
        "- mWifi: Wifi devices around individual subject.\n",
        "- wHr: Heart rate readings recorded by the smartwatch.\n",
        "- wLight: Ambient light measured by the smartwatch.\n",
        "- wPedo: Step data recorded by the smartwatch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkY5S7k0ZLFG"
      },
      "source": [
        "For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records. Each metric consists of values categorized into either two levels (0, 1) or three levels (0, 1, 2), depending on the specific metric. The detailed classification criteria for each metric's levels will be provided in a separate document.These\n",
        "metrics assign a value of 0 for sleep records that do not meet the recommended guidelines.For instance, the first questionnaire metric (Q1) is assigned a value of 1 on days when an\n",
        "individualâ€™s self-reported sleep quality exceeds their average over the experimental period, and 0 when it\n",
        "falls below that average. Similarly, the second and third metrics (Q2 and Q3) are assigned a value of 0\n",
        "on days when the participantâ€™s fatigue and stress levels, respectively, exceed their average, and a value of\n",
        "1 when these levels are below average.\n",
        "\n",
        "- Q1: Overall sleep quality as perceived by a subject immediately after waking up.\n",
        "- Q2: Physical fatigue of a subject just before sleep.\n",
        "- Q3: Stress level experienced by a subject just before sleep.\n",
        "- S1: Adherence to sleep guidelines for total sleep time (TST).\n",
        "- S2: Adherence to sleep guidelines for sleep efficiency (SE).\n",
        "- S3: Adherence to sleep guidelines for sleep onset latency (SOL, or SL).\n",
        "\n",
        "ìˆ˜ë©´ ê±´ê°•, í”¼ë¡œ, ìŠ¤íŠ¸ë ˆìŠ¤ ì˜ˆì¸¡ì„ ìœ„í•œ í•™ìŠµ ëª¨ë¸ì„ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•´, ìˆ˜ë©´ ì„¼ì„œ ë°ì´í„°ì™€ ìê¸° ë³´ê³ ì‹ ì„¤ë¬¸ ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒì˜ 6ê°€ì§€ ì§€í‘œë¥¼ ë„ì¶œí–ˆìŠµë‹ˆë‹¤.\n",
        "ê° ì§€í‘œëŠ” í•´ë‹¹ í•­ëª©ì— ë”°ë¼ ë‘ ìˆ˜ì¤€(0, 1) ë˜ëŠ” ì„¸ ìˆ˜ì¤€(0, 1, 2)ìœ¼ë¡œ êµ¬ë¶„ëœ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
        "ê° ì§€í‘œì˜ ì„¸ë¶€ ë¶„ë¥˜ ê¸°ì¤€ì€ ë³„ë„ì˜ ë¬¸ì„œì—ì„œ ì œê³µë  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
        "\n",
        "- Q1: ê¸°ìƒ ì§í›„ ë³¸ì¸ì´ ì¸ì§€í•œ ì „ë°˜ì ì¸ ìˆ˜ë©´ì˜ ì§ˆ\n",
        " - 0: ê°œì¸ í‰ê·  ì´í•˜\n",
        " - 1: ê°œì¸ í‰ê·  ì´ìƒ\n",
        "- Q2: ì·¨ì¹¨ ì§ì „ ë³¸ì¸ì´ ëŠë‚€ ì‹ ì²´ì  í”¼ë¡œ ìˆ˜ì¤€\n",
        " - 0: ë†’ì€ í”¼ë¡œ ìˆ˜ì¤€\n",
        " - 1: ë‚®ì€ í”¼ë¡œ ìˆ˜ì¤€\n",
        "- Q3: ì·¨ì¹¨ ì§ì „ ë³¸ì¸ì´ ëŠë‚€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        " - 0: ë†’ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        " - 1: ë‚®ì€ ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€\n",
        "- S1: ì´ ìˆ˜ë©´ ì‹œê°„(TST) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ 3LEVELS\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ë¶€ë¶„ì  ì¤€ìˆ˜\n",
        " - 2: ê°€ì´ë“œë¼ì¸ ì™„ì „ ì¤€ìˆ˜\n",
        "- S2: ìˆ˜ë©´ íš¨ìœ¨(SE) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ ì—¬ë¶€\n",
        "- (SE: ì ìë¦¬ì— ëˆ„ì›Œ ìˆì—ˆë˜ ì „ì²´ ì‹œê°„ ëŒ€ë¹„, ì‹¤ì œë¡œ ì ë“  ì‹œê°„ì˜ ë¹„ìœ¨)\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜\n",
        "- S3: ìˆ˜ë©´ ì ë“¤ê¸° ì§€ì—° ì‹œê°„(SOL ë˜ëŠ” SL) ê°€ì´ë“œë¼ì¸ì„ ì¤€ìˆ˜í–ˆëŠ”ì§€ ì—¬ë¶€\n",
        "- (SOL: ì ìë¦¬ì— ëˆ„ìš´ ìˆœê°„ë¶€í„° ì‹¤ì œë¡œ ì ë“œëŠ” ë°ê¹Œì§€ ê±¸ë¦° ì‹œê°„)\n",
        " - 0: ê°€ì´ë“œë¼ì¸ ë¯¸ì¤€ìˆ˜\n",
        " - 1: ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVNXLQtLU6X"
      },
      "source": [
        "### ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN6iwVhQpR_a",
        "outputId": "f9c08795-c5c6-4c0a-c4bf-9b59344b7550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haversine\n",
            "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.9.0\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "! pip install haversine\n",
        "! pip install optuna\n",
        "! pip install category_encoders\n",
        "! pip install timm\n",
        "import timm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "from scipy.stats import entropy\n",
        "from haversine import haversine  # ì„¤ì¹˜ í•„ìš”: pip install haversine\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvEVmxWsRH4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "from tqdm import tqdm  # â† ì¶”ê°€\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from datetime import time\n",
        "from datetime import timedelta\n",
        "from functools import reduce\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
        "import lightgbm as lgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# seed ê³ ì •\n",
        "SD = 42\n",
        "random.seed(SD)\n",
        "np.random.seed(SD)\n",
        "os.environ['PYTHONHASHSEED'] = str(SD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iVOoFq7pSCM",
        "outputId": "576d7ab9-73ff-4aed-fee6-19ab1b7455c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIbC9LQkv6T4"
      },
      "outputs": [],
      "source": [
        "# pandas ì˜µì…˜\n",
        "pd.set_option('display.max_columns', 999)\n",
        "pd.set_option('display.max_rows', 999)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '%0.4f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38uzdH-UYh_3"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_ZQfubWYiCk"
      },
      "outputs": [],
      "source": [
        "def correct_lifelog_date_for_midnight(df, timestamp_col='timestamp', lifelog_col='lifelog_date'):\n",
        "    df = df.copy()\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
        "    df[lifelog_col] = pd.to_datetime(df[lifelog_col])\n",
        "\n",
        "    # ì¡°ê±´: timestampì˜ ì‹œ(hour)ê°€ 0~5ì‹œì¸ ê²½ìš°ë§Œ í•˜ë£¨ ì°¨ê°\n",
        "    mask = (df[timestamp_col].dt.hour >= 0) & (df[timestamp_col].dt.hour < 6)\n",
        "    df.loc[mask, lifelog_col] = df.loc[mask, lifelog_col] - pd.Timedelta(days=1)\n",
        "\n",
        "    # lifelog_dateë¥¼ ë¬¸ìì—´ë¡œ ë°”ê¾¸ëŠ” ê²½ìš°\n",
        "    df[lifelog_col] = df[lifelog_col].dt.date.astype(str)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ikO0GN_KxyQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "string = \"\"\"\n",
        "subject_id\tsleep_date\n",
        "id01\t2024-07-24\n",
        "id01\t2024-07-27\n",
        "id01\t2024-08-18\n",
        "id01\t2024-08-19\n",
        "id01\t2024-08-20\n",
        "id01\t2024-08-21\n",
        "id01\t2024-08-22\n",
        "id01\t2024-08-24\n",
        "id01\t2024-08-25\n",
        "id01\t2024-08-26\n",
        "id01\t2024-08-27\n",
        "id01\t2024-08-28\n",
        "id01\t2024-08-29\n",
        "id01\t2024-08-30\n",
        "id02\t2024-08-23\n",
        "id02\t2024-08-24\n",
        "id02\t2024-09-16\n",
        "id02\t2024-09-17\n",
        "id02\t2024-09-19\n",
        "id02\t2024-09-20\n",
        "id02\t2024-09-21\n",
        "id02\t2024-09-22\n",
        "id02\t2024-09-23\n",
        "id02\t2024-09-24\n",
        "id02\t2024-09-25\n",
        "id02\t2024-09-26\n",
        "id02\t2024-09-27\n",
        "id02\t2024-09-28\n",
        "id03\t2024-08-30\n",
        "id03\t2024-09-01\n",
        "id03\t2024-09-02\n",
        "id03\t2024-09-03\n",
        "id03\t2024-09-05\n",
        "id03\t2024-09-06\n",
        "id03\t2024-09-07\n",
        "id04\t2024-09-03\n",
        "id04\t2024-09-04\n",
        "id04\t2024-09-05\n",
        "id04\t2024-09-06\n",
        "id04\t2024-09-07\n",
        "id04\t2024-09-08\n",
        "id04\t2024-09-09\n",
        "id04\t2024-10-08\n",
        "id04\t2024-10-09\n",
        "id04\t2024-10-10\n",
        "id04\t2024-10-11\n",
        "id04\t2024-10-12\n",
        "id04\t2024-10-13\n",
        "id04\t2024-10-14\n",
        "id05\t2024-10-19\n",
        "id05\t2024-10-23\n",
        "id05\t2024-10-24\n",
        "id05\t2024-10-25\n",
        "id05\t2024-10-26\n",
        "id05\t2024-10-27\n",
        "id05\t2024-10-28\n",
        "id06\t2024-07-25\n",
        "id06\t2024-07-26\n",
        "id06\t2024-07-27\n",
        "id06\t2024-07-28\n",
        "id06\t2024-07-29\n",
        "id06\t2024-07-30\n",
        "id06\t2024-07-31\n",
        "id07\t2024-07-07\n",
        "id07\t2024-07-08\n",
        "id07\t2024-07-09\n",
        "id07\t2024-07-10\n",
        "id07\t2024-07-11\n",
        "id07\t2024-07-12\n",
        "id07\t2024-07-13\n",
        "id07\t2024-07-30\n",
        "id07\t2024-08-01\n",
        "id07\t2024-08-02\n",
        "id07\t2024-08-03\n",
        "id07\t2024-08-04\n",
        "id07\t2024-08-05\n",
        "id07\t2024-08-06\n",
        "id08\t2024-08-28\n",
        "id08\t2024-08-29\n",
        "id08\t2024-08-30\n",
        "id08\t2024-08-31\n",
        "id08\t2024-09-01\n",
        "id08\t2024-09-02\n",
        "id08\t2024-09-04\n",
        "id09\t2024-08-02\n",
        "id09\t2024-08-22\n",
        "id09\t2024-08-23\n",
        "id09\t2024-08-24\n",
        "id09\t2024-08-25\n",
        "id09\t2024-08-27\n",
        "id09\t2024-08-28\n",
        "id09\t2024-08-29\n",
        "id09\t2024-08-30\n",
        "id09\t2024-08-31\n",
        "id09\t2024-09-01\n",
        "id09\t2024-09-02\n",
        "id09\t2024-09-03\n",
        "id09\t2024-09-04\n",
        "id10\t2024-08-28\n",
        "id10\t2024-08-30\n",
        "id10\t2024-08-31\n",
        "id10\t2024-09-01\n",
        "id10\t2024-09-02\n",
        "id10\t2024-09-03\n",
        "id10\t2024-09-06\n",
        "\"\"\"\n",
        "\n",
        "# DataFrame ìƒì„±\n",
        "valid_ids = pd.read_csv(StringIO(string), sep='\\t')\n",
        "valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EvDe55ejzKR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVuRMUMlXQOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQgtvPb3jzQv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEHsA6naKx0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodxdJFiv_DJ"
      },
      "source": [
        "### ğŸ“¦ ë°ì´í„° ì½ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw0cx3wwpSE2"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/data/ch2025_data_items/'\n",
        "\n",
        "# 1\n",
        "mACStatus = pd.read_parquet(path+'ch2025_mACStatus.parquet')\n",
        "mActivity = pd.read_parquet(path+'ch2025_mActivity.parquet')\n",
        "mAmbience = pd.read_parquet(path+'ch2025_mAmbience.parquet')\n",
        "mBle = pd.read_parquet(path+'ch2025_mBle.parquet')\n",
        "mGps = pd.read_parquet(path+'ch2025_mGps.parquet')\n",
        "mLight = pd.read_parquet(path+'ch2025_mLight.parquet')\n",
        "mScreenStatus = pd.read_parquet(path+'ch2025_mScreenStatus.parquet')\n",
        "mUsageStats = pd.read_parquet(path+'ch2025_mUsageStats.parquet')\n",
        "mWifi = pd.read_parquet(path+'ch2025_mWifi.parquet')\n",
        "wHr = pd.read_parquet(path+'ch2025_wHr.parquet')\n",
        "wLight = pd.read_parquet(path+'ch2025_wLight.parquet')\n",
        "wPedo = pd.read_parquet(path+'ch2025_wPedo.parquet')\n",
        "\n",
        "# 2\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/ch2025_metrics_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/ch2025_submission_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk45v0V5xiay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ce508f-2602-4010-9785-5f87d6e17d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.56 s, sys: 906 ms, total: 8.46 s\n",
            "Wall time: 8.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "mACStatus['lifelog_date'] = mACStatus['timestamp'].astype(str).str[:10]\n",
        "mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_labels_and_probs(row):\n",
        "#     items = row['m_ambience']\n",
        "#     labels = [item[0] for item in items]\n",
        "#     probs = [item[1] for item in items]\n",
        "#     return pd.Series({'labels': labels, 'prob': probs})\n",
        "\n",
        "# mAmbience[['labels', 'prob']]  = mAmbience.apply(extract_labels_and_probs, axis=1)\n",
        "# mAmbience['lifelog_date'] = mAmbience['timestamp'].astype(str).str[:10]\n",
        "# mAmbience = mAmbience.drop(columns=['m_ambience'])\n",
        "\n",
        "# def extract_mble_info(row):\n",
        "#     m_data = row['m_ble']\n",
        "#     address = [item['address'] for item in m_data]\n",
        "#     device_class = [item['device_class'] for item in m_data]\n",
        "#     rssi = [item['rssi'] for item in m_data]\n",
        "#     return pd.Series({'address': address, 'device_class': device_class, 'rssi': rssi})\n",
        "\n",
        "# mBle[['address','device_class','rssi']] = mBle.apply(extract_mble_info, axis=1)\n",
        "# mBle['lifelog_date'] = mBle['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_gps_info(row):\n",
        "#     m_data = row['m_gps']\n",
        "#     altitude = [item['altitude'] for item in m_data]\n",
        "#     latitude = [item['latitude'] for item in m_data]\n",
        "#     longitude = [item['longitude'] for item in m_data]\n",
        "#     speed = [item['speed'] for item in m_data]\n",
        "#     return pd.Series({'altitude': altitude, 'latitude': latitude, 'longitude': longitude, 'speed': speed})\n",
        "\n",
        "# mGps[['altitude','latitude','longitude','speed']] = mGps.apply(extract_gps_info, axis=1)\n",
        "# mGps['lifelog_date'] = mGps['timestamp'].astype(str).str[:10]\n",
        "# mGps = mGps.drop(columns=['m_gps'])\n",
        "\n",
        "mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\n",
        "mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_mUsageStats_info(row):\n",
        "#     m_data = row['m_usage_stats']\n",
        "#     app_name = [item['app_name'] for item in m_data]\n",
        "#     total_time = [item['total_time'] for item in m_data]\n",
        "#     return pd.Series({'app_name': app_name, 'total_time': total_time})\n",
        "\n",
        "# mUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\n",
        "# mUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_wifi_info(row):\n",
        "#     wifi_data = row['m_wifi']\n",
        "#     bssids = [item['bssid'] for item in wifi_data]\n",
        "#     rssis = [item['rssi'] for item in wifi_data]\n",
        "#     return pd.Series({'bssid': bssids, 'rssi': rssis})\n",
        "\n",
        "# mWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\n",
        "# mWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\n",
        "\n",
        "wHr['lifelog_date'] = wHr['timestamp'].astype(str).str[:10]\n",
        "wLight['lifelog_date'] = wLight['timestamp'].astype(str).str[:10]\n",
        "wPedo['lifelog_date'] = wPedo['timestamp'].astype(str).str[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp0et2XoiBZ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE-06HN6gtqy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBZKGmxSRBQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAyS_RTHjjp3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp40u0R88PY_"
      },
      "source": [
        "### ğŸ“Œ ì´ë¯¸ì§€ ìƒì„±\n",
        "- spleeptimeë§Œ ì¶”ì¶œ (00ì‹œë¶€í„° 06ì‹œê¹Œì§€)\n",
        "- ì°¸ê³  : https://github.com/seongjiko/Pixleep/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-qgvZd-8cir"
      },
      "outputs": [],
      "source": [
        "def filter_by_group_size(df, group_cols=['subject_id', 'lifelog_date']):\n",
        "    # ê·¸ë£¹ë³„ ê±´ìˆ˜ ê³„ì‚°\n",
        "    group_counts = df.groupby(group_cols).size().reset_index(name='count')\n",
        "    # í‰ê·  ê±´ìˆ˜ ê³„ì‚°\n",
        "    mean_count = group_counts['count'].mean()\n",
        "    # í‰ê·  ì´ˆê³¼ ê·¸ë£¹ë§Œ ì¶”ì¶œ\n",
        "    valid_groups = group_counts[group_counts['count'] > mean_count*0.5][group_cols]\n",
        "    # ì›ë³¸ê³¼ inner joinìœ¼ë¡œ í•„í„°ë§\n",
        "    return df.merge(valid_groups, on=group_cols, how='inner')\n",
        "\n",
        "def make_timestamps_unique(df, timestamp_col='timestamp'):\n",
        "    # 'timestamp' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "    df = df.sort_values(by=[timestamp_col])\n",
        "    # ê° 'timestamp'ê°€ ì¤‘ë³µëœ íšŸìˆ˜ë¥¼ ì„¸ì–´ ë‚˜ë…¸ì´ˆ ë‹¨ìœ„ë¡œ ì¦ê°€ì‹œí‚´\n",
        "    df[timestamp_col] = df[timestamp_col] + pd.to_timedelta(df.groupby(timestamp_col).cumcount(), unit='ns')\n",
        "    return df\n",
        "\n",
        "def average_list_columns(df, list_columns, pk_cols=['subject_id', 'lifelog_date']):\n",
        "\n",
        "    for col in list_columns:\n",
        "\n",
        "        def safe_mean(x):\n",
        "            if isinstance(x, list):\n",
        "                return np.mean(x) if len(x) > 0 else np.nan\n",
        "            elif isinstance(x, (int, float, np.integer, np.floating, type(None))):\n",
        "                return x\n",
        "            elif isinstance(x, (np.ndarray, pd.Series)):\n",
        "                return np.mean(x)\n",
        "            elif pd.api.types.is_scalar(x) and pd.isna(x):\n",
        "                return np.nan\n",
        "            else:\n",
        "                return np.nan\n",
        "\n",
        "        df[col] = df[col].apply(safe_mean)\n",
        "\n",
        "    return df\n",
        "\n",
        "def center_list_values(df, list_columns):\n",
        "    for col in list_columns:\n",
        "        def center(x):\n",
        "            if isinstance(x, list) and len(x) > 0:\n",
        "                mean = np.mean(x)\n",
        "                return [np.round(v - mean,3) for v in x]\n",
        "            return x  # NaNì´ë‚˜ ë¹„ë¦¬ìŠ¤íŠ¸ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
        "        df[col] = df[col].apply(center)\n",
        "    return df\n",
        "\n",
        "def sleeptime_cutter(data): # ì ìëŠ” ì‹œê°„ ë°ì´í„°ê°€ ë” ì¤‘ìš”í•œì§€ ì‹¤í—˜(ğŸ”¥ğŸ”¥ğŸ”¥)\n",
        "\n",
        "    data_filtered = data.copy()\n",
        "    data_filtered['timestamp'] = pd.to_datetime(data_filtered['timestamp'])\n",
        "    data_filtered['lifelog_date'] = pd.to_datetime(data_filtered['lifelog_date'])\n",
        "\n",
        "    # spleeptimeë§Œ ì¶”ì¶œ (00ì‹œë¶€í„° 06ì‹œê¹Œì§€)\n",
        "    data_filtered = data_filtered[(data_filtered['timestamp'].dt.hour >= 0) & (data_filtered['timestamp'].dt.hour < 6)]\n",
        "\n",
        "    # í•˜ë£¨ ì°¨ê°\n",
        "    data_filtered['timestamp'] = data_filtered['timestamp'] - pd.Timedelta(days=1)\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'] - pd.Timedelta(days=1)\n",
        "    # print('>> D-1 í•˜ë£¨ ì°¨ê°! (lifelog_date ì‹¤ì œ ì¼ìëŠ” D+1 ìƒˆë²½(0~6ì‹œ) ë°ì´í„°ì„)')\n",
        "\n",
        "    # lifelog_dateë¥¼ ë‹¤ì‹œ ë¬¸ìì—´ë¡œ\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'].dt.date.astype(str)\n",
        "\n",
        "    return data_filtered\n",
        "\n",
        "def merge_data_for_group(user, date):\n",
        "\n",
        "    # ë°ì´í„° ë¡œë“œ\n",
        "    # acc_group = mGps.copy()\n",
        "    activity_group = mActivity.copy()\n",
        "    hr_group = wHr.copy()\n",
        "    wPedo_group = wPedo[['subject_id','timestamp','lifelog_date','step']].copy()\n",
        "    mLight_group = mLight[['subject_id','timestamp','lifelog_date','m_light']].copy()\n",
        "    wLight_group = wLight[['subject_id','timestamp','lifelog_date','w_light']].copy()\n",
        "\n",
        "    # ê±´ìˆ˜ê°€ ì—†ëŠ” ì¼ì ì´ìƒì¹˜ë¡œ íŒë‹¨í•˜ê³  ì œì™¸\n",
        "    activity_group = filter_by_group_size(activity_group)\n",
        "    hr_group = filter_by_group_size(hr_group)\n",
        "    wPedo_group = filter_by_group_size(wPedo_group)\n",
        "    mLight_group = filter_by_group_size(mLight_group)\n",
        "    wLight_group = filter_by_group_size(wLight_group)\n",
        "\n",
        "    # sleeptimeë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ (ğŸ”¥ğŸ”¥ğŸ”¥)\n",
        "    # activity_group = sleeptime_cutter(activity_group)\n",
        "    # hr_group = sleeptime_cutter(hr_group)\n",
        "    # wPedo_group = sleeptime_cutter(wPedo_group)\n",
        "    # mLight_group = sleeptime_cutter(mLight_group)\n",
        "    # wLight_group = sleeptime_cutter(wLight_group)\n",
        "\n",
        "    # í•„í„°\n",
        "    activity_group = activity_group.loc[(activity_group['subject_id']==user) & (activity_group['lifelog_date']==date),:]\n",
        "    hr_group = hr_group.loc[(hr_group['subject_id']==user) & (hr_group['lifelog_date']==date),:]\n",
        "    wPedo_group = wPedo_group.loc[(wPedo_group['subject_id']==user) & (wPedo_group['lifelog_date']==date),:]\n",
        "    mLight_group = mLight_group.loc[(mLight_group['subject_id']==user) & (mLight_group['lifelog_date']==date),:]\n",
        "    wLight_group = wLight_group.loc[(wLight_group['subject_id']==user) & (wLight_group['lifelog_date']==date),:]\n",
        "\n",
        "    # ë¦¬ìŠ¤íŠ¸ í‰ê· ê°’ìœ¼ë¡œ ë³€í™˜\n",
        "    # acc_group = average_list_columns(acc_group, ['altitude', 'latitude', 'longitude','speed'])\n",
        "    hr_group = average_list_columns(hr_group, ['heart_rate'])\n",
        "\n",
        "    # 'timestamp'ë¥¼ ê³ ìœ í•˜ê²Œ ë§Œë“¦\n",
        "    # acc_group = make_timestamps_unique(acc_group)\n",
        "    activity_group = make_timestamps_unique(activity_group)\n",
        "    hr_group = make_timestamps_unique(hr_group)\n",
        "    wPedo_group = make_timestamps_unique(wPedo_group)\n",
        "    mLight_group = make_timestamps_unique(mLight_group)\n",
        "    wLight_group = make_timestamps_unique(wLight_group)\n",
        "\n",
        "    # 'timestamp'ë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •í•˜ê³  'subject_id'ì™€ 'date' ì»¬ëŸ¼ ì œê±°\n",
        "    # mAcc_data = acc_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    activity_data = activity_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    e4Hr_data = hr_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wPedo_data = wPedo_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    mLight_data = mLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wLight_data = wLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "\n",
        "    # í•˜ë£¨ 86400ì´ˆì˜ íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±\n",
        "    start_time = datetime.strptime(date, '%Y-%m-%d')\n",
        "    end_time = start_time + timedelta(days=1)\n",
        "    all_timestamps = pd.date_range(start=start_time, end=end_time, freq='S', inclusive='left')\n",
        "    merged_data = pd.DataFrame(index=all_timestamps)\n",
        "    merged_data.index.name = 'timestamp'\n",
        "\n",
        "    # ë°ì´í„° ë³‘í•©\n",
        "    # if not mAcc_data.empty:\n",
        "    #     merged_data = merged_data.join(mAcc_data, how='left')\n",
        "    if not e4Hr_data.empty:\n",
        "        merged_data = merged_data.join(e4Hr_data, how='left')\n",
        "    if not activity_data.empty:\n",
        "        merged_data = merged_data.join(activity_data, how='left')\n",
        "    if not wPedo_data.empty:\n",
        "        merged_data = merged_data.join(wPedo_data, how='left')\n",
        "    if not mLight_data.empty:\n",
        "        merged_data = merged_data.join(mLight_data, how='left')\n",
        "    if not wLight_data.empty:\n",
        "        merged_data = merged_data.join(wLight_data, how='left')\n",
        "\n",
        "    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ìœ ì§€í•˜ê³  NaN ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
        "    # merged_data = merged_data.reindex(columns=['altitude', 'latitude', 'longitude', 'speed', 'heart_rate', 'm_activity', 'step'])\n",
        "    merged_data = merged_data.reindex(columns=['heart_rate', 'm_activity', 'step', 'm_light', 'w_light'])\n",
        "\n",
        "    # ì„ í˜• ë³´ê°„ ì ìš©\n",
        "    merged_data = merged_data.interpolate(method='time')\n",
        "\n",
        "    ### Activity ë°ì´í„°ì˜ ê·¸ë£¹í™” ì ìš©\n",
        "    # group0 : 0 (IN_VEHICLE), 1 (ON_BICYCLE), 2 (ON_FOOT), 7 (WALKING), 8 (RUNNING), 5 (TILTING)\n",
        "    # group1 : 3 (STILL)\n",
        "    # group2 : 4 (UNKNOWN)\n",
        "    activity_mapping = {\n",
        "        0: 1,\n",
        "        1: 1,\n",
        "        2: 1,\n",
        "        7: 1,\n",
        "        8: 2,\n",
        "        5: 1,\n",
        "        3: 0,\n",
        "        4: 0\n",
        "    }\n",
        "    merged_data['m_activity'] = merged_data['m_activity'].map(activity_mapping)\n",
        "\n",
        "    # subject_idì™€ dateë¥¼ ì¶”ê°€\n",
        "    merged_data['subject_id'] = user\n",
        "    merged_data['lifelog_date'] = date\n",
        "\n",
        "    return merged_data\n",
        "\n",
        "def plot_time_series(data, user, date, channel_name):\n",
        "\n",
        "    # xì¶•ì„ 00:00:00ë¶€í„° 23:59:59ê¹Œì§€ ê³ ì •\n",
        "    total_seconds = 86400\n",
        "    time_range = pd.date_range(start=datetime.strptime(date, '%Y-%m-%d'), periods=total_seconds, freq='S')\n",
        "\n",
        "    # ë°ì´í„°ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ì •ë ¬\n",
        "    data = data.reindex(time_range)\n",
        "\n",
        "    # ì‹œê³„ì—´ ì´ë¯¸ì§€ ìƒì„±\n",
        "    fig, axes = plt.subplots(5, 1, figsize=(5, 5), sharex=True, facecolor='black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_facecolor('black')\n",
        "        ax.spines['top'].set_visible(False)           # Hide the top spine\n",
        "        ax.spines['right'].set_visible(False)         # Hide the right spine\n",
        "        ax.spines['left'].set_visible(False)          # Hide the left spine\n",
        "        ax.spines['bottom'].set_visible(False)        # Hide the bottom spine\n",
        "\n",
        "    # ì„¤ì •í•œ ì‹œê°„ ë²”ìœ„ì— ë§ê²Œ xì¶• ì„¤ì •\n",
        "    for ax in axes:\n",
        "        ax.set_xlim([time_range[0], time_range[-1]])\n",
        "\n",
        "    # plot\n",
        "    if 'heart_rate' in data.columns:\n",
        "        axes[0].plot(data.index, data['heart_rate'], color='white')\n",
        "    if 'm_activity' in data.columns:\n",
        "        axes[1].plot(data.index, data['m_activity'], color='white')\n",
        "    if 'step' in data.columns:\n",
        "        axes[2].plot(data.index, data['step'], color='white')\n",
        "    if 'm_light' in data.columns:\n",
        "        axes[3].plot(data.index, data['m_light'], color='white')\n",
        "    if 'w_light' in data.columns:\n",
        "        axes[4].plot(data.index, data['w_light'], color='white')\n",
        "\n",
        "    plt.tight_layout()  # Make the layout tight\n",
        "    fname = f'{path}{channel_name}/user{user}_{date}_{channel_name}.png'\n",
        "    plt.savefig(fname)\n",
        "    # print(fname)\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdMb8wEs8c74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "channel_name = 'ch5_sleeptime'\n",
        "\n",
        "# train test ë°ì´í„° í•©ì¹˜ê¸°\n",
        "a1 = train[['subject_id', 'lifelog_date']].copy()\n",
        "a2 = test[['subject_id', 'lifelog_date']].copy()\n",
        "val_df = pd.concat([a1,a2]).reset_index(drop=True)\n",
        "print('# train:',len(train))\n",
        "print('# test:',len(test))\n",
        "print('# ì „ì²´ ë°ì´í„°:',len(val_df))\n",
        "\n",
        "# íŒŒì¼ëª…\n",
        "val_df = val_df[['subject_id', 'lifelog_date']].copy()\n",
        "val_df['filename'] = val_df.apply(lambda x: f\"user{x['subject_id']}_{x['lifelog_date']}_{channel_name}.png\", axis=1)\n",
        "\n",
        "# ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€\n",
        "image_dir = f'{path}{channel_name}'\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith(f'_{channel_name}.png')]\n",
        "\n",
        "# ë‚¨ì€ ìƒ˜í”Œ\n",
        "val_df = val_df.loc[~val_df['filename'].isin(image_files),:].reset_index(drop=True)\n",
        "print('# ë‚¨ì€ ìƒ˜í”Œìˆ˜:',len(val_df))\n",
        "\n",
        "# ====================================\n",
        "# ìƒ˜í”Œ í…ŒìŠ¤íŠ¸\n",
        "# ====================================\n",
        "# rules = (\n",
        "#   (val_df['subject_id']=='id01') & (val_df['lifelog_date'].isin(['2024-07-01']))\n",
        "# )\n",
        "# val_df = val_df.loc[rules,:].copy().head(1)\n",
        "\n",
        "# ì´ë¯¸ì§€ ìƒì„±\n",
        "bar = tqdm(range(val_df.shape[0]))\n",
        "for idx in bar:\n",
        "    user, date, *rest = val_df.iloc[idx].values\n",
        "    bar.set_description(f'user: {user}, date: {date}')\n",
        "    merged_data = merge_data_for_group(user, date)\n",
        "    plot_time_series(merged_data, user, date, channel_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5_sNQjeX8Zb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNSFIDUvX8dG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hC3NWqhDybU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FHA2ZwrDyuf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ“Œ ëª¨ë¸ í•™ìŠµ"
      ],
      "metadata": {
        "id": "8qrXzX72JA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ì •ì‚¬ê°í˜• íŒ¨ë”© í›„, 299x299ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (Xception ê¸°ì¤€)\n",
        "def preprocess_image(img):\n",
        "    # ì •ì‚¬ê°í˜• íŒ¨ë”©\n",
        "    w, h = img.size\n",
        "    max_dim = max(w, h)\n",
        "    padded_img = Image.new(\"RGB\", (max_dim, max_dim), (127, 127, 127))  # ì¤‘ê°„ê°’ 127ë¡œ ì±„ì›€\n",
        "    padded_img.paste(img, ((max_dim - w) // 2, (max_dim - h) // 2))\n",
        "\n",
        "    # ë¦¬ì‚¬ì´ì¦ˆ ë° [-1, 1] ì •ê·œí™”\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((299, 299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # [0,1] -> [-1,1]\n",
        "    ])\n",
        "    return transform(padded_img)"
      ],
      "metadata": {
        "id": "5HrP9Uj1B3LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_name = 'ch5_sleeptime'\n",
        "\n",
        "# ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •\n",
        "dataset_path = f'{path}{channel_name}'\n",
        "\n",
        "# ì´ë¯¸ì§€ í¬ê¸° ì„¤ì • (Resizeì— ì‚¬ìš©í•  ê°’)\n",
        "image_size = 500\n",
        "\n",
        "def find_img_mean_std(dataset_path,image_size):\n",
        "\n",
        "  import torch\n",
        "  import os\n",
        "  from torchvision import transforms\n",
        "  from PIL import Image\n",
        "\n",
        "  # ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ (Normalize ì œì™¸)\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.ToTensor(),  # [0, 255] -> [0, 1]ë¡œ ìŠ¤ì¼€ì¼ë§\n",
        "  ])\n",
        "\n",
        "  # PNG íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°\n",
        "  image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
        "\n",
        "  # ì´ë¯¸ì§€ ë¡œë“œ ë° í…ì„œ ë³€í™˜\n",
        "  images = []\n",
        "  for img_file in image_files:\n",
        "      try:\n",
        "          img = Image.open(img_file).convert('RGB')  # RGBë¡œ ê°•ì œ ë³€í™˜\n",
        "          tensor_img = transform(img)  # [C, H, W] í˜•íƒœ\n",
        "          images.append(tensor_img)\n",
        "      except Exception as e:\n",
        "          print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_file} - {e}\")\n",
        "\n",
        "  # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ì˜ í…ì„œë¡œ ê²°í•©\n",
        "  # shape: [N, C, H, W] (N: ì´ë¯¸ì§€ ìˆ˜, C: ì±„ë„, H: ë†’ì´, W: ë„ˆë¹„)\n",
        "  all_images = torch.stack(images, dim=0)\n",
        "\n",
        "  # ì±„ë„ë³„ í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°\n",
        "  # í‰ê· : [N, C, H, W] â†’ [C,] (ëª¨ë“  ì´ë¯¸ì§€, ëª¨ë“  í”½ì…€ì— ëŒ€í•œ í‰ê· )\n",
        "  # í‘œì¤€í¸ì°¨: ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ê³„ì‚°\n",
        "  mean = all_images.mean(dim=[0, 2, 3])  # [C,] (ì˜ˆ: [R, G, B])\n",
        "  std = all_images.std(dim=[0, 2, 3])    # [C,] (ì˜ˆ: [R, G, B])\n",
        "\n",
        "  # ê²°ê³¼ ì¶œë ¥\n",
        "  print(\"í‰ê· (mean):\", mean.tolist())\n",
        "  print(\"í‘œì¤€í¸ì°¨(std):\", std.tolist())\n",
        "\n",
        "  return mean.tolist(), std.tolist()\n",
        "\n",
        "img_mean, img_std = find_img_mean_std(dataset_path,image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd5VbPgmnRZC",
        "outputId": "8b2fcd8c-3b86-48b4-d9f5-93ce228a18f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "í‰ê· (mean): [0.012695113196969032, 0.012695113196969032, 0.012695113196969032]\n",
            "í‘œì¤€í¸ì°¨(std): [0.10443976521492004, 0.10443976521492004, 0.10443976521492004]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTHFNnZH2HJy"
      },
      "outputs": [],
      "source": [
        "def extract_cnn_features(\n",
        "    image_root_dir,\n",
        "    img_mean, img_std,\n",
        "    nfeatures,\n",
        "    batch_size=32,\n",
        "    image_size=(500, 500),\n",
        "    model_name='resnet50'\n",
        "):\n",
        "    # ì´ë¯¸ì§€ í™•ì¥ì í—ˆìš© ëª©ë¡\n",
        "    valid_exts = {'.png'}\n",
        "\n",
        "    # ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘\n",
        "    def collect_image_paths(root_dir):\n",
        "        image_paths = []\n",
        "        for root, _, files in os.walk(root_dir):\n",
        "            for fname in files:\n",
        "                if os.path.splitext(fname)[1].lower() in valid_exts:\n",
        "                    image_paths.append(os.path.join(root, fname))\n",
        "        return image_paths\n",
        "\n",
        "    # Dataset ì •ì˜\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_paths, transform=None):\n",
        "            self.image_paths = image_paths\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.image_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            path = self.image_paths[idx]\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.relpath(path)\n",
        "\n",
        "    # Transform & ëª¨ë¸\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=img_mean, std=img_std)\n",
        "    ])\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # ëª¨ë¸ ì„ íƒ\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "    # feature_extractor = torch.nn.Sequential(*list(model.children())[:-1]).to(device)\n",
        "    # feature_extractor.eval()\n",
        "\n",
        "    # # ëª¨ë¸ ì„¤ì • ë¶€ë¶„ ìˆ˜ì •\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "\n",
        "    # # ResNet50ì˜ ê²½ìš°, ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±° í›„ Linear(2048 â†’ 10) ì¶”ê°€\n",
        "    # features = list(model.children())[:-1]  # ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±°\n",
        "    # features.extend([\n",
        "    #     torch.nn.Flatten(),  # [B, 2048, 1, 1] â†’ [B, 2048]\n",
        "    #     torch.nn.Linear(2048, nfeatures)  # 2048 â†’ 10 ì°¨ì›\n",
        "    # ])\n",
        "\n",
        "    # Xception ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "    model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "    # ëª¨ë“  ë ˆì´ì–´ fine-tuning ê°€ëŠ¥í•˜ê²Œ ì„¤ì •\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # feature extractor ë§Œë“¤ê¸° (íŠ¹ì§• ì¶”ì¶œ ì „ë‹¨ë§Œ ì‚¬ìš© ì‹œ)\n",
        "    features = list(model.children())[:-1]  # ë§ˆì§€ë§‰ ë¶„ë¥˜ê¸° ì œê±°\n",
        "    features.extend([\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(model.num_features, nfeatures)  # model.num_features â†’ 2048\n",
        "    ])\n",
        "\n",
        "    feature_extractor = torch.nn.Sequential(*features).to(device)\n",
        "    feature_extractor.eval()\n",
        "\n",
        "    # ë°ì´í„°ë¡œë” ìƒì„±\n",
        "    image_paths = collect_image_paths(image_root_dir)\n",
        "    dataset = ImageDataset(image_paths, transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Feature ì¶”ì¶œ\n",
        "    all_features = []\n",
        "    all_names = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(dataloader):\n",
        "            imgs = imgs.to(device)\n",
        "            feats = feature_extractor(imgs)\n",
        "            feats = feats.view(feats.size(0), -1).cpu()\n",
        "            all_features.append(feats)\n",
        "            all_names.extend(names)\n",
        "\n",
        "    features_tensor = torch.cat(all_features, dim=0)\n",
        "    df = pd.DataFrame(features_tensor.numpy())\n",
        "    df.insert(0, 'image_path', all_names)\n",
        "    fname = f\"{path}img_features_{channel_name}.csv\"\n",
        "    df.to_csv(fname, index=False)\n",
        "    print(f\">> Features saved to: {fname}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone_name='resnext101_32x32d'\n",
        "# backbone_name='resnet18'\n",
        "# resnet34\tresnet18ë³´ë‹¤ ê¹Šì§€ë§Œ ì†ë„ ì†í•´ ì ìŒ\n",
        "# resnet50\të„ë¦¬ ê²€ì¦ëœ ëª¨ë¸, ì¼ë°˜ì ì¸ ì´ë¯¸ì§€ ì‘ì—…ì— ë§¤ìš° ì•ˆì •ì \n",
        "# efficientnet_b0\tíŒŒë¼ë¯¸í„° ìˆ˜ ì ê³  ì •í™•ë„ ë†’ìŒ, ëª¨ë°”ì¼/ê²½ëŸ‰ í™˜ê²½ì— ì í•©\n",
        "# convnext_tiny\tìµœì‹  ConvNet êµ¬ì¡°ë¡œ ì„±ëŠ¥ ë†’ê³  ì—°ì‚° íš¨ìœ¨ì \n",
        "# resnet101\të” ê¹Šì€ ë„¤íŠ¸ì›Œí¬ë¡œ ë³µì¡í•œ íŒ¨í„´ì— ê°•í•¨\n",
        "# efficientnet_b3 ~ b5\tì„±ëŠ¥ì€ ë›°ì–´ë‚˜ì§€ë§Œ í•™ìŠµ ì‹œê°„ì´ ë” í¼\n",
        "# convnext_base\tConvNet ì¤‘ ìµœê·¼ ê°€ì¥ ë†’ì€ ì„±ëŠ¥\n",
        "# beit_base_patch16_224\tVision Transformer ê¸°ë°˜, ì‚¬ì „í•™ìŠµ í•„ìˆ˜\n",
        "\n",
        "\"\"\"\n",
        "ì‹¤í—˜1 - íŒŒë¼ë¯¸í„°\n",
        "[ìƒìŠ¹] nfeatures = 10\n",
        "[í•˜ë½] nfeatures = 5\n",
        "[í•˜ë½] nfeatures = 20\n",
        "\n",
        "ì‹¤í—˜2 - ëª¨ë¸\n",
        "[ìƒìŠ¹] resnet50\n",
        "[í•˜ë½] efficientnet_b0\n",
        "\"\"\"\n",
        "\n",
        "# ì´ë¯¸ì§€ íŒŒìƒë³€ìˆ˜ ìƒì„±\n",
        "img_features = extract_cnn_features(\n",
        "    image_root_dir=f'{path}{channel_name}',\n",
        "    img_mean=img_mean, img_std=img_std,\n",
        "    nfeatures = 10,\n",
        "    batch_size = 32,\n",
        "    image_size = (500, 500),\n",
        "    model_name = 'xception'  # ë‹¤ë¥¸ ëª¨ë¸: xception, resnet50, resnet18, resnet101, efficientnet_b0\n",
        ")\n",
        "\n",
        "# check\n",
        "print('# img_features.shape:',img_features.shape)\n",
        "img_features.head()"
      ],
      "metadata": {
        "id": "z-IZ_vjQJEcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "56716958-11ed-468c-f215-e6911bb30361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [07:20<00:00, 20.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Features saved to: /content/drive/MyDrive/data/ch2025_data_items/img_features_ch5_sleeptime.csv\n",
            "# img_features.shape: (700, 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                 image_path  \\\n",
              "0  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png   \n",
              "1  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png   \n",
              "2  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png   \n",
              "3  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png   \n",
              "4  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png   \n",
              "\n",
              "        0       1       2      3       4       5       6       7       8  \\\n",
              "0  0.0036  0.0476 -0.1327 0.1057  0.1635 -0.0514 -0.0260 -0.0408 -0.2636   \n",
              "1  0.0211  0.0250 -0.0910 0.0973  0.1678 -0.0574  0.0251 -0.0858 -0.2881   \n",
              "2 -0.0301 -0.0700 -0.0676 0.1313 -0.0237 -0.1176 -0.0081 -0.1813 -0.3135   \n",
              "3  0.0007 -0.0941 -0.0162 0.1509  0.0013 -0.1168  0.0285 -0.2095 -0.2874   \n",
              "4 -0.0044 -0.0070 -0.1055 0.1611  0.0369 -0.0576  0.0404 -0.0877 -0.2168   \n",
              "\n",
              "        9  \n",
              "0 -0.0121  \n",
              "1 -0.0052  \n",
              "2 -0.0519  \n",
              "3 -0.0769  \n",
              "4 -0.1385  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fca70470-a144-4bb7-8322-5205f19b67b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>-0.0514</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0408</td>\n",
              "      <td>-0.2636</td>\n",
              "      <td>-0.0121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png</td>\n",
              "      <td>0.0211</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>0.0973</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>-0.0574</td>\n",
              "      <td>0.0251</td>\n",
              "      <td>-0.0858</td>\n",
              "      <td>-0.2881</td>\n",
              "      <td>-0.0052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png</td>\n",
              "      <td>-0.0301</td>\n",
              "      <td>-0.0700</td>\n",
              "      <td>-0.0676</td>\n",
              "      <td>0.1313</td>\n",
              "      <td>-0.0237</td>\n",
              "      <td>-0.1176</td>\n",
              "      <td>-0.0081</td>\n",
              "      <td>-0.1813</td>\n",
              "      <td>-0.3135</td>\n",
              "      <td>-0.0519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0941</td>\n",
              "      <td>-0.0162</td>\n",
              "      <td>0.1509</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>-0.1168</td>\n",
              "      <td>0.0285</td>\n",
              "      <td>-0.2095</td>\n",
              "      <td>-0.2874</td>\n",
              "      <td>-0.0769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png</td>\n",
              "      <td>-0.0044</td>\n",
              "      <td>-0.0070</td>\n",
              "      <td>-0.1055</td>\n",
              "      <td>0.1611</td>\n",
              "      <td>0.0369</td>\n",
              "      <td>-0.0576</td>\n",
              "      <td>0.0404</td>\n",
              "      <td>-0.0877</td>\n",
              "      <td>-0.2168</td>\n",
              "      <td>-0.1385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fca70470-a144-4bb7-8322-5205f19b67b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fca70470-a144-4bb7-8322-5205f19b67b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fca70470-a144-4bb7-8322-5205f19b67b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-714cd201-c6b3-4176-bd6e-90ced1c2afdd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-714cd201-c6b3-4176-bd6e-90ced1c2afdd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-714cd201-c6b3-4176-bd6e-90ced1c2afdd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "img_features",
              "summary": "{\n  \"name\": \"img_features\",\n  \"rows\": 700,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 700,\n        \"samples\": [\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid04_2024-09-17_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid02_2024-10-06_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid09_2024-07-25_ch5_sleeptime.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.16333775222301483,\n          -0.035041190683841705,\n          -0.05672355741262436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.08307548612356186,\n          -0.04341660439968109,\n          -0.04869595170021057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.09835391491651535,\n          -0.061300117522478104,\n          -0.054764021188020706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.3141210079193115,\n          0.1597968488931656,\n          0.24819667637348175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.03382708132266998,\n          -0.008011463098227978,\n          -0.05711574852466583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.01653387024998665,\n          -0.1045929342508316,\n          -0.018832147121429443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 478,\n        \"samples\": [\n          -0.08326223492622375,\n          0.05508451163768768,\n          0.029485490173101425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 478,\n        \"samples\": [\n          -0.03813104331493378,\n          -0.16025468707084656,\n          -0.16127584874629974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.32163625955581665,\n          -0.2786847949028015,\n          -0.30157470703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.10823676735162735,\n          -0.0555943101644516,\n          -0.11898816376924515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet(\"/content/drive/MyDrive/data/train_0512.parquet\")\n",
        "test = pd.read_parquet(\"/content/drive/MyDrive/data/test_0512.parquet\")\n",
        "\n",
        "# drop_features = ['afterwork_max_label','sleeptime_max_label','worktime_max_label']\n",
        "drop_features = ['top_bssid'] # ,'week_type','week_type_lag1'\n",
        "drop_features = [i for i in drop_features if i in train.columns.tolist()]\n",
        "print('# drop_features:',drop_features)\n",
        "train = train.drop(columns=drop_features)\n",
        "test = test.drop(columns=drop_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98TGeiQnb3ku",
        "outputId": "3c222465-45ab-4ee5-8661-2465c408822d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# drop_features: ['top_bssid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„° ì½ê¸°\n",
        "img_features = pd.read_csv('/content/drive/MyDrive/data/ch2025_data_items/img_features_ch5_sleeptime.csv')\n",
        "img_features.columns = ['image_path']+['img'+i for i in img_features.columns if i not in ['image_path']]\n",
        "\n",
        "# ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ\n",
        "img_features['subject_id'] = img_features['image_path'].str.extract(r'user(id\\d+)_')[0]\n",
        "img_features['lifelog_date'] = img_features['image_path'].str.extract(r'_(\\d{4}-\\d{2}-\\d{2})_')[0]\n",
        "\n",
        "# check\n",
        "img_features = img_features.drop(columns=['image_path'])\n",
        "print(len(img_features))\n",
        "display(img_features.head(1))\n",
        "\n",
        "# add img features\n",
        "train['lifelog_date'] = train['lifelog_date'].astype(str)\n",
        "test['lifelog_date'] = test['lifelog_date'].astype(str)\n",
        "train = train.merge(img_features,on=['subject_id','lifelog_date'],how='left')\n",
        "test = test.merge(img_features,on=['subject_id','lifelog_date'],how='left')"
      ],
      "metadata": {
        "id": "FCrgC4pSJEpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "7d91e82e-575a-4b19-e9e6-e8744d8801d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    img0   img1    img2   img3   img4    img5    img6    img7    img8    img9  \\\n",
              "0 0.0036 0.0476 -0.1327 0.1057 0.1635 -0.0514 -0.0260 -0.0408 -0.2636 -0.0121   \n",
              "\n",
              "  subject_id lifelog_date  \n",
              "0       id01   2024-06-26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img0</th>\n",
              "      <th>img1</th>\n",
              "      <th>img2</th>\n",
              "      <th>img3</th>\n",
              "      <th>img4</th>\n",
              "      <th>img5</th>\n",
              "      <th>img6</th>\n",
              "      <th>img7</th>\n",
              "      <th>img8</th>\n",
              "      <th>img9</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>lifelog_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>-0.0514</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0408</td>\n",
              "      <td>-0.2636</td>\n",
              "      <td>-0.0121</td>\n",
              "      <td>id01</td>\n",
              "      <td>2024-06-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test = test\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"img0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0036178334,\n        \"max\": 0.0036178334,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0036178334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.04761707,\n        \"max\": 0.04761707,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.04761707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.13266137,\n        \"max\": -0.13266137,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.13266137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1056918,\n        \"max\": 0.1056918,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1056918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1634916,\n        \"max\": 0.1634916,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1634916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.051436387,\n        \"max\": -0.051436387,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.051436387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.025990054,\n        \"max\": -0.025990054,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.025990054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.040842075,\n        \"max\": -0.040842075,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.040842075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.26363862,\n        \"max\": -0.26363862,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.26363862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.01210399,\n        \"max\": -0.01210399,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.01210399\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"id01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lifelog_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-06-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìš”ì¼ ì»¬ëŸ¼ ì¶”ê°€ (ì˜ˆ: ì›”ìš”ì¼, í™”ìš”ì¼, ...)\n",
        "train['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\n",
        "test['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n",
        "\n",
        "# ìš”ì¼\n",
        "weekday_map = {\n",
        "    0: 'ì›”ìš”ì¼', 1: 'í™”ìš”ì¼', 2: 'ìˆ˜ìš”ì¼', 3: 'ëª©ìš”ì¼',\n",
        "    4: 'ê¸ˆìš”ì¼', 5: 'í† ìš”ì¼', 6: 'ì¼ìš”ì¼'\n",
        "}\n",
        "train['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "test['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "\n",
        "# ì›”\n",
        "train['month'] = train['lifelog_date'].dt.month\n",
        "test['month'] = test['lifelog_date'].dt.month\n",
        "\n",
        "# weekend\n",
        "train['weekend'] = np.where(train['weekday'].isin(['í† ìš”ì¼','ì¼ìš”ì¼']),1,0)\n",
        "test['weekend'] = np.where(test['weekday'].isin(['í† ìš”ì¼','ì¼ìš”ì¼']),1,0)\n",
        "\n",
        "# ê³µíœ´ì¼\n",
        "ê³µíœ´ì¼ = [\n",
        "     '2024-08-15'\n",
        "    ,'2024-09-16'\n",
        "    ,'2024-09-17'\n",
        "    ,'2024-09-18'\n",
        "    ,'2024-10-03'\n",
        "    ,'2024-10-09'\n",
        "]\n",
        "train['ê³µíœ´ì¼'] = np.where(train['lifelog_date'].isin(ê³µíœ´ì¼),1,0)\n",
        "test['ê³µíœ´ì¼'] = np.where(test['lifelog_date'].isin(ê³µíœ´ì¼),1,0)\n",
        "\n",
        "# ì£¼ë§ + ê³µíœ´ì¼ ë¬¶ì–´ì£¼ê¸°\n",
        "# train['weekend'] = np.where( ((train['weekend']==0) & (train['ê³µíœ´ì¼']==1)), 1, train['weekend'])\n",
        "# test['weekend'] = np.where( ((test['weekend']==0) & (test['ê³µíœ´ì¼']==1)), 1, test['weekend'])"
      ],
      "metadata": {
        "id": "RLT2TiKsJExf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¶”ì •íœ´ê°€\n",
        "def rule_based_sum(x):\n",
        "    rules = (\n",
        "        # (x['sleep_duration_min'] > (x['avg_sleep_duration'] + 30))\n",
        "          (x['sleep_duration_min'] > (x['avg_sleep_duration']))\n",
        "        & (x['week_type'] == 'weekday')\n",
        "        & (x['month'].isin([7,8]))\n",
        "    )\n",
        "    return rules\n",
        "\n",
        "train['vacation'] = train.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "test['vacation'] = test.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "\n",
        "# check\n",
        "test.groupby(['subject_id'])['vacation'].sum()"
      ],
      "metadata": {
        "id": "H401mU5CJEzy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "d1220550-e99c-4e77-c139-48915de7c0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject_id\n",
              "id01     5\n",
              "id02     1\n",
              "id03     5\n",
              "id04     0\n",
              "id05     0\n",
              "id06    11\n",
              "id07    14\n",
              "id08     3\n",
              "id09     7\n",
              "id10     0\n",
              "Name: vacation, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id01</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id02</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id03</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id04</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id05</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id06</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id07</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id08</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id09</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ìˆ«ìí˜• ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ê²°ì¸¡ê°’ -1ë¡œ ì±„ìš°ê¸°\n",
        "train[train.select_dtypes(include='number').columns] = train.select_dtypes(include='number').fillna(-1)\n",
        "test[test.select_dtypes(include='number').columns] = test.select_dtypes(include='number').fillna(-1)"
      ],
      "metadata": {
        "id": "EckHVeXuJE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oof_predictions(X, y, params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n",
        "\n",
        "    oof_preds = np.zeros(len(X))  # âœ… 1ì°¨ì›ìœ¼ë¡œ ë³€ê²½\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_idx, valid_idx in skf.split(X, y):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        if is_multiclass:\n",
        "            model = LGBMClassifier(**params, objective='multiclass', num_class=num_class)\n",
        "        else:\n",
        "            model = LGBMClassifier(**params)\n",
        "\n",
        "        if early_stop:\n",
        "            model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n",
        "            )\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "        preds = model.predict(X_valid)  # âœ… returns 1D array\n",
        "        oof_preds[valid_idx] = preds  # âœ… 1D -> 1D ì €ì¥\n",
        "\n",
        "    return oof_preds"
      ],
      "metadata": {
        "id": "Toukt4KNJE58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n",
        "\n",
        "    train_df = train.copy()\n",
        "    test_df = test.copy()\n",
        "\n",
        "    submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "    submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n",
        "\n",
        "    # íƒ€ê²Ÿ\n",
        "    targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n",
        "    targets_binary_name = ['ê¸°ìƒì§í›„ìˆ˜ë©´ì§ˆ','ì·¨ì¹¨ì „ì‹ ì²´ì í”¼ë¡œ','ì·¨ì¹¨ì „ìŠ¤íŠ¸ë ˆìŠ¤','ìˆ˜ë©´íš¨ìœ¨','ìˆ˜ë©´ì ë“¤ê¸°ì‹œê°„']\n",
        "    target_multiclass = 'S1'\n",
        "    all_targets = targets_binary + [target_multiclass]\n",
        "\n",
        "    # ë…¸ì´ì¦ˆ ìˆ˜ì¤€ ì„¤ì •\n",
        "    def add_noise(series, noise_level, seed=3):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        return series * (1 + noise_level * rng.standard_normal(len(series)))\n",
        "\n",
        "    noise_level = 0.015  # í•„ìš”ì— ë”°ë¼ ì¡°ì •\n",
        "\n",
        "    # íƒ€ê²Ÿì¸ì½”ë”©\n",
        "    # m = 0: ìŠ¤ë¬´ë”© ì—†ì´ ë²”ì£¼ë³„ í‰ê· ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ê´€ì¸¡ ìˆ˜ê°€ ë§ì€ ë²”ì£¼ì—ëŠ” ì í•©í•˜ì§€ë§Œ, ì ì€ ê²½ìš° ê³¼ì í•© ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.\n",
        "    # m = 1~10: ì¼ë°˜ì ì¸ ê¸°ë³¸ê°’ìœ¼ë¡œ, ëŒ€ë¶€ë¶„ì˜ ìƒí™©ì—ì„œ ì•ˆì •ì ì¸ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
        "    # m = 50~300: ê´€ì¸¡ ìˆ˜ê°€ ë§¤ìš° ì ì€ ë²”ì£¼ê°€ ë§ê±°ë‚˜ ë°ì´í„°ê°€ í¬ì†Œí•œ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤.\n",
        "    for tgt in all_targets:\n",
        "\n",
        "      encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n",
        "\n",
        "      #### íƒ€ê²Ÿì¸ì½”ë”©1\n",
        "\n",
        "      subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n",
        "      train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      global_mean = train_df[tgt].mean()\n",
        "      test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n",
        "\n",
        "      # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
        "      train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n",
        "      test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n",
        "\n",
        "      #### íƒ€ê²Ÿì¸ì½”ë”©2\n",
        "\n",
        "      # ìƒˆë¡œìš´ ë²”ì£¼í˜• ì—´ ìƒì„±\n",
        "      train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "      test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "\n",
        "      # ì¸ì½”ë”\n",
        "      encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n",
        "      encoder.fit(train_df[['TMP']], train_df[tgt])\n",
        "\n",
        "      # ì¸ì½”ë”© ê²°ê³¼ë¥¼ ìƒˆë¡œìš´ ì—´ì— ì €ì¥\n",
        "      train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n",
        "      test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n",
        "\n",
        "      # ë…¸ì´ì¦ˆ ì¶”ê°€\n",
        "      train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n",
        "      test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n",
        "\n",
        "      # ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±°\n",
        "      train_df = train_df.drop(columns=['TMP'])\n",
        "      test_df = test_df.drop(columns=['TMP'])\n",
        "\n",
        "\n",
        "    # ì¸ì½”ë”©\n",
        "    PK = ['sleep_date', 'lifelog_date', 'subject_id']\n",
        "    encoder = LabelEncoder()\n",
        "    categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n",
        "    for col in categorical_features:\n",
        "        print(col)\n",
        "        train_df[col] = encoder.fit_transform(train_df[col])\n",
        "        test_df[col] = encoder.fit_transform(test_df[col])\n",
        "\n",
        "\n",
        "    # X\n",
        "    X = train_df.drop(columns=PK + all_targets)\n",
        "    test_X = test_df.drop(columns=PK + all_targets)\n",
        "    print(f'# X shape: {X.shape}')\n",
        "    print(f'# test_X shape: {test_X.shape}')\n",
        "\n",
        "    print('\\n STEP1: ì‹¤í—˜ ê²°ê³¼ í™•ì¸')\n",
        "    print(\"=============== Validation Results ==============\")\n",
        "    total_avg_f1s = []\n",
        "    best_iteration_temp = {k: [] for k in all_targets}\n",
        "\n",
        "    val_f1 = []\n",
        "    for col in targets_binary:\n",
        "\n",
        "        # binary\n",
        "        y = train_df[col]\n",
        "\n",
        "        valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n",
        "        train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n",
        "\n",
        "        X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "        y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "        # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "        best_param = best_param_dict[col].copy()\n",
        "        best_param['random_state'] = random_state\n",
        "        model = LGBMClassifier(**best_param)\n",
        "\n",
        "        if early_stop:\n",
        "            model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n",
        "            )\n",
        "            best_iteration_temp[col].append(model.best_iteration_)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            best_iteration_temp[col].append(1000)\n",
        "\n",
        "        pred_valid = model.predict(X_valid)\n",
        "        f1 = f1_score(y_valid, pred_valid, average='macro') ### ìˆ˜ì •\n",
        "        val_f1.append(f1)\n",
        "\n",
        "    # multi\n",
        "    y = train_df[target_multiclass]\n",
        "\n",
        "    X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "    y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "    best_param = best_param_dict['S1'].copy()\n",
        "    best_param['random_state'] = random_state\n",
        "    model = LGBMClassifier(**best_param, objective='multiclass', num_class=3)\n",
        "\n",
        "    if early_stop:\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "            callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n",
        "        )\n",
        "        best_iteration_temp[target_multiclass].append(model.best_iteration_)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_iteration_temp[target_multiclass].append(1000)\n",
        "\n",
        "    pred_valid = model.predict(X_valid)\n",
        "    f1 = f1_score(y_valid, pred_valid, average='macro')\n",
        "    val_f1.append(f1)\n",
        "\n",
        "\n",
        "    avg_f1 = np.mean(val_f1)\n",
        "    total_avg_f1s.append(avg_f1)\n",
        "    detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n",
        "    print(f\" í‰ê·  F1: {avg_f1:.4f} / [ìƒì„¸] {detail}\")\n",
        "\n",
        "    best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n",
        "\n",
        "    if early_stop==True:\n",
        "      print(\"\\n[best_iteration_dict]\")\n",
        "      for k, v in best_iteration_dict.items():\n",
        "          print(f\"{k}: {v}\")\n",
        "\n",
        "\n",
        "    print(f\"# ì „ì²´ í‰ê·  F1: {np.mean(total_avg_f1s):.4f}\")\n",
        "    print(\"================================================\")\n",
        "\n",
        "    # modoling with 100% train & no valid\n",
        "    print('\\n STEP2: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ')\n",
        "    print(\"====== modoling with 100% train & no valid =====\")\n",
        "\n",
        "    # binary\n",
        "    binary_preds = {}\n",
        "    for col in targets_binary:\n",
        "        binary_params = best_param_dict[col].copy()\n",
        "        binary_params['random_state'] = random_state\n",
        "        y = train_df[col]\n",
        "\n",
        "        if early_stop:\n",
        "          binary_params['n_estimators']=best_iteration_dict[col]\n",
        "          model = LGBMClassifier(**binary_params)\n",
        "          model.fit(X, y)\n",
        "        else:\n",
        "          model = LGBMClassifier(**binary_params)\n",
        "          model.fit(X, y)\n",
        "\n",
        "        binary_preds[col] = model.predict(test_X)\n",
        "        fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
        "        top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "        feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "        print(f\"[{col}] {feat_str}\")\n",
        "\n",
        "    # multiclass\n",
        "    y = train_df['S1']\n",
        "    binary_params = best_param_dict['S1'].copy()\n",
        "    binary_params['random_state'] = random_state\n",
        "\n",
        "    if early_stop:\n",
        "      binary_params['n_estimators']=best_iteration_dict['S1']\n",
        "      model = LGBMClassifier(**binary_params)\n",
        "      model.fit(X, y)\n",
        "    else:\n",
        "      model = LGBMClassifier(**binary_params)\n",
        "      model.fit(X, y)\n",
        "\n",
        "    multiclass_pred = model.predict(test_X)\n",
        "    fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
        "    top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "    feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "    print(f\"[S1] {feat_str}\")\n",
        "\n",
        "    # ì˜ˆì¸¡ ì €ì¥\n",
        "    submission_final['S1'] = multiclass_pred\n",
        "    for col in targets_binary:\n",
        "      submission_final[col] = binary_preds[col]\n",
        "    submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n",
        "    fname = f\"/content/drive/MyDrive/data/submission_{np.mean(total_avg_f1s)}.csv\"\n",
        "    submission_final.to_csv(fname, index=False)\n",
        "    print(f\"# {fname} ì €ì¥ ì™„ë£Œ\")\n",
        "    print(f\"# submission shape:{submission_final.shape}\")\n",
        "    print(\"================================================\")\n",
        "\n",
        "    # ëª¨ë¸ë³„ ì˜ˆì¸¡ê²°ê³¼ ë¹„ìœ¨ ë¹„êµ\n",
        "    a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n",
        "    result.columns = ['í•™ìŠµsum','í•™ìŠµlen','í•™ìŠµmean','í…ŒìŠ¤íŠ¸sum','í…ŒìŠ¤íŠ¸len','í…ŒìŠ¤íŠ¸mean']\n",
        "    print('\\n STEP3: ì˜ˆì¸¡ê²°ê³¼ ë¹„êµí‘œ')\n",
        "    display(result)\n",
        "\n",
        "    # === STEP4: OOF ì˜ˆì¸¡ ìƒì„± (train setì— ëŒ€í•´) ===\n",
        "\n",
        "    # n_splits = 10\n",
        "    mask = train['month'] != 6\n",
        "    print(f'# k-fold: {n_splits}')\n",
        "    print(f'# train: {len(y[mask])}')\n",
        "\n",
        "    oof_f1 = []\n",
        "    print('\\n STEP4: OOF ì˜ˆì¸¡ ìƒì„±')\n",
        "    oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "    for col in targets_binary:\n",
        "        params = best_param_dict[col].copy()\n",
        "        params['random_state'] = random_state\n",
        "        y = train_df[col]\n",
        "        oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n",
        "        oof_result[col] = oof_preds\n",
        "        f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n",
        "        oof_f1.append(f1)\n",
        "        print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n",
        "\n",
        "    # multiclass\n",
        "    col = 'S1'\n",
        "    params = best_param_dict[col].copy()\n",
        "    params['random_state'] = random_state\n",
        "    y = train_df[col]\n",
        "    oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n",
        "    oof_result[col] = oof_preds\n",
        "    f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n",
        "    oof_f1.append(f1)\n",
        "    print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n",
        "    print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n",
        "\n",
        "    # oof_result ì €ì¥\n",
        "    fname = f\"/content/drive/MyDrive/data/oof_result_{np.mean(total_avg_f1s)}.csv\"\n",
        "    oof_result.to_csv(fname, index=False)\n",
        "    print(f\"# {fname} ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "    return submission_final, oof_result"
      ],
      "metadata": {
        "id": "rdo8wqFTJFA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run"
      ],
      "metadata": {
        "id": "pzYyd5Qqch-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "week_type\n",
        "week_type_lag1\n",
        "weekday\n",
        "# X shape: (450, 168)\n",
        "# test_X shape: (250, 168)\n",
        "\n",
        " STEP1: ì‹¤í—˜ ê²°ê³¼ í™•ì¸\n",
        "=============== Validation Results ==============\n",
        " í‰ê·  F1: 0.6322 / [ìƒì„¸] Q1(ê¸°ìƒì§í›„ìˆ˜ë©´ì§ˆ):0.7278 Q2(ì·¨ì¹¨ì „ì‹ ì²´ì í”¼ë¡œ):0.7122 Q3(ì·¨ì¹¨ì „ìŠ¤íŠ¸ë ˆìŠ¤):0.6830 S2(ìˆ˜ë©´íš¨ìœ¨):0.5726 S3(ìˆ˜ë©´ì ë“¤ê¸°ì‹œê°„):0.6686 S1(S1):0.4293\n",
        "# ì „ì²´ í‰ê·  F1: 0.6322\n",
        "================================================\n",
        "\n",
        " STEP2: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
        "====== modoling with 100% train & no valid =====\n",
        "[Q1] Q1_te2(557), light_night_mean(469), wake_time_ratio(405), wake_time_diff_lag1(340), í†µí™”_time(326), Q1_te(325), sleep_duration_diff(242), activehour_unique_label_count(200), ble_class_others_ratio_worktime(175), wake_time(155)\n",
        "[Q2] Q2_te2(2791), total_screen_time(351), wake_up_early_minutes(331), speed_le5_max(307), rolling_wake_time_3d(288), rolling_sleep_time_3d(233), sleep_time_diff(224), Q2_te(198), wlight_evening_mean(182), hr_evening_std(176)\n",
        "[Q3] Q3_te2(2199), light_max(366), sleep_duration_diff_lag1(274), sleep_duration_min(227), sleep_duration_ratio(211), screen_time_vs_avg_pct(187), lat_change(181), all_VEHICLE_minutes(179), sleep_time(177), í†µí™”_time(167)\n",
        "[S2] S2_te(3725), S2_te2(2773), wake_time_diff_lag1(340), light_max(292), light_night_mean(245), S1_te2(189), ble_class_unknwn_ratio_sleeptime(179), í†µí™”_time(175), sleep_duration_lag1(171), sleep_duration_min(170)\n",
        "[S3] S3_te(639), light_night_mean(443), S3_te2(336), ble_rssi_mean_afterwork(256), hr_evening_min(242), activehour_unique_label_count(242), ble_class_unknwn_ratio_sleeptime(235), wlight_evening_mean(231), sleep_time_diff_lag1(230), vehicle_minutes(180)\n",
        "[S1] S1_te2(3990), S1_te(661), sleep_duration_ratio(646), wake_time_ratio(554), sleep_duration_diff(452), sleep_duration_min(429), vehicle_minutes(427), rolling_wake_time_3d(410), speed_le5_max(408), hour_span_minutes(379)\n",
        "# /content/drive/MyDrive/data/submission_0.6322252622334963.csv ì €ì¥ ì™„ë£Œ\n",
        "# submission shape:(250, 9)\n",
        "================================================\n",
        "\n",
        " STEP3: ì˜ˆì¸¡ê²°ê³¼ ë¹„êµí‘œ\n",
        "í•™ìŠµsum\tí•™ìŠµlen\tí•™ìŠµmean\tí…ŒìŠ¤íŠ¸sum\tí…ŒìŠ¤íŠ¸len\tí…ŒìŠ¤íŠ¸mean\n",
        "Q1\t223\t450\t0.4956\t131\t250\t0.5240\n",
        "Q2\t253\t450\t0.5622\t150\t250\t0.6000\n",
        "Q3\t270\t450\t0.6000\t173\t250\t0.6920\n",
        "S1\t390\t450\t0.8667\t202\t250\t0.8080\n",
        "S2\t293\t450\t0.6511\t170\t250\t0.6800\n",
        "S3\t298\t450\t0.6622\t171\t250\t0.6840\n",
        "\n",
        "\n",
        "# k-fold: 5\n",
        "# train: 392\n",
        "\n",
        " STEP4: OOF ì˜ˆì¸¡ ìƒì„±\n",
        "[OOF - Q1] F1 score: 0.6976\n",
        "[OOF - Q2] F1 score: 0.7041\n",
        "[OOF - Q3] F1 score: 0.6605\n",
        "[OOF - S2] F1 score: 0.6610\n",
        "[OOF - S3] F1 score: 0.7106\n",
        "[OOF - S1] F1 score: 0.5233\n",
        "[OOF] F1 score: 0.6595\n",
        "# /content/drive/MyDrive/data/oof_result_0.6322252622334963.csv ì €ì¥ ì™„ë£Œ\n",
        "\"\"\"\n",
        "\n",
        "# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "common_params = {\n",
        "  'n_estimators': 5000,\n",
        "  \"learning_rate\": 0.01,\n",
        "  # \"shrinkage_rate\": 0.12,\n",
        "  # 'min_data_in_leaf':2,\n",
        "  # 'bagging_fraction':0.9,\n",
        "  # 'feature_fraction':0.6,\n",
        "  'lambda_l1': 5,\n",
        "  'lambda_l2': 1,\n",
        "  # 'max_depth': 4,\n",
        "  'n_jobs': -1,\n",
        "  'verbosity': -1\n",
        "}\n",
        "\n",
        "# ëª¨ë¸ë³„ ì„¸ë¶€ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "best_param_dict = {'Q1': {'learning_rate': 0.1473150575266255,\n",
        "  'shrinkage_rate': 0.08585454450680065,\n",
        "  'min_data_in_leaf': 13,\n",
        "  'bagging_fraction': 0.5900885111562433,\n",
        "  'feature_fraction': 0.7398526832500182,\n",
        "  'lambda_l1': 0.7309384079752819,\n",
        "  'lambda_l2': 0.010419978985191203,\n",
        "  'max_depth': 2},\n",
        " 'Q2': {'learning_rate': 0.1433742819325529,\n",
        "  'shrinkage_rate': 0.4777741359643458,\n",
        "  'min_data_in_leaf': 11,\n",
        "  'bagging_fraction': 0.8942012129234453,\n",
        "  'feature_fraction': 0.3442323511952453,\n",
        "  'lambda_l1': 0.11108296857244106,\n",
        "  'lambda_l2': 0.5000682520529595,\n",
        "  'max_depth': 11},\n",
        " 'Q3': {'learning_rate': 0.005440413154494791,\n",
        "  'shrinkage_rate': 0.4869550654391126,\n",
        "  'min_data_in_leaf': 5,\n",
        "  'bagging_fraction': 0.992720410336095,\n",
        "  'feature_fraction': 0.10854085794750301,\n",
        "  'lambda_l1': 8.765258863766789,\n",
        "  'lambda_l2': 0.010911793484805324,\n",
        "  'max_depth': -1},\n",
        " 'S1': {'learning_rate': 0.19808502263166988,\n",
        "  'shrinkage_rate': 0.3292477285579064,\n",
        "  'min_data_in_leaf': 9,\n",
        "  'bagging_fraction': 0.5929013243246726,\n",
        "  'feature_fraction': 0.8481981135327139,\n",
        "  'lambda_l1': 0.010377995886618164,\n",
        "  'lambda_l2': 0.6226891522266145,\n",
        "  'max_depth': 10},\n",
        " 'S2': {'learning_rate': 0.27099064035077214,\n",
        "  'shrinkage_rate': 0.028901883938906636,\n",
        "  'min_data_in_leaf': 9,\n",
        "  'bagging_fraction': 0.8134249396247819,\n",
        "  'feature_fraction': 0.2321570003912355,\n",
        "  'lambda_l1': 8.780092357464005,\n",
        "  'lambda_l2': 9.605716023562762,\n",
        "  'max_depth': 7},\n",
        " 'S3': {'learning_rate': 0.14542046442644,\n",
        "  'shrinkage_rate': 0.3047247759570036,\n",
        "  'min_data_in_leaf': 10,\n",
        "  'bagging_fraction': 0.8493532899163512,\n",
        "  'feature_fraction': 0.7940889257506005,\n",
        "  'lambda_l1': 9.299803284110112,\n",
        "  'lambda_l2': 0.12938944891518922,\n",
        "  'max_depth': 6}\n",
        "}\n",
        "\n",
        "# ê³µí†µ í•˜ì´í¼íŒŒë¼ë¯¸í„° ëŒ€ì²´ (ì´ìƒí•œ ëª¨ë¸ì˜ ê²½ìš°)\n",
        "best_param_dict['Q3'] = common_params\n",
        "best_param_dict['S1'] = common_params\n",
        "best_param_dict['S2'] = common_params\n",
        "best_param_dict['S3'] = common_params\n",
        "best_param_dict['Q1'] = common_params\n",
        "best_param_dict['Q2'] = common_params\n",
        "\n",
        "# ì „ì²´ í‰ê·  F1: 0.6322\n",
        "# [OOF] F1 score: 0.6595\n",
        "# [OOF - Q1] F1 score: 0.6976\n",
        "# [OOF - Q2] F1 score: 0.7041\n",
        "# [OOF - Q3] F1 score: 0.6605\n",
        "# [OOF - S2] F1 score: 0.6610\n",
        "# [OOF - S3] F1 score: 0.7106\n",
        "# [OOF - S1] F1 score: 0.5233\n",
        "submission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)"
      ],
      "metadata": {
        "id": "x4rBoUTMJFDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "3ee007a3-1d5a-4a45-ebe3-e0abf52a350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "week_type\n",
            "week_type_lag1\n",
            "weekday\n",
            "# X shape: (450, 190)\n",
            "# test_X shape: (250, 190)\n",
            "\n",
            " STEP1: ì‹¤í—˜ ê²°ê³¼ í™•ì¸\n",
            "=============== Validation Results ==============\n",
            " í‰ê·  F1: 0.6448 / [ìƒì„¸] Q1(ê¸°ìƒì§í›„ìˆ˜ë©´ì§ˆ):0.7314 Q2(ì·¨ì¹¨ì „ì‹ ì²´ì í”¼ë¡œ):0.7518 Q3(ì·¨ì¹¨ì „ìŠ¤íŠ¸ë ˆìŠ¤):0.6546 S2(ìˆ˜ë©´íš¨ìœ¨):0.6179 S3(ìˆ˜ë©´ì ë“¤ê¸°ì‹œê°„):0.6485 S1(S1):0.4642\n",
            "# ì „ì²´ í‰ê·  F1: 0.6448\n",
            "================================================\n",
            "\n",
            " STEP2: ì „ì²´ ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ\n",
            "====== modoling with 100% train & no valid =====\n",
            "[Q1] Q1_te2(539), light_night_mean(373), wake_time_ratio(360), wake_time_diff_lag1(290), Q1_te(262), sleep_duration_diff(257), wake_time(192), beforebed_ì „í™”_time(179), beforebed_í†µí™”_time(178), ble_rssi_max_afterwork(174)\n",
            "[Q2] Q2_te2(1510), rolling_wake_time_3d(250), wake_up_early_minutes(249), wlight_evening_mean(230), Q2_te(229), activehour_total_screen_time(193), rolling_sleep_time_3d(179), activehour_screen_time_vs_avg_pct(170), avg_rssi(167), activehour_ì „í™”_time(161)\n",
            "[Q3] Q3_te2(641), light_max(403), sleep_duration_min(241), activehour_í†µí™”_time(236), sleep_duration_diff_lag1(210), sleep_duration_lag1(164), ble_class_others_ratio_afterwork(154), sleep_time(153), vehicle_minutes(148), hr_morning_max(148)\n",
            "[S2] S2_te(2072), S2_te2(435), img0(329), beforebed_total_screen_time(238), wake_time_diff_lag1(229), ble_class_unknwn_ratio_sleeptime(195), activehour_screen_time_vs_avg_pct(158), light_night_mean(154), beforebed_OneUIí™ˆ_time(147), sleep_duration_ratio(142)\n",
            "[S3] S3_te(528), S3_te2(333), light_night_mean(331), ble_rssi_mean_afterwork(293), lon_change(252), sleep_time_diff_lag1(206), ble_class_unknwn_ratio_sleeptime(200), img7(193), hr_evening_min(175), activehour_unique_label_count(173)\n",
            "[S1] S1_te(767), S1_te2(717), img4(567), sleep_duration_ratio(562), beforebed_screen_time_vs_avg_pct(562), wake_time_ratio(524), sleep_duration_min(468), beforebed_total_screen_time(466), sleep_duration_diff(442), hour_span_minutes(366)\n",
            "# /content/drive/MyDrive/data/submission_0.6447528574485211.csv ì €ì¥ ì™„ë£Œ\n",
            "# submission shape:(250, 9)\n",
            "================================================\n",
            "\n",
            " STEP3: ì˜ˆì¸¡ê²°ê³¼ ë¹„êµí‘œ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    í•™ìŠµsum  í•™ìŠµlen  í•™ìŠµmean  í…ŒìŠ¤íŠ¸sum  í…ŒìŠ¤íŠ¸len  í…ŒìŠ¤íŠ¸mean\n",
              "Q1    223    450  0.4956     127     250   0.5080\n",
              "Q2    253    450  0.5622     151     250   0.6040\n",
              "Q3    270    450  0.6000     174     250   0.6960\n",
              "S1    390    450  0.8667     199     250   0.7960\n",
              "S2    293    450  0.6511     166     250   0.6640\n",
              "S3    298    450  0.6622     167     250   0.6680"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-867d516f-4ba4-4529-bbb3-76930c1eca8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>í•™ìŠµsum</th>\n",
              "      <th>í•™ìŠµlen</th>\n",
              "      <th>í•™ìŠµmean</th>\n",
              "      <th>í…ŒìŠ¤íŠ¸sum</th>\n",
              "      <th>í…ŒìŠ¤íŠ¸len</th>\n",
              "      <th>í…ŒìŠ¤íŠ¸mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q1</th>\n",
              "      <td>223</td>\n",
              "      <td>450</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>127</td>\n",
              "      <td>250</td>\n",
              "      <td>0.5080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q2</th>\n",
              "      <td>253</td>\n",
              "      <td>450</td>\n",
              "      <td>0.5622</td>\n",
              "      <td>151</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3</th>\n",
              "      <td>270</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>174</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S1</th>\n",
              "      <td>390</td>\n",
              "      <td>450</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>199</td>\n",
              "      <td>250</td>\n",
              "      <td>0.7960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S2</th>\n",
              "      <td>293</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6511</td>\n",
              "      <td>166</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S3</th>\n",
              "      <td>298</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6622</td>\n",
              "      <td>167</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-867d516f-4ba4-4529-bbb3-76930c1eca8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-867d516f-4ba4-4529-bbb3-76930c1eca8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-867d516f-4ba4-4529-bbb3-76930c1eca8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d970f34-34a2-451d-989c-4c6e621cc466\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d970f34-34a2-451d-989c-4c6e621cc466')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d970f34-34a2-451d-989c-4c6e621cc466 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"submission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\ud559\\uc2b5sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 223,\n        \"max\": 390,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          223,\n          253,\n          298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud559\\uc2b5len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 450,\n        \"max\": 450,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud559\\uc2b5mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1268919374350011,\n        \"min\": 0.4955555555555556,\n        \"max\": 0.8666666666666667,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4955555555555556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 127,\n        \"max\": 199,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 250,\n        \"max\": 250,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09593331016909612,\n        \"min\": 0.508,\n        \"max\": 0.796,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# k-fold: 5\n",
            "# train: 392\n",
            "\n",
            " STEP4: OOF ì˜ˆì¸¡ ìƒì„±\n",
            "[OOF - Q1] F1 score: 0.6980\n",
            "[OOF - Q2] F1 score: 0.6873\n",
            "[OOF - Q3] F1 score: 0.6779\n",
            "[OOF - S2] F1 score: 0.6678\n",
            "[OOF - S3] F1 score: 0.7158\n",
            "[OOF - S1] F1 score: 0.5464\n",
            "[OOF] F1 score: 0.6655\n",
            "# /content/drive/MyDrive/data/oof_result_0.6447528574485211.csv ì €ì¥ ì™„ë£Œ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiMLigXg-ZuE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCYE6A1N6foi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDbhAsqTb16h+p+q3pVTiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}