{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacobgreen4477/The-4th-ETRI-AI-Human-Understanding-Competition/blob/main/202_%EC%8B%A4%ED%97%98_v2_0_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTgURBTcpY0Q"
      },
      "source": [
        "> title : 제 4회 ETRI 휴먼이해 인공지능 논문경진대회 <br>\n",
        "> author : hjy <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QhncbejZIfV"
      },
      "source": [
        "In our study, we used smartphones, smartwatches, sleep sensors, and self-recording apps to collect daily life logs and sleep health records of study participants in 2024.The data collection procedures and methods followed a similar approach to those used in previous studies. Here, we pu﻿blicly provide the following 12 data items, which comprise a total of 700 days' worth of lifelog data, strictly for non-commercial and academic research purposes only.\n",
        "- mACStatus: Indicates whether the smartphone is currently being charged.\n",
        "- mActivity: Value calculated by the Google Activity Recognition API.\n",
        "- mAmbience: Ambient sound identification labels and their respective probabilities.\n",
        "- mBle: Bluetooth devices around individual subject.\n",
        "- mGps: Multiple GPS coordinates measured within a single minute using the smartphone.\n",
        "- mLight: Ambient light measured by the smartphone.\n",
        "- mScreenStatus: Indicates whether the smartphone screen is in use.\n",
        "- mUsageStats: Indicates which apps were used on the smartphone and for how long.\n",
        "- mWifi: Wifi devices around individual subject.\n",
        "- wHr: Heart rate readings recorded by the smartwatch.\n",
        "- wLight: Ambient light measured by the smartwatch.\n",
        "- wPedo: Step data recorded by the smartwatch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkY5S7k0ZLFG"
      },
      "source": [
        "For the purpose of training a learning model to predict sleep health, fatigue, and stress, the following six metrics were derived from sleep sensor data and self-reported survey records. Each metric consists of values categorized into either two levels (0, 1) or three levels (0, 1, 2), depending on the specific metric. The detailed classification criteria for each metric's levels will be provided in a separate document.These\n",
        "metrics assign a value of 0 for sleep records that do not meet the recommended guidelines.For instance, the first questionnaire metric (Q1) is assigned a value of 1 on days when an\n",
        "individual’s self-reported sleep quality exceeds their average over the experimental period, and 0 when it\n",
        "falls below that average. Similarly, the second and third metrics (Q2 and Q3) are assigned a value of 0\n",
        "on days when the participant’s fatigue and stress levels, respectively, exceed their average, and a value of\n",
        "1 when these levels are below average.\n",
        "\n",
        "- Q1: Overall sleep quality as perceived by a subject immediately after waking up.\n",
        "- Q2: Physical fatigue of a subject just before sleep.\n",
        "- Q3: Stress level experienced by a subject just before sleep.\n",
        "- S1: Adherence to sleep guidelines for total sleep time (TST).\n",
        "- S2: Adherence to sleep guidelines for sleep efficiency (SE).\n",
        "- S3: Adherence to sleep guidelines for sleep onset latency (SOL, or SL).\n",
        "\n",
        "수면 건강, 피로, 스트레스 예측을 위한 학습 모델을 훈련시키기 위해, 수면 센서 데이터와 자기 보고식 설문 기록을 기반으로 다음의 6가지 지표를 도출했습니다.\n",
        "각 지표는 해당 항목에 따라 두 수준(0, 1) 또는 세 수준(0, 1, 2)으로 구분된 값을 가집니다.\n",
        "각 지표의 세부 분류 기준은 별도의 문서에서 제공될 예정입니다.\n",
        "\n",
        "- Q1: 기상 직후 본인이 인지한 전반적인 수면의 질\n",
        " - 0: 개인 평균 이하\n",
        " - 1: 개인 평균 이상\n",
        "- Q2: 취침 직전 본인이 느낀 신체적 피로 수준\n",
        " - 0: 높은 피로 수준\n",
        " - 1: 낮은 피로 수준\n",
        "- Q3: 취침 직전 본인이 느낀 스트레스 수준\n",
        " - 0: 높은 스트레스 수준\n",
        " - 1: 낮은 스트레스 수준\n",
        "- S1: 총 수면 시간(TST) 가이드라인을 준수했는지 3LEVELS\n",
        " - 0: 가이드라인 미준수\n",
        " - 1: 가이드라인 부분적 준수\n",
        " - 2: 가이드라인 완전 준수\n",
        "- S2: 수면 효율(SE) 가이드라인을 준수했는지 여부\n",
        "- (SE: 잠자리에 누워 있었던 전체 시간 대비, 실제로 잠든 시간의 비율)\n",
        " - 0: 가이드라인 미준수\n",
        " - 1: 가이드라인 준수\n",
        "- S3: 수면 잠들기 지연 시간(SOL 또는 SL) 가이드라인을 준수했는지 여부\n",
        "- (SOL: 잠자리에 누운 순간부터 실제로 잠드는 데까지 걸린 시간)\n",
        " - 0: 가이드라인 미준수\n",
        " - 1: 가이드라인 준수"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDVNXLQtLU6X"
      },
      "source": [
        "### 📦 라이브러리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN6iwVhQpR_a",
        "outputId": "f9c08795-c5c6-4c0a-c4bf-9b59344b7550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haversine\n",
            "  Downloading haversine-2.9.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading haversine-2.9.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Installing collected packages: haversine\n",
            "Successfully installed haversine-2.9.0\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.1)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.15.3)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.6.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.1\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "! pip install haversine\n",
        "! pip install optuna\n",
        "! pip install category_encoders\n",
        "! pip install timm\n",
        "import timm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "from tqdm.auto import tqdm\n",
        "from collections import Counter\n",
        "from scipy.stats import entropy\n",
        "from haversine import haversine  # 설치 필요: pip install haversine\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvEVmxWsRH4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "from tqdm import tqdm  # ← 추가\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from datetime import time\n",
        "from datetime import timedelta\n",
        "from functools import reduce\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
        "import lightgbm as lgb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from lightgbm import LGBMClassifier, log_evaluation, early_stopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# seed 고정\n",
        "SD = 42\n",
        "random.seed(SD)\n",
        "np.random.seed(SD)\n",
        "os.environ['PYTHONHASHSEED'] = str(SD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iVOoFq7pSCM",
        "outputId": "576d7ab9-73ff-4aed-fee6-19ab1b7455c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIbC9LQkv6T4"
      },
      "outputs": [],
      "source": [
        "# pandas 옵션\n",
        "pd.set_option('display.max_columns', 999)\n",
        "pd.set_option('display.max_rows', 999)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.float_format', lambda x: '%0.4f' % x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38uzdH-UYh_3"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_ZQfubWYiCk"
      },
      "outputs": [],
      "source": [
        "def correct_lifelog_date_for_midnight(df, timestamp_col='timestamp', lifelog_col='lifelog_date'):\n",
        "    df = df.copy()\n",
        "    df[timestamp_col] = pd.to_datetime(df[timestamp_col])\n",
        "    df[lifelog_col] = pd.to_datetime(df[lifelog_col])\n",
        "\n",
        "    # 조건: timestamp의 시(hour)가 0~5시인 경우만 하루 차감\n",
        "    mask = (df[timestamp_col].dt.hour >= 0) & (df[timestamp_col].dt.hour < 6)\n",
        "    df.loc[mask, lifelog_col] = df.loc[mask, lifelog_col] - pd.Timedelta(days=1)\n",
        "\n",
        "    # lifelog_date를 문자열로 바꾸는 경우\n",
        "    df[lifelog_col] = df[lifelog_col].dt.date.astype(str)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ikO0GN_KxyQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from io import StringIO\n",
        "\n",
        "string = \"\"\"\n",
        "subject_id\tsleep_date\n",
        "id01\t2024-07-24\n",
        "id01\t2024-07-27\n",
        "id01\t2024-08-18\n",
        "id01\t2024-08-19\n",
        "id01\t2024-08-20\n",
        "id01\t2024-08-21\n",
        "id01\t2024-08-22\n",
        "id01\t2024-08-24\n",
        "id01\t2024-08-25\n",
        "id01\t2024-08-26\n",
        "id01\t2024-08-27\n",
        "id01\t2024-08-28\n",
        "id01\t2024-08-29\n",
        "id01\t2024-08-30\n",
        "id02\t2024-08-23\n",
        "id02\t2024-08-24\n",
        "id02\t2024-09-16\n",
        "id02\t2024-09-17\n",
        "id02\t2024-09-19\n",
        "id02\t2024-09-20\n",
        "id02\t2024-09-21\n",
        "id02\t2024-09-22\n",
        "id02\t2024-09-23\n",
        "id02\t2024-09-24\n",
        "id02\t2024-09-25\n",
        "id02\t2024-09-26\n",
        "id02\t2024-09-27\n",
        "id02\t2024-09-28\n",
        "id03\t2024-08-30\n",
        "id03\t2024-09-01\n",
        "id03\t2024-09-02\n",
        "id03\t2024-09-03\n",
        "id03\t2024-09-05\n",
        "id03\t2024-09-06\n",
        "id03\t2024-09-07\n",
        "id04\t2024-09-03\n",
        "id04\t2024-09-04\n",
        "id04\t2024-09-05\n",
        "id04\t2024-09-06\n",
        "id04\t2024-09-07\n",
        "id04\t2024-09-08\n",
        "id04\t2024-09-09\n",
        "id04\t2024-10-08\n",
        "id04\t2024-10-09\n",
        "id04\t2024-10-10\n",
        "id04\t2024-10-11\n",
        "id04\t2024-10-12\n",
        "id04\t2024-10-13\n",
        "id04\t2024-10-14\n",
        "id05\t2024-10-19\n",
        "id05\t2024-10-23\n",
        "id05\t2024-10-24\n",
        "id05\t2024-10-25\n",
        "id05\t2024-10-26\n",
        "id05\t2024-10-27\n",
        "id05\t2024-10-28\n",
        "id06\t2024-07-25\n",
        "id06\t2024-07-26\n",
        "id06\t2024-07-27\n",
        "id06\t2024-07-28\n",
        "id06\t2024-07-29\n",
        "id06\t2024-07-30\n",
        "id06\t2024-07-31\n",
        "id07\t2024-07-07\n",
        "id07\t2024-07-08\n",
        "id07\t2024-07-09\n",
        "id07\t2024-07-10\n",
        "id07\t2024-07-11\n",
        "id07\t2024-07-12\n",
        "id07\t2024-07-13\n",
        "id07\t2024-07-30\n",
        "id07\t2024-08-01\n",
        "id07\t2024-08-02\n",
        "id07\t2024-08-03\n",
        "id07\t2024-08-04\n",
        "id07\t2024-08-05\n",
        "id07\t2024-08-06\n",
        "id08\t2024-08-28\n",
        "id08\t2024-08-29\n",
        "id08\t2024-08-30\n",
        "id08\t2024-08-31\n",
        "id08\t2024-09-01\n",
        "id08\t2024-09-02\n",
        "id08\t2024-09-04\n",
        "id09\t2024-08-02\n",
        "id09\t2024-08-22\n",
        "id09\t2024-08-23\n",
        "id09\t2024-08-24\n",
        "id09\t2024-08-25\n",
        "id09\t2024-08-27\n",
        "id09\t2024-08-28\n",
        "id09\t2024-08-29\n",
        "id09\t2024-08-30\n",
        "id09\t2024-08-31\n",
        "id09\t2024-09-01\n",
        "id09\t2024-09-02\n",
        "id09\t2024-09-03\n",
        "id09\t2024-09-04\n",
        "id10\t2024-08-28\n",
        "id10\t2024-08-30\n",
        "id10\t2024-08-31\n",
        "id10\t2024-09-01\n",
        "id10\t2024-09-02\n",
        "id10\t2024-09-03\n",
        "id10\t2024-09-06\n",
        "\"\"\"\n",
        "\n",
        "# DataFrame 생성\n",
        "valid_ids = pd.read_csv(StringIO(string), sep='\\t')\n",
        "valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EvDe55ejzKR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yVuRMUMlXQOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQgtvPb3jzQv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEHsA6naKx0G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodxdJFiv_DJ"
      },
      "source": [
        "### 📦 데이터 읽기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw0cx3wwpSE2"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/data/ch2025_data_items/'\n",
        "\n",
        "# 1\n",
        "mACStatus = pd.read_parquet(path+'ch2025_mACStatus.parquet')\n",
        "mActivity = pd.read_parquet(path+'ch2025_mActivity.parquet')\n",
        "mAmbience = pd.read_parquet(path+'ch2025_mAmbience.parquet')\n",
        "mBle = pd.read_parquet(path+'ch2025_mBle.parquet')\n",
        "mGps = pd.read_parquet(path+'ch2025_mGps.parquet')\n",
        "mLight = pd.read_parquet(path+'ch2025_mLight.parquet')\n",
        "mScreenStatus = pd.read_parquet(path+'ch2025_mScreenStatus.parquet')\n",
        "mUsageStats = pd.read_parquet(path+'ch2025_mUsageStats.parquet')\n",
        "mWifi = pd.read_parquet(path+'ch2025_mWifi.parquet')\n",
        "wHr = pd.read_parquet(path+'ch2025_wHr.parquet')\n",
        "wLight = pd.read_parquet(path+'ch2025_wLight.parquet')\n",
        "wPedo = pd.read_parquet(path+'ch2025_wPedo.parquet')\n",
        "\n",
        "# 2\n",
        "train = pd.read_csv('/content/drive/MyDrive/data/ch2025_metrics_train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/data/ch2025_submission_sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk45v0V5xiay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83ce508f-2602-4010-9785-5f87d6e17d9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.56 s, sys: 906 ms, total: 8.46 s\n",
            "Wall time: 8.35 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "mACStatus['lifelog_date'] = mACStatus['timestamp'].astype(str).str[:10]\n",
        "mActivity['lifelog_date'] = mActivity['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_labels_and_probs(row):\n",
        "#     items = row['m_ambience']\n",
        "#     labels = [item[0] for item in items]\n",
        "#     probs = [item[1] for item in items]\n",
        "#     return pd.Series({'labels': labels, 'prob': probs})\n",
        "\n",
        "# mAmbience[['labels', 'prob']]  = mAmbience.apply(extract_labels_and_probs, axis=1)\n",
        "# mAmbience['lifelog_date'] = mAmbience['timestamp'].astype(str).str[:10]\n",
        "# mAmbience = mAmbience.drop(columns=['m_ambience'])\n",
        "\n",
        "# def extract_mble_info(row):\n",
        "#     m_data = row['m_ble']\n",
        "#     address = [item['address'] for item in m_data]\n",
        "#     device_class = [item['device_class'] for item in m_data]\n",
        "#     rssi = [item['rssi'] for item in m_data]\n",
        "#     return pd.Series({'address': address, 'device_class': device_class, 'rssi': rssi})\n",
        "\n",
        "# mBle[['address','device_class','rssi']] = mBle.apply(extract_mble_info, axis=1)\n",
        "# mBle['lifelog_date'] = mBle['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_gps_info(row):\n",
        "#     m_data = row['m_gps']\n",
        "#     altitude = [item['altitude'] for item in m_data]\n",
        "#     latitude = [item['latitude'] for item in m_data]\n",
        "#     longitude = [item['longitude'] for item in m_data]\n",
        "#     speed = [item['speed'] for item in m_data]\n",
        "#     return pd.Series({'altitude': altitude, 'latitude': latitude, 'longitude': longitude, 'speed': speed})\n",
        "\n",
        "# mGps[['altitude','latitude','longitude','speed']] = mGps.apply(extract_gps_info, axis=1)\n",
        "# mGps['lifelog_date'] = mGps['timestamp'].astype(str).str[:10]\n",
        "# mGps = mGps.drop(columns=['m_gps'])\n",
        "\n",
        "mLight['lifelog_date'] = mLight['timestamp'].astype(str).str[:10]\n",
        "mScreenStatus['lifelog_date'] = mScreenStatus['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_mUsageStats_info(row):\n",
        "#     m_data = row['m_usage_stats']\n",
        "#     app_name = [item['app_name'] for item in m_data]\n",
        "#     total_time = [item['total_time'] for item in m_data]\n",
        "#     return pd.Series({'app_name': app_name, 'total_time': total_time})\n",
        "\n",
        "# mUsageStats[['app_name', 'total_time']] = mUsageStats.apply(extract_mUsageStats_info, axis=1)\n",
        "# mUsageStats['lifelog_date'] = mUsageStats['timestamp'].astype(str).str[:10]\n",
        "\n",
        "# def extract_wifi_info(row):\n",
        "#     wifi_data = row['m_wifi']\n",
        "#     bssids = [item['bssid'] for item in wifi_data]\n",
        "#     rssis = [item['rssi'] for item in wifi_data]\n",
        "#     return pd.Series({'bssid': bssids, 'rssi': rssis})\n",
        "\n",
        "# mWifi[['bssid', 'rssi']] = mWifi.apply(extract_wifi_info, axis=1)\n",
        "# mWifi['lifelog_date'] = mWifi['timestamp'].astype(str).str[:10]\n",
        "\n",
        "wHr['lifelog_date'] = wHr['timestamp'].astype(str).str[:10]\n",
        "wLight['lifelog_date'] = wLight['timestamp'].astype(str).str[:10]\n",
        "wPedo['lifelog_date'] = wPedo['timestamp'].astype(str).str[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp0et2XoiBZ7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE-06HN6gtqy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBZKGmxSRBQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAyS_RTHjjp3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp40u0R88PY_"
      },
      "source": [
        "### 📌 이미지 생성\n",
        "- spleeptime만 추출 (00시부터 06시까지)\n",
        "- 참고 : https://github.com/seongjiko/Pixleep/tree/master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-qgvZd-8cir"
      },
      "outputs": [],
      "source": [
        "def filter_by_group_size(df, group_cols=['subject_id', 'lifelog_date']):\n",
        "    # 그룹별 건수 계산\n",
        "    group_counts = df.groupby(group_cols).size().reset_index(name='count')\n",
        "    # 평균 건수 계산\n",
        "    mean_count = group_counts['count'].mean()\n",
        "    # 평균 초과 그룹만 추출\n",
        "    valid_groups = group_counts[group_counts['count'] > mean_count*0.5][group_cols]\n",
        "    # 원본과 inner join으로 필터링\n",
        "    return df.merge(valid_groups, on=group_cols, how='inner')\n",
        "\n",
        "def make_timestamps_unique(df, timestamp_col='timestamp'):\n",
        "    # 'timestamp' 컬럼을 기준으로 정렬\n",
        "    df = df.sort_values(by=[timestamp_col])\n",
        "    # 각 'timestamp'가 중복된 횟수를 세어 나노초 단위로 증가시킴\n",
        "    df[timestamp_col] = df[timestamp_col] + pd.to_timedelta(df.groupby(timestamp_col).cumcount(), unit='ns')\n",
        "    return df\n",
        "\n",
        "def average_list_columns(df, list_columns, pk_cols=['subject_id', 'lifelog_date']):\n",
        "\n",
        "    for col in list_columns:\n",
        "\n",
        "        def safe_mean(x):\n",
        "            if isinstance(x, list):\n",
        "                return np.mean(x) if len(x) > 0 else np.nan\n",
        "            elif isinstance(x, (int, float, np.integer, np.floating, type(None))):\n",
        "                return x\n",
        "            elif isinstance(x, (np.ndarray, pd.Series)):\n",
        "                return np.mean(x)\n",
        "            elif pd.api.types.is_scalar(x) and pd.isna(x):\n",
        "                return np.nan\n",
        "            else:\n",
        "                return np.nan\n",
        "\n",
        "        df[col] = df[col].apply(safe_mean)\n",
        "\n",
        "    return df\n",
        "\n",
        "def center_list_values(df, list_columns):\n",
        "    for col in list_columns:\n",
        "        def center(x):\n",
        "            if isinstance(x, list) and len(x) > 0:\n",
        "                mean = np.mean(x)\n",
        "                return [np.round(v - mean,3) for v in x]\n",
        "            return x  # NaN이나 비리스트는 그대로 유지\n",
        "        df[col] = df[col].apply(center)\n",
        "    return df\n",
        "\n",
        "def sleeptime_cutter(data): # 잠자는 시간 데이터가 더 중요한지 실험(🔥🔥🔥)\n",
        "\n",
        "    data_filtered = data.copy()\n",
        "    data_filtered['timestamp'] = pd.to_datetime(data_filtered['timestamp'])\n",
        "    data_filtered['lifelog_date'] = pd.to_datetime(data_filtered['lifelog_date'])\n",
        "\n",
        "    # spleeptime만 추출 (00시부터 06시까지)\n",
        "    data_filtered = data_filtered[(data_filtered['timestamp'].dt.hour >= 0) & (data_filtered['timestamp'].dt.hour < 6)]\n",
        "\n",
        "    # 하루 차감\n",
        "    data_filtered['timestamp'] = data_filtered['timestamp'] - pd.Timedelta(days=1)\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'] - pd.Timedelta(days=1)\n",
        "    # print('>> D-1 하루 차감! (lifelog_date 실제 일자는 D+1 새벽(0~6시) 데이터임)')\n",
        "\n",
        "    # lifelog_date를 다시 문자열로\n",
        "    data_filtered['lifelog_date'] = data_filtered['lifelog_date'].dt.date.astype(str)\n",
        "\n",
        "    return data_filtered\n",
        "\n",
        "def merge_data_for_group(user, date):\n",
        "\n",
        "    # 데이터 로드\n",
        "    # acc_group = mGps.copy()\n",
        "    activity_group = mActivity.copy()\n",
        "    hr_group = wHr.copy()\n",
        "    wPedo_group = wPedo[['subject_id','timestamp','lifelog_date','step']].copy()\n",
        "    mLight_group = mLight[['subject_id','timestamp','lifelog_date','m_light']].copy()\n",
        "    wLight_group = wLight[['subject_id','timestamp','lifelog_date','w_light']].copy()\n",
        "\n",
        "    # 건수가 없는 일자 이상치로 판단하고 제외\n",
        "    activity_group = filter_by_group_size(activity_group)\n",
        "    hr_group = filter_by_group_size(hr_group)\n",
        "    wPedo_group = filter_by_group_size(wPedo_group)\n",
        "    mLight_group = filter_by_group_size(mLight_group)\n",
        "    wLight_group = filter_by_group_size(wLight_group)\n",
        "\n",
        "    # sleeptime만 남기고 나머지 삭제 (🔥🔥🔥)\n",
        "    # activity_group = sleeptime_cutter(activity_group)\n",
        "    # hr_group = sleeptime_cutter(hr_group)\n",
        "    # wPedo_group = sleeptime_cutter(wPedo_group)\n",
        "    # mLight_group = sleeptime_cutter(mLight_group)\n",
        "    # wLight_group = sleeptime_cutter(wLight_group)\n",
        "\n",
        "    # 필터\n",
        "    activity_group = activity_group.loc[(activity_group['subject_id']==user) & (activity_group['lifelog_date']==date),:]\n",
        "    hr_group = hr_group.loc[(hr_group['subject_id']==user) & (hr_group['lifelog_date']==date),:]\n",
        "    wPedo_group = wPedo_group.loc[(wPedo_group['subject_id']==user) & (wPedo_group['lifelog_date']==date),:]\n",
        "    mLight_group = mLight_group.loc[(mLight_group['subject_id']==user) & (mLight_group['lifelog_date']==date),:]\n",
        "    wLight_group = wLight_group.loc[(wLight_group['subject_id']==user) & (wLight_group['lifelog_date']==date),:]\n",
        "\n",
        "    # 리스트 평균값으로 변환\n",
        "    # acc_group = average_list_columns(acc_group, ['altitude', 'latitude', 'longitude','speed'])\n",
        "    hr_group = average_list_columns(hr_group, ['heart_rate'])\n",
        "\n",
        "    # 'timestamp'를 고유하게 만듦\n",
        "    # acc_group = make_timestamps_unique(acc_group)\n",
        "    activity_group = make_timestamps_unique(activity_group)\n",
        "    hr_group = make_timestamps_unique(hr_group)\n",
        "    wPedo_group = make_timestamps_unique(wPedo_group)\n",
        "    mLight_group = make_timestamps_unique(mLight_group)\n",
        "    wLight_group = make_timestamps_unique(wLight_group)\n",
        "\n",
        "    # 'timestamp'를 인덱스로 설정하고 'subject_id'와 'date' 컬럼 제거\n",
        "    # mAcc_data = acc_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    activity_data = activity_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    e4Hr_data = hr_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wPedo_data = wPedo_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    mLight_data = mLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "    wLight_data = wLight_group.set_index('timestamp').drop(columns=['subject_id', 'lifelog_date']).resample('S').nearest()\n",
        "\n",
        "    # 하루 86400초의 타임스탬프 생성\n",
        "    start_time = datetime.strptime(date, '%Y-%m-%d')\n",
        "    end_time = start_time + timedelta(days=1)\n",
        "    all_timestamps = pd.date_range(start=start_time, end=end_time, freq='S', inclusive='left')\n",
        "    merged_data = pd.DataFrame(index=all_timestamps)\n",
        "    merged_data.index.name = 'timestamp'\n",
        "\n",
        "    # 데이터 병합\n",
        "    # if not mAcc_data.empty:\n",
        "    #     merged_data = merged_data.join(mAcc_data, how='left')\n",
        "    if not e4Hr_data.empty:\n",
        "        merged_data = merged_data.join(e4Hr_data, how='left')\n",
        "    if not activity_data.empty:\n",
        "        merged_data = merged_data.join(activity_data, how='left')\n",
        "    if not wPedo_data.empty:\n",
        "        merged_data = merged_data.join(wPedo_data, how='left')\n",
        "    if not mLight_data.empty:\n",
        "        merged_data = merged_data.join(mLight_data, how='left')\n",
        "    if not wLight_data.empty:\n",
        "        merged_data = merged_data.join(wLight_data, how='left')\n",
        "\n",
        "    # 필요한 컬럼만 유지하고 NaN 값으로 채우기\n",
        "    # merged_data = merged_data.reindex(columns=['altitude', 'latitude', 'longitude', 'speed', 'heart_rate', 'm_activity', 'step'])\n",
        "    merged_data = merged_data.reindex(columns=['heart_rate', 'm_activity', 'step', 'm_light', 'w_light'])\n",
        "\n",
        "    # 선형 보간 적용\n",
        "    merged_data = merged_data.interpolate(method='time')\n",
        "\n",
        "    ### Activity 데이터의 그룹화 적용\n",
        "    # group0 : 0 (IN_VEHICLE), 1 (ON_BICYCLE), 2 (ON_FOOT), 7 (WALKING), 8 (RUNNING), 5 (TILTING)\n",
        "    # group1 : 3 (STILL)\n",
        "    # group2 : 4 (UNKNOWN)\n",
        "    activity_mapping = {\n",
        "        0: 1,\n",
        "        1: 1,\n",
        "        2: 1,\n",
        "        7: 1,\n",
        "        8: 2,\n",
        "        5: 1,\n",
        "        3: 0,\n",
        "        4: 0\n",
        "    }\n",
        "    merged_data['m_activity'] = merged_data['m_activity'].map(activity_mapping)\n",
        "\n",
        "    # subject_id와 date를 추가\n",
        "    merged_data['subject_id'] = user\n",
        "    merged_data['lifelog_date'] = date\n",
        "\n",
        "    return merged_data\n",
        "\n",
        "def plot_time_series(data, user, date, channel_name):\n",
        "\n",
        "    # x축을 00:00:00부터 23:59:59까지 고정\n",
        "    total_seconds = 86400\n",
        "    time_range = pd.date_range(start=datetime.strptime(date, '%Y-%m-%d'), periods=total_seconds, freq='S')\n",
        "\n",
        "    # 데이터를 시간 단위로 정렬\n",
        "    data = data.reindex(time_range)\n",
        "\n",
        "    # 시계열 이미지 생성\n",
        "    fig, axes = plt.subplots(5, 1, figsize=(5, 5), sharex=True, facecolor='black')\n",
        "    fig.patch.set_facecolor('black')\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_facecolor('black')\n",
        "        ax.spines['top'].set_visible(False)           # Hide the top spine\n",
        "        ax.spines['right'].set_visible(False)         # Hide the right spine\n",
        "        ax.spines['left'].set_visible(False)          # Hide the left spine\n",
        "        ax.spines['bottom'].set_visible(False)        # Hide the bottom spine\n",
        "\n",
        "    # 설정한 시간 범위에 맞게 x축 설정\n",
        "    for ax in axes:\n",
        "        ax.set_xlim([time_range[0], time_range[-1]])\n",
        "\n",
        "    # plot\n",
        "    if 'heart_rate' in data.columns:\n",
        "        axes[0].plot(data.index, data['heart_rate'], color='white')\n",
        "    if 'm_activity' in data.columns:\n",
        "        axes[1].plot(data.index, data['m_activity'], color='white')\n",
        "    if 'step' in data.columns:\n",
        "        axes[2].plot(data.index, data['step'], color='white')\n",
        "    if 'm_light' in data.columns:\n",
        "        axes[3].plot(data.index, data['m_light'], color='white')\n",
        "    if 'w_light' in data.columns:\n",
        "        axes[4].plot(data.index, data['w_light'], color='white')\n",
        "\n",
        "    plt.tight_layout()  # Make the layout tight\n",
        "    fname = f'{path}{channel_name}/user{user}_{date}_{channel_name}.png'\n",
        "    plt.savefig(fname)\n",
        "    # print(fname)\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdMb8wEs8c74"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "channel_name = 'ch5_sleeptime'\n",
        "\n",
        "# train test 데이터 합치기\n",
        "a1 = train[['subject_id', 'lifelog_date']].copy()\n",
        "a2 = test[['subject_id', 'lifelog_date']].copy()\n",
        "val_df = pd.concat([a1,a2]).reset_index(drop=True)\n",
        "print('# train:',len(train))\n",
        "print('# test:',len(test))\n",
        "print('# 전체 데이터:',len(val_df))\n",
        "\n",
        "# 파일명\n",
        "val_df = val_df[['subject_id', 'lifelog_date']].copy()\n",
        "val_df['filename'] = val_df.apply(lambda x: f\"user{x['subject_id']}_{x['lifelog_date']}_{channel_name}.png\", axis=1)\n",
        "\n",
        "# 만들어진 이미지\n",
        "image_dir = f'{path}{channel_name}'\n",
        "image_files = [f for f in os.listdir(image_dir) if f.endswith(f'_{channel_name}.png')]\n",
        "\n",
        "# 남은 샘플\n",
        "val_df = val_df.loc[~val_df['filename'].isin(image_files),:].reset_index(drop=True)\n",
        "print('# 남은 샘플수:',len(val_df))\n",
        "\n",
        "# ====================================\n",
        "# 샘플 테스트\n",
        "# ====================================\n",
        "# rules = (\n",
        "#   (val_df['subject_id']=='id01') & (val_df['lifelog_date'].isin(['2024-07-01']))\n",
        "# )\n",
        "# val_df = val_df.loc[rules,:].copy().head(1)\n",
        "\n",
        "# 이미지 생성\n",
        "bar = tqdm(range(val_df.shape[0]))\n",
        "for idx in bar:\n",
        "    user, date, *rest = val_df.iloc[idx].values\n",
        "    bar.set_description(f'user: {user}, date: {date}')\n",
        "    merged_data = merge_data_for_group(user, date)\n",
        "    plot_time_series(merged_data, user, date, channel_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5_sNQjeX8Zb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNSFIDUvX8dG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hC3NWqhDybU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FHA2ZwrDyuf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📌 모델 학습"
      ],
      "metadata": {
        "id": "8qrXzX72JA0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 정사각형 패딩 후, 299x299로 리사이즈 (Xception 기준)\n",
        "def preprocess_image(img):\n",
        "    # 정사각형 패딩\n",
        "    w, h = img.size\n",
        "    max_dim = max(w, h)\n",
        "    padded_img = Image.new(\"RGB\", (max_dim, max_dim), (127, 127, 127))  # 중간값 127로 채움\n",
        "    padded_img.paste(img, ((max_dim - w) // 2, (max_dim - h) // 2))\n",
        "\n",
        "    # 리사이즈 및 [-1, 1] 정규화\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((299, 299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # [0,1] -> [-1,1]\n",
        "    ])\n",
        "    return transform(padded_img)"
      ],
      "metadata": {
        "id": "5HrP9Uj1B3LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_name = 'ch5_sleeptime'\n",
        "\n",
        "# 이미지 경로 설정\n",
        "dataset_path = f'{path}{channel_name}'\n",
        "\n",
        "# 이미지 크기 설정 (Resize에 사용할 값)\n",
        "image_size = 500\n",
        "\n",
        "def find_img_mean_std(dataset_path,image_size):\n",
        "\n",
        "  import torch\n",
        "  import os\n",
        "  from torchvision import transforms\n",
        "  from PIL import Image\n",
        "\n",
        "  # 전처리 파이프라인 (Normalize 제외)\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize(image_size),\n",
        "      transforms.ToTensor(),  # [0, 255] -> [0, 1]로 스케일링\n",
        "  ])\n",
        "\n",
        "  # PNG 파일 목록 가져오기\n",
        "  image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
        "\n",
        "  # 이미지 로드 및 텐서 변환\n",
        "  images = []\n",
        "  for img_file in image_files:\n",
        "      try:\n",
        "          img = Image.open(img_file).convert('RGB')  # RGB로 강제 변환\n",
        "          tensor_img = transform(img)  # [C, H, W] 형태\n",
        "          images.append(tensor_img)\n",
        "      except Exception as e:\n",
        "          print(f\"이미지 로드 실패: {img_file} - {e}\")\n",
        "\n",
        "  # 모든 이미지를 하나의 텐서로 결합\n",
        "  # shape: [N, C, H, W] (N: 이미지 수, C: 채널, H: 높이, W: 너비)\n",
        "  all_images = torch.stack(images, dim=0)\n",
        "\n",
        "  # 채널별 평균 및 표준편차 계산\n",
        "  # 평균: [N, C, H, W] → [C,] (모든 이미지, 모든 픽셀에 대한 평균)\n",
        "  # 표준편차: 동일한 방식으로 계산\n",
        "  mean = all_images.mean(dim=[0, 2, 3])  # [C,] (예: [R, G, B])\n",
        "  std = all_images.std(dim=[0, 2, 3])    # [C,] (예: [R, G, B])\n",
        "\n",
        "  # 결과 출력\n",
        "  print(\"평균(mean):\", mean.tolist())\n",
        "  print(\"표준편차(std):\", std.tolist())\n",
        "\n",
        "  return mean.tolist(), std.tolist()\n",
        "\n",
        "img_mean, img_std = find_img_mean_std(dataset_path,image_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd5VbPgmnRZC",
        "outputId": "8b2fcd8c-3b86-48b4-d9f5-93ce228a18f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균(mean): [0.012695113196969032, 0.012695113196969032, 0.012695113196969032]\n",
            "표준편차(std): [0.10443976521492004, 0.10443976521492004, 0.10443976521492004]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTHFNnZH2HJy"
      },
      "outputs": [],
      "source": [
        "def extract_cnn_features(\n",
        "    image_root_dir,\n",
        "    img_mean, img_std,\n",
        "    nfeatures,\n",
        "    batch_size=32,\n",
        "    image_size=(500, 500),\n",
        "    model_name='resnet50'\n",
        "):\n",
        "    # 이미지 확장자 허용 목록\n",
        "    valid_exts = {'.png'}\n",
        "\n",
        "    # 이미지 경로 수집\n",
        "    def collect_image_paths(root_dir):\n",
        "        image_paths = []\n",
        "        for root, _, files in os.walk(root_dir):\n",
        "            for fname in files:\n",
        "                if os.path.splitext(fname)[1].lower() in valid_exts:\n",
        "                    image_paths.append(os.path.join(root, fname))\n",
        "        return image_paths\n",
        "\n",
        "    # Dataset 정의\n",
        "    class ImageDataset(Dataset):\n",
        "        def __init__(self, image_paths, transform=None):\n",
        "            self.image_paths = image_paths\n",
        "            self.transform = transform\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.image_paths)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            path = self.image_paths[idx]\n",
        "            image = Image.open(path).convert('RGB')\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, os.path.relpath(path)\n",
        "\n",
        "    # Transform & 모델\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=img_mean, std=img_std)\n",
        "    ])\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # 모델 선택\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "    # feature_extractor = torch.nn.Sequential(*list(model.children())[:-1]).to(device)\n",
        "    # feature_extractor.eval()\n",
        "\n",
        "    # # 모델 설정 부분 수정\n",
        "    # model = getattr(models, model_name)(pretrained=True)\n",
        "\n",
        "    # # ResNet50의 경우, 마지막 FC 레이어 제거 후 Linear(2048 → 10) 추가\n",
        "    # features = list(model.children())[:-1]  # 마지막 FC 레이어 제거\n",
        "    # features.extend([\n",
        "    #     torch.nn.Flatten(),  # [B, 2048, 1, 1] → [B, 2048]\n",
        "    #     torch.nn.Linear(2048, nfeatures)  # 2048 → 10 차원\n",
        "    # ])\n",
        "\n",
        "    # Xception 모델 불러오기\n",
        "    model = timm.create_model(model_name, pretrained=True)\n",
        "\n",
        "    # 모든 레이어 fine-tuning 가능하게 설정\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    # feature extractor 만들기 (특징 추출 전단만 사용 시)\n",
        "    features = list(model.children())[:-1]  # 마지막 분류기 제거\n",
        "    features.extend([\n",
        "        torch.nn.Flatten(),\n",
        "        torch.nn.Linear(model.num_features, nfeatures)  # model.num_features → 2048\n",
        "    ])\n",
        "\n",
        "    feature_extractor = torch.nn.Sequential(*features).to(device)\n",
        "    feature_extractor.eval()\n",
        "\n",
        "    # 데이터로더 생성\n",
        "    image_paths = collect_image_paths(image_root_dir)\n",
        "    dataset = ImageDataset(image_paths, transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Feature 추출\n",
        "    all_features = []\n",
        "    all_names = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, names in tqdm(dataloader):\n",
        "            imgs = imgs.to(device)\n",
        "            feats = feature_extractor(imgs)\n",
        "            feats = feats.view(feats.size(0), -1).cpu()\n",
        "            all_features.append(feats)\n",
        "            all_names.extend(names)\n",
        "\n",
        "    features_tensor = torch.cat(all_features, dim=0)\n",
        "    df = pd.DataFrame(features_tensor.numpy())\n",
        "    df.insert(0, 'image_path', all_names)\n",
        "    fname = f\"{path}img_features_{channel_name}.csv\"\n",
        "    df.to_csv(fname, index=False)\n",
        "    print(f\">> Features saved to: {fname}\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backbone_name='resnext101_32x32d'\n",
        "# backbone_name='resnet18'\n",
        "# resnet34\tresnet18보다 깊지만 속도 손해 적음\n",
        "# resnet50\t널리 검증된 모델, 일반적인 이미지 작업에 매우 안정적\n",
        "# efficientnet_b0\t파라미터 수 적고 정확도 높음, 모바일/경량 환경에 적합\n",
        "# convnext_tiny\t최신 ConvNet 구조로 성능 높고 연산 효율적\n",
        "# resnet101\t더 깊은 네트워크로 복잡한 패턴에 강함\n",
        "# efficientnet_b3 ~ b5\t성능은 뛰어나지만 학습 시간이 더 큼\n",
        "# convnext_base\tConvNet 중 최근 가장 높은 성능\n",
        "# beit_base_patch16_224\tVision Transformer 기반, 사전학습 필수\n",
        "\n",
        "\"\"\"\n",
        "실험1 - 파라미터\n",
        "[상승] nfeatures = 10\n",
        "[하락] nfeatures = 5\n",
        "[하락] nfeatures = 20\n",
        "\n",
        "실험2 - 모델\n",
        "[상승] resnet50\n",
        "[하락] efficientnet_b0\n",
        "\"\"\"\n",
        "\n",
        "# 이미지 파생변수 생성\n",
        "img_features = extract_cnn_features(\n",
        "    image_root_dir=f'{path}{channel_name}',\n",
        "    img_mean=img_mean, img_std=img_std,\n",
        "    nfeatures = 10,\n",
        "    batch_size = 32,\n",
        "    image_size = (500, 500),\n",
        "    model_name = 'xception'  # 다른 모델: xception, resnet50, resnet18, resnet101, efficientnet_b0\n",
        ")\n",
        "\n",
        "# check\n",
        "print('# img_features.shape:',img_features.shape)\n",
        "img_features.head()"
      ],
      "metadata": {
        "id": "z-IZ_vjQJEcB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "56716958-11ed-468c-f215-e6911bb30361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22/22 [07:20<00:00, 20.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Features saved to: /content/drive/MyDrive/data/ch2025_data_items/img_features_ch5_sleeptime.csv\n",
            "# img_features.shape: (700, 11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                 image_path  \\\n",
              "0  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png   \n",
              "1  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png   \n",
              "2  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png   \n",
              "3  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png   \n",
              "4  drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png   \n",
              "\n",
              "        0       1       2      3       4       5       6       7       8  \\\n",
              "0  0.0036  0.0476 -0.1327 0.1057  0.1635 -0.0514 -0.0260 -0.0408 -0.2636   \n",
              "1  0.0211  0.0250 -0.0910 0.0973  0.1678 -0.0574  0.0251 -0.0858 -0.2881   \n",
              "2 -0.0301 -0.0700 -0.0676 0.1313 -0.0237 -0.1176 -0.0081 -0.1813 -0.3135   \n",
              "3  0.0007 -0.0941 -0.0162 0.1509  0.0013 -0.1168  0.0285 -0.2095 -0.2874   \n",
              "4 -0.0044 -0.0070 -0.1055 0.1611  0.0369 -0.0576  0.0404 -0.0877 -0.2168   \n",
              "\n",
              "        9  \n",
              "0 -0.0121  \n",
              "1 -0.0052  \n",
              "2 -0.0519  \n",
              "3 -0.0769  \n",
              "4 -0.1385  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fca70470-a144-4bb7-8322-5205f19b67b1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_path</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-26_ch5_sleeptime.png</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>-0.0514</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0408</td>\n",
              "      <td>-0.2636</td>\n",
              "      <td>-0.0121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-27_ch5_sleeptime.png</td>\n",
              "      <td>0.0211</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>-0.0910</td>\n",
              "      <td>0.0973</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>-0.0574</td>\n",
              "      <td>0.0251</td>\n",
              "      <td>-0.0858</td>\n",
              "      <td>-0.2881</td>\n",
              "      <td>-0.0052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-28_ch5_sleeptime.png</td>\n",
              "      <td>-0.0301</td>\n",
              "      <td>-0.0700</td>\n",
              "      <td>-0.0676</td>\n",
              "      <td>0.1313</td>\n",
              "      <td>-0.0237</td>\n",
              "      <td>-0.1176</td>\n",
              "      <td>-0.0081</td>\n",
              "      <td>-0.1813</td>\n",
              "      <td>-0.3135</td>\n",
              "      <td>-0.0519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-29_ch5_sleeptime.png</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>-0.0941</td>\n",
              "      <td>-0.0162</td>\n",
              "      <td>0.1509</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>-0.1168</td>\n",
              "      <td>0.0285</td>\n",
              "      <td>-0.2095</td>\n",
              "      <td>-0.2874</td>\n",
              "      <td>-0.0769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid01_2024-06-30_ch5_sleeptime.png</td>\n",
              "      <td>-0.0044</td>\n",
              "      <td>-0.0070</td>\n",
              "      <td>-0.1055</td>\n",
              "      <td>0.1611</td>\n",
              "      <td>0.0369</td>\n",
              "      <td>-0.0576</td>\n",
              "      <td>0.0404</td>\n",
              "      <td>-0.0877</td>\n",
              "      <td>-0.2168</td>\n",
              "      <td>-0.1385</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fca70470-a144-4bb7-8322-5205f19b67b1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fca70470-a144-4bb7-8322-5205f19b67b1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fca70470-a144-4bb7-8322-5205f19b67b1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-714cd201-c6b3-4176-bd6e-90ced1c2afdd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-714cd201-c6b3-4176-bd6e-90ced1c2afdd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-714cd201-c6b3-4176-bd6e-90ced1c2afdd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "img_features",
              "summary": "{\n  \"name\": \"img_features\",\n  \"rows\": 700,\n  \"fields\": [\n    {\n      \"column\": \"image_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 700,\n        \"samples\": [\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid04_2024-09-17_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid02_2024-10-06_ch5_sleeptime.png\",\n          \"drive/MyDrive/data/ch2025_data_items/ch5_sleeptime/userid09_2024-07-25_ch5_sleeptime.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.16333775222301483,\n          -0.035041190683841705,\n          -0.05672355741262436\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.08307548612356186,\n          -0.04341660439968109,\n          -0.04869595170021057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.09835391491651535,\n          -0.061300117522478104,\n          -0.054764021188020706\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          0.3141210079193115,\n          0.1597968488931656,\n          0.24819667637348175\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.03382708132266998,\n          -0.008011463098227978,\n          -0.05711574852466583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.01653387024998665,\n          -0.1045929342508316,\n          -0.018832147121429443\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 478,\n        \"samples\": [\n          -0.08326223492622375,\n          0.05508451163768768,\n          0.029485490173101425\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 7,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 478,\n        \"samples\": [\n          -0.03813104331493378,\n          -0.16025468707084656,\n          -0.16127584874629974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 8,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.32163625955581665,\n          -0.2786847949028015,\n          -0.30157470703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 9,\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 479,\n        \"samples\": [\n          -0.10823676735162735,\n          -0.0555943101644516,\n          -0.11898816376924515\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_parquet(\"/content/drive/MyDrive/data/train_0512.parquet\")\n",
        "test = pd.read_parquet(\"/content/drive/MyDrive/data/test_0512.parquet\")\n",
        "\n",
        "# drop_features = ['afterwork_max_label','sleeptime_max_label','worktime_max_label']\n",
        "drop_features = ['top_bssid'] # ,'week_type','week_type_lag1'\n",
        "drop_features = [i for i in drop_features if i in train.columns.tolist()]\n",
        "print('# drop_features:',drop_features)\n",
        "train = train.drop(columns=drop_features)\n",
        "test = test.drop(columns=drop_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98TGeiQnb3ku",
        "outputId": "3c222465-45ab-4ee5-8661-2465c408822d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# drop_features: ['top_bssid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 읽기\n",
        "img_features = pd.read_csv('/content/drive/MyDrive/data/ch2025_data_items/img_features_ch5_sleeptime.csv')\n",
        "img_features.columns = ['image_path']+['img'+i for i in img_features.columns if i not in ['image_path']]\n",
        "\n",
        "# 정규표현식으로 추출\n",
        "img_features['subject_id'] = img_features['image_path'].str.extract(r'user(id\\d+)_')[0]\n",
        "img_features['lifelog_date'] = img_features['image_path'].str.extract(r'_(\\d{4}-\\d{2}-\\d{2})_')[0]\n",
        "\n",
        "# check\n",
        "img_features = img_features.drop(columns=['image_path'])\n",
        "print(len(img_features))\n",
        "display(img_features.head(1))\n",
        "\n",
        "# add img features\n",
        "train['lifelog_date'] = train['lifelog_date'].astype(str)\n",
        "test['lifelog_date'] = test['lifelog_date'].astype(str)\n",
        "train = train.merge(img_features,on=['subject_id','lifelog_date'],how='left')\n",
        "test = test.merge(img_features,on=['subject_id','lifelog_date'],how='left')"
      ],
      "metadata": {
        "id": "FCrgC4pSJEpj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "7d91e82e-575a-4b19-e9e6-e8744d8801d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    img0   img1    img2   img3   img4    img5    img6    img7    img8    img9  \\\n",
              "0 0.0036 0.0476 -0.1327 0.1057 0.1635 -0.0514 -0.0260 -0.0408 -0.2636 -0.0121   \n",
              "\n",
              "  subject_id lifelog_date  \n",
              "0       id01   2024-06-26  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img0</th>\n",
              "      <th>img1</th>\n",
              "      <th>img2</th>\n",
              "      <th>img3</th>\n",
              "      <th>img4</th>\n",
              "      <th>img5</th>\n",
              "      <th>img6</th>\n",
              "      <th>img7</th>\n",
              "      <th>img8</th>\n",
              "      <th>img9</th>\n",
              "      <th>subject_id</th>\n",
              "      <th>lifelog_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0476</td>\n",
              "      <td>-0.1327</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>-0.0514</td>\n",
              "      <td>-0.0260</td>\n",
              "      <td>-0.0408</td>\n",
              "      <td>-0.2636</td>\n",
              "      <td>-0.0121</td>\n",
              "      <td>id01</td>\n",
              "      <td>2024-06-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d8ca4a8b-0dd9-427a-8e2b-0b788cfdd4f4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test = test\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"img0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0036178334,\n        \"max\": 0.0036178334,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0036178334\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.04761707,\n        \"max\": 0.04761707,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.04761707\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.13266137,\n        \"max\": -0.13266137,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.13266137\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1056918,\n        \"max\": 0.1056918,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1056918\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.1634916,\n        \"max\": 0.1634916,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.1634916\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.051436387,\n        \"max\": -0.051436387,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.051436387\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.025990054,\n        \"max\": -0.025990054,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.025990054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.040842075,\n        \"max\": -0.040842075,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.040842075\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.26363862,\n        \"max\": -0.26363862,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.26363862\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"img9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": -0.01210399,\n        \"max\": -0.01210399,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -0.01210399\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subject_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"id01\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lifelog_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2024-06-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 요일 컬럼 추가 (예: 월요일, 화요일, ...)\n",
        "train['lifelog_date'] = pd.to_datetime(train['lifelog_date'])\n",
        "test['lifelog_date'] = pd.to_datetime(test['lifelog_date'])\n",
        "\n",
        "# 요일\n",
        "weekday_map = {\n",
        "    0: '월요일', 1: '화요일', 2: '수요일', 3: '목요일',\n",
        "    4: '금요일', 5: '토요일', 6: '일요일'\n",
        "}\n",
        "train['weekday'] = train['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "test['weekday'] = test['lifelog_date'].dt.dayofweek.map(weekday_map)\n",
        "\n",
        "# 월\n",
        "train['month'] = train['lifelog_date'].dt.month\n",
        "test['month'] = test['lifelog_date'].dt.month\n",
        "\n",
        "# weekend\n",
        "train['weekend'] = np.where(train['weekday'].isin(['토요일','일요일']),1,0)\n",
        "test['weekend'] = np.where(test['weekday'].isin(['토요일','일요일']),1,0)\n",
        "\n",
        "# 공휴일\n",
        "공휴일 = [\n",
        "     '2024-08-15'\n",
        "    ,'2024-09-16'\n",
        "    ,'2024-09-17'\n",
        "    ,'2024-09-18'\n",
        "    ,'2024-10-03'\n",
        "    ,'2024-10-09'\n",
        "]\n",
        "train['공휴일'] = np.where(train['lifelog_date'].isin(공휴일),1,0)\n",
        "test['공휴일'] = np.where(test['lifelog_date'].isin(공휴일),1,0)\n",
        "\n",
        "# 주말 + 공휴일 묶어주기\n",
        "# train['weekend'] = np.where( ((train['weekend']==0) & (train['공휴일']==1)), 1, train['weekend'])\n",
        "# test['weekend'] = np.where( ((test['weekend']==0) & (test['공휴일']==1)), 1, test['weekend'])"
      ],
      "metadata": {
        "id": "RLT2TiKsJExf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 추정휴가\n",
        "def rule_based_sum(x):\n",
        "    rules = (\n",
        "        # (x['sleep_duration_min'] > (x['avg_sleep_duration'] + 30))\n",
        "          (x['sleep_duration_min'] > (x['avg_sleep_duration']))\n",
        "        & (x['week_type'] == 'weekday')\n",
        "        & (x['month'].isin([7,8]))\n",
        "    )\n",
        "    return rules\n",
        "\n",
        "train['vacation'] = train.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "test['vacation'] = test.groupby('subject_id').apply(rule_based_sum).reset_index(level=0, drop=True).astype(int)\n",
        "\n",
        "# check\n",
        "test.groupby(['subject_id'])['vacation'].sum()"
      ],
      "metadata": {
        "id": "H401mU5CJEzy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "outputId": "d1220550-e99c-4e77-c139-48915de7c0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "subject_id\n",
              "id01     5\n",
              "id02     1\n",
              "id03     5\n",
              "id04     0\n",
              "id05     0\n",
              "id06    11\n",
              "id07    14\n",
              "id08     3\n",
              "id09     7\n",
              "id10     0\n",
              "Name: vacation, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vacation</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>subject_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id01</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id02</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id03</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id04</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id05</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id06</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id07</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id08</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id09</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자형 컬럼만 선택해서 결측값 -1로 채우기\n",
        "train[train.select_dtypes(include='number').columns] = train.select_dtypes(include='number').fillna(-1)\n",
        "test[test.select_dtypes(include='number').columns] = test.select_dtypes(include='number').fillna(-1)"
      ],
      "metadata": {
        "id": "EckHVeXuJE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_oof_predictions(X, y, params, n_splits=5, is_multiclass=False, num_class=None, early_stop=False):\n",
        "\n",
        "    oof_preds = np.zeros(len(X))  # ✅ 1차원으로 변경\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    for train_idx, valid_idx in skf.split(X, y):\n",
        "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
        "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
        "\n",
        "        if is_multiclass:\n",
        "            model = LGBMClassifier(**params, objective='multiclass', num_class=num_class)\n",
        "        else:\n",
        "            model = LGBMClassifier(**params)\n",
        "\n",
        "        if early_stop:\n",
        "            model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100, verbose=False)]\n",
        "            )\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "        preds = model.predict(X_valid)  # ✅ returns 1D array\n",
        "        oof_preds[valid_idx] = preds  # ✅ 1D -> 1D 저장\n",
        "\n",
        "    return oof_preds"
      ],
      "metadata": {
        "id": "Toukt4KNJE58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_basemodel(train, test, valid_ids, common_params, n_splits, random_state=42, early_stop=False):\n",
        "\n",
        "    train_df = train.copy()\n",
        "    test_df = test.copy()\n",
        "\n",
        "    submission_final = test_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "    submission_final['lifelog_date'] = pd.to_datetime(submission_final['lifelog_date']).dt.date\n",
        "\n",
        "    # 타겟\n",
        "    targets_binary = ['Q1', 'Q2', 'Q3', 'S2', 'S3']\n",
        "    targets_binary_name = ['기상직후수면질','취침전신체적피로','취침전스트레스','수면효율','수면잠들기시간']\n",
        "    target_multiclass = 'S1'\n",
        "    all_targets = targets_binary + [target_multiclass]\n",
        "\n",
        "    # 노이즈 수준 설정\n",
        "    def add_noise(series, noise_level, seed=3):\n",
        "        rng = np.random.default_rng(seed)\n",
        "        return series * (1 + noise_level * rng.standard_normal(len(series)))\n",
        "\n",
        "    noise_level = 0.015  # 필요에 따라 조정\n",
        "\n",
        "    # 타겟인코딩\n",
        "    # m = 0: 스무딩 없이 범주별 평균만 사용합니다. 관측 수가 많은 범주에는 적합하지만, 적은 경우 과적합 위험이 있습니다.\n",
        "    # m = 1~10: 일반적인 기본값으로, 대부분의 상황에서 안정적인 성능을 보입니다.\n",
        "    # m = 50~300: 관측 수가 매우 적은 범주가 많거나 데이터가 희소한 경우에 유용합니다.\n",
        "    for tgt in all_targets:\n",
        "\n",
        "      encoder_feats = ['subject_id','month','weekend'] # 'weekday', 'subject_id','month','weekend'\n",
        "\n",
        "      #### 타겟인코딩1\n",
        "\n",
        "      subject_mean = train_df.groupby(encoder_feats)[tgt].mean().rename(f'{tgt}_te')\n",
        "      train_df = train_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      test_df = test_df.merge(subject_mean, on=encoder_feats, how='left')\n",
        "      global_mean = train_df[tgt].mean()\n",
        "      test_df[f'{tgt}_te'] = test_df[f'{tgt}_te'].fillna(global_mean)\n",
        "\n",
        "      # 노이즈 추가\n",
        "      train_df[f'{tgt}_te'] = add_noise(train_df[f'{tgt}_te'], noise_level)\n",
        "      test_df[f'{tgt}_te'] = add_noise(test_df[f'{tgt}_te'], noise_level)\n",
        "\n",
        "      #### 타겟인코딩2\n",
        "\n",
        "      # 새로운 범주형 열 생성\n",
        "      train_df['TMP'] = train_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "      test_df['TMP'] = test_df[encoder_feats].applymap(str).apply(lambda x: ''.join(x) ,axis=1)\n",
        "\n",
        "      # 인코더\n",
        "      encoder = TargetEncoder(cols=['TMP'], smoothing=300) # 40\n",
        "      encoder.fit(train_df[['TMP']], train_df[tgt])\n",
        "\n",
        "      # 인코딩 결과를 새로운 열에 저장\n",
        "      train_df[f'{tgt}_te2'] = encoder.transform(train_df[['TMP']])\n",
        "      test_df[f'{tgt}_te2'] = encoder.transform(test_df[['TMP']])\n",
        "\n",
        "      # 노이즈 추가\n",
        "      train_df[f'{tgt}_te2'] = add_noise(train_df[f'{tgt}_te2'], noise_level)\n",
        "      test_df[f'{tgt}_te2'] = add_noise(test_df[f'{tgt}_te2'], noise_level)\n",
        "\n",
        "      # 불필요한 변수 제거\n",
        "      train_df = train_df.drop(columns=['TMP'])\n",
        "      test_df = test_df.drop(columns=['TMP'])\n",
        "\n",
        "\n",
        "    # 인코딩\n",
        "    PK = ['sleep_date', 'lifelog_date', 'subject_id']\n",
        "    encoder = LabelEncoder()\n",
        "    categorical_features = [i for i in train_df.select_dtypes(include=['object', 'category']).columns if i not in PK+['pk']]\n",
        "    for col in categorical_features:\n",
        "        print(col)\n",
        "        train_df[col] = encoder.fit_transform(train_df[col])\n",
        "        test_df[col] = encoder.fit_transform(test_df[col])\n",
        "\n",
        "\n",
        "    # X\n",
        "    X = train_df.drop(columns=PK + all_targets)\n",
        "    test_X = test_df.drop(columns=PK + all_targets)\n",
        "    print(f'# X shape: {X.shape}')\n",
        "    print(f'# test_X shape: {test_X.shape}')\n",
        "\n",
        "    print('\\n STEP1: 실험 결과 확인')\n",
        "    print(\"=============== Validation Results ==============\")\n",
        "    total_avg_f1s = []\n",
        "    best_iteration_temp = {k: [] for k in all_targets}\n",
        "\n",
        "    val_f1 = []\n",
        "    for col in targets_binary:\n",
        "\n",
        "        # binary\n",
        "        y = train_df[col]\n",
        "\n",
        "        valid_ids['pk'] = valid_ids['subject_id']+valid_ids['sleep_date']\n",
        "        train_df['pk'] = train_df['subject_id']+train_df['sleep_date']\n",
        "\n",
        "        X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "        y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "        y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "        # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "        best_param = best_param_dict[col].copy()\n",
        "        best_param['random_state'] = random_state\n",
        "        model = LGBMClassifier(**best_param)\n",
        "\n",
        "        if early_stop:\n",
        "            model.fit(\n",
        "                X_train, y_train,\n",
        "                eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "                callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n",
        "            )\n",
        "            best_iteration_temp[col].append(model.best_iteration_)\n",
        "        else:\n",
        "            model.fit(X_train, y_train)\n",
        "            best_iteration_temp[col].append(1000)\n",
        "\n",
        "        pred_valid = model.predict(X_valid)\n",
        "        f1 = f1_score(y_valid, pred_valid, average='macro') ### 수정\n",
        "        val_f1.append(f1)\n",
        "\n",
        "    # multi\n",
        "    y = train_df[target_multiclass]\n",
        "\n",
        "    X_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    X_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),X.columns.tolist()].reset_index(drop=True).copy()\n",
        "    y_valid = train_df.loc[train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "    y_train = train_df.loc[~train_df['pk'].isin(valid_ids['pk']),y.name].reset_index(drop=True).copy()\n",
        "    # X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
        "\n",
        "    best_param = best_param_dict['S1'].copy()\n",
        "    best_param['random_state'] = random_state\n",
        "    model = LGBMClassifier(**best_param, objective='multiclass', num_class=3)\n",
        "\n",
        "    if early_stop:\n",
        "        model.fit(\n",
        "            X_train, y_train,\n",
        "            eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
        "            callbacks=[early_stopping(stopping_rounds=100,verbose=False)]\n",
        "        )\n",
        "        best_iteration_temp[target_multiclass].append(model.best_iteration_)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        best_iteration_temp[target_multiclass].append(1000)\n",
        "\n",
        "    pred_valid = model.predict(X_valid)\n",
        "    f1 = f1_score(y_valid, pred_valid, average='macro')\n",
        "    val_f1.append(f1)\n",
        "\n",
        "\n",
        "    avg_f1 = np.mean(val_f1)\n",
        "    total_avg_f1s.append(avg_f1)\n",
        "    detail = \" \".join([f\"{name}({tname}):{score:.4f}\" for name, tname, score in zip(targets_binary + [target_multiclass], targets_binary_name + ['S1'], val_f1)])\n",
        "    print(f\" 평균 F1: {avg_f1:.4f} / [상세] {detail}\")\n",
        "\n",
        "    best_iteration_dict = {k: max(best_iteration_temp[k]) for k in all_targets}\n",
        "\n",
        "    if early_stop==True:\n",
        "      print(\"\\n[best_iteration_dict]\")\n",
        "      for k, v in best_iteration_dict.items():\n",
        "          print(f\"{k}: {v}\")\n",
        "\n",
        "\n",
        "    print(f\"# 전체 평균 F1: {np.mean(total_avg_f1s):.4f}\")\n",
        "    print(\"================================================\")\n",
        "\n",
        "    # modoling with 100% train & no valid\n",
        "    print('\\n STEP2: 전체 데이터로 모델 재학습')\n",
        "    print(\"====== modoling with 100% train & no valid =====\")\n",
        "\n",
        "    # binary\n",
        "    binary_preds = {}\n",
        "    for col in targets_binary:\n",
        "        binary_params = best_param_dict[col].copy()\n",
        "        binary_params['random_state'] = random_state\n",
        "        y = train_df[col]\n",
        "\n",
        "        if early_stop:\n",
        "          binary_params['n_estimators']=best_iteration_dict[col]\n",
        "          model = LGBMClassifier(**binary_params)\n",
        "          model.fit(X, y)\n",
        "        else:\n",
        "          model = LGBMClassifier(**binary_params)\n",
        "          model.fit(X, y)\n",
        "\n",
        "        binary_preds[col] = model.predict(test_X)\n",
        "        fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
        "        top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "        feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "        print(f\"[{col}] {feat_str}\")\n",
        "\n",
        "    # multiclass\n",
        "    y = train_df['S1']\n",
        "    binary_params = best_param_dict['S1'].copy()\n",
        "    binary_params['random_state'] = random_state\n",
        "\n",
        "    if early_stop:\n",
        "      binary_params['n_estimators']=best_iteration_dict['S1']\n",
        "      model = LGBMClassifier(**binary_params)\n",
        "      model.fit(X, y)\n",
        "    else:\n",
        "      model = LGBMClassifier(**binary_params)\n",
        "      model.fit(X, y)\n",
        "\n",
        "    multiclass_pred = model.predict(test_X)\n",
        "    fi_df = pd.DataFrame({'feature': X.columns, 'importance': model.feature_importances_})\n",
        "    top10 = fi_df.sort_values(by='importance', ascending=False).head(10)\n",
        "    feat_str = \", \".join([f\"{row['feature']}({int(row['importance'])})\" for _, row in top10.iterrows()])\n",
        "    print(f\"[S1] {feat_str}\")\n",
        "\n",
        "    # 예측 저장\n",
        "    submission_final['S1'] = multiclass_pred\n",
        "    for col in targets_binary:\n",
        "      submission_final[col] = binary_preds[col]\n",
        "    submission_final = submission_final[['subject_id', 'sleep_date', 'lifelog_date', 'Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']]\n",
        "    fname = f\"/content/drive/MyDrive/data/submission_{np.mean(total_avg_f1s)}.csv\"\n",
        "    submission_final.to_csv(fname, index=False)\n",
        "    print(f\"# {fname} 저장 완료\")\n",
        "    print(f\"# submission shape:{submission_final.shape}\")\n",
        "    print(\"================================================\")\n",
        "\n",
        "    # 모델별 예측결과 비율 비교\n",
        "    a11 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a13 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a12 = train_df[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    a21 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].sum()\n",
        "    a23 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].apply(len)\n",
        "    a22 = submission_final[['Q1', 'Q2', 'Q3', 'S1', 'S2', 'S3']].mean()\n",
        "    result = pd.concat([a11, a13, a12, a21, a23, a22], axis=1)\n",
        "    result.columns = ['학습sum','학습len','학습mean','테스트sum','테스트len','테스트mean']\n",
        "    print('\\n STEP3: 예측결과 비교표')\n",
        "    display(result)\n",
        "\n",
        "    # === STEP4: OOF 예측 생성 (train set에 대해) ===\n",
        "\n",
        "    # n_splits = 10\n",
        "    mask = train['month'] != 6\n",
        "    print(f'# k-fold: {n_splits}')\n",
        "    print(f'# train: {len(y[mask])}')\n",
        "\n",
        "    oof_f1 = []\n",
        "    print('\\n STEP4: OOF 예측 생성')\n",
        "    oof_result = train_df[['subject_id', 'sleep_date', 'lifelog_date']].copy()\n",
        "    for col in targets_binary:\n",
        "        params = best_param_dict[col].copy()\n",
        "        params['random_state'] = random_state\n",
        "        y = train_df[col]\n",
        "        oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=False, early_stop=early_stop)\n",
        "        oof_result[col] = oof_preds\n",
        "        f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n",
        "        oof_f1.append(f1)\n",
        "        print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n",
        "\n",
        "    # multiclass\n",
        "    col = 'S1'\n",
        "    params = best_param_dict[col].copy()\n",
        "    params['random_state'] = random_state\n",
        "    y = train_df[col]\n",
        "    oof_preds = get_oof_predictions(X, y, params, n_splits=n_splits, is_multiclass=True, num_class=3, early_stop=early_stop)\n",
        "    oof_result[col] = oof_preds\n",
        "    f1 = f1_score(y[mask], oof_preds[mask], average='macro')\n",
        "    oof_f1.append(f1)\n",
        "    print(f\"[OOF - {col}] F1 score: {f1:.4f}\")\n",
        "    print(f\"[OOF] F1 score: {np.mean(oof_f1):.4f}\")\n",
        "\n",
        "    # oof_result 저장\n",
        "    fname = f\"/content/drive/MyDrive/data/oof_result_{np.mean(total_avg_f1s)}.csv\"\n",
        "    oof_result.to_csv(fname, index=False)\n",
        "    print(f\"# {fname} 저장 완료\")\n",
        "\n",
        "    return submission_final, oof_result"
      ],
      "metadata": {
        "id": "rdo8wqFTJFA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### run"
      ],
      "metadata": {
        "id": "pzYyd5Qqch-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "week_type\n",
        "week_type_lag1\n",
        "weekday\n",
        "# X shape: (450, 168)\n",
        "# test_X shape: (250, 168)\n",
        "\n",
        " STEP1: 실험 결과 확인\n",
        "=============== Validation Results ==============\n",
        " 평균 F1: 0.6322 / [상세] Q1(기상직후수면질):0.7278 Q2(취침전신체적피로):0.7122 Q3(취침전스트레스):0.6830 S2(수면효율):0.5726 S3(수면잠들기시간):0.6686 S1(S1):0.4293\n",
        "# 전체 평균 F1: 0.6322\n",
        "================================================\n",
        "\n",
        " STEP2: 전체 데이터로 모델 재학습\n",
        "====== modoling with 100% train & no valid =====\n",
        "[Q1] Q1_te2(557), light_night_mean(469), wake_time_ratio(405), wake_time_diff_lag1(340), 통화_time(326), Q1_te(325), sleep_duration_diff(242), activehour_unique_label_count(200), ble_class_others_ratio_worktime(175), wake_time(155)\n",
        "[Q2] Q2_te2(2791), total_screen_time(351), wake_up_early_minutes(331), speed_le5_max(307), rolling_wake_time_3d(288), rolling_sleep_time_3d(233), sleep_time_diff(224), Q2_te(198), wlight_evening_mean(182), hr_evening_std(176)\n",
        "[Q3] Q3_te2(2199), light_max(366), sleep_duration_diff_lag1(274), sleep_duration_min(227), sleep_duration_ratio(211), screen_time_vs_avg_pct(187), lat_change(181), all_VEHICLE_minutes(179), sleep_time(177), 통화_time(167)\n",
        "[S2] S2_te(3725), S2_te2(2773), wake_time_diff_lag1(340), light_max(292), light_night_mean(245), S1_te2(189), ble_class_unknwn_ratio_sleeptime(179), 통화_time(175), sleep_duration_lag1(171), sleep_duration_min(170)\n",
        "[S3] S3_te(639), light_night_mean(443), S3_te2(336), ble_rssi_mean_afterwork(256), hr_evening_min(242), activehour_unique_label_count(242), ble_class_unknwn_ratio_sleeptime(235), wlight_evening_mean(231), sleep_time_diff_lag1(230), vehicle_minutes(180)\n",
        "[S1] S1_te2(3990), S1_te(661), sleep_duration_ratio(646), wake_time_ratio(554), sleep_duration_diff(452), sleep_duration_min(429), vehicle_minutes(427), rolling_wake_time_3d(410), speed_le5_max(408), hour_span_minutes(379)\n",
        "# /content/drive/MyDrive/data/submission_0.6322252622334963.csv 저장 완료\n",
        "# submission shape:(250, 9)\n",
        "================================================\n",
        "\n",
        " STEP3: 예측결과 비교표\n",
        "학습sum\t학습len\t학습mean\t테스트sum\t테스트len\t테스트mean\n",
        "Q1\t223\t450\t0.4956\t131\t250\t0.5240\n",
        "Q2\t253\t450\t0.5622\t150\t250\t0.6000\n",
        "Q3\t270\t450\t0.6000\t173\t250\t0.6920\n",
        "S1\t390\t450\t0.8667\t202\t250\t0.8080\n",
        "S2\t293\t450\t0.6511\t170\t250\t0.6800\n",
        "S3\t298\t450\t0.6622\t171\t250\t0.6840\n",
        "\n",
        "\n",
        "# k-fold: 5\n",
        "# train: 392\n",
        "\n",
        " STEP4: OOF 예측 생성\n",
        "[OOF - Q1] F1 score: 0.6976\n",
        "[OOF - Q2] F1 score: 0.7041\n",
        "[OOF - Q3] F1 score: 0.6605\n",
        "[OOF - S2] F1 score: 0.6610\n",
        "[OOF - S3] F1 score: 0.7106\n",
        "[OOF - S1] F1 score: 0.5233\n",
        "[OOF] F1 score: 0.6595\n",
        "# /content/drive/MyDrive/data/oof_result_0.6322252622334963.csv 저장 완료\n",
        "\"\"\"\n",
        "\n",
        "# 공통 하이퍼파라미터\n",
        "common_params = {\n",
        "  'n_estimators': 5000,\n",
        "  \"learning_rate\": 0.01,\n",
        "  # \"shrinkage_rate\": 0.12,\n",
        "  # 'min_data_in_leaf':2,\n",
        "  # 'bagging_fraction':0.9,\n",
        "  # 'feature_fraction':0.6,\n",
        "  'lambda_l1': 5,\n",
        "  'lambda_l2': 1,\n",
        "  # 'max_depth': 4,\n",
        "  'n_jobs': -1,\n",
        "  'verbosity': -1\n",
        "}\n",
        "\n",
        "# 모델별 세부 하이퍼파라미터\n",
        "best_param_dict = {'Q1': {'learning_rate': 0.1473150575266255,\n",
        "  'shrinkage_rate': 0.08585454450680065,\n",
        "  'min_data_in_leaf': 13,\n",
        "  'bagging_fraction': 0.5900885111562433,\n",
        "  'feature_fraction': 0.7398526832500182,\n",
        "  'lambda_l1': 0.7309384079752819,\n",
        "  'lambda_l2': 0.010419978985191203,\n",
        "  'max_depth': 2},\n",
        " 'Q2': {'learning_rate': 0.1433742819325529,\n",
        "  'shrinkage_rate': 0.4777741359643458,\n",
        "  'min_data_in_leaf': 11,\n",
        "  'bagging_fraction': 0.8942012129234453,\n",
        "  'feature_fraction': 0.3442323511952453,\n",
        "  'lambda_l1': 0.11108296857244106,\n",
        "  'lambda_l2': 0.5000682520529595,\n",
        "  'max_depth': 11},\n",
        " 'Q3': {'learning_rate': 0.005440413154494791,\n",
        "  'shrinkage_rate': 0.4869550654391126,\n",
        "  'min_data_in_leaf': 5,\n",
        "  'bagging_fraction': 0.992720410336095,\n",
        "  'feature_fraction': 0.10854085794750301,\n",
        "  'lambda_l1': 8.765258863766789,\n",
        "  'lambda_l2': 0.010911793484805324,\n",
        "  'max_depth': -1},\n",
        " 'S1': {'learning_rate': 0.19808502263166988,\n",
        "  'shrinkage_rate': 0.3292477285579064,\n",
        "  'min_data_in_leaf': 9,\n",
        "  'bagging_fraction': 0.5929013243246726,\n",
        "  'feature_fraction': 0.8481981135327139,\n",
        "  'lambda_l1': 0.010377995886618164,\n",
        "  'lambda_l2': 0.6226891522266145,\n",
        "  'max_depth': 10},\n",
        " 'S2': {'learning_rate': 0.27099064035077214,\n",
        "  'shrinkage_rate': 0.028901883938906636,\n",
        "  'min_data_in_leaf': 9,\n",
        "  'bagging_fraction': 0.8134249396247819,\n",
        "  'feature_fraction': 0.2321570003912355,\n",
        "  'lambda_l1': 8.780092357464005,\n",
        "  'lambda_l2': 9.605716023562762,\n",
        "  'max_depth': 7},\n",
        " 'S3': {'learning_rate': 0.14542046442644,\n",
        "  'shrinkage_rate': 0.3047247759570036,\n",
        "  'min_data_in_leaf': 10,\n",
        "  'bagging_fraction': 0.8493532899163512,\n",
        "  'feature_fraction': 0.7940889257506005,\n",
        "  'lambda_l1': 9.299803284110112,\n",
        "  'lambda_l2': 0.12938944891518922,\n",
        "  'max_depth': 6}\n",
        "}\n",
        "\n",
        "# 공통 하이퍼파라미터 대체 (이상한 모델의 경우)\n",
        "best_param_dict['Q3'] = common_params\n",
        "best_param_dict['S1'] = common_params\n",
        "best_param_dict['S2'] = common_params\n",
        "best_param_dict['S3'] = common_params\n",
        "best_param_dict['Q1'] = common_params\n",
        "best_param_dict['Q2'] = common_params\n",
        "\n",
        "# 전체 평균 F1: 0.6322\n",
        "# [OOF] F1 score: 0.6595\n",
        "# [OOF - Q1] F1 score: 0.6976\n",
        "# [OOF - Q2] F1 score: 0.7041\n",
        "# [OOF - Q3] F1 score: 0.6605\n",
        "# [OOF - S2] F1 score: 0.6610\n",
        "# [OOF - S3] F1 score: 0.7106\n",
        "# [OOF - S1] F1 score: 0.5233\n",
        "submission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)"
      ],
      "metadata": {
        "id": "x4rBoUTMJFDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "outputId": "3ee007a3-1d5a-4a45-ebe3-e0abf52a350d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "week_type\n",
            "week_type_lag1\n",
            "weekday\n",
            "# X shape: (450, 190)\n",
            "# test_X shape: (250, 190)\n",
            "\n",
            " STEP1: 실험 결과 확인\n",
            "=============== Validation Results ==============\n",
            " 평균 F1: 0.6448 / [상세] Q1(기상직후수면질):0.7314 Q2(취침전신체적피로):0.7518 Q3(취침전스트레스):0.6546 S2(수면효율):0.6179 S3(수면잠들기시간):0.6485 S1(S1):0.4642\n",
            "# 전체 평균 F1: 0.6448\n",
            "================================================\n",
            "\n",
            " STEP2: 전체 데이터로 모델 재학습\n",
            "====== modoling with 100% train & no valid =====\n",
            "[Q1] Q1_te2(539), light_night_mean(373), wake_time_ratio(360), wake_time_diff_lag1(290), Q1_te(262), sleep_duration_diff(257), wake_time(192), beforebed_전화_time(179), beforebed_통화_time(178), ble_rssi_max_afterwork(174)\n",
            "[Q2] Q2_te2(1510), rolling_wake_time_3d(250), wake_up_early_minutes(249), wlight_evening_mean(230), Q2_te(229), activehour_total_screen_time(193), rolling_sleep_time_3d(179), activehour_screen_time_vs_avg_pct(170), avg_rssi(167), activehour_전화_time(161)\n",
            "[Q3] Q3_te2(641), light_max(403), sleep_duration_min(241), activehour_통화_time(236), sleep_duration_diff_lag1(210), sleep_duration_lag1(164), ble_class_others_ratio_afterwork(154), sleep_time(153), vehicle_minutes(148), hr_morning_max(148)\n",
            "[S2] S2_te(2072), S2_te2(435), img0(329), beforebed_total_screen_time(238), wake_time_diff_lag1(229), ble_class_unknwn_ratio_sleeptime(195), activehour_screen_time_vs_avg_pct(158), light_night_mean(154), beforebed_OneUI홈_time(147), sleep_duration_ratio(142)\n",
            "[S3] S3_te(528), S3_te2(333), light_night_mean(331), ble_rssi_mean_afterwork(293), lon_change(252), sleep_time_diff_lag1(206), ble_class_unknwn_ratio_sleeptime(200), img7(193), hr_evening_min(175), activehour_unique_label_count(173)\n",
            "[S1] S1_te(767), S1_te2(717), img4(567), sleep_duration_ratio(562), beforebed_screen_time_vs_avg_pct(562), wake_time_ratio(524), sleep_duration_min(468), beforebed_total_screen_time(466), sleep_duration_diff(442), hour_span_minutes(366)\n",
            "# /content/drive/MyDrive/data/submission_0.6447528574485211.csv 저장 완료\n",
            "# submission shape:(250, 9)\n",
            "================================================\n",
            "\n",
            " STEP3: 예측결과 비교표\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    학습sum  학습len  학습mean  테스트sum  테스트len  테스트mean\n",
              "Q1    223    450  0.4956     127     250   0.5080\n",
              "Q2    253    450  0.5622     151     250   0.6040\n",
              "Q3    270    450  0.6000     174     250   0.6960\n",
              "S1    390    450  0.8667     199     250   0.7960\n",
              "S2    293    450  0.6511     166     250   0.6640\n",
              "S3    298    450  0.6622     167     250   0.6680"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-867d516f-4ba4-4529-bbb3-76930c1eca8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>학습sum</th>\n",
              "      <th>학습len</th>\n",
              "      <th>학습mean</th>\n",
              "      <th>테스트sum</th>\n",
              "      <th>테스트len</th>\n",
              "      <th>테스트mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q1</th>\n",
              "      <td>223</td>\n",
              "      <td>450</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>127</td>\n",
              "      <td>250</td>\n",
              "      <td>0.5080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q2</th>\n",
              "      <td>253</td>\n",
              "      <td>450</td>\n",
              "      <td>0.5622</td>\n",
              "      <td>151</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3</th>\n",
              "      <td>270</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>174</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S1</th>\n",
              "      <td>390</td>\n",
              "      <td>450</td>\n",
              "      <td>0.8667</td>\n",
              "      <td>199</td>\n",
              "      <td>250</td>\n",
              "      <td>0.7960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S2</th>\n",
              "      <td>293</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6511</td>\n",
              "      <td>166</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>S3</th>\n",
              "      <td>298</td>\n",
              "      <td>450</td>\n",
              "      <td>0.6622</td>\n",
              "      <td>167</td>\n",
              "      <td>250</td>\n",
              "      <td>0.6680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-867d516f-4ba4-4529-bbb3-76930c1eca8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-867d516f-4ba4-4529-bbb3-76930c1eca8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-867d516f-4ba4-4529-bbb3-76930c1eca8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0d970f34-34a2-451d-989c-4c6e621cc466\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0d970f34-34a2-451d-989c-4c6e621cc466')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0d970f34-34a2-451d-989c-4c6e621cc466 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"submission_final, oof_result = run_basemodel(train, test, valid_ids, best_param_dict, n_splits=5, random_state=41, early_stop=False)\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"\\ud559\\uc2b5sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 57,\n        \"min\": 223,\n        \"max\": 390,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          223,\n          253,\n          298\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud559\\uc2b5len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 450,\n        \"max\": 450,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          450\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud559\\uc2b5mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1268919374350011,\n        \"min\": 0.4955555555555556,\n        \"max\": 0.8666666666666667,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4955555555555556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8sum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 23,\n        \"min\": 127,\n        \"max\": 199,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8len\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 250,\n        \"max\": 250,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud14c\\uc2a4\\ud2b8mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09593331016909612,\n        \"min\": 0.508,\n        \"max\": 0.796,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.508\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# k-fold: 5\n",
            "# train: 392\n",
            "\n",
            " STEP4: OOF 예측 생성\n",
            "[OOF - Q1] F1 score: 0.6980\n",
            "[OOF - Q2] F1 score: 0.6873\n",
            "[OOF - Q3] F1 score: 0.6779\n",
            "[OOF - S2] F1 score: 0.6678\n",
            "[OOF - S3] F1 score: 0.7158\n",
            "[OOF - S1] F1 score: 0.5464\n",
            "[OOF] F1 score: 0.6655\n",
            "# /content/drive/MyDrive/data/oof_result_0.6447528574485211.csv 저장 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiMLigXg-ZuE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCYE6A1N6foi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDbhAsqTb16h+p+q3pVTiD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}